{"id": "2512.16926", "categories": ["cs.DC", "cs.OS", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.16926", "abs": "https://arxiv.org/abs/2512.16926", "authors": ["Oren Bell", "Harun Teper", "Mario G\u00fcnzel", "Chris Gill", "Jian-Jia Chen"], "title": "Fixed-Priority and EDF Schedules for ROS2 Graphs on Uniprocessor", "comment": "18 pages, 5 figure", "summary": "This paper addresses limitations of current scheduling methods in the Robot Operating System (ROS)2, focusing on scheduling tasks beyond simple chains and analyzing arbitrary Directed Acyclic Graphs (DAGs). While previous research has focused mostly on chain-based scheduling with ad-hoc response time analyses, we propose a novel approach using the events executor to implement fixed-job-level-priority schedulers for arbitrary ROS2 graphs on uniprocessor systems. We demonstrate that ROS 2 applications can be abstracted as forests of trees, enabling the mapping of ROS 2 applications to traditional real-time DAG task models. Our usage of the events executor requires a special implementation of the events queue and a communication middleware that supports LIFO-ordered message delivery, features not yet standard in ROS2. We show that our implementation generates the same schedules as a conventional fixed-priority DAG task scheduler, in spite of lacking access to the precedence information that usually is required. This further closes the gap between established real-time systems theory and ROS2 scheduling analyses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684ROS2\u8c03\u5ea6\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e8b\u4ef6\u6267\u884c\u5668\u5b9e\u73b0\u56fa\u5b9a\u4f5c\u4e1a\u7ea7\u4f18\u5148\u7ea7\u8c03\u5ea6\u5668\uff0c\u652f\u6301\u4efb\u610f\u6709\u5411\u65e0\u73af\u56fe\u4efb\u52a1\uff0c\u586b\u8865\u4e86\u5b9e\u65f6\u7cfb\u7edf\u7406\u8bba\u4e0eROS2\u8c03\u5ea6\u5206\u6790\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524dROS2\u8c03\u5ea6\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u7b80\u5355\u7684\u94fe\u5f0f\u4efb\u52a1\u8c03\u5ea6\uff0c\u7f3a\u4e4f\u5bf9\u4efb\u610f\u6709\u5411\u65e0\u73af\u56fe\u4efb\u52a1\u7684\u652f\u6301\u3002\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u5728\u94fe\u5f0f\u8c03\u5ea6\u548c\u4e34\u65f6\u54cd\u5e94\u65f6\u95f4\u5206\u6790\u4e0a\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u8c03\u5ea6\u65b9\u6848\u6765\u652f\u6301\u590d\u6742\u7684ROS2\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u4e8b\u4ef6\u6267\u884c\u5668\u5b9e\u73b0\u56fa\u5b9a\u4f5c\u4e1a\u7ea7\u4f18\u5148\u7ea7\u8c03\u5ea6\u5668\uff0c\u5c06ROS2\u5e94\u7528\u62bd\u8c61\u4e3a\u6811\u72b6\u68ee\u6797\u7ed3\u6784\uff0c\u6620\u5c04\u5230\u4f20\u7edf\u7684\u5b9e\u65f6DAG\u4efb\u52a1\u6a21\u578b\u3002\u9700\u8981\u7279\u6b8a\u5b9e\u73b0\u4e8b\u4ef6\u961f\u5217\u548c\u652f\u6301LIFO\u987a\u5e8f\u6d88\u606f\u4f20\u9012\u7684\u901a\u4fe1\u4e2d\u95f4\u4ef6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5355\u5904\u7406\u5668\u7cfb\u7edf\u4e0a\u4e3a\u4efb\u610fROS2\u56fe\u751f\u6210\u4e0e\u4f20\u7edf\u56fa\u5b9a\u4f18\u5148\u7ea7DAG\u4efb\u52a1\u8c03\u5ea6\u5668\u76f8\u540c\u7684\u8c03\u5ea6\u7ed3\u679c\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u901a\u5e38\u6240\u9700\u7684\u4f18\u5148\u7ea7\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u5b9e\u65f6\u7cfb\u7edf\u7406\u8bba\u4e0eROS2\u8c03\u5ea6\u5206\u6790\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3aROS2\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u590d\u6742\u7684DAG\u4efb\u52a1\u7ed3\u6784\uff0c\u4f46\u9700\u8981ROS2\u5e73\u53f0\u652f\u6301LIFO\u6d88\u606f\u4f20\u9012\u7b49\u65b0\u7279\u6027\u3002"}}
{"id": "2512.17023", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17023", "abs": "https://arxiv.org/abs/2512.17023", "authors": ["Patrick Diehl", "Noujoud Nader", "Deepti Gupta"], "title": "LLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation", "comment": null, "summary": "Parallel programming remains one of the most challenging aspects of High-Performance Computing (HPC), requiring deep knowledge of synchronization, communication, and memory models. While modern C++ standards and frameworks like OpenMP and MPI have simplified parallelism, mastering these paradigms is still complex. Recently, Large Language Models (LLMs) have shown promise in automating code generation, but their effectiveness in producing correct and efficient HPC code is not well understood. In this work, we systematically evaluate leading LLMs including ChatGPT 4 and 5, Claude, and LLaMA on the task of generating C++ implementations of the Mandelbrot set using shared-memory, directive-based, and distributed-memory paradigms. Each generated program is compiled and executed with GCC 11.5.0 to assess its correctness, robustness, and scalability. Results show that ChatGPT-4 and ChatGPT-5 achieve strong syntactic precision and scalable performance.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u9ad8\u6027\u80fd\u8ba1\u7b97\u4ee3\u7801\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9Mandelbrot\u96c6\u5728\u4e0d\u540c\u5e76\u884c\u8303\u5f0f\u4e0b\u7684C++\u5b9e\u73b0\u3002", "motivation": "\u5e76\u884c\u7f16\u7a0b\u4ecd\u7136\u662f\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u6700\u5177\u6311\u6218\u6027\u7684\u65b9\u9762\u4e4b\u4e00\uff0c\u9700\u8981\u6df1\u5165\u4e86\u89e3\u540c\u6b65\u3001\u901a\u4fe1\u548c\u5185\u5b58\u6a21\u578b\u3002\u867d\u7136\u73b0\u4ee3C++\u6807\u51c6\u548cOpenMP\u3001MPI\u7b49\u6846\u67b6\u7b80\u5316\u4e86\u5e76\u884c\u6027\uff0c\u4f46\u638c\u63e1\u8fd9\u4e9b\u8303\u5f0f\u4ecd\u7136\u5f88\u590d\u6742\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u751f\u6210\u6b63\u786e\u9ad8\u6548\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u4ee3\u7801\u65b9\u9762\u7684\u6548\u679c\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u5305\u62ecChatGPT 4\u548c5\u3001Claude\u548cLLaMA\u5728\u5185\u7684\u9886\u5148\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u751f\u6210\u4f7f\u7528\u5171\u4eab\u5185\u5b58\u3001\u57fa\u4e8e\u6307\u4ee4\u548c\u5206\u5e03\u5f0f\u5185\u5b58\u8303\u5f0f\u7684Mandelbrot\u96c6C++\u5b9e\u73b0\u65b9\u9762\u7684\u80fd\u529b\u3002\u6bcf\u4e2a\u751f\u6210\u7684\u7a0b\u5e8f\u90fd\u4f7f\u7528GCC 11.5.0\u7f16\u8bd1\u548c\u6267\u884c\uff0c\u4ee5\u8bc4\u4f30\u5176\u6b63\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cChatGPT-4\u548cChatGPT-5\u5728\u8bed\u6cd5\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u80fd\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7279\u522b\u662fChatGPT\u7cfb\u5217\u5728\u751f\u6210\u9ad8\u6027\u80fd\u8ba1\u7b97\u4ee3\u7801\u65b9\u9762\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u4ea7\u751f\u8bed\u6cd5\u6b63\u786e\u4e14\u5177\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027\u7684\u5e76\u884c\u4ee3\u7801\u5b9e\u73b0\u3002"}}
{"id": "2512.17077", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17077", "abs": "https://arxiv.org/abs/2512.17077", "authors": ["Jiakun Fan", "Yanglin Zhang", "Xiangchen Li", "Dimitrios S. Nikolopoulos"], "title": "Taming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving", "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to Autoregressive Models (ARMs), utilizing parallel decoding to overcome sequential bottlenecks. However, existing research focuses primarily on kernel-level optimizations, lacking a holistic serving framework that addresses the unique memory dynamics of diffusion processes in production. We identify a critical \"memory footprint crisis\" specific to dLLMs, driven by monolithic logit tensors and the severe resource oscillation between compute-bound \"Refresh\" phases and bandwidth-bound \"Reuse\" phases. To bridge this gap, we present dLLM-Serve, an efficient dLLM serving system that co-optimizes memory footprint, computational scheduling, and generation quality. dLLM-Serve introduces Logit-Aware Activation Budgeting to decompose transient tensor peaks, a Phase-Multiplexed Scheduler to interleave heterogeneous request phases, and Head-Centric Sparse Attention to decouple logical sparsity from physical storage. We evaluate dLLM-Serve on diverse workloads (LiveBench, Burst, OSC) and GPUs (RTX 4090, L40S). Relative to the state-of-the-art baseline, dLLM-Serve improves throughput by 1.61$\\times$-1.81$\\times$ on the consumer-grade RTX 4090 and 1.60$\\times$-1.74$\\times$ on the server-grade NVIDIA L40S, while reducing tail latency by nearly 4$\\times$ under heavy contention. dLLM-Serve establishes the first blueprint for scalable dLLM inference, converting theoretical algorithmic sparsity into tangible wall-clock acceleration across heterogeneous hardware.", "AI": {"tldr": "dLLM-Serve\u662f\u4e00\u4e2a\u9488\u5bf9\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5185\u5b58\u4f18\u5316\u3001\u8ba1\u7b97\u8c03\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u534f\u540c\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u7279\u6709\u7684\u5185\u5b58\u5360\u7528\u5371\u673a\u548c\u8d44\u6e90\u632f\u8361\u95ee\u9898\uff0c\u5728\u6d88\u8d39\u7ea7\u548c\u670d\u52a1\u5668\u7ea7GPU\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u541e\u5410\u91cf\u63d0\u5347\u548c\u5ef6\u8fdf\u964d\u4f4e\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5185\u6838\u7ea7\u4f18\u5316\uff0c\u7f3a\u4e4f\u9488\u5bf9\u751f\u4ea7\u73af\u5883\u4e2d\u6269\u6563\u8fc7\u7a0b\u72ec\u7279\u5185\u5b58\u52a8\u6001\u7684\u6574\u4f53\u670d\u52a1\u6846\u67b6\u3002\u4f5c\u8005\u8bc6\u522b\u51fadLLM\u7279\u6709\u7684\"\u5185\u5b58\u5360\u7528\u5371\u673a\"\uff0c\u7531\u5355\u4e00logit\u5f20\u91cf\u548c\u8ba1\u7b97\u5bc6\u96c6\u578b\"\u5237\u65b0\"\u9636\u6bb5\u4e0e\u5e26\u5bbd\u5bc6\u96c6\u578b\"\u91cd\u7528\"\u9636\u6bb5\u4e4b\u95f4\u7684\u4e25\u91cd\u8d44\u6e90\u632f\u8361\u9a71\u52a8\u3002", "method": "dLLM-Serve\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1) Logit-Aware Activation Budgeting\u5206\u89e3\u77ac\u6001\u5f20\u91cf\u5cf0\u503c\uff1b2) Phase-Multiplexed Scheduler\u4ea4\u9519\u5904\u7406\u5f02\u6784\u8bf7\u6c42\u9636\u6bb5\uff1b3) Head-Centric Sparse Attention\u5c06\u903b\u8f91\u7a00\u758f\u6027\u4e0e\u7269\u7406\u5b58\u50a8\u89e3\u8026\u3002", "result": "\u5728\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d(LiveBench\u3001Burst\u3001OSC)\u548cGPU(RTX 4090\u3001L40S)\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\uff0cdLLM-Serve\u5728\u6d88\u8d39\u7ea7RTX 4090\u4e0a\u63d0\u5347\u541e\u5410\u91cf1.61-1.81\u500d\uff0c\u5728\u670d\u52a1\u5668\u7ea7L40S\u4e0a\u63d0\u53471.60-1.74\u500d\uff0c\u5728\u91cd\u5ea6\u4e89\u7528\u4e0b\u5c3e\u90e8\u5ef6\u8fdf\u964d\u4f4e\u8fd14\u500d\u3002", "conclusion": "dLLM-Serve\u4e3a\u53ef\u6269\u5c55\u7684dLLM\u63a8\u7406\u5efa\u7acb\u4e86\u9996\u4e2a\u84dd\u56fe\uff0c\u5c06\u7406\u8bba\u7b97\u6cd5\u7a00\u758f\u6027\u8f6c\u5316\u4e3a\u8de8\u5f02\u6784\u786c\u4ef6\u7684\u5b9e\u9645\u65f6\u949f\u52a0\u901f\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u670d\u52a1\u7684\u5173\u952e\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2512.17264", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17264", "abs": "https://arxiv.org/abs/2512.17264", "authors": ["Yuming Xu", "Qianxi Zhang", "Qi Chen", "Baotong Lu", "Menghao Li", "Philip Adams", "Mingqin Li", "Zengzhong Li", "Jing Liu", "Cheng Li", "Fan Yang"], "title": "Scalable Distributed Vector Search via Accuracy Preserving Index Construction", "comment": null, "summary": "Scaling Approximate Nearest Neighbor Search (ANNS) to billions of vectors requires distributed indexes that balance accuracy, latency, and throughput. Yet existing index designs struggle with this tradeoff. This paper presents SPIRE, a scalable vector index based on two design decisions. First, it identifies a balanced partition granularity that avoids read-cost explosion. Second, it introduces an accuracy-preserving recursive construction that builds a multi-level index with predictable search cost and stable accuracy. In experiments with up to 8 billion vectors across 46 nodes, SPIRE achieves high scalability and up to 9.64X higher throughput than state-of-the-art systems.", "AI": {"tldr": "SPIRE\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5411\u91cf\u7d22\u5f15\u7cfb\u7edf\uff0c\u901a\u8fc7\u5e73\u8861\u5206\u533a\u7c92\u5ea6\u548c\u9012\u5f52\u6784\u5efa\u591a\u7ea7\u7d22\u5f15\uff0c\u5728\u6570\u5341\u4ebf\u5411\u91cf\u89c4\u6a21\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u3001\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff08ANNS\uff09\u7d22\u5f15\u8bbe\u8ba1\u5728\u5904\u7406\u6570\u5341\u4ebf\u5411\u91cf\u65f6\u96be\u4ee5\u5e73\u8861\u51c6\u786e\u7387\u3001\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002", "method": "SPIRE\u91c7\u7528\u4e24\u4e2a\u6838\u5fc3\u8bbe\u8ba1\uff1a1\uff09\u8bc6\u522b\u5e73\u8861\u7684\u5206\u533a\u7c92\u5ea6\u4ee5\u907f\u514d\u8bfb\u53d6\u6210\u672c\u7206\u70b8\uff1b2\uff09\u5f15\u5165\u4fdd\u6301\u51c6\u786e\u7387\u7684\u9012\u5f52\u6784\u5efa\u65b9\u6cd5\uff0c\u6784\u5efa\u5177\u6709\u53ef\u9884\u6d4b\u641c\u7d22\u6210\u672c\u548c\u7a33\u5b9a\u51c6\u786e\u7387\u7684\u591a\u7ea7\u7d22\u5f15\u3002", "result": "\u572846\u4e2a\u8282\u70b9\u4e0a\u5904\u7406\u9ad8\u8fbe80\u4ebf\u5411\u91cf\u7684\u5b9e\u9a8c\u4e2d\uff0cSPIRE\u5b9e\u73b0\u4e86\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u6bd4\u6700\u5148\u8fdb\u7cfb\u7edf\u7684\u541e\u5410\u91cf\u63d0\u9ad8\u4e869.64\u500d\u3002", "conclusion": "SPIRE\u901a\u8fc7\u521b\u65b0\u7684\u5206\u533a\u7c92\u5ea6\u548c\u9012\u5f52\u7d22\u5f15\u6784\u5efa\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u5411\u91cf\u641c\u7d22\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u51c6\u786e\u7387\u3001\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u8861\u3002"}}
{"id": "2512.17060", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17060", "abs": "https://arxiv.org/abs/2512.17060", "authors": ["Monika Zamojska", "Jaros\u0142aw A. Chudziak"], "title": "On the Role of Contextual Information and Ego States in LLM Agent Behavior for Transactional Analysis Dialogues", "comment": "Presented at the 39th Pacific Asia Conference on Language, Information and Computation (PACLIC 39)", "summary": "LLM-powered agents are now used in many areas, from customer support to education, and there is increasing interest in their ability to act more like humans. This includes fields such as social, political, and psychological research, where the goal is to model group dynamics and social behavior. However, current LLM agents often lack the psychological depth and consistency needed to capture the real patterns of human thinking. They usually provide direct or statistically likely answers, but they miss the deeper goals, emotional conflicts, and motivations that drive real human interactions. This paper proposes a Multi-Agent System (MAS) inspired by Transactional Analysis (TA) theory. In the proposed system, each agent is divided into three ego states - Parent, Adult, and Child. The ego states are treated as separate knowledge structures with their own perspectives and reasoning styles. To enrich their response process, they have access to an information retrieval mechanism that allows them to retrieve relevant contextual information from their vector stores. This architecture is evaluated through ablation tests in a simulated dialogue scenario, comparing agents with and without information retrieval. The results are promising and open up new directions for exploring how psychologically grounded structures can enrich agent behavior. The contribution is an agent architecture that integrates Transactional Analysis theory with contextual information retrieval to enhance the realism of LLM-based multi-agent simulations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ea4\u4e92\u5206\u6790\u7406\u8bba\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u6bcf\u4e2a\u667a\u80fd\u4f53\u5212\u5206\u4e3a\u7236\u6bcd\u3001\u6210\u4eba\u548c\u513f\u7ae5\u4e09\u79cd\u81ea\u6211\u72b6\u6001\uff0c\u5e76\u7ed3\u5408\u4fe1\u606f\u68c0\u7d22\u673a\u5236\uff0c\u589e\u5f3a\u4e86LLM\u667a\u80fd\u4f53\u7684\u5fc3\u7406\u6df1\u5ea6\u548c\u884c\u4e3a\u771f\u5b9e\u6027\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u5728\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u65f6\u7f3a\u4e4f\u5fc3\u7406\u6df1\u5ea6\u548c\u4e00\u81f4\u6027\uff0c\u53ea\u80fd\u63d0\u4f9b\u76f4\u63a5\u6216\u7edf\u8ba1\u4e0a\u53ef\u80fd\u7684\u7b54\u6848\uff0c\u800c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4eba\u7c7b\u601d\u7ef4\u4e2d\u7684\u6df1\u5c42\u76ee\u6807\u3001\u60c5\u611f\u51b2\u7a81\u548c\u52a8\u673a\u3002\u5728\u793e\u4f1a\u79d1\u5b66\u3001\u653f\u6cbb\u5b66\u548c\u5fc3\u7406\u5b66\u7814\u7a76\u4e2d\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u7684\u667a\u80fd\u4f53\u6765\u6a21\u62df\u7fa4\u4f53\u52a8\u6001\u548c\u793e\u4f1a\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4ea4\u4e92\u5206\u6790\u7406\u8bba\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5c06\u6bcf\u4e2a\u667a\u80fd\u4f53\u5212\u5206\u4e3a\u4e09\u79cd\u81ea\u6211\u72b6\u6001\uff1a\u7236\u6bcd\u3001\u6210\u4eba\u548c\u513f\u7ae5\u3002\u8fd9\u4e9b\u81ea\u6211\u72b6\u6001\u4f5c\u4e3a\u72ec\u7acb\u7684\u77e5\u8bc6\u7ed3\u6784\uff0c\u62e5\u6709\u5404\u81ea\u7684\u89c6\u89d2\u548c\u63a8\u7406\u98ce\u683c\u3002\u540c\u65f6\uff0c\u667a\u80fd\u4f53\u914d\u5907\u4fe1\u606f\u68c0\u7d22\u673a\u5236\uff0c\u53ef\u4ee5\u4ece\u5411\u91cf\u5b58\u50a8\u4e2d\u68c0\u7d22\u76f8\u5173\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u4e30\u5bcc\u54cd\u5e94\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u5728\u6a21\u62df\u5bf9\u8bdd\u573a\u666f\u4e2d\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u6709\u4fe1\u606f\u68c0\u7d22\u548c\u65e0\u4fe1\u606f\u68c0\u7d22\u7684\u667a\u80fd\u4f53\u8868\u73b0\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u67b6\u6784\u5177\u6709\u826f\u597d\u524d\u666f\uff0c\u4e3a\u63a2\u7d22\u57fa\u4e8e\u5fc3\u7406\u5b66\u7684\u7ed3\u6784\u5982\u4f55\u4e30\u5bcc\u667a\u80fd\u4f53\u884c\u4e3a\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u7684\u8d21\u732e\u5728\u4e8e\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4ea4\u4e92\u5206\u6790\u7406\u8bba\u4e0e\u4e0a\u4e0b\u6587\u4fe1\u606f\u68c0\u7d22\u76f8\u7ed3\u5408\u7684\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u80fd\u591f\u589e\u5f3a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6a21\u62df\u7684\u771f\u5b9e\u6027\uff0c\u4e3a\u521b\u5efa\u66f4\u5177\u5fc3\u7406\u6df1\u5ea6\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.16953", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.16953", "abs": "https://arxiv.org/abs/2512.16953", "authors": ["Pietro Cofone", "Giovanni Amendola", "Marco Manna", "Aldo Ricioppo"], "title": "Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases", "comment": null, "summary": "Recognizing similarities among entities is central to both human cognition and computational intelligence. Within this broader landscape, Entity Set Expansion is one prominent task aimed at taking an initial set of (tuples of) entities and identifying additional ones that share relevant semantic properties with the former -- potentially repeating the process to form increasingly broader sets. However, this ``linear'' approach does not unveil the richer ``taxonomic'' structures present in knowledge resources. A recent logic-based framework introduces the notion of an expansion graph: a rooted directed acyclic graph where each node represents a semantic generalization labeled by a logical formula, and edges encode strict semantic inclusion. This structure supports taxonomic expansions of entity sets driven by knowledge bases. Yet, the potentially large size of such graphs may make full materialization impractical in real-world scenarios. To overcome this, we formalize reasoning tasks that check whether two tuples belong to comparable, incomparable, or the same nodes in the graph. Our results show that, under realistic assumptions -- such as bounding the input or limiting entity descriptions -- these tasks can be implemented efficiently. This enables local, incremental navigation of expansion graphs, supporting practical applications without requiring full graph construction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u903b\u8f91\u6846\u67b6\u7684\u5b9e\u4f53\u96c6\u6269\u5c55\u56fe\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u63a8\u7406\u4efb\u52a1\u5b9e\u73b0\u9ad8\u6548\u5bfc\u822a\uff0c\u907f\u514d\u5b8c\u6574\u56fe\u6784\u5efa\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "\u4f20\u7edf\u7684\u7ebf\u6027\u5b9e\u4f53\u96c6\u6269\u5c55\u65b9\u6cd5\u65e0\u6cd5\u63ed\u793a\u77e5\u8bc6\u8d44\u6e90\u4e2d\u4e30\u5bcc\u7684\u5206\u7c7b\u7ed3\u6784\uff0c\u800c\u5b8c\u6574\u7684\u6269\u5c55\u56fe\u6784\u5efa\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u53ef\u80fd\u4e0d\u5207\u5b9e\u9645\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5c40\u90e8\u5bfc\u822a\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u903b\u8f91\u7684\u6269\u5c55\u56fe\u6846\u67b6\uff0c\u5176\u4e2d\u8282\u70b9\u8868\u793a\u7531\u903b\u8f91\u516c\u5f0f\u6807\u8bb0\u7684\u8bed\u4e49\u6cdb\u5316\uff0c\u8fb9\u7f16\u7801\u4e25\u683c\u7684\u8bed\u4e49\u5305\u542b\u5173\u7cfb\u3002\u901a\u8fc7\u5f62\u5f0f\u5316\u63a8\u7406\u4efb\u52a1\u6765\u68c0\u67e5\u4e24\u4e2a\u5143\u7ec4\u662f\u5426\u5c5e\u4e8e\u53ef\u6bd4\u8f83\u3001\u4e0d\u53ef\u6bd4\u8f83\u6216\u76f8\u540c\u7684\u8282\u70b9\u3002", "result": "\u5728\u73b0\u5b9e\u5047\u8bbe\u4e0b\uff08\u5982\u9650\u5236\u8f93\u5165\u6216\u5b9e\u4f53\u63cf\u8ff0\uff09\uff0c\u8fd9\u4e9b\u63a8\u7406\u4efb\u52a1\u53ef\u4ee5\u9ad8\u6548\u5b9e\u73b0\uff0c\u652f\u6301\u5bf9\u6269\u5c55\u56fe\u7684\u5c40\u90e8\u589e\u91cf\u5bfc\u822a\uff0c\u65e0\u9700\u6784\u5efa\u5b8c\u6574\u56fe\u7ed3\u6784\u3002", "conclusion": "\u901a\u8fc7\u5c40\u90e8\u63a8\u7406\u4efb\u52a1\u5b9e\u73b0\u6269\u5c55\u56fe\u7684\u9ad8\u6548\u5bfc\u822a\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u907f\u514d\u4e86\u5b8c\u6574\u56fe\u6784\u5efa\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002"}}
{"id": "2512.17506", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17506", "abs": "https://arxiv.org/abs/2512.17506", "authors": ["Brienna M. Larrick", "L. Philip Schumm", "Mingfei Shao", "Craig Barnes", "Anthony Juehne", "Hara Prasad Juvvla", "Michael B. Kranz", "Michael Lukowski", "Clint Malson", "Jessica N. Mazerik", "Christopher G. Meyer", "Jawad Qureshi", "Erin Spaniol", "Andrea Tentner", "Alexander VanTol", "Peter Vassilatos", "Sara Volk de Garcia", "Robert L. Grossman"], "title": "The HEAL Data Platform", "comment": "12 pages, 3 figures", "summary": "Objective: The objective was to develop a cloud-based, federated system to serve as a single point of search, discovery and analysis for data generated under the NIH Helping to End Addiction Long-term (HEAL) Initiative.\n  Materials and methods: The HEAL Data Platform is built on the open source Gen3 platform, utilizing a small set of framework services and exposed APIs to interoperate with both NIH and non-NIH data repositories. Framework services include those for authentication and authorization, creating persistent identifiers for data objects, and adding and updating metadata.\n  Results: The HEAL Data Platform serves as a single point of discovery of over one thousand studies funded under the HEAL Initiative. With hundreds of users per month, the HEAL Data Platform provides rich metadata and interoperates with data repositories and commons to provide access to shared datasets. Secure, cloud-based compute environments that are integrated with STRIDES facilitate secondary analysis of HEAL data. The HEAL Data Platform currently interoperates with nineteen data repositories.\n  Discussion: Studies funded under the HEAL Initiative generate a wide variety of data types, which are deposited across multiple NIH and third-party data repositories. The mesh architecture of the HEAL Data Platform provides a single point of discovery of these data resources, accelerating and facilitating secondary use.\n  Conclusion: The HEAL Data Platform enables search, discovery, and analysis of data that are deposited in connected data repositories and commons. By ensuring that these data are fully Findable, Accessible, Interoperable and Reusable (FAIR), the HEAL Data Platform maximizes the value of data generated under the HEAL Initiative.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8e\u4e91\u7684\u8054\u90a6\u7cfb\u7edf\u4f5c\u4e3aNIH HEAL\u8ba1\u5212\u6570\u636e\u7684\u7edf\u4e00\u641c\u7d22\u3001\u53d1\u73b0\u548c\u5206\u6790\u5e73\u53f0", "motivation": "HEAL\u8ba1\u5212\u4ea7\u751f\u7684\u591a\u6837\u5316\u6570\u636e\u5206\u6563\u5728\u591a\u4e2aNIH\u548c\u7b2c\u4e09\u65b9\u6570\u636e\u5b58\u50a8\u5e93\u4e2d\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u53d1\u73b0\u5e73\u53f0\u6765\u4fc3\u8fdb\u6570\u636e\u7684\u4e8c\u6b21\u5229\u7528", "method": "\u57fa\u4e8e\u5f00\u6e90Gen3\u5e73\u53f0\u6784\u5efa\uff0c\u4f7f\u7528\u6846\u67b6\u670d\u52a1\uff08\u8ba4\u8bc1\u6388\u6743\u3001\u6301\u4e45\u6807\u8bc6\u7b26\u3001\u5143\u6570\u636e\u7ba1\u7406\uff09\u548cAPI\u4e0e\u6570\u636e\u5b58\u50a8\u5e93\u4e92\u64cd\u4f5c", "result": "\u5e73\u53f0\u5df2\u6574\u54081000\u591a\u9879HEAL\u7814\u7a76\uff0c\u6bcf\u6708\u6570\u767e\u7528\u6237\u4f7f\u7528\uff0c\u4e0e19\u4e2a\u6570\u636e\u5b58\u50a8\u5e93\u4e92\u64cd\u4f5c\uff0c\u63d0\u4f9b\u4e30\u5bcc\u5143\u6570\u636e\u548c\u5b89\u5168\u7684\u4e91\u8ba1\u7b97\u73af\u5883", "conclusion": "HEAL\u6570\u636e\u5e73\u53f0\u5b9e\u73b0\u4e86\u5bf9\u5206\u6563\u6570\u636e\u7684\u7edf\u4e00\u53d1\u73b0\u548c\u5206\u6790\uff0c\u901a\u8fc7\u786e\u4fddFAIR\u539f\u5219\u6700\u5927\u5316HEAL\u8ba1\u5212\u6570\u636e\u7684\u4ef7\u503c"}}
{"id": "2512.17187", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.17187", "abs": "https://arxiv.org/abs/2512.17187", "authors": ["Zhaoqilin Yang", "Axin Xiang", "Kedi Yang", "Tianjun Liu", "Youliang Tian"], "title": "MAPPO-LCR: Multi-Agent Policy Optimization with Local Cooperation Reward in Spatial Public Goods Games", "comment": null, "summary": "Spatial public goods games model collective dilemmas where individual payoffs depend on population-level strategy configurations. Most existing studies rely on evolutionary update rules or value-based reinforcement learning methods. These approaches struggle to represent payoff coupling and non-stationarity in large interacting populations. This work introduces Multi-Agent Proximal Policy Optimization (MAPPO) into spatial public goods games for the first time. In these games, individual returns are intrinsically coupled through overlapping group interactions. Proximal Policy Optimization (PPO) treats agents as independent learners and ignores this coupling during value estimation. MAPPO addresses this limitation through a centralized critic that evaluates joint strategy configurations. To study neighborhood-level cooperation signals under this framework, we propose MAPPO with Local Cooperation Reward, termed MAPPO-LCR. The local cooperation reward aligns policy updates with surrounding cooperative density without altering the original game structure. MAPPO-LCR preserves decentralized execution while enabling population-level value estimation during training. Extensive simulations demonstrate stable cooperation emergence and reliable convergence across enhancement factors. Statistical analyses further confirm the learning advantage of MAPPO over PPO in spatial public goods games.", "AI": {"tldr": "\u9996\u6b21\u5c06MAPPO\u5f15\u5165\u7a7a\u95f4\u516c\u5171\u7269\u54c1\u535a\u5f08\uff0c\u63d0\u51faMAPPO-LCR\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u5408\u4f5c\u5956\u52b1\u4fc3\u8fdb\u5408\u4f5c\u6d8c\u73b0\uff0c\u76f8\u6bd4PPO\u5728\u8026\u5408\u6536\u76ca\u73af\u5883\u4e2d\u8868\u73b0\u66f4\u4f18", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u6f14\u5316\u66f4\u65b0\u89c4\u5219\u6216\u57fa\u4e8e\u4ef7\u503c\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u4ea4\u4e92\u7fa4\u4f53\u4e2d\u7684\u6536\u76ca\u8026\u5408\u548c\u975e\u5e73\u7a33\u6027\u95ee\u9898\u3002\u4f20\u7edfPPO\u5c06\u667a\u80fd\u4f53\u89c6\u4e3a\u72ec\u7acb\u5b66\u4e60\u8005\uff0c\u5ffd\u7565\u4e86\u7a7a\u95f4\u516c\u5171\u7269\u54c1\u535a\u5f08\u4e2d\u901a\u8fc7\u91cd\u53e0\u7fa4\u4f53\u4ea4\u4e92\u4ea7\u751f\u7684\u5185\u5728\u6536\u76ca\u8026\u5408\u3002", "method": "\u5f15\u5165\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08MAPPO\uff09\u5230\u7a7a\u95f4\u516c\u5171\u7269\u54c1\u535a\u5f08\u4e2d\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u8bc4\u8bba\u5bb6\u8bc4\u4f30\u8054\u5408\u7b56\u7565\u914d\u7f6e\u3002\u63d0\u51faMAPPO-LCR\u65b9\u6cd5\uff0c\u6dfb\u52a0\u5c40\u90e8\u5408\u4f5c\u5956\u52b1\u4f7f\u7b56\u7565\u66f4\u65b0\u4e0e\u5468\u56f4\u5408\u4f5c\u5bc6\u5ea6\u5bf9\u9f50\uff0c\u4e0d\u6539\u53d8\u539f\u59cb\u535a\u5f08\u7ed3\u6784\uff0c\u4fdd\u6301\u5206\u6563\u6267\u884c\u7684\u540c\u65f6\u5728\u8bad\u7ec3\u671f\u95f4\u5b9e\u73b0\u7fa4\u4f53\u7ea7\u4ef7\u503c\u4f30\u8ba1\u3002", "result": "\u5927\u91cf\u4eff\u771f\u5b9e\u9a8c\u663e\u793aMAPPO-LCR\u80fd\u591f\u7a33\u5b9a\u4fc3\u8fdb\u5408\u4f5c\u6d8c\u73b0\u5e76\u5728\u4e0d\u540c\u589e\u5f3a\u56e0\u5b50\u4e0b\u5b9e\u73b0\u53ef\u9760\u6536\u655b\u3002\u7edf\u8ba1\u5206\u6790\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86MAPPO\u5728\u7a7a\u95f4\u516c\u5171\u7269\u54c1\u535a\u5f08\u4e2d\u76f8\u5bf9\u4e8ePPO\u7684\u5b66\u4e60\u4f18\u52bf\u3002", "conclusion": "MAPPO\u6846\u67b6\u901a\u8fc7\u96c6\u4e2d\u5f0f\u8bc4\u8bba\u5bb6\u6709\u6548\u89e3\u51b3\u4e86\u7a7a\u95f4\u516c\u5171\u7269\u54c1\u535a\u5f08\u4e2d\u7684\u6536\u76ca\u8026\u5408\u95ee\u9898\uff0cMAPPO-LCR\u65b9\u6cd5\u901a\u8fc7\u5c40\u90e8\u5408\u4f5c\u5956\u52b1\u6210\u529f\u4fc3\u8fdb\u4e86\u5408\u4f5c\u884c\u4e3a\u7684\u6d8c\u73b0\uff0c\u4e3a\u5904\u7406\u5927\u89c4\u6a21\u4ea4\u4e92\u7fa4\u4f53\u4e2d\u7684\u96c6\u4f53\u56f0\u5883\u63d0\u4f9b\u4e86\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.16969", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16969", "abs": "https://arxiv.org/abs/2512.16969", "authors": ["Wanghan Xu", "Yuhao Zhou", "Yifan Zhou", "Qinglong Cao", "Shuo Li", "Jia Bu", "Bo Liu", "Yixin Chen", "Xuming He", "Xiangyu Zhao", "Xiang Zhuang", "Fengxiang Wang", "Zhiwang Zhou", "Qiantai Feng", "Wenxuan Huang", "Jiaqi Wei", "Hao Wu", "Yuejin Yang", "Guangshuai Wang", "Sheng Xu", "Ziyan Huang", "Xinyao Liu", "Jiyao Liu", "Cheng Tang", "Wei Li", "Ying Chen", "Junzhi Ning", "Pengfei Jiang", "Chenglong Ma", "Ye Du", "Changkai Ji", "Huihui Xu", "Ming Hu", "Jiangbin Zheng", "Xin Chen", "Yucheng Wu", "Feifei Jiang", "Xi Chen", "Xiangru Tang", "Yuchen Fu", "Yingzhou Lu", "Yuanyuan Zhang", "Lihao Sun", "Chengbo Li", "Jinzhe Ma", "Wanhao Liu", "Yating Liu", "Kuo-Cheng Wu", "Shengdu Chai", "Yizhou Wang", "Ouwen Zhangjin", "Chen Tang", "Shufei Zhang", "Wenbo Cao", "Junjie Ren", "Taoyong Cui", "Zhouheng Yao", "Juntao Deng", "Yijie Sun", "Feng Liu", "Wangxu Wei", "Jingyi Xu", "Zhangrui Li", "Junchao Gong", "Zijie Guo", "Zhiyu Yao", "Zaoyu Chen", "Tianhao Peng", "Fangchen Yu", "Bo Zhang", "Dongzhan Zhou", "Shixiang Tang", "Jiaheng Liu", "Fenghua Ling", "Yan Lu", "Yuchen Ren", "Ben Fei", "Zhen Zhao", "Xinyu Gu", "Rui Su", "Xiao-Ming Wu", "Weikang Si", "Yang Liu", "Hao Chen", "Xiangchao Yan", "Xue Yang", "Junchi Yan", "Jiamin Wu", "Qihao Zheng", "Chenhui Li", "Zhiqiang Gao", "Hao Kong", "Junjun He", "Mao Su", "Tianfan Fu", "Peng Ye", "Chunfeng Song", "Nanqing Dong", "Yuqiang Li", "Huazhu Fu", "Siqi Sun", "Lijing Cheng", "Jintai Lin", "Wanli Ouyang", "Bowen Zhou", "Wenlong Zhang", "Lei Bai"], "title": "Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows", "comment": null, "summary": "Despite advances in scientific AI, a coherent framework for Scientific General Intelligence (SGI)-the ability to autonomously conceive, investigate, and reason across scientific domains-remains lacking. We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberation, Conception, Action, Perception) and operationalize it via four scientist-aligned tasks: deep research, idea generation, dry/wet experiments, and experimental reasoning. SGI-Bench comprises over 1,000 expert-curated, cross-disciplinary samples inspired by Science's 125 Big Questions, enabling systematic evaluation of state-of-the-art LLMs. Results reveal gaps: low exact match (10--20%) in deep research despite step-level alignment; ideas lacking feasibility and detail; high code executability but low execution result accuracy in dry experiments; low sequence fidelity in wet protocols; and persistent multimodal comparative-reasoning challenges. We further introduce Test-Time Reinforcement Learning (TTRL), which optimizes retrieval-augmented novelty rewards at inference, enhancing hypothesis novelty without reference answer. Together, our PIM-grounded definition, workflow-centric benchmark, and empirical insights establish a foundation for AI systems that genuinely participate in scientific discovery.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u79d1\u5b66\u901a\u7528\u667a\u80fd\uff08SGI\uff09\u7684\u64cd\u4f5c\u6027\u5b9a\u4e49\uff0c\u57fa\u4e8e\u5b9e\u7528\u63a2\u7a76\u6a21\u578b\uff08PIM\uff09\uff0c\u5e76\u521b\u5efa\u4e86\u5305\u542b1000\u591a\u4e2a\u8de8\u5b66\u79d1\u6837\u672c\u7684SGI-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u7814\u7a76\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u6df1\u5ea6\u7814\u7a76\u3001\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u63a8\u7406\u7b49\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e86\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\uff08TTRL\uff09\u65b9\u6cd5\u6765\u63d0\u5347\u5047\u8bbe\u65b0\u9896\u6027\u3002", "motivation": "\u5c3d\u7ba1\u79d1\u5b66AI\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u8fde\u8d2f\u7684\u79d1\u5b66\u901a\u7528\u667a\u80fd\uff08SGI\uff09\u6846\u67b6\uff0c\u5373\u80fd\u591f\u81ea\u4e3b\u6784\u601d\u3001\u7814\u7a76\u548c\u8de8\u79d1\u5b66\u9886\u57df\u63a8\u7406\u7684\u80fd\u529b\u3002\u73b0\u6709AI\u7cfb\u7edf\u5728\u53c2\u4e0e\u771f\u6b63\u7684\u79d1\u5b66\u53d1\u73b0\u65b9\u9762\u4ecd\u6709\u5c40\u9650\u3002", "method": "\u57fa\u4e8e\u5b9e\u7528\u63a2\u7a76\u6a21\u578b\uff08PIM\uff1a\u5ba1\u8bae\u3001\u6784\u601d\u3001\u884c\u52a8\u3001\u611f\u77e5\uff09\u5efa\u7acbSGI\u7684\u64cd\u4f5c\u6027\u5b9a\u4e49\uff0c\u901a\u8fc7\u56db\u4e2a\u79d1\u5b66\u5bb6\u5bf9\u9f50\u7684\u4efb\u52a1\uff08\u6df1\u5ea6\u7814\u7a76\u3001\u60f3\u6cd5\u751f\u6210\u3001\u5e72/\u6e7f\u5b9e\u9a8c\u3001\u5b9e\u9a8c\u63a8\u7406\uff09\u8fdb\u884c\u5b9e\u73b0\u3002\u521b\u5efaSGI-Bench\u57fa\u51c6\uff0c\u5305\u542b1000\u591a\u4e2a\u4e13\u5bb6\u7b56\u5212\u7684\u8de8\u5b66\u79d1\u6837\u672c\uff0c\u8bc4\u4f30\u6700\u5148\u8fdb\u7684LLMs\u3002\u63d0\u51fa\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\uff08TTRL\uff09\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u4f18\u5316\u68c0\u7d22\u589e\u5f3a\u7684\u65b0\u9896\u6027\u5956\u52b1\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u663e\u8457\u5dee\u8ddd\uff1a\u6df1\u5ea6\u7814\u7a76\u7684\u7cbe\u786e\u5339\u914d\u7387\u4f4e\uff0810-20%\uff09\uff0c\u60f3\u6cd5\u7f3a\u4e4f\u53ef\u884c\u6027\u548c\u7ec6\u8282\uff0c\u5e72\u5b9e\u9a8c\u4ee3\u7801\u53ef\u6267\u884c\u6027\u9ad8\u4f46\u6267\u884c\u7ed3\u679c\u51c6\u786e\u6027\u4f4e\uff0c\u6e7f\u5b9e\u9a8c\u534f\u8bae\u5e8f\u5217\u4fdd\u771f\u5ea6\u4f4e\uff0c\u591a\u6a21\u6001\u6bd4\u8f83\u63a8\u7406\u6311\u6218\u6301\u7eed\u5b58\u5728\u3002TTRL\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u53c2\u8003\u7b54\u6848\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u5047\u8bbe\u65b0\u9896\u6027\u3002", "conclusion": "\u57fa\u4e8ePIM\u7684\u5b9a\u4e49\u3001\u4ee5\u5de5\u4f5c\u6d41\u7a0b\u4e3a\u4e2d\u5fc3\u7684\u57fa\u51c6\u548c\u5b9e\u8bc1\u89c1\u89e3\u4e3a\u771f\u6b63\u53c2\u4e0e\u79d1\u5b66\u53d1\u73b0\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dAI\u5728\u79d1\u5b66\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\uff0c\u63a8\u52a8\u4e86\u79d1\u5b66\u901a\u7528\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.17574", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17574", "abs": "https://arxiv.org/abs/2512.17574", "authors": ["Lingxiao Zhao", "Haoran Zhou", "Yuezhi Che", "Dazhao Cheng"], "title": "Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing", "comment": null, "summary": "Multimodal large language models (MLLMs) extend LLMs with visual understanding through a three-stage pipeline: multimodal preprocessing, vision encoding, and LLM inference. While these stages enhance capability, they introduce significant system bottlenecks. First, multimodal preprocessing-especially video decoding-often dominates Time-to-First-Token (TTFT). Most systems rely on CPU-based decoding, which severely limits throughput, while existing GPU-based approaches prioritize throughput-oriented parallelism and fail to meet the latency-sensitive requirements of MLLM inference. Second, the vision encoder is a standalone, compute-intensive stage that produces visual embeddings and cannot be co-batched with LLM prefill or decoding. This heterogeneity forces inter-stage blocking and increases token-generation latency. Even when deployed on separate GPUs, these stages underutilize available compute and memory resources, reducing overall utilization and constraining system throughput.\n  To address these challenges, we present FlashCodec and UnifiedServe, two complementary designs that jointly optimize the end-to-end MLLM pipeline. FlashCodec accelerates the multimodal preprocessing stage through collaborative multi-GPU video decoding, reducing decoding latency while preserving high throughput. UnifiedServe optimizes the vision-to-text and inference stages using a logically decoupled their execution to eliminate inter-stage blocking, yet physically sharing GPU resources to maximize GPU system utilization. By carefully orchestrating execution across stages and minimizing interference, UnifiedServe Together, our proposed framework forms an end-to-end optimized stack that can serve up to 3.0$\\times$ more requests or enforce 1.5$\\times$ tighter SLOs, while achieving up to 4.4$\\times$ higher throughput compared to state-of-the-art systems.", "AI": {"tldr": "FlashCodec\u548cUnifiedServe\u8054\u5408\u4f18\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u534f\u540c\u591aGPU\u89c6\u9891\u89e3\u7801\u52a0\u901f\u9884\u5904\u7406\uff0c\u5e76\u901a\u8fc7\u903b\u8f91\u89e3\u8026\u4f46\u7269\u7406\u5171\u4eabGPU\u8d44\u6e90\u7684\u65b9\u5f0f\u4f18\u5316\u89c6\u89c9\u7f16\u7801\u548c\u63a8\u7406\u9636\u6bb5\uff0c\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u548c\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff08\u591a\u6a21\u6001\u9884\u5904\u7406\u3001\u89c6\u89c9\u7f16\u7801\u3001LLM\u63a8\u7406\uff09\u5b58\u5728\u663e\u8457\u7cfb\u7edf\u74f6\u9888\uff1a1\uff09CPU\u89c6\u9891\u89e3\u7801\u4e3b\u5bfc\u9996token\u5ef6\u8fdf\uff1b2\uff09\u89c6\u89c9\u7f16\u7801\u5668\u4f5c\u4e3a\u72ec\u7acb\u8ba1\u7b97\u5bc6\u96c6\u578b\u9636\u6bb5\uff0c\u65e0\u6cd5\u4e0eLLM\u9884\u586b\u5145\u6216\u89e3\u7801\u534f\u540c\u6279\u5904\u7406\uff0c\u5bfc\u81f4\u9636\u6bb5\u95f4\u963b\u585e\u548c\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faFlashCodec\u548cUnifiedServe\u4e24\u4e2a\u4e92\u8865\u8bbe\u8ba1\uff1aFlashCodec\u901a\u8fc7\u534f\u540c\u591aGPU\u89c6\u9891\u89e3\u7801\u52a0\u901f\u591a\u6a21\u6001\u9884\u5904\u7406\uff1bUnifiedServe\u91c7\u7528\u903b\u8f91\u89e3\u8026\u4f46\u7269\u7406\u5171\u4eabGPU\u8d44\u6e90\u7684\u6267\u884c\u65b9\u5f0f\uff0c\u4f18\u5316\u89c6\u89c9\u5230\u6587\u672c\u548c\u63a8\u7406\u9636\u6bb5\uff0c\u6d88\u9664\u9636\u6bb5\u95f4\u963b\u585e\u5e76\u6700\u5927\u5316GPU\u5229\u7528\u7387\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u670d\u52a1\u6700\u591a3.0\u500d\u8bf7\u6c42\u91cf\u6216\u5f3a\u5236\u6267\u884c1.5\u500d\u66f4\u4e25\u683c\u7684SLOs\uff0c\u540c\u65f6\u76f8\u6bd4\u6700\u5148\u8fdb\u7cfb\u7edf\u5b9e\u73b0\u6700\u9ad84.4\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "FlashCodec\u548cUnifiedServe\u5171\u540c\u6784\u6210\u4e86\u7aef\u5230\u7aef\u4f18\u5316\u7684MLLM\u670d\u52a1\u5806\u6808\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u9884\u5904\u7406\u5ef6\u8fdf\u548c\u89c6\u89c9\u7f16\u7801\u5668\u4e0eLLM\u63a8\u7406\u9636\u6bb5\u95f4\u7684\u5f02\u6784\u6027\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2512.16970", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.16970", "abs": "https://arxiv.org/abs/2512.16970", "authors": ["Kamer Ali Yuksel"], "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "comment": null, "summary": "Large Language Model (LLM) agents are increasingly deployed in complex, multi-step workflows involving planning, tool use, reflection, and interaction with external knowledge systems. These workflows generate rapidly expanding contexts that must be curated, transformed, and compressed to maintain fidelity, avoid attention dilution, and reduce inference cost. Prior work on summarization and query-aware compression largely ignores the multi-step, plan-aware nature of agentic reasoning. In this work, we introduce PAACE (Plan-Aware Automated Context Engineering), a unified framework for optimizing the evolving state of LLM agents through next-k-task relevance modeling, plan-structure analysis, instruction co-refinement, and function-preserving compression. PAACE comprises (1) PAACE-Syn, a large-scale generator of synthetic agent workflows annotated with stepwise compression supervision, and (2) PAACE-FT, a family of distilled, plan-aware compressors trained from successful teacher demonstrations. Experiments on long-horizon benchmarks (AppWorld, OfficeBench, and 8-Objective QA) demonstrate that PAACE consistently improves agent correctness while substantially reducing context load. On AppWorld, PAACE achieves higher accuracy than all baselines while lowering peak context and cumulative dependency. On OfficeBench and multi-hop QA, PAACE improves both accuracy and F1, achieving fewer steps, lower peak tokens, and reduced attention dependency. Distilled PAACE-FT retains 97 percent of the teacher's performance while reducing inference cost by over an order of magnitude, enabling practical deployment of plan-aware compression with compact models.", "AI": {"tldr": "PAACE\u662f\u4e00\u4e2a\u9488\u5bf9LLM\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u8ba1\u5212\u611f\u77e5\u81ea\u52a8\u4e0a\u4e0b\u6587\u5de5\u7a0b\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u538b\u7f29\u4f18\u5316\u591a\u6b65\u63a8\u7406\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u591a\u6b65\u5de5\u4f5c\u6d41\u4e2d\u4f1a\u4ea7\u751f\u5feb\u901f\u6269\u5c55\u7684\u4e0a\u4e0b\u6587\uff0c\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u5ffd\u89c6\u4e86\u8ba1\u5212\u611f\u77e5\u7279\u6027\uff0c\u5bfc\u81f4\u6ce8\u610f\u529b\u7a00\u91ca\u548c\u63a8\u7406\u6210\u672c\u589e\u52a0\u3002", "method": "PAACE\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1aPAACE-Syn\u751f\u6210\u5e26\u538b\u7f29\u76d1\u7763\u7684\u5408\u6210\u5de5\u4f5c\u6d41\u6570\u636e\uff0cPAACE-FT\u8bad\u7ec3\u84b8\u998f\u7684\u8ba1\u5212\u611f\u77e5\u538b\u7f29\u5668\u3002\u6846\u67b6\u91c7\u7528next-k-task\u76f8\u5173\u6027\u5efa\u6a21\u3001\u8ba1\u5212\u7ed3\u6784\u5206\u6790\u3001\u6307\u4ee4\u534f\u540c\u7ec6\u5316\u548c\u51fd\u6570\u4fdd\u7559\u538b\u7f29\u3002", "result": "\u5728AppWorld\u3001OfficeBench\u548c8-Objective QA\u7b49\u957f\u89c6\u91ce\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPAACE\u5728\u63d0\u9ad8\u667a\u80fd\u4f53\u6b63\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e0a\u4e0b\u6587\u8d1f\u8f7d\u3002\u84b8\u998f\u6a21\u578b\u4fdd\u755997%\u6559\u5e08\u6027\u80fd\uff0c\u63a8\u7406\u6210\u672c\u964d\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "PAACE\u4e3aLLM\u667a\u80fd\u4f53\u7684\u591a\u6b65\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ba1\u5212\u611f\u77e5\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u5b9e\u7528\u5316\u90e8\u7f72\uff0c\u89e3\u51b3\u4e86\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u96be\u9898\u3002"}}
{"id": "2512.17043", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17043", "abs": "https://arxiv.org/abs/2512.17043", "authors": ["Yinxu Tang", "Chengsong Huang", "Jiaxin Huang", "William Yeoh"], "title": "UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering", "comment": null, "summary": "Knowledge Graph Question Answering (KGQA) has traditionally focused on entity-centric queries that return a single answer entity. However, real-world queries are often relational, seeking to understand how entities are associated. In this work, we introduce relation-centric KGQA, a complementary setting where the answer is a subgraph capturing the semantic connections among entities rather than an individual entity. The main challenge lies in the abundance of candidate subgraphs, where trivial or overly common connections often obscure the identification of unique and informative answers. To tackle this, we propose UniRel-R1, a unified framework that integrates subgraph selection, multi-stage graph pruning, and an LLM fine-tuned with reinforcement learning. The reward function is designed to encourage compact and specific subgraphs with more informative relations and lower-degree intermediate entities. Extensive experiments show that UniRel-R1 achieves significant gains in connectivity and reward over Vanilla baselines and generalizes effectively to unseen entities and relations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5173\u7cfb\u4e2d\u5fc3\u7684\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u65b0\u8303\u5f0fUniRel-R1\uff0c\u901a\u8fc7\u5b50\u56fe\u9009\u62e9\u3001\u591a\u9636\u6bb5\u56fe\u526a\u679d\u548c\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03LLM\uff0c\u89e3\u51b3\u4f20\u7edf\u5b9e\u4f53\u4e2d\u5fc3\u95ee\u7b54\u65e0\u6cd5\u5904\u7406\u5173\u7cfb\u67e5\u8be2\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u4e3b\u8981\u5173\u6ce8\u8fd4\u56de\u5355\u4e2a\u7b54\u6848\u5b9e\u4f53\u7684\u5b9e\u4f53\u4e2d\u5fc3\u67e5\u8be2\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u67e5\u8be2\u901a\u5e38\u662f\u5173\u7cfb\u6027\u7684\uff0c\u9700\u8981\u7406\u89e3\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u8054\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u5173\u7cfb\u4e2d\u5fc3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faUniRel-R1\u7edf\u4e00\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u5b50\u56fe\u9009\u62e9\u3001\u591a\u9636\u6bb5\u56fe\u526a\u679d\u3001\u4ee5\u53ca\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u9f13\u52b1\u9009\u62e9\u7d27\u51d1\u4e14\u5177\u4f53\u7684\u5b50\u56fe\uff0c\u5305\u542b\u66f4\u591a\u4fe1\u606f\u6027\u5173\u7cfb\u548c\u4f4e\u5ea6\u4e2d\u95f4\u5b9e\u4f53\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cUniRel-R1\u5728\u8fde\u63a5\u6027\u548c\u5956\u52b1\u65b9\u9762\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u3002", "conclusion": "UniRel-R1\u6210\u529f\u89e3\u51b3\u4e86\u5173\u7cfb\u4e2d\u5fc3\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u6846\u67b6\u5904\u7406\u5019\u9009\u5b50\u56fe\u8fc7\u591a\u7684\u95ee\u9898\uff0c\u4e3a\u7406\u89e3\u5b9e\u4f53\u95f4\u8bed\u4e49\u8fde\u63a5\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.17066", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17066", "abs": "https://arxiv.org/abs/2512.17066", "authors": ["Suhaib Abdurahman", "Farzan Karimi-Malekabadi", "Chenxiao Yu", "Nour S. Kteily", "Morteza Dehghani"], "title": "Realistic threat perception drives intergroup conflict: A causal, dynamic analysis using generative-agent simulations", "comment": null, "summary": "Human conflict is often attributed to threats against material conditions and symbolic values, yet it remains unclear how they interact and which dominates. Progress is limited by weak causal control, ethical constraints, and scarce temporal data. We address these barriers using simulations of large language model (LLM)-driven agents in virtual societies, independently varying realistic and symbolic threat while tracking actions, language, and attitudes. Representational analyses show that the underlying LLM encodes realistic threat, symbolic threat, and hostility as distinct internal states, that our manipulations map onto them, and that steering these states causally shifts behavior. Our simulations provide a causal account of threat-driven conflict over time: realistic threat directly increases hostility, whereas symbolic threat effects are weaker, fully mediated by ingroup bias, and increase hostility only when realistic threat is absent. Non-hostile intergroup contact buffers escalation, and structural asymmetries concentrate hostility among majority groups.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u6a21\u62df\u793e\u4f1a\u51b2\u7a81\uff0c\u53d1\u73b0\u7269\u8d28\u5a01\u80c1\u76f4\u63a5\u589e\u52a0\u654c\u610f\uff0c\u800c\u8c61\u5f81\u6027\u5a01\u80c1\u4e3b\u8981\u901a\u8fc7\u5185\u7fa4\u4f53\u504f\u89c1\u95f4\u63a5\u5f71\u54cd\uff0c\u4e14\u53ea\u5728\u7269\u8d28\u5a01\u80c1\u7f3a\u5931\u65f6\u589e\u52a0\u654c\u610f\u3002", "motivation": "\u4eba\u7c7b\u51b2\u7a81\u901a\u5e38\u5f52\u56e0\u4e8e\u7269\u8d28\u6761\u4ef6\u548c\u8c61\u5f81\u6027\u4ef7\u503c\u89c2\u53d7\u5230\u7684\u5a01\u80c1\uff0c\u4f46\u4e24\u8005\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u4ee5\u53ca\u54ea\u4e2a\u5360\u4e3b\u5bfc\u5730\u4f4d\u5c1a\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u8fdb\u5c55\u53d7\u5230\u56e0\u679c\u63a7\u5236\u8584\u5f31\u3001\u4f26\u7406\u7ea6\u675f\u548c\u65f6\u95f4\u6570\u636e\u7a00\u7f3a\u7684\u9650\u5236\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5728\u865a\u62df\u793e\u4f1a\u4e2d\u6a21\u62df\uff0c\u72ec\u7acb\u53d8\u5316\u73b0\u5b9e\u5a01\u80c1\u548c\u8c61\u5f81\u6027\u5a01\u80c1\uff0c\u540c\u65f6\u8ffd\u8e2a\u884c\u52a8\u3001\u8bed\u8a00\u548c\u6001\u5ea6\u3002\u901a\u8fc7\u8868\u5f81\u5206\u6790\u7814\u7a76LLM\u5982\u4f55\u7f16\u7801\u8fd9\u4e9b\u72b6\u6001\uff0c\u5e76\u901a\u8fc7\u64cd\u7eb5\u8fd9\u4e9b\u72b6\u6001\u6765\u56e0\u679c\u6027\u5730\u6539\u53d8\u884c\u4e3a\u3002", "result": "LLM\u5c06\u73b0\u5b9e\u5a01\u80c1\u3001\u8c61\u5f81\u6027\u5a01\u80c1\u548c\u654c\u610f\u7f16\u7801\u4e3a\u4e0d\u540c\u7684\u5185\u90e8\u72b6\u6001\uff1b\u73b0\u5b9e\u5a01\u80c1\u76f4\u63a5\u589e\u52a0\u654c\u610f\uff0c\u800c\u8c61\u5f81\u6027\u5a01\u80c1\u6548\u5e94\u8f83\u5f31\uff0c\u5b8c\u5168\u901a\u8fc7\u5185\u7fa4\u4f53\u504f\u89c1\u4e2d\u4ecb\uff0c\u4e14\u53ea\u5728\u73b0\u5b9e\u5a01\u80c1\u7f3a\u5931\u65f6\u589e\u52a0\u654c\u610f\uff1b\u975e\u654c\u610f\u7684\u7fa4\u4f53\u95f4\u63a5\u89e6\u80fd\u7f13\u51b2\u51b2\u7a81\u5347\u7ea7\uff0c\u7ed3\u6784\u6027\u4e0d\u5bf9\u79f0\u4f7f\u654c\u610f\u96c6\u4e2d\u5728\u591a\u6570\u7fa4\u4f53\u4e2d\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5a01\u80c1\u9a71\u52a8\u51b2\u7a81\u7684\u56e0\u679c\u89e3\u91ca\u6846\u67b6\uff0c\u533a\u5206\u4e86\u73b0\u5b9e\u5a01\u80c1\u548c\u8c61\u5f81\u6027\u5a01\u80c1\u7684\u4e0d\u540c\u4f5c\u7528\u673a\u5236\uff0c\u4e3a\u7406\u89e3\u793e\u4f1a\u51b2\u7a81\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u7684\u6a21\u62df\u65b9\u6cd5\u5b66\u89c6\u89d2\u3002"}}
{"id": "2512.17086", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17086", "abs": "https://arxiv.org/abs/2512.17086", "authors": ["Cole Wyeth", "Marcus Hutter"], "title": "Value Under Ignorance in Universal Artificial Intelligence", "comment": null, "summary": "We generalize the AIXI reinforcement learning agent to admit a wider class of utility functions. Assigning a utility to each possible interaction history forces us to confront the ambiguity that some hypotheses in the agent's belief distribution only predict a finite prefix of the history, which is sometimes interpreted as implying a chance of death equal to a quantity called the semimeasure loss. This death interpretation suggests one way to assign utilities to such history prefixes. We argue that it is as natural to view the belief distributions as imprecise probability distributions, with the semimeasure loss as total ignorance. This motivates us to consider the consequences of computing expected utilities with Choquet integrals from imprecise probability theory, including an investigation of their computability level. We recover the standard recursive value function as a special case. However, our most general expected utilities under the death interpretation cannot be characterized as such Choquet integrals.", "AI": {"tldr": "\u5c06AIXI\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u6548\u7528\u51fd\u6570\u7c7b\u522b\uff0c\u901a\u8fc7\u5904\u7406\u4fe1\u5ff5\u5206\u5e03\u4e2d\u53ea\u80fd\u9884\u6d4b\u6709\u9650\u5386\u53f2\u524d\u7f00\u7684\u5047\u8bbe\uff0c\u63a2\u8ba8\u4e86\u534a\u6d4b\u5ea6\u635f\u5931\u4f5c\u4e3a\u6b7b\u4ea1\u6982\u7387\u6216\u5b8c\u5168\u65e0\u77e5\u7684\u4e0d\u540c\u89e3\u91ca\uff0c\u5e76\u7814\u7a76\u4e86\u4f7f\u7528Choquet\u79ef\u5206\u8ba1\u7b97\u671f\u671b\u6548\u7528\u7684\u8ba1\u7b97\u6027", "motivation": "AIXI\u667a\u80fd\u4f53\u901a\u5e38\u5047\u8bbe\u6548\u7528\u51fd\u6570\u5b9a\u4e49\u5728\u5b8c\u6574\u4ea4\u4e92\u5386\u53f2\u4e0a\uff0c\u4f46\u5b9e\u9645\u4e2d\u8bb8\u591a\u5047\u8bbe\u53ea\u80fd\u9884\u6d4b\u6709\u9650\u5386\u53f2\u524d\u7f00\uff0c\u8fd9\u5bfc\u81f4\u534a\u6d4b\u5ea6\u635f\u5931\u95ee\u9898\u3002\u9700\u8981\u89e3\u51b3\u5982\u4f55\u4e3a\u8fd9\u4e9b\u6709\u9650\u5386\u53f2\u5206\u914d\u6548\u7528\uff0c\u5e76\u63a2\u8ba8\u534a\u6d4b\u5ea6\u635f\u5931\u7684\u4e0d\u540c\u89e3\u91ca\uff08\u6b7b\u4ea1\u6982\u7387vs\u5b8c\u5168\u65e0\u77e5\uff09", "method": "\u5c06AIXI\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u6548\u7528\u51fd\u6570\u7c7b\u522b\uff1b\u4f7f\u7528\u4e0d\u7cbe\u786e\u6982\u7387\u7406\u8bba\u4e2d\u7684Choquet\u79ef\u5206\u8ba1\u7b97\u671f\u671b\u6548\u7528\uff1b\u5206\u6790\u4e0d\u540c\u89e3\u91ca\u4e0b\uff08\u6b7b\u4ea1\u89e3\u91cavs\u5b8c\u5168\u65e0\u77e5\uff09\u7684\u6548\u7528\u5206\u914d\u65b9\u6cd5\uff1b\u7814\u7a76\u8fd9\u4e9b\u65b9\u6cd5\u7684\u53ef\u8ba1\u7b97\u6027\u6c34\u5e73", "result": "\u6807\u51c6\u9012\u5f52\u503c\u51fd\u6570\u53ef\u4ee5\u4f5c\u4e3aChoquet\u79ef\u5206\u7684\u7279\u4f8b\u6062\u590d\uff1b\u5728\u6b7b\u4ea1\u89e3\u91ca\u4e0b\u6700\u4e00\u822c\u7684\u671f\u671b\u6548\u7528\u4e0d\u80fd\u8868\u5f81\u4e3aChoquet\u79ef\u5206\uff1b\u63a2\u8ba8\u4e86\u4e0d\u540c\u65b9\u6cd5\u5728\u53ef\u8ba1\u7b97\u6027\u65b9\u9762\u7684\u7279\u6027", "conclusion": "\u901a\u8fc7\u63a8\u5e7fAIXI\u667a\u80fd\u4f53\u4ee5\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u6548\u7528\u51fd\u6570\uff0c\u5e76\u5229\u7528\u4e0d\u7cbe\u786e\u6982\u7387\u7406\u8bba\u4e2d\u7684Choquet\u79ef\u5206\uff0c\u4e3a\u5904\u7406\u6709\u9650\u5386\u53f2\u9884\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4f46\u6b7b\u4ea1\u89e3\u91ca\u4e0b\u7684\u6700\u4e00\u822c\u671f\u671b\u6548\u7528\u9700\u8981\u5176\u4ed6\u6570\u5b66\u5de5\u5177"}}
{"id": "2512.17093", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.17093", "abs": "https://arxiv.org/abs/2512.17093", "authors": ["Timo Pierre Schrader", "Lukas Lange", "Tobias Kaminski", "Simon Razniewski", "Annemarie Friedrich"], "title": "A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving", "comment": "15 pages, 7 figures, accepted at AAAI'26", "summary": "The rise of large language models (LLMs) has sparked interest in coding assistants. While general-purpose programming languages are well supported, generating code for domain-specific languages remains a challenging problem for LLMs. In this paper, we focus on the LLM-based generation of code for Answer Set Programming (ASP), a particularly effective approach for finding solutions to combinatorial search problems. The effectiveness of LLMs in ASP code generation is currently hindered by the limited number of examples seen during their initial pre-training phase.\n  In this paper, we introduce a novel ASP-solver-in-the-loop approach for solver-guided instruction-tuning of LLMs to addressing the highly complex semantic parsing task inherent in ASP code generation. Our method only requires problem specifications in natural language and their solutions. Specifically, we sample ASP statements for program continuations from LLMs for unriddling logic puzzles. Leveraging the special property of declarative ASP programming that partial encodings increasingly narrow down the solution space, we categorize them into chosen and rejected instances based on solver feedback. We then apply supervised fine-tuning to train LLMs on the curated data and further improve robustness using a solver-guided search that includes best-of-N sampling. Our experiments demonstrate consistent improvements in two distinct prompting settings on two datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdASP\u6c42\u89e3\u5668\u5728\u73af\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6c42\u89e3\u5668\u5f15\u5bfc\u7684\u6307\u4ee4\u5fae\u8c03\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7b54\u6848\u96c6\u7f16\u7a0b\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u4ec5\u9700\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u548c\u89e3\u51b3\u65b9\u6848\u5373\u53ef\u8bad\u7ec3\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528\u7f16\u7a0b\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08\u5982\u7b54\u6848\u96c6\u7f16\u7a0bASP\uff09\u7684\u4ee3\u7801\u751f\u6210\u4e0a\u4ecd\u9762\u4e34\u6311\u6218\u3002ASP\u662f\u4e00\u79cd\u89e3\u51b3\u7ec4\u5408\u641c\u7d22\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f46LLMs\u5728ASP\u4ee3\u7801\u751f\u6210\u4e0a\u7684\u6548\u679c\u53d7\u5230\u9884\u8bad\u7ec3\u9636\u6bb5\u6240\u89c1\u793a\u4f8b\u6570\u91cf\u6709\u9650\u7684\u9650\u5236\u3002", "method": "\u63d0\u51faASP\u6c42\u89e3\u5668\u5728\u73af\u7684\u65b9\u6cd5\u8fdb\u884c\u6c42\u89e3\u5668\u5f15\u5bfc\u7684\u6307\u4ee4\u5fae\u8c03\u3002\u65b9\u6cd5\u4ec5\u9700\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u53ca\u5176\u89e3\u51b3\u65b9\u6848\uff1a1\uff09\u4eceLLMs\u91c7\u6837ASP\u8bed\u53e5\u4f5c\u4e3a\u7a0b\u5e8f\u5ef6\u7eed\uff1b2\uff09\u5229\u7528ASP\u58f0\u660e\u5f0f\u7f16\u7a0b\u7684\u7279\u6027\uff08\u90e8\u5206\u7f16\u7801\u9010\u6b65\u7f29\u5c0f\u89e3\u7a7a\u95f4\uff09\uff0c\u57fa\u4e8e\u6c42\u89e3\u5668\u53cd\u9988\u5c06\u91c7\u6837\u5206\u4e3a\u63a5\u53d7\u548c\u62d2\u7edd\u5b9e\u4f8b\uff1b3\uff09\u5bf9\u7b5b\u9009\u6570\u636e\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff1b4\uff09\u4f7f\u7528\u6c42\u89e3\u5668\u5f15\u5bfc\u7684\u641c\u7d22\uff08\u5305\u62ec\u6700\u4f73N\u91c7\u6837\uff09\u8fdb\u4e00\u6b65\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e24\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u8bbe\u7f6e\u548c\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u4e86\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7ASP\u6c42\u89e3\u5668\u5728\u73af\u7684\u6307\u4ee4\u5fae\u8c03\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347LLMs\u5728ASP\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u7684\u6311\u6218\u3002"}}
{"id": "2512.17102", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17102", "abs": "https://arxiv.org/abs/2512.17102", "authors": ["Jiongxiao Wang", "Qiaojing Yan", "Yawei Wang", "Yijun Tian", "Soumya Smruti Mishra", "Zhichao Xu", "Megha Gandhi", "Panpan Xu", "Lin Lee Cheong"], "title": "Reinforcement Learning for Self-Improving Agent with Skill Library", "comment": null, "summary": "Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in complex reasoning and multi-turn interactions but struggle to continuously improve and adapt when deployed in new environments. One promising approach is implementing skill libraries that allow agents to learn, validate, and apply new skills. However, current skill library approaches rely primarily on LLM prompting, making consistent skill library implementation challenging. To overcome these challenges, we propose a Reinforcement Learning (RL)-based approach to enhance agents' self-improvement capabilities with a skill library. Specifically, we introduce Skill Augmented GRPO for self-Evolution (SAGE), a novel RL framework that systematically incorporates skills into learning. The framework's key component, Sequential Rollout, iteratively deploys agents across a chain of similar tasks for each rollout. As agents navigate through the task chain, skills generated from previous tasks accumulate in the library and become available for subsequent tasks. Additionally, the framework enhances skill generation and utilization through a Skill-integrated Reward that complements the original outcome-based rewards. Experimental results on AppWorld demonstrate that SAGE, when applied to supervised-finetuned model with expert experience, achieves 8.9% higher Scenario Goal Completion while requiring 26% fewer interaction steps and generating 59% fewer tokens, substantially outperforming existing approaches in both accuracy and efficiency.", "AI": {"tldr": "SAGE\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6280\u80fd\u5e93\u589e\u5f3aLLM\u667a\u80fd\u4f53\u7684\u81ea\u6211\u8fdb\u5316\u80fd\u529b\uff0c\u5728AppWorld\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u76ee\u6807\u5b8c\u6210\u7387\u5e76\u51cf\u5c11\u4e86\u4ea4\u4e92\u6b65\u9aa4\u548ctoken\u6d88\u8017\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u63a8\u7406\u548c\u591a\u8f6e\u4ea4\u4e92\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u65b0\u73af\u5883\u4e2d\u90e8\u7f72\u65f6\u96be\u4ee5\u6301\u7eed\u6539\u8fdb\u548c\u9002\u5e94\u3002\u73b0\u6709\u7684\u6280\u80fd\u5e93\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56LLM\u63d0\u793a\uff0c\u96be\u4ee5\u5b9e\u73b0\u4e00\u81f4\u7684\u6280\u80fd\u5e93\u5b9e\u65bd\u3002", "method": "\u63d0\u51faSAGE\uff08Skill Augmented GRPO for self-Evolution\uff09\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7Sequential Rollout\u673a\u5236\u5728\u76f8\u4f3c\u4efb\u52a1\u94fe\u4e2d\u8fed\u4ee3\u90e8\u7f72\u667a\u80fd\u4f53\uff0c\u8ba9\u5148\u524d\u4efb\u52a1\u751f\u6210\u7684\u6280\u80fd\u79ef\u7d2f\u5230\u5e93\u4e2d\u4f9b\u540e\u7eed\u4efb\u52a1\u4f7f\u7528\uff0c\u5e76\u901a\u8fc7Skill-integrated Reward\u589e\u5f3a\u6280\u80fd\u751f\u6210\u548c\u5229\u7528\u3002", "result": "\u5728AppWorld\u5b9e\u9a8c\u4e2d\uff0cSAGE\u5e94\u7528\u4e8e\u6709\u4e13\u5bb6\u7ecf\u9a8c\u7684\u76d1\u7763\u5fae\u8c03\u6a21\u578b\uff0c\u5b9e\u73b0\u4e868.9%\u66f4\u9ad8\u7684\u573a\u666f\u76ee\u6807\u5b8c\u6210\u7387\uff0c\u540c\u65f6\u9700\u8981\u51cf\u5c1126%\u7684\u4ea4\u4e92\u6b65\u9aa4\u548c\u751f\u621059%\u66f4\u5c11\u7684token\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SAGE\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u589e\u5f3a\u4e86LLM\u667a\u80fd\u4f53\u7684\u81ea\u6211\u6539\u8fdb\u80fd\u529b\uff0c\u901a\u8fc7\u6280\u80fd\u5e93\u548c\u987a\u5e8f\u90e8\u7f72\u673a\u5236\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u4efb\u52a1\u5b8c\u6210\uff0c\u4e3a\u667a\u80fd\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6301\u7eed\u9002\u5e94\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.17145", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.17145", "abs": "https://arxiv.org/abs/2512.17145", "authors": ["Josh Barber", "Rourke Young", "Cameron Coombe", "Will Browne"], "title": "Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty", "comment": "10 pages, ACRA 2025, Submitted, Accepted and Presented", "summary": "Reasoning under uncertainty is a key challenge in AI, especially for real-world tasks, where problems with sparse data demands systematic generalisation. Existing approaches struggle to balance accuracy and simplicity when evaluating multiple candidate solutions. We propose a Solomonoff-inspired method that weights LLM-generated hypotheses by simplicity and predictive fit. Applied to benchmark (Mini-ARC) tasks, our method produces Solomonoff-weighted mixtures for per-cell predictions, yielding conservative, uncertainty-aware outputs even when hypotheses are noisy or partially incorrect. Compared to Bayesian Model Averaging (BMA), Solomonoff scoring spreads probability more evenly across competing hypotheses, while BMA concentrates weight on the most likely but potentially flawed candidates. Across tasks, this highlights the value of algorithmic information-theoretic priors for interpretable, reliable multi-hypothesis reasoning under uncertainty.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6240\u7f57\u95e8\u8bfa\u592b\u7406\u8bba\u7684LLM\u5047\u8bbe\u52a0\u6743\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u6d01\u6027\u548c\u9884\u6d4b\u62df\u5408\u5ea6\u8bc4\u4f30\u591a\u4e2a\u5019\u9009\u89e3\uff0c\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u5b9e\u73b0\u66f4\u5e73\u8861\u7684\u6982\u7387\u5206\u5e03", "motivation": "\u73b0\u5b9e\u4e16\u754cAI\u4efb\u52a1\u4e2d\uff0c\u7a00\u758f\u6570\u636e\u4e0b\u7684\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u662f\u6838\u5fc3\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u51c6\u786e\u6027\u548c\u7b80\u6d01\u6027\u4e4b\u95f4\u5e73\u8861\u8bc4\u4f30\u591a\u4e2a\u5019\u9009\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fa\u6240\u7f57\u95e8\u8bfa\u592b\u542f\u53d1\u7684\u65b9\u6cd5\uff0c\u5bf9LLM\u751f\u6210\u7684\u5047\u8bbe\u6309\u7b80\u6d01\u6027\u548c\u9884\u6d4b\u62df\u5408\u5ea6\u8fdb\u884c\u52a0\u6743\uff0c\u5e94\u7528\u4e8eMini-ARC\u57fa\u51c6\u4efb\u52a1\uff0c\u751f\u6210\u6bcf\u4e2a\u5355\u5143\u683c\u9884\u6d4b\u7684\u6240\u7f57\u95e8\u8bfa\u592b\u52a0\u6743\u6df7\u5408", "result": "\u76f8\u6bd4\u8d1d\u53f6\u65af\u6a21\u578b\u5e73\u5747\uff0c\u6240\u7f57\u95e8\u8bfa\u592b\u8bc4\u5206\u5728\u7ade\u4e89\u5047\u8bbe\u95f4\u66f4\u5747\u5300\u5730\u5206\u5e03\u6982\u7387\uff0c\u800cBMA\u96c6\u4e2d\u5728\u6700\u53ef\u80fd\u4f46\u53ef\u80fd\u6709\u7f3a\u9677\u7684\u5019\u9009\u4e0a\uff0c\u4ea7\u751f\u4fdd\u5b88\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u8f93\u51fa", "conclusion": "\u7b97\u6cd5\u4fe1\u606f\u8bba\u5148\u9a8c\u5bf9\u4e8e\u53ef\u89e3\u91ca\u3001\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4e0b\u591a\u5047\u8bbe\u63a8\u7406\u5177\u6709\u91cd\u8981\u4ef7\u503c"}}
{"id": "2512.17194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17194", "abs": "https://arxiv.org/abs/2512.17194", "authors": ["Shengwei Zhao", "Jingwen Yao", "Sitong Wei", "Linhai Xu", "Yuying Liu", "Dong Zhang", "Zhiqiang Tian", "Shaoyi Du"], "title": "MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation", "comment": "This paper was accepted to AAAI2026", "summary": "Multi-modal Retrieval-Augmented Generation (MMRAG) enables highly credible generation by integrating external multi-modal knowledge, thus demonstrating impressive performance in complex multi-modal scenarios. However, existing MMRAG methods fail to clarify the reasoning logic behind retrieval and response generation, which limits the explainability of the results. To address this gap, we propose to introduce reinforcement learning into multi-modal retrieval-augmented generation, enhancing the reasoning capabilities of multi-modal large language models through a two-stage reinforcement fine-tuning framework to achieve explainable multi-modal retrieval-augmented generation. Specifically, in the first stage, rule-based reinforcement fine-tuning is employed to perform coarse-grained point-wise ranking of multi-modal documents, effectively filtering out those that are significantly irrelevant. In the second stage, reasoning-based reinforcement fine-tuning is utilized to jointly optimize fine-grained list-wise ranking and answer generation, guiding multi-modal large language models to output explainable reasoning logic in the MMRAG process. Our method achieves state-of-the-art results on WebQA and MultimodalQA, two benchmark datasets for multi-modal retrieval-augmented generation, and its effectiveness is validated through comprehensive ablation experiments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03\u6846\u67b6\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728WebQA\u548cMultimodalQA\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709MMRAG\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u68c0\u7d22\u548c\u54cd\u5e94\u751f\u6210\u80cc\u540e\u63a8\u7406\u903b\u8f91\u7684\u89e3\u91ca\uff0c\u9650\u5236\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u7f3a\u9677\uff0c\u4f5c\u8005\u63d0\u51fa\u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u6765\u589e\u5f3a\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5fae\u8c03\u5bf9\u591a\u6a21\u6001\u6587\u6863\u8fdb\u884c\u7c97\u7c92\u5ea6\u7684\u70b9\u5f0f\u6392\u5e8f\uff0c\u8fc7\u6ee4\u663e\u8457\u4e0d\u76f8\u5173\u7684\u6587\u6863\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u57fa\u4e8e\u63a8\u7406\u7684\u5f3a\u5316\u5fae\u8c03\u8054\u5408\u4f18\u5316\u7ec6\u7c92\u5ea6\u7684\u5217\u8868\u5f0f\u6392\u5e8f\u548c\u7b54\u6848\u751f\u6210\uff0c\u5f15\u5bfc\u6a21\u578b\u8f93\u51fa\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u903b\u8f91\u3002", "result": "\u5728WebQA\u548cMultimodalQA\u4e24\u4e2a\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u5168\u9762\u7684\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u89e3\u91caMMRAG\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u4e3a\u590d\u6742\u591a\u6a21\u6001\u573a\u666f\u63d0\u4f9b\u4e86\u66f4\u53ef\u4fe1\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.17196", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17196", "abs": "https://arxiv.org/abs/2512.17196", "authors": ["Kai Liu", "Leyang Chen", "Wenbo Li", "Zhikai Chen", "Zhixin Wang", "Renjing Pei", "Linghe Kong", "Yulun Zhang"], "title": "UmniBench: Unified Understand and Generation Model Oriented Omni-dimensional Benchmark", "comment": "Project Page: https://umnibench.github.io/", "summary": "Unifying multimodal understanding and generation has shown impressive capabilities in cutting-edge proprietary systems. However, evaluations of unified multimodal models (UMMs) remain decoupled, assessing their understanding and generation abilities separately with corresponding datasets. To address this, we propose UmniBench, a benchmark tailored for UMMs with omni-dimensional evaluation. First, UmniBench can assess the understanding, generation, and editing ability within a single evaluation process. Based on human-examined prompts and QA pairs, UmniBench leverages UMM itself to evaluate its generation and editing ability with its understanding ability. This simple but effective paradigm allows comprehensive evaluation of UMMs. Second, UmniBench covers 13 major domains and more than 200 concepts, ensuring a thorough inspection of UMMs. Moreover, UmniBench can also decouple and separately evaluate understanding, generation, and editing abilities, providing a fine-grained assessment. Based on UmniBench, we benchmark 24 popular models, including both UMMs and single-ability large models. We hope this benchmark provides a more comprehensive and objective view of unified models and logistical support for improving the performance of the community model.", "AI": {"tldr": "UmniBench\u662f\u4e00\u4e2a\u9488\u5bf9\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\uff08UMMs\uff09\u7684\u5168\u7ef4\u5ea6\u8bc4\u4f30\u57fa\u51c6\uff0c\u80fd\u591f\u5728\u5355\u4e00\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u540c\u65f6\u6d4b\u8bd5\u7406\u89e3\u3001\u751f\u6210\u548c\u7f16\u8f91\u80fd\u529b\uff0c\u8986\u76d613\u4e2a\u4e3b\u8981\u9886\u57df\u548c200\u591a\u4e2a\u6982\u5ff5\u3002", "motivation": "\u5f53\u524d\u5bf9\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u7684\u8bc4\u4f30\u662f\u5206\u79bb\u7684\uff0c\u5206\u522b\u8bc4\u4f30\u5176\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u7f3a\u4e4f\u4e00\u4e2a\u7efc\u5408\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5168\u9762\u8bc4\u4f30UMMs\u5404\u65b9\u9762\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "UmniBench\u5229\u7528\u4eba\u7c7b\u68c0\u67e5\u7684\u63d0\u793a\u548c\u95ee\u7b54\u5bf9\uff0c\u901a\u8fc7UMM\u81ea\u8eab\u7684\u7406\u89e3\u80fd\u529b\u6765\u8bc4\u4f30\u5176\u751f\u6210\u548c\u7f16\u8f91\u80fd\u529b\u3002\u8fd9\u79cd\u7b80\u5355\u6709\u6548\u7684\u8303\u5f0f\u5141\u8bb8\u5728\u5355\u4e00\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u540c\u65f6\u6d4b\u8bd5\u7406\u89e3\u3001\u751f\u6210\u548c\u7f16\u8f91\u4e09\u4e2a\u7ef4\u5ea6\u3002", "result": "\u57fa\u4e8eUmniBench\u5bf924\u4e2a\u6d41\u884c\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ecUMMs\u548c\u5355\u80fd\u529b\u5927\u6a21\u578b\u3002\u8be5\u57fa\u51c6\u63d0\u4f9b\u4e86\u5bf9\u7edf\u4e00\u6a21\u578b\u66f4\u5168\u9762\u5ba2\u89c2\u7684\u8bc4\u4f30\u89c6\u89d2\uff0c\u5e76\u4e3a\u793e\u533a\u6a21\u578b\u6027\u80fd\u6539\u8fdb\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "conclusion": "UmniBench\u4e3a\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u3001\u5ba2\u89c2\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u8bc4\u4f30\u7406\u89e3\u3001\u751f\u6210\u548c\u7f16\u8f91\u80fd\u529b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u793e\u533a\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.17266", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17266", "abs": "https://arxiv.org/abs/2512.17266", "authors": ["Miru Hong", "Minho Lee", "Geonhee Jo", "Jae-Hee So", "Pascal Bauer", "Sang-Ki Ko"], "title": "ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework", "comment": "8 pages, 2 figures, 7 tables. To appear in Hudl Performance Insights 2025", "summary": "Transfers play a pivotal role in shaping a football club's success, yet forecasting whether a transfer will succeed remains difficult due to the strong context-dependence of on-field performance. Existing evaluation practices often rely on static summary statistics or post-hoc value models, which fail to capture how a player's contribution adapts to a new tactical environment or different teammates. To address this gap, we introduce EventGPT, a player-conditioned, value-aware next-event prediction model built on a GPT-style autoregressive transformer. Our model treats match play as a sequence of discrete tokens, jointly learning to predict the next on-ball action's type, location, timing, and its estimated residual On-Ball Value (rOBV) based on the preceding context and player identity. A key contribution of this framework is the ability to perform counterfactual simulations. By substituting learned player embeddings into new event sequences, we can simulate how a player's behavioral distribution and value profile would change when placed in a different team or tactical structure. Evaluated on five seasons of Premier League event data, EventGPT outperforms existing sequence-based baselines in next-event prediction accuracy and spatial precision. Furthermore, we demonstrate the model's practical utility for transfer analysis through case studies-such as comparing striker performance across different systems and identifying stylistic replacements for specific roles-showing that our approach provides a principled method for evaluating transfer fit.", "AI": {"tldr": "EventGPT\uff1a\u57fa\u4e8eGPT\u67b6\u6784\u7684\u7403\u5458\u6761\u4ef6\u5316\u4ef7\u503c\u611f\u77e5\u4e0b\u4e00\u4e8b\u4ef6\u9884\u6d4b\u6a21\u578b\uff0c\u7528\u4e8e\u8db3\u7403\u8f6c\u4f1a\u5206\u6790\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6a21\u62df\u8bc4\u4f30\u7403\u5458\u5728\u4e0d\u540c\u6218\u672f\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u8f6c\u4f1a\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u7edf\u8ba1\u6570\u636e\u6216\u4e8b\u540e\u4ef7\u503c\u6a21\u578b\uff0c\u65e0\u6cd5\u6355\u6349\u7403\u5458\u5728\u65b0\u6218\u672f\u73af\u5883\u6216\u4e0d\u540c\u961f\u53cb\u914d\u5408\u4e0b\u7684\u9002\u5e94\u6027\u53d8\u5316\u3002\u8db3\u7403\u4ff1\u4e50\u90e8\u6210\u529f\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u8f6c\u4f1a\u51b3\u7b56\uff0c\u4f46\u9884\u6d4b\u8f6c\u4f1a\u662f\u5426\u6210\u529f\u4ecd\u7136\u56f0\u96be\uff0c\u56e0\u4e3a\u573a\u4e0a\u8868\u73b0\u5177\u6709\u5f3a\u70c8\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u3002", "method": "\u63d0\u51faEventGPT\u6a21\u578b\uff0c\u57fa\u4e8eGPT\u98ce\u683c\u7684\u81ea\u56de\u5f52transformer\u67b6\u6784\uff0c\u5c06\u6bd4\u8d5b\u89c6\u4e3a\u79bb\u6563token\u5e8f\u5217\uff0c\u8054\u5408\u9884\u6d4b\u4e0b\u4e00\u6301\u7403\u52a8\u4f5c\u7684\u7c7b\u578b\u3001\u4f4d\u7f6e\u3001\u65f6\u95f4\u53ca\u5176\u4f30\u8ba1\u7684\u6b8b\u5dee\u6301\u7403\u4ef7\u503c(rOBV)\u3002\u6a21\u578b\u5b66\u4e60\u7403\u5458\u5d4c\u5165\u8868\u793a\uff0c\u80fd\u591f\u901a\u8fc7\u66ff\u6362\u7403\u5458\u5d4c\u5165\u5230\u65b0\u4e8b\u4ef6\u5e8f\u5217\u4e2d\u8fdb\u884c\u53cd\u4e8b\u5b9e\u6a21\u62df\u3002", "result": "\u5728\u4e94\u4e2a\u8d5b\u5b63\u7684\u82f1\u8d85\u8054\u8d5b\u4e8b\u4ef6\u6570\u636e\u4e0a\u8bc4\u4f30\uff0cEventGPT\u5728\u4e0b\u4e00\u4e8b\u4ef6\u9884\u6d4b\u51c6\u786e\u6027\u548c\u7a7a\u95f4\u7cbe\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5e8f\u5217\u7684\u57fa\u7ebf\u6a21\u578b\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6a21\u578b\u5728\u8f6c\u4f1a\u5206\u6790\u4e2d\u7684\u5b9e\u9645\u6548\u7528\uff0c\u5982\u6bd4\u8f83\u4e0d\u540c\u4f53\u7cfb\u4e0b\u524d\u950b\u8868\u73b0\uff0c\u8bc6\u522b\u7279\u5b9a\u89d2\u8272\u7684\u98ce\u683c\u66ff\u4ee3\u8005\u3002", "conclusion": "EventGPT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u8f6c\u4f1a\u5339\u914d\u5ea6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6a21\u62df\u80fd\u591f\u9884\u6d4b\u7403\u5458\u5728\u4e0d\u540c\u7403\u961f\u6216\u6218\u672f\u7ed3\u6784\u4e2d\u7684\u884c\u4e3a\u5206\u5e03\u548c\u4ef7\u503c\u53d8\u5316\uff0c\u4e3a\u8f6c\u4f1a\u51b3\u7b56\u63d0\u4f9b\u66f4\u79d1\u5b66\u7684\u4f9d\u636e\u3002"}}
{"id": "2512.17308", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.17308", "abs": "https://arxiv.org/abs/2512.17308", "authors": ["Daksh Jain", "Aarya Jain", "Ashutosh Desai", "Avyakt Verma", "Ishan Bhanuka", "Pratik Narang", "Dhruv Kumar"], "title": "Large Language Models as Pok\u00e9mon Battle Agents: Strategic Play and Content Generation", "comment": "Under Review", "summary": "Strategic decision-making in Pok\u00e9mon battles presents a unique testbed for evaluating large language models. Pok\u00e9mon battles demand reasoning about type matchups, statistical trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language Models (LLMs) can serve as competent battle agents, capable of both making tactically sound decisions and generating novel, balanced game content. We developed a turn-based Pok\u00e9mon battle system where LLMs select moves based on battle state rather than pre-programmed logic. The framework captures essential Pok\u00e9mon mechanics: type effectiveness multipliers, stat-based damage calculations, and multi-Pok\u00e9mon team management. Through systematic evaluation across multiple model architectures we measured win rates, decision latency, type-alignment accuracy, and token efficiency. These results suggest LLMs can function as dynamic game opponents without domain-specific training, offering a practical alternative to reinforcement learning for turn-based strategic games. The dual capability of tactical reasoning and content creation, positions LLMs as both players and designers, with implications for procedural generation and adaptive difficulty systems in interactive entertainment.", "AI": {"tldr": "LLMs\u5728\u5b9d\u53ef\u68a6\u5bf9\u6218\u4e2d\u88ab\u8bc4\u4f30\u4e3a\u6218\u7565\u51b3\u7b56\u8005\uff0c\u65e2\u80fd\u505a\u51fa\u6218\u672f\u51b3\u7b56\u53c8\u80fd\u751f\u6210\u5e73\u8861\u7684\u6e38\u620f\u5185\u5bb9\uff0c\u65e0\u9700\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u5373\u53ef\u4f5c\u4e3a\u52a8\u6001\u6e38\u620f\u5bf9\u624b\u3002", "motivation": "\u5b9d\u53ef\u68a6\u5bf9\u6218\u9700\u8981\u7c7b\u578b\u5339\u914d\u3001\u7edf\u8ba1\u6743\u8861\u548c\u98ce\u9669\u8bc4\u4f30\u7b49\u6218\u7565\u601d\u7ef4\uff0c\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6218\u7565\u51b3\u7b56\u80fd\u529b\u63d0\u4f9b\u4e86\u72ec\u7279\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u56de\u5408\u7684\u5b9d\u53ef\u68a6\u5bf9\u6218\u7cfb\u7edf\uff0cLLMs\u6839\u636e\u6218\u6597\u72b6\u6001\u9009\u62e9\u62db\u5f0f\u800c\u975e\u9884\u7f16\u7a0b\u903b\u8f91\uff0c\u7cfb\u7edf\u5305\u542b\u7c7b\u578b\u6548\u679c\u4e58\u6570\u3001\u57fa\u4e8e\u7edf\u8ba1\u7684\u4f24\u5bb3\u8ba1\u7b97\u548c\u591a\u5b9d\u53ef\u68a6\u961f\u4f0d\u7ba1\u7406\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6a21\u578b\u67b6\u6784\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u6d4b\u91cf\u4e86\u80dc\u7387\u3001\u51b3\u7b56\u5ef6\u8fdf\u3001\u7c7b\u578b\u5bf9\u9f50\u51c6\u786e\u6027\u548c\u4ee4\u724c\u6548\u7387\uff0c\u7ed3\u679c\u8868\u660eLLMs\u65e0\u9700\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u5373\u53ef\u4f5c\u4e3a\u52a8\u6001\u6e38\u620f\u5bf9\u624b\u3002", "conclusion": "LLMs\u517c\u5177\u6218\u672f\u63a8\u7406\u548c\u5185\u5bb9\u521b\u9020\u7684\u53cc\u91cd\u80fd\u529b\uff0c\u65e2\u80fd\u4f5c\u4e3a\u73a9\u5bb6\u53c8\u80fd\u4f5c\u4e3a\u8bbe\u8ba1\u5e08\uff0c\u5bf9\u4ea4\u4e92\u5a31\u4e50\u4e2d\u7684\u7a0b\u5e8f\u751f\u6210\u548c\u81ea\u9002\u5e94\u96be\u5ea6\u7cfb\u7edf\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.17373", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17373", "abs": "https://arxiv.org/abs/2512.17373", "authors": ["Zhengmian Hu"], "title": "Dialectics for Artificial Intelligence", "comment": null, "summary": "Can artificial intelligence discover, from raw experience and without human supervision, concepts that humans have discovered? One challenge is that human concepts themselves are fluid: conceptual boundaries can shift, split, and merge as inquiry progresses (e.g., Pluto is no longer considered a planet). To make progress, we need a definition of \"concept\" that is not merely a dictionary label, but a structure that can be revised, compared, and aligned across agents. We propose an algorithmic-information viewpoint that treats a concept as an information object defined only through its structural relation to an agent's total experience. The core constraint is determination: a set of parts forms a reversible consistency relation if any missing part is recoverable from the others (up to the standard logarithmic slack in Kolmogorov-style identities). This reversibility prevents \"concepts\" from floating free of experience and turns concept existence into a checkable structural claim. To judge whether a decomposition is natural, we define excess information, measuring the redundancy overhead introduced by splitting experience into multiple separately described parts. On top of these definitions, we formulate dialectics as an optimization dynamics: as new patches of information appear (or become contested), competing concepts bid to explain them via shorter conditional descriptions, driving systematic expansion, contraction, splitting, and merging. Finally, we formalize low-cost concept transmission and multi-agent alignment using small grounds/seeds that allow another agent to reconstruct the same concept under a shared protocol, making communication a concrete compute-bits trade-off.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u7b97\u6cd5\u4fe1\u606f\u8bba\u89d2\u5ea6\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u5ff5\u5b9a\u4e49\u6846\u67b6\uff0c\u5c06\u6982\u5ff5\u89c6\u4e3a\u4e0e\u667a\u80fd\u4f53\u6574\u4f53\u7ecf\u9a8c\u76f8\u5173\u7684\u4fe1\u606f\u5bf9\u8c61\uff0c\u901a\u8fc7\u53ef\u9006\u4e00\u81f4\u6027\u5173\u7cfb\u548c\u5197\u4f59\u4fe1\u606f\u5ea6\u91cf\u6765\u5f62\u5f0f\u5316\u6982\u5ff5\u53d1\u73b0\u4e0e\u6f14\u5316\u8fc7\u7a0b\u3002", "motivation": "\u4eba\u7c7b\u6982\u5ff5\u672c\u8eab\u5177\u6709\u6d41\u52a8\u6027\uff08\u5982\u51a5\u738b\u661f\u4e0d\u518d\u88ab\u89c6\u4e3a\u884c\u661f\uff09\uff0c\u4f20\u7edf\u57fa\u4e8e\u5b57\u5178\u6807\u7b7e\u7684\u6982\u5ff5\u5b9a\u4e49\u65e0\u6cd5\u6355\u6349\u8fd9\u79cd\u52a8\u6001\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u88ab\u4fee\u8ba2\u3001\u6bd4\u8f83\u548c\u5728\u667a\u80fd\u4f53\u95f4\u5bf9\u9f50\u7684\u6982\u5ff5\u5b9a\u4e49\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7b97\u6cd5\u4fe1\u606f\u8bba\u89c6\u89d2\uff0c\u5c06\u6982\u5ff5\u5b9a\u4e49\u4e3a\u901a\u8fc7\u53ef\u9006\u4e00\u81f4\u6027\u5173\u7cfb\u4e0e\u667a\u80fd\u4f53\u7ecf\u9a8c\u76f8\u5173\u7684\u4fe1\u606f\u5bf9\u8c61\u3002\u63d0\u51fa\u5197\u4f59\u4fe1\u606f\u5ea6\u91cf\u6765\u8861\u91cf\u6982\u5ff5\u5206\u89e3\u7684\u81ea\u7136\u6027\uff0c\u5e76\u5f62\u5f0f\u5316\u8fa9\u8bc1\u6cd5\u4f5c\u4e3a\u4f18\u5316\u52a8\u6001\u8fc7\u7a0b\uff0c\u8ba9\u7ade\u4e89\u6982\u5ff5\u901a\u8fc7\u66f4\u77ed\u7684\u63cf\u8ff0\u6765\u89e3\u91ca\u65b0\u4fe1\u606f\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u4f7f\u5f97\u6982\u5ff5\u5b58\u5728\u6027\u6210\u4e3a\u53ef\u68c0\u9a8c\u7684\u7ed3\u6784\u6027\u4e3b\u5f20\uff0c\u9632\u6b62\u6982\u5ff5\u8131\u79bb\u7ecf\u9a8c\u57fa\u7840\u3002\u63d0\u51fa\u4e86\u4f4e\u4ee3\u4ef7\u6982\u5ff5\u4f20\u8f93\u548c\u591a\u667a\u80fd\u4f53\u5bf9\u9f50\u673a\u5236\uff0c\u901a\u8fc7\u5171\u4eab\u534f\u8bae\u4e0b\u7684\u79cd\u5b50\u5b9e\u73b0\u6982\u5ff5\u91cd\u6784\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aAI\u4ece\u539f\u59cb\u7ecf\u9a8c\u4e2d\u81ea\u4e3b\u53d1\u73b0\u6982\u5ff5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u7ea6\u675f\u786e\u4fdd\u6982\u5ff5\u7684\u5b9e\u8bc1\u57fa\u7840\uff0c\u5e76\u5f62\u5f0f\u5316\u4e86\u6982\u5ff5\u6f14\u5316\u3001\u4f20\u8f93\u548c\u5bf9\u9f50\u7684\u8ba1\u7b97\u673a\u5236\u3002"}}
{"id": "2512.17470", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17470", "abs": "https://arxiv.org/abs/2512.17470", "authors": ["Dennis Gross", "J\u00f8rn Eirik Betten", "Helge Spieker"], "title": "Translating the Rashomon Effect to Sequential Decision-Making Tasks", "comment": null, "summary": "The Rashomon effect describes the phenomenon where multiple models trained on the same data produce identical predictions while differing in which features they rely on internally. This effect has been studied extensively in classification tasks, but not in sequential decision-making, where an agent learns a policy to achieve an objective by taking actions in an environment. In this paper, we translate the Rashomon effect to sequential decision-making. We define it as multiple policies that exhibit identical behavior, visiting the same states and selecting the same actions, while differing in their internal structure, such as feature attributions. Verifying identical behavior in sequential decision-making differs from classification. In classification, predictions can be directly compared to ground-truth labels. In sequential decision-making with stochastic transitions, the same policy may succeed or fail on any single trajectory due to randomness. We address this using formal verification methods that construct and compare the complete probabilistic behavior of each policy in the environment. Our experiments demonstrate that the Rashomon effect exists in sequential decision-making. We further show that ensembles constructed from the Rashomon set exhibit greater robustness to distribution shifts than individual policies. Additionally, permissive policies derived from the Rashomon set reduce computational requirements for verification while maintaining optimal performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06Rashomon\u6548\u5e94\u4ece\u5206\u7c7b\u4efb\u52a1\u6269\u5c55\u5230\u5e8f\u5217\u51b3\u7b56\u9886\u57df\uff0c\u53d1\u73b0\u591a\u4e2a\u7b56\u7565\u5728\u884c\u4e3a\u8868\u73b0\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\u5185\u90e8\u7ed3\u6784\u5b58\u5728\u5dee\u5f02\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u79cd\u591a\u6837\u6027\u96c6\u5408\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u4f18\u52bf\u3002", "motivation": "Rashomon\u6548\u5e94\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u5e8f\u5217\u51b3\u7b56\u9886\u57df\u5c1a\u672a\u88ab\u63a2\u7d22\u3002\u5e8f\u5217\u51b3\u7b56\u4e2d\u7b56\u7565\u7684\u884c\u4e3a\u9a8c\u8bc1\u6bd4\u5206\u7c7b\u4efb\u52a1\u66f4\u590d\u6742\uff0c\u56e0\u4e3a\u5b58\u5728\u968f\u673a\u8f6c\u79fb\u548c\u5355\u6b21\u8f68\u8ff9\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u6784\u5efa\u548c\u6bd4\u8f83\u6bcf\u4e2a\u7b56\u7565\u5728\u73af\u5883\u4e2d\u7684\u5b8c\u6574\u6982\u7387\u884c\u4e3a\uff0c\u9a8c\u8bc1\u7b56\u7565\u662f\u5426\u8868\u73b0\u51fa\u76f8\u540c\u884c\u4e3a\u3002\u901a\u8fc7\u6784\u9020Rashomon\u96c6\u5408\uff0c\u7814\u7a76\u5176\u591a\u6837\u6027\u548c\u9c81\u68d2\u6027\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eRashomon\u6548\u5e94\u5b58\u5728\u4e8e\u5e8f\u5217\u51b3\u7b56\u4e2d\u3002\u4eceRashomon\u96c6\u5408\u6784\u5efa\u7684\u96c6\u6210\u7b56\u7565\u5bf9\u5206\u5e03\u504f\u79fb\u8868\u73b0\u51fa\u6bd4\u5355\u4e2a\u7b56\u7565\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002\u4eceRashomon\u96c6\u5408\u6d3e\u751f\u7684\u5bbd\u677e\u7b56\u7565\u5728\u4fdd\u6301\u6700\u4f18\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u9a8c\u8bc1\u7684\u8ba1\u7b97\u9700\u6c42\u3002", "conclusion": "Rashomon\u6548\u5e94\u5728\u5e8f\u5217\u51b3\u7b56\u4e2d\u786e\u5b9e\u5b58\u5728\uff0c\u8fd9\u79cd\u591a\u6837\u6027\u4e0d\u4ec5\u662f\u4e00\u4e2a\u7406\u8bba\u73b0\u8c61\uff0c\u8fd8\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u5982\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u964d\u4f4e\u9a8c\u8bc1\u6210\u672c\u3002"}}
{"id": "2512.17559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17559", "abs": "https://arxiv.org/abs/2512.17559", "authors": ["Maliha Tabassum", "M Shamim Kaiser"], "title": "Towards Explainable Conversational AI for Early Diagnosis with Large Language Models", "comment": null, "summary": "Healthcare systems around the world are grappling with issues like inefficient diagnostics, rising costs, and limited access to specialists. These problems often lead to delays in treatment and poor health outcomes. Most current AI and deep learning diagnostic systems are not very interactive or transparent, making them less effective in real-world, patient-centered environments. This research introduces a diagnostic chatbot powered by a Large Language Model (LLM), using GPT-4o, Retrieval-Augmented Generation, and explainable AI techniques. The chatbot engages patients in a dynamic conversation, helping to extract and normalize symptoms while prioritizing potential diagnoses through similarity matching and adaptive questioning. With Chain-of-Thought prompting, the system also offers more transparent reasoning behind its diagnoses. When tested against traditional machine learning models like Naive Bayes, Logistic Regression, SVM, Random Forest, and KNN, the LLM-based system delivered impressive results, achieving an accuracy of 90% and Top-3 accuracy of 100%. These findings offer a promising outlook for more transparent, interactive, and clinically relevant AI in healthcare.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\uff09\u7684\u8bca\u65ad\u804a\u5929\u673a\u5668\u4eba\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u53ef\u89e3\u91caAI\u6280\u672f\uff0c\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u5b9e\u73b090%\u51c6\u786e\u7387\u548c100%\u7684Top-3\u51c6\u786e\u7387\u3002", "motivation": "\u5168\u7403\u533b\u7597\u7cfb\u7edf\u9762\u4e34\u8bca\u65ad\u6548\u7387\u4f4e\u3001\u6210\u672c\u4e0a\u5347\u548c\u4e13\u5bb6\u8d44\u6e90\u6709\u9650\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u6cbb\u7597\u5ef6\u8bef\u548c\u4e0d\u826f\u5065\u5eb7\u7ed3\u679c\u3002\u73b0\u6709AI\u8bca\u65ad\u7cfb\u7edf\u7f3a\u4e4f\u4ea4\u4e92\u6027\u548c\u900f\u660e\u5ea6\uff0c\u96be\u4ee5\u5728\u5b9e\u9645\u4e34\u5e8a\u73af\u5883\u4e2d\u6709\u6548\u5e94\u7528\u3002", "method": "\u91c7\u7528\u57fa\u4e8eGPT-4o\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bca\u65ad\u804a\u5929\u673a\u5668\u4eba\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u53ef\u89e3\u91caAI\u6280\u672f\u3002\u7cfb\u7edf\u901a\u8fc7\u52a8\u6001\u5bf9\u8bdd\u63d0\u53d6\u548c\u6807\u51c6\u5316\u75c7\u72b6\uff0c\u4f7f\u7528\u76f8\u4f3c\u6027\u5339\u914d\u548c\u81ea\u9002\u5e94\u63d0\u95ee\u4f18\u5148\u8003\u8651\u6f5c\u5728\u8bca\u65ad\uff0c\u5e76\u901a\u8fc7\u601d\u7ef4\u94fe\u63d0\u793a\u63d0\u4f9b\u900f\u660e\u63a8\u7406\u3002", "result": "\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u6734\u7d20\u8d1d\u53f6\u65af\u3001\u903b\u8f91\u56de\u5f52\u3001SVM\u3001\u968f\u673a\u68ee\u6797\u3001KNN\uff09\u76f8\u6bd4\uff0cLLM\u7cfb\u7edf\u8868\u73b0\u4f18\u5f02\uff0c\u8fbe\u523090%\u7684\u51c6\u786e\u7387\u548c100%\u7684Top-3\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u533b\u7597\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u900f\u660e\u3001\u4ea4\u4e92\u6027\u5f3a\u4e14\u4e34\u5e8a\u76f8\u5173\u7684AI\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86LLM\u5728\u6539\u5584\u533b\u7597\u8bca\u65ad\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2512.17637", "categories": ["cs.AI", "cs.FL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.17637", "abs": "https://arxiv.org/abs/2512.17637", "authors": ["Anirban Majumdar", "Ritam Raha", "Rajarshi Roy", "David Parker", "Marta Kwiatkowska"], "title": "About Time: Model-free Reinforcement Learning with Timed Reward Machines", "comment": null, "summary": "Reward specification plays a central role in reinforcement learning (RL), guiding the agent's behavior. To express non-Markovian rewards, formalisms such as reward machines have been introduced to capture dependencies on histories. However, traditional reward machines lack the ability to model precise timing constraints, limiting their use in time-sensitive applications. In this paper, we propose timed reward machines (TRMs), which are an extension of reward machines that incorporate timing constraints into the reward structure. TRMs enable more expressive specifications with tunable reward logic, for example, imposing costs for delays and granting rewards for timely actions. We study model-free RL frameworks (i.e., tabular Q-learning) for learning optimal policies with TRMs under digital and real-time semantics. Our algorithms integrate the TRM into learning via abstractions of timed automata, and employ counterfactual-imagining heuristics that exploit the structure of the TRM to improve the search. Experimentally, we demonstrate that our algorithm learns policies that achieve high rewards while satisfying the timing constraints specified by the TRM on popular RL benchmarks. Moreover, we conduct comparative studies of performance under different TRM semantics, along with ablations that highlight the benefits of counterfactual-imagining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5b9a\u65f6\u5956\u52b1\u673a\uff08TRMs\uff09\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u5956\u52b1\u673a\u4ee5\u7eb3\u5165\u65f6\u95f4\u7ea6\u675f\uff0c\u4f7f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1\u89c4\u8303\u80fd\u8868\u8fbe\u7cbe\u786e\u7684\u65f6\u95f4\u8981\u6c42\uff0c\u5e76\u5f00\u53d1\u4e86\u76f8\u5e94\u7684\u6a21\u578b\u65e0\u5173RL\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5956\u52b1\u673a\u65e0\u6cd5\u5efa\u6a21\u7cbe\u786e\u7684\u65f6\u95f4\u7ea6\u675f\uff0c\u9650\u5236\u4e86\u5728\u65f6\u95f4\u654f\u611f\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8868\u8fbe\u65f6\u95f4\u76f8\u5173\u5956\u52b1\u89c4\u8303\u7684\u673a\u5236\uff0c\u4f8b\u5982\u5bf9\u5ef6\u8fdf\u65bd\u52a0\u6210\u672c\u3001\u5bf9\u53ca\u65f6\u884c\u52a8\u7ed9\u4e88\u5956\u52b1\u3002", "method": "\u63d0\u51fa\u4e86\u5b9a\u65f6\u5956\u52b1\u673a\uff08TRMs\uff09\uff0c\u5c06\u65f6\u95f4\u7ea6\u675f\u6574\u5408\u5230\u5956\u52b1\u7ed3\u6784\u4e2d\u3002\u7814\u7a76\u4e86\u6a21\u578b\u65e0\u5173RL\u6846\u67b6\uff08\u8868\u683cQ\u5b66\u4e60\uff09\u5728\u6570\u5b57\u548c\u5b9e\u65f6\u8bed\u4e49\u4e0b\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u3002\u7b97\u6cd5\u901a\u8fc7\u5b9a\u65f6\u81ea\u52a8\u673a\u62bd\u8c61\u5c06TRM\u6574\u5408\u5230\u5b66\u4e60\u4e2d\uff0c\u5e76\u5229\u7528\u53cd\u4e8b\u5b9e\u60f3\u8c61\u542f\u53d1\u5f0f\u65b9\u6cd5\u5229\u7528TRM\u7ed3\u6784\u6539\u8fdb\u641c\u7d22\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u7b97\u6cd5\u5728\u6d41\u884c\u7684RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b66\u4e60\u5230\u7684\u7b56\u7565\u80fd\u591f\u83b7\u5f97\u9ad8\u5956\u52b1\u540c\u65f6\u6ee1\u8db3TRM\u6307\u5b9a\u7684\u65f6\u95f4\u7ea6\u675f\u3002\u6bd4\u8f83\u7814\u7a76\u5c55\u793a\u4e86\u4e0d\u540cTRM\u8bed\u4e49\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u6d88\u878d\u5b9e\u9a8c\u7a81\u51fa\u4e86\u53cd\u4e8b\u5b9e\u60f3\u8c61\u7684\u4f18\u52bf\u3002", "conclusion": "\u5b9a\u65f6\u5956\u52b1\u673a\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u5956\u52b1\u89c4\u8303\u8868\u8fbe\u80fd\u529b\uff0c\u80fd\u591f\u5904\u7406\u65f6\u95f4\u654f\u611f\u4efb\u52a1\uff0c\u76f8\u5e94\u7684\u5b66\u4e60\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5b66\u4e60\u6ee1\u8db3\u65f6\u95f4\u7ea6\u675f\u7684\u6700\u4f18\u7b56\u7565\u3002"}}
{"id": "2512.17898", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17898", "abs": "https://arxiv.org/abs/2512.17898", "authors": ["Robin Schimmelpfennig", "Mark D\u00edaz", "Vinodkumar Prabhakaran", "Aida Davani"], "title": "Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally", "comment": null, "summary": "Over a billion users across the globe interact with AI systems engineered with increasing sophistication to mimic human traits. This shift has triggered urgent debate regarding Anthropomorphism, the attribution of human characteristics to synthetic agents, and its potential to induce misplaced trust or emotional dependency. However, the causal link between more humanlike AI design and subsequent effects on engagement and trust has not been tested in realistic human-AI interactions with a global user pool. Prevailing safety frameworks continue to rely on theoretical assumptions derived from Western populations, overlooking the global diversity of AI users. Here, we address these gaps through two large-scale cross-national experiments (N=3,500) across 10 diverse nations, involving real-time and open-ended interactions with an AI system. We find that when evaluating an AI's human-likeness, users focus less on the kind of theoretical aspects often cited in policy (e.g., sentience or consciousness), but rather applied, interactional cues like conversation flow or understanding the user's perspective. We also experimentally demonstrate that humanlike design levers can causally increase anthropomorphism among users; however, we do not find that humanlike design universally increases behavioral measures for user engagement and trust, as previous theoretical work suggests. Instead, part of the connection between human-likeness and behavioral outcomes is fractured by culture: specific design choices that foster self-reported trust in AI-systems in some populations (e.g., Brazil) may trigger the opposite result in others (e.g., Japan). Our findings challenge prevailing narratives of inherent risk in humanlike AI design. Instead, we identify a nuanced, culturally mediated landscape of human-AI interaction, which demands that we move beyond a one-size-fits-all approach in AI governance.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u8de8\u56fd\u5b9e\u9a8c\u53d1\u73b0\uff0cAI\u62df\u4eba\u5316\u8bbe\u8ba1\u5bf9\u7528\u6237\u4fe1\u4efb\u548c\u53c2\u4e0e\u5ea6\u7684\u5f71\u54cd\u5177\u6709\u6587\u5316\u7279\u5f02\u6027\uff0c\u6311\u6218\u4e86\u666e\u904d\u98ce\u9669\u5047\u8bbe", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u65e5\u76ca\u6a21\u4eff\u4eba\u7c7b\u7279\u5f81\u5f15\u53d1\u5bf9\u62df\u4eba\u5316\u98ce\u9669\u7684\u62c5\u5fe7\uff0c\u4f46\u73b0\u6709\u5b89\u5168\u6846\u67b6\u4e3b\u8981\u57fa\u4e8e\u897f\u65b9\u7406\u8bba\u5047\u8bbe\uff0c\u7f3a\u4e4f\u5168\u7403\u7528\u6237\u7fa4\u4f53\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u9700\u8981\u9a8c\u8bc1\u62df\u4eba\u5316\u8bbe\u8ba1\u4e0e\u7528\u6237\u4fe1\u4efb\u3001\u53c2\u4e0e\u5ea6\u7684\u56e0\u679c\u5173\u7cfb", "method": "\u572810\u4e2a\u4e0d\u540c\u56fd\u5bb6\u8fdb\u884c\u4e24\u9879\u5927\u89c4\u6a21\u8de8\u56fd\u5b9e\u9a8c\uff08N=3,500\uff09\uff0c\u6d89\u53ca\u4e0eAI\u7cfb\u7edf\u7684\u5b9e\u65f6\u5f00\u653e\u5f0f\u4e92\u52a8\uff0c\u5b9e\u9a8c\u6027\u5730\u6d4b\u8bd5\u62df\u4eba\u5316\u8bbe\u8ba1\u6760\u6746\u5bf9\u7528\u6237\u611f\u77e5\u548c\u884c\u4e3a\u7684\u5f71\u54cd", "result": "\u7528\u6237\u8bc4\u4f30AI\u62df\u4eba\u5316\u65f6\u66f4\u5173\u6ce8\u4ea4\u4e92\u6027\u7ebf\u7d22\u800c\u975e\u7406\u8bba\u7279\u5f81\uff1b\u62df\u4eba\u5316\u8bbe\u8ba1\u80fd\u589e\u52a0\u7528\u6237\u62df\u4eba\u5316\u611f\u77e5\uff0c\u4f46\u4e0d\u4f1a\u666e\u904d\u589e\u52a0\u884c\u4e3a\u5c42\u9762\u7684\u53c2\u4e0e\u5ea6\u548c\u4fe1\u4efb\uff1b\u6587\u5316\u56e0\u7d20\u8c03\u8282\u4e86\u62df\u4eba\u5316\u4e0e\u884c\u4e3a\u7ed3\u679c\u7684\u5173\u7cfb\uff0c\u67d0\u4e9b\u8bbe\u8ba1\u5728\u67d0\u4e9b\u6587\u5316\u4e2d\u589e\u52a0\u4fe1\u4efb\uff0c\u5728\u5176\u4ed6\u6587\u5316\u4e2d\u53ef\u80fd\u4ea7\u751f\u76f8\u53cd\u6548\u679c", "conclusion": "AI\u62df\u4eba\u5316\u8bbe\u8ba1\u7684\u5f71\u54cd\u662f\u6587\u5316\u4e2d\u4ecb\u7684\u590d\u6742\u666f\u89c2\uff0c\u6311\u6218\u4e86\u666e\u904d\u98ce\u9669\u7684\u53d9\u4e8b\uff0c\u9700\u8981\u8d85\u8d8a\u4e00\u5200\u5207\u7684AI\u6cbb\u7406\u65b9\u6cd5\uff0c\u8003\u8651\u6587\u5316\u591a\u6837\u6027"}}
{"id": "2512.17901", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.17901", "abs": "https://arxiv.org/abs/2512.17901", "authors": ["Junyu Zhang", "Yifan Sun", "Tianang Leng", "Jingyan Shen", "Liu Ziyin", "Paul Pu Liang", "Huan Zhang"], "title": "When Reasoning Meets Its Laws", "comment": null, "summary": "Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. We first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity. Beyond compute, we extend LoRe with a supplementary accuracy law. Since the question complexity is difficult to quantify in practice, we examine these hypotheses by two properties of the laws, monotonicity and compositionality. We therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models. Evaluation shows that most reasoning models exhibit reasonable monotonicity but lack compositionality. In response, we develop an effective finetuning approach that enforces compute-law compositionality. Extensive empirical studies demonstrate that better compliance with compute laws yields consistently improved reasoning performance on multiple benchmarks, and uncovers synergistic effects across properties and laws. Project page: https://lore-project.github.io/", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u63a8\u7406\u5b9a\u5f8b\uff08LoRe\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u5b9a\u5f8b\u548c\u51c6\u786e\u7387\u5b9a\u5f8b\u6765\u5f62\u5f0f\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u7406\u60f3\u63a8\u7406\u884c\u4e3a\uff0c\u5e76\u5f00\u53d1\u4e86LoRe-Bench\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u5355\u8c03\u6027\u548c\u7ec4\u5408\u6027\uff0c\u6700\u540e\u901a\u8fc7\u5fae\u8c03\u65b9\u6cd5\u63d0\u5347\u6a21\u578b\u5bf9\u8ba1\u7b97\u5b9a\u5f8b\u7684\u9075\u5faa\u5ea6\uff0c\u4ece\u800c\u6539\u5584\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u63a8\u7406\u884c\u4e3a\u5e38\u5e38\u8fdd\u53cd\u76f4\u89c9\uff0c\u5bfc\u81f4\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3002\u4e3a\u4e86\u4ece\u7406\u8bba\u4e0a\u5f62\u5f0f\u5316\u7406\u60f3\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u8868\u5f81LRMs\u7684\u5185\u5728\u63a8\u7406\u6a21\u5f0f\u3002", "method": "1. \u63d0\u51fa\u63a8\u7406\u5b9a\u5f8b\uff08LoRe\uff09\u6846\u67b6\uff0c\u5305\u62ec\u8ba1\u7b97\u5b9a\u5f8b\uff08\u63a8\u7406\u8ba1\u7b97\u91cf\u5e94\u4e0e\u95ee\u9898\u590d\u6742\u5ea6\u7ebf\u6027\u7f29\u653e\uff09\u548c\u8865\u5145\u7684\u51c6\u786e\u7387\u5b9a\u5f8b\u30022. \u7531\u4e8e\u95ee\u9898\u590d\u6742\u5ea6\u96be\u4ee5\u91cf\u5316\uff0c\u901a\u8fc7\u5355\u8c03\u6027\u548c\u7ec4\u5408\u6027\u8fd9\u4e24\u4e2a\u53ef\u5904\u7406\u5c5e\u6027\u6765\u68c0\u9a8c\u5b9a\u5f8b\u5047\u8bbe\u30023. \u5f00\u53d1LoRe-Bench\u57fa\u51c6\u7cfb\u7edf\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8fd9\u4e24\u4e2a\u5c5e\u6027\u30024. \u63d0\u51fa\u6709\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5f3a\u5236\u6a21\u578b\u9075\u5faa\u8ba1\u7b97\u5b9a\u5f8b\u7684\u7ec4\u5408\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5927\u591a\u6570\u63a8\u7406\u6a21\u578b\u8868\u73b0\u51fa\u5408\u7406\u7684\u5355\u8c03\u6027\u4f46\u7f3a\u4e4f\u7ec4\u5408\u6027\u3002\u901a\u8fc7\u5f3a\u5236\u8ba1\u7b97\u5b9a\u5f8b\u7ec4\u5408\u6027\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u6301\u7eed\u6539\u8fdb\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u5c5e\u6027\u548c\u5b9a\u5f8b\u4e4b\u95f4\u7684\u534f\u540c\u6548\u5e94\u3002", "conclusion": "\u63a8\u7406\u5b9a\u5f8b\uff08LoRe\uff09\u4e3a\u5f62\u5f0f\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u7406\u60f3\u884c\u4e3a\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7LoRe-Bench\u8bc4\u4f30\u548c\u9488\u5bf9\u6027\u5fae\u8c03\uff0c\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u5bf9\u8ba1\u7b97\u5b9a\u5f8b\u7684\u9075\u5faa\u5ea6\uff0c\u4ece\u800c\u663e\u8457\u6539\u5584\u63a8\u7406\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5c5e\u6027\u4e0e\u63a8\u7406\u5b9a\u5f8b\u4e4b\u95f4\u7684\u91cd\u8981\u5173\u7cfb\u3002"}}
