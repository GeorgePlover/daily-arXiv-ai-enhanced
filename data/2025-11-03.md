<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 14]
- [cs.DC](#cs.DC) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [CATArena: Evaluation of LLM Agents through Iterative Tournament Competitions](https://arxiv.org/abs/2510.26852)
*Lingyue Fu,Xin Ding,Yaoming Zhu,Shao Zhang,Lin Qiu,Weiwen Liu,Weinan Zhang,Xuezhi Cao,Xunliang Cai,Jiaxin Ding,Yong Yu*

Main category: cs.AI

TL;DR: 本文提出了CATArena评估平台，通过四款棋牌游戏的无上限评分系统，解决现有基准测试中的分数饱和问题，系统评估LLM智能体的学习能力和策略编码能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体基准测试主要评估固定场景下的端到端性能，存在分数饱和、依赖专家标注等问题，无法有效评估智能体的学习能力。

Method: 提出迭代式竞争性同伴学习框架，让智能体通过重复交互和反馈优化策略；构建CATArena平台，包含四款开放式棋牌游戏，采用无上限评分系统。

Result: 实验结果表明CATArena为智能体核心能力（特别是学习能力和策略编码）提供了可靠、稳定和可扩展的基准测试。

Conclusion: CATArena能够持续动态地评估快速发展的智能体能力，特别是学习能力这一推动智能体向人类水平智能进化的核心驱动力。

Abstract: Large Language Model (LLM) agents have evolved from basic text generation to
autonomously completing complex tasks through interaction with external tools.
However, current benchmarks mainly assess end-to-end performance in fixed
scenarios, restricting evaluation to specific skills and suffering from score
saturation and growing dependence on expert annotation as agent capabilities
improve. In this work, we emphasize the importance of learning ability,
including both self-improvement and peer-learning, as a core driver for agent
evolution toward human-level intelligence. We propose an iterative, competitive
peer-learning framework, which allows agents to refine and optimize their
strategies through repeated interactions and feedback, thereby systematically
evaluating their learning capabilities. To address the score saturation issue
in current benchmarks, we introduce CATArena, a tournament-style evaluation
platform featuring four diverse board and card games with open-ended scoring.
By providing tasks without explicit upper score limits, CATArena enables
continuous and dynamic evaluation of rapidly advancing agent capabilities.
Experimental results and analyses involving both minimal and commercial code
agents demonstrate that CATArena provides reliable, stable, and scalable
benchmarking for core agent abilities, particularly learning ability and
strategy coding.

</details>


### [2] [Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations](https://arxiv.org/abs/2510.26905)
*Pedro Antonio Alarcón Granadeno,Arturo Miguel Bernal Russell,Sofia Nelson,Demetrius Hernandez,Maureen Petterson,Michael Murphy,Walter J. Scheirer,Jane Cleland-Huang*

Main category: cs.AI

TL;DR: 该论文提出了认知包络的概念，旨在为AI生成的决策建立推理边界，以解决基础模型在物理信息系统中产生的幻觉、过度泛化和上下文错位等错误。


<details>
  <summary>Details</summary>
Motivation: 随着物理信息系统越来越多地依赖基础模型来增强自主性，这些模型引入了新的错误类型，导致不正确的决策，因此需要建立推理边界来约束AI决策。

Method: 引入认知包络概念，建立推理边界来约束AI生成的决策，同时补充元认知和传统安全包络的使用，需要定义、验证和保证的系统化流程。

Result: 提出了认知包络的概念框架，为约束基础模型在物理信息系统中的决策错误提供了系统性解决方案。

Conclusion: 认知包络需要实用的指导方针和系统化流程来进行定义、验证和保证，类似于安全包络的要求，以有效应对基础模型带来的新挑战。

Abstract: Cyber-physical systems increasingly rely on Foundational Models such as Large
Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy
through enhanced perception, inference, and planning. However, these models
also introduce new types of errors, such as hallucinations,
overgeneralizations, and context misalignments, resulting in incorrect and
flawed decisions. To address this, we introduce the concept of Cognition
Envelopes, designed to establish reasoning boundaries that constrain
AI-generated decisions while complementing the use of meta-cognition and
traditional safety envelopes. As with safety envelopes, Cognition Envelopes
require practical guidelines and systematic processes for their definition,
validation, and assurance.

</details>


### [3] [SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation](https://arxiv.org/abs/2510.26989)
*Agorakis Bompotas,Konstantinos Koutras,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Dimitra Gariza,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.AI

TL;DR: SUSTAINABLE是一个智能农业平台，整合物联网、人工智能、卫星成像和基于角色的任务编排，旨在实现高效、可追溯和可持续的农业，并以葡萄栽培为试点应用案例。


<details>
  <summary>Details</summary>
Motivation: 全球农业部门面临粮食需求增长、气候多变性和可持续实践需求，需要转型以应对这些挑战。

Method: 平台整合物联网、AI、卫星成像和基于角色的任务编排，特别针对地中海葡萄园提供卫星指数集成、实时环境数据和角色感知任务管理。

Result: 论文对现有智能农业解决方案进行了比较评估，并介绍了SUSTAINABLE平台的关键特性。

Conclusion: SUSTAINABLE平台通过技术创新为农业可持续发展提供了解决方案，特别是在葡萄栽培领域展示了应用潜力。

Abstract: The global agricultural sector is undergoing a transformative shift, driven
by increasing food demands, climate variability and the need for sustainable
practices. SUSTAINABLE is a smart farming platform designed to integrate IoT,
AI, satellite imaging, and role-based task orchestration to enable efficient,
traceable, and sustainable agriculture with a pilot usecase in viticulture.
This paper explores current smart agriculture solutions, presents a comparative
evaluation, and introduces SUSTAINABLE's key features, including satellite
index integration, real-time environmental data, and role-aware task management
tailored to Mediterranean vineyards.

</details>


### [4] [Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models](https://arxiv.org/abs/2510.27009)
*Jared Junkin,Samuel Nathanson*

Main category: cs.AI

TL;DR: 研究表明，在非顺序数据上应用因果掩码是可行的，在棋类等空间结构数据上，基于空间表示训练的模型表现优于基于顺序表示训练的模型。


<details>
  <summary>Details</summary>
Motivation: 探讨在具有空间或关系结构的领域中，接受因果掩码带来的信息损失是否可行，以及空间表示与顺序表示在语言模型训练中的效果差异。

Method: 在棋类领域训练具有双向和因果自注意力机制的语言模型，分别使用空间（棋盘状态）和顺序（走棋序列）两种数据表示方式。

Result: 基于空间棋盘状态训练的模型（即使使用因果掩码）在棋力方面始终优于基于顺序数据训练的模型。

Conclusion: 在空间数据上应用因果掩码是训练单模态大语言模型的有效方法，在某些领域甚至优于顺序化处理。

Abstract: Language models are traditionally designed around causal masking. In domains
with spatial or relational structure, causal masking is often viewed as
inappropriate, and sequential linearizations are instead used. Yet the question
of whether it is viable to accept the information loss introduced by causal
masking on nonsequential data has received little direct study, in part because
few domains offer both spatial and sequential representations of the same
dataset. In this work, we investigate this issue in the domain of chess, which
naturally supports both representations. We train language models with
bidirectional and causal self-attention mechanisms on both spatial
(board-based) and sequential (move-based) data. Our results show that models
trained on spatial board states - \textit{even with causal masking} -
consistently achieve stronger playing strength than models trained on
sequential data. While our experiments are conducted on chess, our results are
methodological and may have broader implications: applying causal masking to
spatial data is a viable procedure for training unimodal LLMs on spatial data,
and in some domains is even preferable to sequentialization.

</details>


### [5] [e1: Learning Adaptive Control of Reasoning Effort](https://arxiv.org/abs/2510.27042)
*Michael Kleinman,Matthew Trager,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: 提出自适应努力控制方法，让AI模型根据用户指定的努力参数动态调整推理长度，实现成本-准确性的灵活权衡，相比标准方法减少约3倍推理长度同时保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要用户预先指定绝对token数量，但用户难以事先知道问题难度来设置合适的token预算。需要让用户能够根据输出质量与延迟成本的权衡，对特定查询精细控制推理努力程度。

Method: 提出自适应努力控制方法，使用强化学习训练模型，让模型根据用户指定的相对当前平均思维链长度的token比例来调整推理努力。用户可以在推理时通过连续努力参数动态调整成本-准确性权衡。

Result: 模型自动学习按任务难度比例分配资源，在1.5B到32B参数规模范围内，相比用于RL训练的基础模型，该方法能够减少约3倍的思维链长度，同时保持或提升性能。

Conclusion: 自适应努力控制方法消除了数据集和阶段特定的调优需求，相比标准方法产生更好的成本-准确性权衡曲线，为用户提供了动态调整推理努力的灵活控制能力。

Abstract: Increasing the thinking budget of AI models can significantly improve
accuracy, but not all questions warrant the same amount of reasoning. Users may
prefer to allocate different amounts of reasoning effort depending on how they
value output quality versus latency and cost. To leverage this tradeoff
effectively, users need fine-grained control over the amount of thinking used
for a particular query, but few approaches enable such control. Existing
methods require users to specify the absolute number of desired tokens, but
this requires knowing the difficulty of the problem beforehand to appropriately
set the token budget for a query. To address these issues, we propose Adaptive
Effort Control, a self-adaptive reinforcement learning method that trains
models to use a user-specified fraction of tokens relative to the current
average chain-of-thought length for each query. This approach eliminates
dataset- and phase-specific tuning while producing better cost-accuracy
tradeoff curves compared to standard methods. Users can dynamically adjust the
cost-accuracy trade-off through a continuous effort parameter specified at
inference time. We observe that the model automatically learns to allocate
resources proportionally to the task difficulty and, across model scales
ranging from 1.5B to 32B parameters, our approach enables approximately 3x
reduction in chain-of-thought length while maintaining or improving performance
relative to the base model used for RL training.

</details>


### [6] [CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning](https://arxiv.org/abs/2510.27094)
*Hamed Mahdavi,Pouria Mahdavinia,Alireza Farhadi,Pegah Mohammadipour,Samira Malek,Majid Daliri,Pedram Mohammadipour,Alireza Hashemi,Amir Khasahmadi,Vasant Honavar*

Main category: cs.AI

TL;DR: 该论文评估了先进LLMs在证明评分方面的能力，包括错误检测、严重性判断和分数分配，并提出了一种基于智能体工作流程的评分方法来解决部分分数分配不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 随着SOTA LLMs从难以解决基于证明的奥赛问题发展到能够解决大部分IMO 2025问题，需要评估这些模型在证明评分方面的能力，特别是检测错误、判断严重性和分配公平分数。

Method: 使用包含90个Gemini 2.5 Pro生成解决方案的语料库，采用1-4分制进行评分和详细错误标注；同时使用MathArena的IMO/USAMO 2025解决方案集进行0-7分制评分。引入智能体工作流程，提取和分析参考解决方案，自动推导问题特定的评分标准，实现多步骤评分过程。

Result: 模型能够可靠地标记错误解决方案（包括细微错误），但在部分分数分配方面存在校准差距。提出的智能体工作流程在人工评分一致性和部分分数处理一致性方面表现更好。

Conclusion: 智能体工作流程能够提高与人工评分的一致性，并在部分分数处理方面更加一致，为未来研究提供了代码、数据和提示/日志资源。

Abstract: State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based
Olympiad problems to solving most of the IMO 2025 problems, with leading
systems reportedly handling 5 of 6 problems. Given this progress, we assess how
well these models can grade proofs: detecting errors, judging their severity,
and assigning fair scores beyond binary correctness. We study proof-analysis
capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we
grade on a 1-4 scale with detailed error annotations, and on MathArena solution
sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models
can reliably flag incorrect (including subtly incorrect) solutions but exhibit
calibration gaps in how partial credit is assigned. To address this, we
introduce agentic workflows that extract and analyze reference solutions and
automatically derive problem-specific rubrics for a multi-step grading process.
We instantiate and compare different design choices for the grading workflows,
and evaluate their trade-offs. Across our annotated corpus and MathArena, our
proposed workflows achieve higher agreement with human grades and more
consistent handling of partial credit across metrics. We release all code,
data, and prompts/logs to facilitate future research.

</details>


### [7] [Discriminative Rule Learning for Outcome-Guided Process Model Discovery](https://arxiv.org/abs/2510.27343)
*Ali Norouzifar,Wil van der Aalst*

Main category: cs.AI

TL;DR: 提出了一种基于结果感知的过程发现方法，通过区分理想和不理想的过程执行轨迹，分别学习过程模型，从而揭示关键行为差异。


<details>
  <summary>Details</summary>
Motivation: 传统过程发现方法不考虑执行结果差异，导致模型难以有效支持合规检查和性能分析，无法捕捉理想与不理想执行之间的关键行为区别。

Method: 通过学习控制流特征上的可解释判别规则，将具有相似理想性特征的轨迹分组，并在每个组内分别应用过程发现技术。

Result: 该方法在多个真实事件日志上得到验证，能够有效分离和可视化关键过程模式，生成聚焦且可解释的模型。

Conclusion: 结果感知的过程发现方法能够更好地揭示理想和不理想过程执行的驱动因素，为过程改进提供更有针对性的见解。

Abstract: Event logs extracted from information systems offer a rich foundation for
understanding and improving business processes. In many real-world
applications, it is possible to distinguish between desirable and undesirable
process executions, where desirable traces reflect efficient or compliant
behavior, and undesirable ones may involve inefficiencies, rule violations,
delays, or resource waste. This distinction presents an opportunity to guide
process discovery in a more outcome-aware manner. Discovering a single process
model without considering outcomes can yield representations poorly suited for
conformance checking and performance analysis, as they fail to capture critical
behavioral differences. Moreover, prioritizing one behavior over the other may
obscure structural distinctions vital for understanding process outcomes. By
learning interpretable discriminative rules over control-flow features, we
group traces with similar desirability profiles and apply process discovery
separately within each group. This results in focused and interpretable models
that reveal the drivers of both desirable and undesirable executions. The
approach is implemented as a publicly available tool and it is evaluated on
multiple real-life event logs, demonstrating its effectiveness in isolating and
visualizing critical process patterns.

</details>


### [8] [An In-depth Study of LLM Contributions to the Bin Packing Problem](https://arxiv.org/abs/2510.27353)
*Julien Herrmann,Guillaume Pallez*

Main category: cs.AI

TL;DR: 本文重新评估了LLMs在数学发现中的贡献，通过对LLM生成的启发式算法进行详细分析，发现这些算法虽然人类可读但难以解释，并提出了更简单、高效、可解释的新算法，强调了对LLM生成输出进行严格验证的重要性。


<details>
  <summary>Details</summary>
Motivation: 重新评估LLMs在数学发现中的贡献，特别是针对在线装箱问题中LLM生成的启发式算法的有效性和可解释性进行深入分析。

Method: 详细分析LLM生成的启发式算法行为与可解释性，提出针对特定装箱问题实例的新算法类别，并与LLM生成算法进行对比。

Result: 发现LLM生成的启发式算法虽然人类可读但对领域专家仍不透明，提出的新算法更简单、高效、可解释且更具泛化性，表明所考虑的问题实例本身相对简单。

Conclusion: LLMs对该问题的贡献存在局限性，基于错误假设（认为这些实例已被研究过），强调需要对LLM生成输出进行严格验证和情境化评估。

Abstract: Recent studies have suggested that Large Language Models (LLMs) could provide
interesting ideas contributing to mathematical discovery. This claim was
motivated by reports that LLM-based genetic algorithms produced heuristics
offering new insights into the online bin packing problem under uniform and
Weibull distributions. In this work, we reassess this claim through a detailed
analysis of the heuristics produced by LLMs, examining both their behavior and
interpretability. Despite being human-readable, these heuristics remain largely
opaque even to domain experts. Building on this analysis, we propose a new
class of algorithms tailored to these specific bin packing instances. The
derived algorithms are significantly simpler, more efficient, more
interpretable, and more generalizable, suggesting that the considered instances
are themselves relatively simple. We then discuss the limitations of the claim
regarding LLMs' contribution to this problem, which appears to rest on the
mistaken assumption that the instances had previously been studied. Our
findings instead emphasize the need for rigorous validation and
contextualization when assessing the scientific value of LLM-generated outputs.

</details>


### [9] [Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints](https://arxiv.org/abs/2510.27383)
*Yueyang Wang,Mehmet Dogar,Gustav Markkula*

Main category: cs.AI

TL;DR: 提出一个结合视觉和运动约束的多智能体强化学习框架，用于模拟行人-驾驶员交互行为，在真实世界无信号人行横道数据集上验证了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖规则逻辑、博弈论或黑盒机器学习，缺乏灵活性且忽视感知和运动约束等底层机制，这些机制塑造了行人和驾驶员在交互场景中的感知和行为方式。

Method: 使用多智能体强化学习框架，整合行人和驾驶员智能体的视觉和运动约束，评估了四种模型变体：无约束、仅运动约束、仅视觉约束、两者兼备。

Result: 结合视觉和运动约束的模型表现最佳。运动约束产生更平滑的运动，类似人类在穿越交互中的速度调整；视觉约束引入感知不确定性和视野限制，使智能体表现出更谨慎和可变的行为。在数据有限情况下，该模型优于监督行为克隆模型。

Conclusion: 结合人类约束的多智能体强化学习是模拟真实道路用户交互的有前景的建模方法，通过将控制人类约束的参数建模为群体级分布来考虑个体差异，这是先前行人-车辆交互建模工作中未探索的视角。

Abstract: Modelling pedestrian-driver interactions is critical for understanding human
road user behaviour and developing safe autonomous vehicle systems. Existing
approaches often rely on rule-based logic, game-theoretic models, or
'black-box' machine learning methods. However, these models typically lack
flexibility or overlook the underlying mechanisms, such as sensory and motor
constraints, which shape how pedestrians and drivers perceive and act in
interactive scenarios. In this study, we propose a multi-agent reinforcement
learning (RL) framework that integrates both visual and motor constraints of
pedestrian and driver agents. Using a real-world dataset from an unsignalised
pedestrian crossing, we evaluate four model variants, one without constraints,
two with either motor or visual constraints, and one with both, across
behavioural metrics of interaction realism. Results show that the combined
model with both visual and motor constraints performs best. Motor constraints
lead to smoother movements that resemble human speed adjustments during
crossing interactions. The addition of visual constraints introduces perceptual
uncertainty and field-of-view limitations, leading the agents to exhibit more
cautious and variable behaviour, such as less abrupt deceleration. In this
data-limited setting, our model outperforms a supervised behavioural cloning
model, demonstrating that our approach can be effective without large training
datasets. Finally, our framework accounts for individual differences by
modelling parameters controlling the human constraints as population-level
distributions, a perspective that has not been explored in previous work on
pedestrian-vehicle interaction modelling. Overall, our work demonstrates that
multi-agent RL with human constraints is a promising modelling approach for
simulating realistic road user interactions.

</details>


### [10] [DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains](https://arxiv.org/abs/2510.27419)
*Tian Liang,Wenxiang Jiao,Zhiwei He,Jiahao Xu,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: DeepCompress是一个新颖框架，通过自适应长度奖励机制同时提升大型推理模型的准确性和效率，根据问题难度动态调整推理链长度。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用监督微调或带token长度奖励的强化学习来提高效率，但往往以牺牲准确性为代价。大型推理模型存在认知效率低下的问题，如对简单问题"过度思考"和对复杂问题"思考不足"。

Method: DeepCompress采用自适应长度奖励机制，实时根据模型能力将问题动态分类为"简单"或"困难"。对于简单问题鼓励更短、更高效的推理，对于困难问题则促进更长、更具探索性的思维链。

Result: 在具有挑战性的数学基准测试中，DeepCompress始终优于基线方法，在显著提高token效率的同时实现了更优的准确性。

Conclusion: 该框架使模型能够自主调整其思维链长度，压缩已掌握问题的推理过程，并扩展其认为具有挑战性问题的推理过程，从而同时提升准确性和效率。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive capabilities but
suffer from cognitive inefficiencies like ``overthinking'' simple problems and
``underthinking'' complex ones. While existing methods that use supervised
fine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can
improve efficiency, they often do so at the cost of accuracy. This paper
introduces \textbf{DeepCompress}, a novel framework that simultaneously
enhances both the accuracy and efficiency of LRMs. We challenge the prevailing
approach of consistently favoring shorter reasoning paths, showing that longer
responses can contain a broader range of correct solutions for difficult
problems. DeepCompress employs an adaptive length reward mechanism that
dynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on
the model's evolving capability. It encourages shorter, more efficient
reasoning for ``Simple'' problems while promoting longer, more exploratory
thought chains for ``Hard'' problems. This dual-reward strategy enables the
model to autonomously adjust its Chain-of-Thought (CoT) length, compressing
reasoning for well-mastered problems and extending it for those it finds
challenging. Experimental results on challenging mathematical benchmarks show
that DeepCompress consistently outperforms baseline methods, achieving superior
accuracy while significantly improving token efficiency.

</details>


### [11] [GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language](https://arxiv.org/abs/2510.27448)
*Yuhao Zhang,Dingxin Hu,Tinghao Yu,Hao Liu,Yiting Liu*

Main category: cs.AI

TL;DR: GeoFM提出了一种使用形式语言在度量空间中探索条件组合的新方法，通过符号引擎生成高保真几何问题，显著提升了多模态大语言模型在几何推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在数学几何推理方面面临高质量几何数据稀缺的挑战，现有合成几何数据方法存在多样性不足、噪声多、图像变化有限且与真实几何图偏离较大的问题。

Method: GeoFM使用形式语言在度量空间中探索条件组合，通过符号引擎生成与原始问题不同但确保正确性的高保真几何问题。

Result: 实验结果显示，使用GeoFM合成数据训练的模型在MathVista几何问题解决任务上超过GPT-4o模型18.7%，在GeoQA上超过16.5%；在开源模型中，在MathVista上超过5.7%，在GeoQA上超过2.7%。

Conclusion: GeoFM方法能够生成高质量的合成几何数据，显著提升多模态大语言模型在几何推理任务上的性能表现。

Abstract: Multi-modal Large Language Models (MLLMs) have gained significant attention
in both academia and industry for their capabilities in handling multi-modal
tasks. However, these models face challenges in mathematical geometric
reasoning due to the scarcity of high-quality geometric data. To address this
issue, synthetic geometric data has become an essential strategy. Current
methods for generating synthetic geometric data involve rephrasing or expanding
existing problems and utilizing predefined rules and templates to create
geometric images and problems. However, these approaches often produce data
that lacks diversity or is prone to noise. Additionally, the geometric images
synthesized by existing methods tend to exhibit limited variation and deviate
significantly from authentic geometric diagrams. To overcome these limitations,
we propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses
formal languages to explore combinations of conditions within metric space,
generating high-fidelity geometric problems that differ from the originals
while ensuring correctness through a symbolic engine. Experimental results show
that our synthetic data significantly outperforms existing methods. The model
trained with our data surpass the proprietary GPT-4o model by 18.7\% on
geometry problem-solving tasks in MathVista and by 16.5\% on GeoQA.
Additionally, it exceeds the performance of a leading open-source model by
5.7\% on MathVista and by 2.7\% on GeoQA.

</details>


### [12] [SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning](https://arxiv.org/abs/2510.27568)
*Ali Asgarov,Umid Suleymanov,Aadyant Khatri*

Main category: cs.AI

TL;DR: SIGMA是一个多智能体检索增强框架，通过协调专门智能体进行独立推理、目标搜索和结果合成，在数学推理任务中显著优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强模型存在单视角依赖、搜索策略僵化、多源信息整合困难等问题，无法有效解决复杂的数学推理问题。

Method: 引入SIGMA框架，通过专门智能体独立推理并生成假设性段落优化检索，使用调节机制合成发现，实现上下文敏感且计算高效的知识整合。

Result: 在MATH500、AIME和GPQA等挑战性基准测试中，SIGMA持续优于开源和闭源系统，绝对性能提升7.4%。

Conclusion: 多智能体按需知识整合显著提高了推理准确性和效率，为复杂知识密集型问题解决提供了可扩展方法。

Abstract: Solving mathematical reasoning problems requires not only accurate access to
relevant knowledge but also careful, multi-step thinking. However, current
retrieval-augmented models often rely on a single perspective, follow
inflexible search strategies, and struggle to effectively combine information
from multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge
Integration for AGentic Mathematical reAsoning), a unified framework that
orchestrates specialized agents to independently reason, perform targeted
searches, and synthesize findings through a moderator mechanism. Each agent
generates hypothetical passages to optimize retrieval for its analytic
perspective, ensuring knowledge integration is both context-sensitive and
computation-efficient. When evaluated on challenging benchmarks such as
MATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms
both open- and closed-source systems, achieving an absolute performance
improvement of 7.4%. Our results demonstrate that multi-agent, on-demand
knowledge integration significantly enhances both reasoning accuracy and
efficiency, offering a scalable approach for complex, knowledge-intensive
problem-solving. We will release the code upon publication.

</details>


### [13] [VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation](https://arxiv.org/abs/2510.27617)
*Heng Ping,Arijit Bhattacharjee,Peiyu Zhang,Shixuan Li,Wei Yang,Anzhe Cheng,Xiaole Zhang,Jesse Thomason,Ali Jannesari,Nesreen Ahmed,Paul Bogdan*

Main category: cs.AI

TL;DR: VeriMoA是一个无需训练的多智能体框架，通过质量引导缓存和多路径生成策略，显著提升了硬件描述语言(HDL)生成性能，在多个基准测试中实现了15-30%的Pass@1改进。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在硬件描述语言生成方面面临参数知识有限和领域特定约束的挑战，而现有的多智能体方法存在噪声传播和推理空间受限的问题。

Method: 提出两种协同创新：1) 质量引导缓存机制，维护所有中间HDL输出并进行质量排序选择；2) 多路径生成策略，利用C++和Python作为中间表示，将规范到HDL的翻译分解为两阶段过程。

Result: 在VerilogEval 2.0和RTLLM 2.0基准测试中，VeriMoA实现了15-30%的Pass@1改进，特别是使较小模型能够匹配较大模型和微调替代方案，无需昂贵训练。

Conclusion: VeriMoA提供了一个无需训练的高效框架，通过多智能体协作显著提升了HDL生成能力，为硬件设计自动化提供了有前景的解决方案。

Abstract: Automation of Register Transfer Level (RTL) design can help developers meet
increasing computational demands. Large Language Models (LLMs) show promise for
Hardware Description Language (HDL) generation, but face challenges due to
limited parametric knowledge and domain-specific constraints. While prompt
engineering and fine-tuning have limitations in knowledge coverage and training
costs, multi-agent architectures offer a training-free paradigm to enhance
reasoning through collaborative generation. However, current multi-agent
approaches suffer from two critical deficiencies: susceptibility to noise
propagation and constrained reasoning space exploration. We propose VeriMoA, a
training-free mixture-of-agents (MoA) framework with two synergistic
innovations. First, a quality-guided caching mechanism to maintain all
intermediate HDL outputs and enables quality-based ranking and selection across
the entire generation process, encouraging knowledge accumulation over layers
of reasoning. Second, a multi-path generation strategy that leverages C++ and
Python as intermediate representations, decomposing specification-to-HDL
translation into two-stage processes that exploit LLM fluency in high-resource
languages while promoting solution diversity. Comprehensive experiments on
VerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves
15--30% improvements in Pass@1 across diverse LLM backbones, especially
enabling smaller models to match larger models and fine-tuned alternatives
without requiring costly training.

</details>


### [14] [Validity Is What You Need](https://arxiv.org/abs/2510.27628)
*Sebastian Benthall,Andrew Clark*

Main category: cs.AI

TL;DR: 本文提出了Agentic AI的新定义，将其视为在复杂企业环境中自主工作的软件交付机制，强调验证的重要性而非仅依赖大语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前对Agentic AI的定义不够清晰，需要从现实应用角度重新定义，并强调验证在Agentic AI系统中的核心地位。

Method: 通过比较Agentic AI与SaaS的相似性，提出新的现实主义定义，并分析验证工具与基础模型评估工具的区别。

Result: 发现Agentic AI主要是应用而非基础，其成功依赖于终端用户和主要利益相关者的验证，在良好验证机制下，基础模型可被更简单、快速、可解释的模型替代。

Conclusion: Agentic AI的关键在于有效性验证，大语言模型只是实现这一目标的可能选项之一，而非必要条件。

Abstract: While AI agents have long been discussed and studied in computer science,
today's Agentic AI systems are something new. We consider other definitions of
Agentic AI and propose a new realist definition. Agentic AI is a software
delivery mechanism, comparable to software as a service (SaaS), which puts an
application to work autonomously in a complex enterprise setting. Recent
advances in large language models (LLMs) as foundation models have driven
excitement in Agentic AI. We note, however, that Agentic AI systems are
primarily applications, not foundations, and so their success depends on
validation by end users and principal stakeholders. The tools and techniques
needed by the principal users to validate their applications are quite
different from the tools and techniques used to evaluate foundation models.
Ironically, with good validation measures in place, in many cases the
foundation models can be replaced with much simpler, faster, and more
interpretable models that handle core logic. When it comes to Agentic AI,
validity is what you need. LLMs are one option that might achieve it.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [15] [FlowMesh: A Service Fabric for Composable LLM Workflows](https://arxiv.org/abs/2510.26913)
*Junyi Shen,Noppanat Wadlom,Lingfeng Zhou,Dequan Wang,Xu Miao,Lei Fang,Yao Lu*

Main category: cs.DC

TL;DR: FlowMesh是一个多租户服务架构，将AI工作流分解为细粒度算子，通过全局控制平面和数据平面实现跨用户工作去重、请求批处理，在异构GPU上平衡吞吐量、成本和数据局部性，相比基准方案可降低3.8倍成本和2.0倍能耗。


<details>
  <summary>Details</summary>
Motivation: AI部署正从单一LLM任务转向数据转换、微调和智能体交互的流水线模式，如RLHF/RLAIF训练和智能体工作流。为应对这一转变，需要一种能够执行和优化这些工作负载的共享服务，而不是孤立的流水线。

Method: 将工作流分解为具有记录谱系的细粒度算子，实现跨用户工作去重和在相同硬件上批量处理请求；全局控制平面维护集群范围的算子池，使用单一效用函数选择批次和工作者；数据平面是无状态工作者弹性舰队，支持内容寻址存储，实现快速自动扩展、安全重试和跨集群可移植性。

Result: 相比基准解决方案，FlowMesh实现高达3.8倍成本降低和2.0倍能耗降低，提供相似或更好的延迟特性，在动态和易故障条件下保持高效。

Conclusion: FlowMesh通过多租户服务架构有效解决了AI工作流从单一任务向复杂流水线转变的挑战，在成本、能耗和性能方面均表现出显著优势，特别适合动态和故障易发的部署环境。

Abstract: AI deployment increasingly resembles a pipeline of data transformation,
fine-tuning, and agent interactions rather than a monolithic LLM job; recent
examples include RLHF/RLAIF training and agentic workflows. To cope with this
shift, we propose FlowMesh, a multi-tenant service fabric that executes and
optimizes these workloads as one shared service instead of isolated pipelines.
It decomposes workflows into fine-grained operators with recorded lineage,
enabling de-duplication of work across users and batching requests on the same
hardware while preserving per-workflow provenance. A global control plane
maintains a cluster-wide pool of ready operators and uses a single utility
function to pick both the batch and the worker, balancing throughput, cost, and
data locality on heterogeneous GPUs. The data plane is an elastic fleet of
stateless workers backed by a content-addressable store, enabling rapid,
automatic scale-out, safe retry after preemption, and portability across
managed clusters such as Kubernetes and geo-distributed GPU marketplaces such
as Vast.ai. Compared with baseline solutions, FlowMesh achieves up to 3.8x cost
reduction and 2.0x lower energy usage, provides a similar or better latency
profile, and remains efficient under dynamic and failure-prone conditions.

</details>


### [16] [Synergistic Tensor and Pipeline Parallelism](https://arxiv.org/abs/2510.27257)
*Mengshi Qi,Jiaxuan Peng,Jie Zhang,Juan Zhu,Yong Li,Huadong Ma*

Main category: cs.DC

TL;DR: 提出了一种协同张量并行和流水线并行调度方法，通过解耦前向和后向传播为细粒度计算单元并编织成复合计算序列，同时减少两种并行模式中的通信开销和流水线气泡。


<details>
  <summary>Details</summary>
Motivation: 现有混合并行训练方法中，张量并行带来显著的集体通信开销，而流水线并行存在同步效率低下的流水线气泡问题。现有工作多从孤立角度解决这些问题，缺乏协同优化。

Method: 将流水线并行的前向和后向传播解耦为细粒度计算单元，编织成复合计算序列以消除张量并行相关气泡，并在此基础上设计流水线并行调度以最小化流水线气泡。

Result: 实验结果表明，相比现有调度方法，该方法在LLM训练中提升吞吐量达12%，在MLLM训练中提升达16%。

Conclusion: 提出的协同张量和流水线并行调度方法能有效同时减少两种并行模式中的气泡问题，显著提升大模型训练效率。

Abstract: In the machine learning system, the hybrid model parallelism combining tensor
parallelism (TP) and pipeline parallelism (PP) has become the dominant solution
for distributed training of Large Language Models~(LLMs) and Multimodal LLMs
(MLLMs). However, TP introduces significant collective communication overheads,
while PP suffers from synchronization inefficiencies such as pipeline bubbles.
Existing works primarily address these challenges from isolated perspectives,
focusing either on overlapping TP communication or on flexible PP scheduling to
mitigate pipeline bubbles. In this paper, we propose a new synergistic tensor
and pipeline parallelism schedule that simultaneously reduces both types of
bubbles. Our proposed schedule decouples the forward and backward passes in PP
into fine-grained computation units, which are then braided to form a composite
computation sequence. This compositional structure enables near-complete
elimination of TP-related bubbles. Building upon this structure, we further
design the PP schedule to minimize PP bubbles. Experimental results demonstrate
that our approach improves training throughput by up to 12% for LLMs and 16%
for MLLMs compared to existing scheduling methods. Our source code is avaiable
at https://github.com/MICLAB-BUPT/STP.

</details>


### [17] [Dynamic Service Scheduling and Resource Management in Energy-Harvesting Multi-access Edge Computing](https://arxiv.org/abs/2510.27317)
*Shuyi Chen,Panagiotis Oikonomou,Zhengchang Hua,Nikos Tziritas,Karim Djemame,Nan Zhang,Georgios Theodoropoulos*

Main category: cs.DC

TL;DR: 本文提出了一种在线策略，用于完全由能量收集供电的多接入边缘计算系统，通过动态调度计算任务和控制能耗来平衡间歇性能量与动态用户需求。


<details>
  <summary>Details</summary>
Motivation: 多接入边缘计算系统与可再生能源收集技术结合以提升可持续性，但在无电网供电情况下，平衡间歇性能量与动态用户需求存在资源分配挑战。

Method: 提出在线策略，动态调度具有依赖关系的计算任务，通过服务器频率调整和服务模块迁移实时控制能耗。

Result: 使用真实世界数据集的实验表明，该算法在有效利用收集能量的同时保持低服务延迟。

Conclusion: 所提出的在线策略能够有效解决能量收集供电的边缘计算系统中的资源分配问题，实现可持续的低延迟服务。

Abstract: Multi-access Edge Computing (MEC) delivers low-latency services by hosting
applications near end-users. To promote sustainability, these systems are
increasingly integrated with renewable Energy Harvesting (EH) technologies,
enabling operation where grid electricity is unavailable. However, balancing
the intermittent nature of harvested energy with dynamic user demand presents a
significant resource allocation challenge. This work proposes an online
strategy for an MEC system powered exclusively by EH to address this trade-off.
Our strategy dynamically schedules computational tasks with dependencies and
governs energy consumption through real-time decisions on server frequency
scaling and service module migration. Experiments using real-world datasets
demonstrate our algorithm's effectiveness in efficiently utilizing harvested
energy while maintaining low service latency.

</details>


### [18] [ML-Based Optimum Sub-system Size Heuristic for the GPU Implementation of the Tridiagonal Partition Method](https://arxiv.org/abs/2510.27351)
*Milena Veneva*

Main category: cs.DC

TL;DR: 本文提出了一种基于机器学习的启发式方法，用于寻找并行分区算法CUDA实现的最佳子系统大小。通过k近邻分类方法建立预测模型，并将该方法扩展到递归并行分区算法。


<details>
  <summary>Details</summary>
Motivation: 为并行分区算法的CUDA实现寻找最优子系统大小，以提高计算效率，并通过机器学习方法建立预测模型来避免耗时的经验性测试。

Method: 对不同规模的线性代数方程组进行计算实验，经验性地找到最优子系统大小；使用k近邻分类方法建立子系统大小的预测模型；将启发式方法扩展到递归并行分区算法，构建预测最优递归步数的kNN模型。

Result: 通过比较预测值与实际数据，算法表现良好；成功构建了预测最优子系统大小和递归步数的模型。

Conclusion: 基于机器学习的启发式方法能够有效预测并行分区算法的最优子系统大小和递归步数，为CUDA实现提供了实用的优化工具。

Abstract: This paper presents a machine learning (ML)-based heuristic for finding the
optimum sub-system size for the CUDA implementation of the parallel partition
algorithm. Computational experiments for different system of linear algebraic
equation (SLAE) sizes are conducted, and the optimum sub-system size for each
of them is found empirically. To estimate a model for the sub-system size, we
perform the k-nearest neighbors (kNN) classification method. Statistical
analysis of the results is done. By comparing the predicted values with the
actual data, the algorithm is deemed to be acceptably good. Next, the heuristic
is expanded to work for the recursive parallel partition algorithm as well. An
algorithm for determining the optimum sub-system size for each recursive step
is formulated. A kNN model for predicting the optimum number of recursive steps
for a particular SLAE size is built.

</details>
