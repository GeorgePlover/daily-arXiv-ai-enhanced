<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 6]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Marionette: Data Structure Description and Management for Heterogeneous Computing](https://arxiv.org/abs/2511.04853)
*Nuno dos Santos Fernandes,Pedro Tomás,Nuno Roma,Frank Winklmeier,Patricia Conde-Muíño*

Main category: cs.DC

TL;DR: Marionette是一个C++17库，旨在解决大型面向对象C++代码库在异构平台（如GPU）上进行硬件加速时的挑战，通过解耦数据布局与接口描述，提供灵活、高效、可移植的数据结构定义。


<details>
  <summary>Details</summary>
Motivation: 适应大型面向对象C++代码库进行硬件加速极具挑战性，特别是在面向GPU等异构平台时。现有方法难以平衡效率、灵活性和代码兼容性。

Method: Marionette采用编译时抽象，解耦数据布局与接口描述，支持多种内存管理策略，提供跨设备的高效数据传输和转换，允许接口通过任意函数进行增强。

Result: 该库在保持最小运行时开销的同时，维持与现有代码的兼容性，支持从简单到高级的各种使用场景。基于CUDA的案例研究证明了其效率和灵活性。

Conclusion: Marionette为大型C++代码库在异构平台上的硬件加速提供了一种有效的解决方案，通过编译时抽象实现了高效、灵活且可移植的数据结构管理。

Abstract: Adapting large, object-oriented C++ codebases for hardware acceleration might
be extremely challenging, particularly when targeting heterogeneous platforms
such as GPUs. Marionette is a C++17 library designed to address this by
enabling flexible, efficient, and portable data structure definitions. It
decouples data layout from the description of the interface, supports multiple
memory management strategies, and provides efficient data transfers and
conversions across devices, all of this with minimal runtime overhead due to
the compile-time nature of its abstractions. By allowing interfaces to be
augmented with arbitrary functions, Marionette maintains compatibility with
existing code and offers a streamlined interface that supports both
straightforward and advanced use cases. This paper outlines its design, usage,
and performance, including a CUDA-based case study demonstrating its efficiency
and flexibility.

</details>


### [2] [GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters](https://arxiv.org/abs/2511.05067)
*Giuseppe Esposito,Juan-David Guerrero-Balaguera,Josie Esteban Rodriguez Condia,Matteo Sonza Reorda,Marco Barbiero,Rossella Fortuna*

Main category: cs.DC

TL;DR: 该论文提出了一种结合在线遥测参数和硬件性能计数器来评估GPU工作负载压力的方法，用于预测可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 持续的工作负载会对GPU组件造成显著压力，引发可靠性担忧，需要评估应用引起的压力来预测可靠性问题（特别是老化效应）。

Method: 结合在线遥测参数和硬件性能计数器来评估GPU压力，选定的性能计数器主要测量吞吐量、已发出指令数量和停顿事件。

Result: 实验结果表明，通过结合遥测数据和性能计数器可以估计并行工作负载引起的压力，这些计数器揭示了目标工作负载在资源使用方面的效率。

Conclusion: 结合遥测数据和性能计数器是评估GPU工作负载压力的有效方法，有助于预测可靠性问题。

Abstract: Graphics Processing Units (GPUs) are specialized accelerators in data centers
and high-performance computing (HPC) systems, enabling the fast execution of
compute-intensive applications, such as Convolutional Neural Networks (CNNs).
However, sustained workloads can impose significant stress on GPU components,
raising reliability concerns due to potential faults that corrupt the
intermediate application computations, leading to incorrect results. Estimating
the stress induced by an application is thus crucial to predict reliability
(with\,special\,emphasis\,on\,aging\,effects). In this work, we combine online
telemetry parameters and hardware performance counters to assess GPU stress
induced by different applications. The experimental results indicate the stress
induced by a parallel workload can be estimated by combining telemetry data and
Performance Counters that reveal the efficiency in the resource usage of the
target workload. For this purpose the selected performance counters focus on
measuring the i) throughput, ii) amount of issued instructions and iii) stall
events.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [3] [TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems](https://arxiv.org/abs/2511.05269)
*Ishan Kavathekar,Hemang Jain,Ameya Rathod,Ponnurangam Kumaraguru,Tanuja Ganu*

Main category: cs.MA

TL;DR: TAMAS是一个专门评估多智能体LLM系统安全性的基准测试，包含5个场景、300个对抗性实例、6种攻击类型和211个工具，揭示了当前多智能体系统在面对攻击时的高度脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体LLM系统在复杂任务中的广泛应用，其安全性和鲁棒性研究严重不足。现有基准主要关注单智能体设置，无法捕捉多智能体动态协调中的独特漏洞。

Method: 开发了TAMAS基准，包含多样化的攻击场景和工具，评估了10个骨干LLM模型在Autogen和CrewAI框架下的三种智能体交互配置，并引入了有效鲁棒性评分(ERS)来量化安全性与任务效果之间的权衡。

Result: 研究发现多智能体系统对对抗性攻击高度脆弱，现有部署存在严重的安全挑战和失效模式，迫切需要更强的防御机制。

Conclusion: TAMAS为系统研究和改进多智能体LLM系统的安全性提供了基础，强调了当前多智能体部署中安全问题的紧迫性。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities as
autonomous agents through tool use, planning, and decision-making abilities,
leading to their widespread adoption across diverse tasks. As task complexity
grows, multi-agent LLM systems are increasingly used to solve problems
collaboratively. However, safety and security of these systems remains largely
under-explored. Existing benchmarks and datasets predominantly focus on
single-agent settings, failing to capture the unique vulnerabilities of
multi-agent dynamics and co-ordination. To address this gap, we introduce
$\textbf{T}$hreats and $\textbf{A}$ttacks in $\textbf{M}$ulti-$\textbf{A}$gent
$\textbf{S}$ystems ($\textbf{TAMAS}$), a benchmark designed to evaluate the
robustness and safety of multi-agent LLM systems. TAMAS includes five distinct
scenarios comprising 300 adversarial instances across six attack types and 211
tools, along with 100 harmless tasks. We assess system performance across ten
backbone LLMs and three agent interaction configurations from Autogen and
CrewAI frameworks, highlighting critical challenges and failure modes in
current multi-agent deployments. Furthermore, we introduce Effective Robustness
Score (ERS) to assess the tradeoff between safety and task effectiveness of
these frameworks. Our findings show that multi-agent systems are highly
vulnerable to adversarial attacks, underscoring the urgent need for stronger
defenses. TAMAS provides a foundation for systematically studying and improving
the safety of multi-agent LLM systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 本文介绍了团队在2024年集成医疗排班竞赛中获得第三名的算法、实现和结果，采用混合整数规划、约束规划和模拟退火的3阶段分解方法，并首次提供了基准实例的最优解下界。


<details>
  <summary>Details</summary>
Motivation: 解决集成医疗排班问题，通过组合多种优化技术来提高排班效率和质量，在竞赛中验证方法的有效性。

Method: 采用3阶段分解方法：混合整数规划、约束规划和模拟退火，将复杂问题分解为子问题分别求解。

Result: 在2024年集成医疗排班竞赛中获得第三名，并首次提供了基准实例的最优解下界。

Conclusion: 该方法在医疗排班问题上表现良好，但仍存在一些开放问题需要解决以进一步提升性能。

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [5] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 本文提出了一种基于认知不确定性的拒绝选项预测器，能够在训练数据不足的区域主动放弃预测，以最小化期望后悔值。


<details>
  <summary>Details</summary>
Motivation: 传统拒绝选项方法只关注偶然不确定性，但在数据有限的实际场景中，认知不确定性不可忽略。需要一种能够识别训练数据不足区域的预测框架。

Method: 基于贝叶斯学习，重新定义最优预测器为最小化期望后悔值的模型。当输入导致的后悔值超过指定拒绝成本时，模型选择放弃预测。

Result: 提出了首个能够系统识别训练数据不足输入的原则性框架，使预测器能够在认知不确定性高的区域主动放弃预测。

Conclusion: 该框架为高风险应用中的不确定性量化提供了新方法，特别适用于数据有限的场景，能够提高预测系统的可靠性。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [6] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: DMA是一个在线学习框架，通过整合多粒度人类反馈来动态调整RAG系统的检索排序，解决了静态检索无法适应意图变化和内容漂移的问题。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统依赖静态检索，无法适应动态变化的用户意图和内容漂移，需要在线学习机制来实时优化检索性能。

Method: DMA构建了连贯的学习流程：监督训练点对和列表排序器、基于响应级偏好的策略优化、以及将知识蒸馏到轻量级评分器中实现低延迟服务。

Result: 在线部署显示人类参与度显著提升，离线测试在TriviaQA和HotpotQA等对话问答任务上取得显著收益，同时保持了基础检索竞争力。

Conclusion: DMA为RAG系统提供了基于反馈的实时自适应方法，在不牺牲基础能力的前提下实现了性能提升。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [7] [Real-Time Reasoning Agents in Evolving Environments](https://arxiv.org/abs/2511.04898)
*Yule Wen,Yixin Ye,Yanzhe Zhang,Diyi Yang,Hao Zhu*

Main category: cs.AI

TL;DR: 本文提出了实时推理的新问题框架，研究在动态环境中智能体的推理能力。通过构建Real-Time Reasoning Gym，比较了反应式智能体和规划式智能体两种范式，并提出AgileThinker方法同时结合两种推理范式，在任务难度和时间压力增加时表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的智能体需要同时做出逻辑性和及时性的判断，但现有语言模型推理方法未能充分考虑环境的动态特性。智能体在推理过程中环境仍在变化，危险可能出现、机会可能产生，这要求智能体具备实时推理能力。

Method: 构建Real-Time Reasoning Gym测试平台，研究两种语言模型部署范式：反应式智能体（使用有限推理计算实现快速响应）和规划式智能体（允许扩展推理计算处理复杂问题）。提出AgileThinker方法，同时结合两种推理范式。

Result: 实验表明，即使是最先进的模型在两种范式中都难以同时做出逻辑性和及时性的判断。AgileThinker在任务难度和时间压力增加时，始终优于仅使用单一推理范式的智能体，能有效平衡推理深度和响应延迟。

Conclusion: 实时推理是开发实用智能体的关键测试基准，为时间约束AI系统的研究奠定了基础，指明了实现实时能力智能体的发展方向。

Abstract: Agents in the real world must make not only logical but also timely
judgments. This requires continuous awareness of the dynamic environment:
hazards emerge, opportunities arise, and other agents act, while the agent's
reasoning is still unfolding. Despite advances in language model reasoning,
existing approaches fail to account for this dynamic nature. We introduce
real-time reasoning as a new problem formulation for agents in evolving
environments and build Real-Time Reasoning Gym to demonstrate it. We study two
paradigms for deploying language models in agents: (1) reactive agents, which
employ language models with bounded reasoning computation for rapid responses,
and (2) planning agents, which allow extended reasoning computation for complex
problems. Our experiments show that even state-of-the-art models struggle with
making logical and timely judgments in either paradigm. To address this
limitation, we propose AgileThinker, which simultaneously engages both
reasoning paradigms. AgileThinker consistently outperforms agents engaging only
one reasoning paradigm as the task difficulty and time pressure rise,
effectively balancing reasoning depth and response latency. Our work
establishes real-time reasoning as a critical testbed for developing practical
agents and provides a foundation for research in temporally constrained AI
systems, highlighting a path toward real-time capable agents.

</details>


### [8] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 提出一种支持军事地面作战决策的方法论，为机械化营生成和评估行动方案，通过系统生成数千个行动替代方案并评估其效果，在动态作战环境中为决策者提供修订的行动方案。


<details>
  <summary>Details</summary>
Motivation: 在军事地面作战执行阶段，需要有效的决策支持方法来评估和选择最佳行动方案，以应对复杂的战场环境和对手行动。

Method: 从初始行动方案集开始，系统生成数千个行动替代方案，结合对手状态和行动进行评估，考虑部队组成、力量比、攻防类型和预期推进率等因素，使用野战手册评估战斗结果。

Result: 该方法能够生成多样化的行动替代方案，识别具有更优结果的行动路线，并在作战过程中动态更新行动方案。

Conclusion: 该决策支持方法能够有效管理行动方案的生成和评估，在动态作战环境中为决策者提供及时的行动建议。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


### [9] [Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance](https://arxiv.org/abs/2511.05311)
*Valeriu Dimidov,Faisal Hawlader,Sasan Jafarnejad,Raphaël Frank*

Main category: cs.AI

TL;DR: 本文探讨了基于大语言模型（LLM）的智能体在汽车行业预测性维护（PdM）数据清洗管道中的应用潜力，特别是在处理维护日志中的六种噪声类型方面表现出有效性。


<details>
  <summary>Details</summary>
Motivation: 经济约束、数据集可用性有限以及专业人才短缺一直是汽车行业采用和推进预测性维护的主要挑战。LLM的进展为克服这些障碍提供了机会，加速PdM从研究到工业实践的过渡。

Method: 研究评估了LLM智能体在维护日志清洗任务中的表现，重点关注六种不同类型的噪声处理，包括拼写错误、缺失字段、近似重复条目和错误日期等。

Result: 研究发现LLM在处理通用清洗任务方面表现有效，为未来工业应用提供了有前景的基础。尽管领域特定错误仍然具有挑战性，但这些结果显示了通过专门训练和增强智能体能力进一步改进的潜力。

Conclusion: LLM智能体在预测性维护数据清洗方面具有显著潜力，能够有效处理维护日志中的多种噪声类型，为工业应用提供了可行的解决方案，但需要进一步改进以应对领域特定挑战。

Abstract: Economic constraints, limited availability of datasets for reproducibility
and shortages of specialized expertise have long been recognized as key
challenges to the adoption and advancement of predictive maintenance (PdM) in
the automotive sector. Recent progress in large language models (LLMs) presents
an opportunity to overcome these barriers and speed up the transition of PdM
from research to industrial practice. Under these conditions, we explore the
potential of LLM-based agents to support PdM cleaning pipelines. Specifically,
we focus on maintenance logs, a critical data source for training
well-performing machine learning (ML) models, but one often affected by errors
such as typos, missing fields, near-duplicate entries, and incorrect dates. We
evaluate LLM agents on cleaning tasks involving six distinct types of noise.
Our findings show that LLMs are effective at handling generic cleaning tasks
and offer a promising foundation for future industrial applications. While
domain-specific errors remain challenging, these results highlight the
potential for further improvements through specialized training and enhanced
agentic capabilities.

</details>
