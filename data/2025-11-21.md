<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 5]
- [cs.AI](#cs.AI) [Total: 43]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Efficient Chromosome Parallelization for Precision Medicine Genomic Workflows](https://arxiv.org/abs/2511.15977)
*Daniel Mas Montserrat,Ray Verma,Míriam Barrabés,Francisco M. de la Vega,Carlos D. Bustamante,Alexander G. Ioannidis*

Main category: cs.DC

TL;DR: 本文提出了多种自适应内存优化机制，用于并行化染色体级生物信息学工作流，包括符号回归模型预测内存消耗、动态调度器优化任务打包以及静态调度器优化处理顺序，以减少内存溢出并提高执行效率。


<details>
  <summary>Details</summary>
Motivation: 大规模基因组工作流在处理每个样本数十到数百GB数据时，面临高内存峰值、密集磁盘I/O和内存不足导致的任务失败问题。静态资源分配方法难以处理每个染色体RAM需求的变异性，导致资源利用率低和运行时间长。

Method: 1. 开发符号回归模型估计每个染色体的内存消耗，引入插值偏置保守最小化过度分配；2. 提出动态调度器使用多项式回归模型自适应预测RAM使用，将任务打包视为背包问题优化批处理；3. 提出静态调度器优化染色体处理顺序以最小化峰值内存同时保持吞吐量。

Result: 在模拟和真实基因组流程中的评估表明，所提方法提供了减少内存溢出和跨线程负载平衡的新机制，实现了更快的端到端执行。

Conclusion: 这些方法展示了优化大规模基因组工作流的潜力，通过自适应内存管理提高了资源利用率和执行效率。

Abstract: Large-scale genomic workflows used in precision medicine can process datasets spanning tens to hundreds of gigabytes per sample, leading to high memory spikes, intensive disk I/O, and task failures due to out-of-memory errors. Simple static resource allocation methods struggle to handle the variability in per-chromosome RAM demands, resulting in poor resource utilization and long runtimes. In this work, we propose multiple mechanisms for adaptive, RAM-efficient parallelization of chromosome-level bioinformatics workflows. First, we develop a symbolic regression model that estimates per-chromosome memory consumption for a given task and introduces an interpolating bias to conservatively minimize over-allocation. Second, we present a dynamic scheduler that adaptively predicts RAM usage with a polynomial regression model, treating task packing as a Knapsack problem to optimally batch jobs based on predicted memory requirements. Additionally, we present a static scheduler that optimizes chromosome processing order to minimize peak memory while preserving throughput. Our proposed methods, evaluated on simulations and real-world genomic pipelines, provide new mechanisms to reduce memory overruns and balance load across threads. We thereby achieve faster end-to-end execution, showcasing the potential to optimize large-scale genomic workflows.

</details>


### [2] [Can Asymmetric Tile Buffering Be Beneficial?](https://arxiv.org/abs/2511.16041)
*Chengyue Wang,Wesley Pang,Xinrui Wu,Gregory Jun,Luis Romero,Endri Taka,Diana Marculescu,Tony Nowatzki,Pranathi Vasireddy,Joseph Melber,Deming Chen,Jason Cong*

Main category: cs.DC

TL;DR: 本文提出了一种非对称瓦片缓冲（ATB）技术，通过解耦输入和输出操作数的缓冲瓦片维度，显著提升了通用矩阵乘法（GEMM）的性能。在AMD XDNA2 AI Engine上的应用实现了4.54倍加速，达到24.6 TFLOPS的混合精度性能。


<details>
  <summary>Details</summary>
Motivation: 传统对称瓦片缓冲方法限制了GEMM计算效率，作者旨在通过解耦输入输出瓦片维度来提升算术强度，从而优化现代AI工作负载的计算性能。

Method: 提出非对称瓦片缓冲（ATB）技术，开发包含ATB收益和开销的性能模型，并在AMD XDNA2 AI Engine上进行案例研究。

Result: 在AMD XDNA2 AI Engine上实现了4.54倍加速，从4.8 TFLOPS提升到24.6 TFLOPS的混合精度BFP16-BF16 GEMM性能，创下新的性能记录。

Conclusion: ATB技术被证明是实用且高效的，能够显著提升GEMM计算性能，为AI加速器设计提供了新的优化方向。

Abstract: General matrix multiplication (GEMM) is the computational backbone of modern AI workloads, and its efficiency is critically dependent on effective tiling strategies. Conventional approaches employ symmetric tile buffering, where the buffered tile size of the input $A$ along the dimension $M$ matches the output tile size of $C$.
  In this paper, we introduce asymmetric tile buffering (ATB), a simple but powerful technique that decouples the buffered tile dimensions of the input and output operands. We show, for the first time, that ATB is both practical and highly beneficial. To explain this effect, we develop a performance model that incorporates both the benefits of ATB (higher arithmetic intensity) and its overheads (higher kernel switching costs), providing insight into how to select effective ATB tiling factors. As a case study, we apply ATB to AMD's latest XDNA2 AI Engine (AIE), achieving up to a 4.54x speedup, from 4.8 to 24.6 TFLOPS on mixed-precision BFP16--BF16 GEMM, establishing a new performance record for XDNA2 AIE.

</details>


### [3] [Mitigating Shared Storage Congestion Using Control Theory](https://arxiv.org/abs/2511.16177)
*Thomas Collignon,Kouds Halitim,Raphaël Bleuse,Sophie Cerf,Bogdan Robu,Éric Rutten,Lionel Seinturier,Alexandre van Kempen*

Main category: cs.DC

TL;DR: 提出一种基于控制理论的自适应方法，动态调节客户端I/O速率以缓解HPC系统中的I/O拥塞问题，实验表明可减少20%总运行时间并降低尾部延迟。


<details>
  <summary>Details</summary>
Motivation: 传统I/O栈优化方法存在工作负载特定性、需要专业知识且难以泛化的问题，共享HPC环境中资源拥塞导致性能不可预测，需要更通用的解决方案。

Method: 基于控制理论设计自适应控制器，利用少量运行时系统负载指标动态调节客户端I/O速率，在多节点集群上实现并评估。

Result: 实验结果显示该方法有效缓解I/O拥塞，总运行时间最多减少20%，尾部延迟降低，同时保持稳定的性能表现。

Conclusion: 基于控制理论的自适应I/O速率调节方法能够有效解决HPC系统中的I/O拥塞问题，提高性能稳定性，具有良好的应用前景。

Abstract: Efficient data access in High-Performance Computing (HPC) systems is essential to the performance of intensive computing tasks. Traditional optimizations of the I/O stack aim to improve peak performance but are often workload specific and require deep expertise, making them difficult to generalize or re-use. In shared HPC environments, resource congestion can lead to unpredictable performance, causing slowdowns and timeouts. To address these challenges, we propose a self-adaptive approach based on Control Theory to dynamically regulate client-side I/O rates. Our approach leverages a small set of runtime system load metrics to reduce congestion and enhance performance stability. We implement a controller in a multi-node cluster and evaluate it on a real testbed under a representative workload. Experimental results demonstrate that our method effectively mitigates I/O congestion, reducing total runtime by up to 20% and lowering tail latency, while maintaining stable performance.

</details>


### [4] [Fast LLM Post-training via Decoupled and Best-of-N Speculation](https://arxiv.org/abs/2511.16193)
*Rongxin Cheng,Kai Zhou,Xingda Wei,Siyuan Liu,Mingcong Han,Mingjing Ai,Yeju Zhou,Baoquan Zhong,Wencong Xiao,Xin Liu,Rong Chen,Haibo Chen*

Main category: cs.DC

TL;DR: SpecActor通过动态解耦推测和动态Best-of-N推测方法，在大型语言模型后训练中实现快速rollout，比传统方法快1.3-1.7倍。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型后训练中rollout阶段耗时过长的问题，特别是在大批次配置下传统推测解码效率低下的挑战。

Method: 采用动态解耦推测执行方法最大化GPU计算效率，以及动态Best-of-N推测方法根据rollout进度选择和组合不同的草稿方法。

Result: SpecActor比常见的后训练基线快1.3-1.7倍，比简单采用推测解码的rollout方法快1.3-1.5倍。

Conclusion: SpecActor通过创新的推测解码技术有效加速了LLM后训练中的rollout过程，显著提升了训练效率。

Abstract: Rollout dominates the training time in large language model (LLM) post-training, where the trained model is used to generate tokens given a batch of prompts. SpecActor achieves fast rollout with speculative decoding that deploys a fast path (e.g., a smaller model) to accelerate the unparallelizable generation, while the correctness is guaranteed by fast parallel verification of the outputs with the original model. SpecActor addresses two foundational challenges in speculative rollout by (1) a \emph{dynamic decoupled speculation} execution method that maximizes the GPU computational efficiency to realize speedup for large-batch execution -- a configuration common in training but unfriendly to speculative execution and (2) a \emph{dynamic Best-of-N speculation} method that selects and combines different drafting methods according to the rollout progress. It substantially improves the speculation accuracy even when the best drafting method is unknown a priori, meanwhile without requiring adding extra computation resources. {\sys} is {1.3--1.7}\,$\times$ faster than common post-training baselines, and is {1.3--1.5}\,$\times$ faster compared to naively adopting speculative decoding for rollout.

</details>


### [5] [Optimizing Federated Learning in the Era of LLMs: Message Quantization and Streaming](https://arxiv.org/abs/2511.16450)
*Ziyue Xu,Zhihong Zhang,Holger R. Roth,Chester Chen,Yan Cheng,Andrew Feng*

Main category: cs.DC

TL;DR: 本文介绍了NVIDIA FLARE如何通过消息量化和容器/文件流技术解决联邦学习中大型语言模型面临的通信开销和本地资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护数据隐私的同时训练分布式模型，但大型语言模型的数十亿参数加剧了内存和通信约束，需要高效的传输和处理方法。

Method: 使用消息量化和容器/文件流两种关键技术：量化减少消息大小，流式传输实现高效内存管理，提高可扩展性和工作流集成。

Result: 这些技术显著增强了联邦学习与大型语言模型的鲁棒性和效率，在现实联邦学习场景中确保更好的性能。

Conclusion: NVIDIA FLARE通过先进的通信能力有效解决了联邦学习中大型语言模型的通信和资源限制问题，提升了实际部署的可行性。

Abstract: Federated Learning (FL) offers a promising solution for training machine learning models across distributed data sources while preserving data privacy. However, FL faces critical challenges related to communication overhead and local resource constraints, especially in the era of Large Language Models (LLMs) with billions of parameters. The sheer size of these models exacerbates both memory and communication constraints, making efficient transmission and processing essential for practical deployment. NVIDIA FLARE, an open-source SDK for federated learning, addresses these challenges by introducing advanced communication capabilities. Building upon existing solutions for large object streaming, we enhance FL workflows for LLMs through two key techniques: message quantization and container/file streaming. Quantization reduces message size, while streaming enables efficient memory management, improving scalability and integration with existing workflows. These advancements significantly enhance the robustness and efficiency of FL with LLMs, ensuring better performance in real-world federated learning scenarios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization](https://arxiv.org/abs/2511.15714)
*Ariel Kamen,Yakov Kamen*

Main category: cs.AI

TL;DR: 本文提出了一个基于大语言模型的非结构化文本分类集成框架(eLLM)，通过集成多个模型解决单个系统的常见弱点，在IAB分层分类法上实现了高达65%的F1分数提升，达到接近人类专家水平的性能。


<details>
  <summary>Details</summary>
Motivation: 解决单个大语言模型在文本分类中存在的弱点，包括不一致性、幻觉、类别膨胀和错误分类问题，提高分类的可靠性和准确性。

Method: 提出集成大语言模型(eLLM)框架，通过数学建模集体决策过程并建立原则性聚合标准，在零样本条件下评估10个最先进的大语言模型，使用IAB分层分类法对8,660个人工标注样本进行分类。

Result: eLLM框架相比最强单模型实现了高达65%的F1分数提升，个体模型由于将语义丰富的文本压缩为稀疏分类表示而性能趋于稳定，而eLLM同时提高了鲁棒性和准确性，达到接近人类专家水平的性能。

Conclusion: eLLM为基于分类法的分类提供了可扩展且可靠的解决方案，可能显著减少对人类专家标注的依赖。

Abstract: This study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65\% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8{,}660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.

</details>


### [7] [Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems](https://arxiv.org/abs/2511.15715)
*Yash Raj Singh*

Main category: cs.AI

TL;DR: 提出Graph-Memoized Reasoning框架，通过图结构记忆表示、存储和重用推理工作流，减少重复计算，提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型推理系统经常在不同任务中重复计算相似的推理步骤，浪费计算资源、增加推理延迟并限制可重现性，需要持久化推理机制来回忆和重用先前的计算痕迹。

Method: 引入图记忆推理框架，将推理工作流表示为图结构记忆，通过结构和语义相似性检索过去的决策图，实现跨新推理任务的子图组合重用。

Result: 制定了最小化总推理成本并正则化存储与生成工作流不一致性的优化目标，为智能系统中的效率-一致性权衡提供理论基础，并提出了概念性评估协议。

Conclusion: 该框架为可解释、成本高效和自我改进的推理架构奠定了基础，朝着大规模智能系统中的持久记忆迈出了一步。

Abstract: Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces.
  We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks.
  We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective.
  This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.

</details>


### [8] [MACIE: Multi-Agent Causal Intelligence Explainer for Collective Behavior Understanding](https://arxiv.org/abs/2511.15716)
*Abraham Itzhak Weinberg*

Main category: cs.AI

TL;DR: MACIE是一个多智能体因果智能解释框架，结合结构因果模型、干预反事实和Shapley值，为多智能体强化学习系统提供全面解释，解决个体因果贡献、系统涌现智能和可操作解释三个问题。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体强化学习系统在安全关键应用中广泛使用，理解智能体决策原因和集体行为实现方式变得至关重要。现有可解释AI方法在多智能体环境中表现不佳，无法将集体结果归因于个体、量化涌现行为或捕捉复杂交互。

Method: MACIE框架结合结构因果模型、干预反事实和Shapley值，通过干预归因分数分析个体因果贡献，使用协同指标分离集体效应与个体贡献，并通过自然语言叙述合成因果洞察提供可操作解释。

Result: 在四个MARL场景（合作、竞争和混合动机）中评估显示：准确的结果归因（平均φ_i=5.07，标准差<0.05），在合作任务中检测到积极涌现（协同指数高达0.461），以及高效计算（CPU上每个数据集0.79秒）。

Conclusion: MACIE独特地结合了因果严谨性、涌现量化和多智能体支持，同时保持实时使用的实用性，代表了向可解释、可信赖和负责任的多智能体AI迈出的一步。

Abstract: As Multi Agent Reinforcement Learning systems are used in safety critical applications. Understanding why agents make decisions and how they achieve collective behavior is crucial. Existing explainable AI methods struggle in multi agent settings. They fail to attribute collective outcomes to individuals, quantify emergent behaviors, or capture complex interactions. We present MACIE Multi Agent Causal Intelligence Explainer, a framework combining structural causal models, interventional counterfactuals, and Shapley values to provide comprehensive explanations. MACIE addresses three questions. First, each agent's causal contribution using interventional attribution scores. Second, system level emergent intelligence through synergy metrics separating collective effects from individual contributions. Third, actionable explanations using natural language narratives synthesizing causal insights. We evaluate MACIE across four MARL scenarios: cooperative, competitive, and mixed motive. Results show accurate outcome attribution, mean phi_i equals 5.07, standard deviation less than 0.05, detection of positive emergence in cooperative tasks, synergy index up to 0.461, and efficient computation, 0.79 seconds per dataset on CPU. MACIE uniquely combines causal rigor, emergence quantification, and multi agent support while remaining practical for real time use. This represents a step toward interpretable, trustworthy, and accountable multi agent AI.

</details>


### [9] [How Modality Shapes Perception and Reasoning: A Study of Error Propagation in ARC-AGI](https://arxiv.org/abs/2511.15717)
*Bo Wen,Chen Wang,Erhan Bilal*

Main category: cs.AI

TL;DR: 本文研究了不同模态（文本和图像）在ARC-AGI任务中对模型感知能力的影响，发现结构化文本能精确定位稀疏特征，图像能捕捉2D形状但对分辨率敏感，两者结合可提升执行效果。


<details>
  <summary>Details</summary>
Motivation: 当前指令优先系统将网格转换为自然语言或DSL规则执行，但缺乏对编码如何影响模型感知的系统分析，以及如何区分指令错误和执行错误。

Method: 使用加权集合分歧度量和两阶段推理流程，在九种文本和图像模态中分离感知与推理，测试模态对网格特征感知的影响。

Result: 结构化文本在稀疏特征上提供精确坐标，图像能捕捉2D形状但对分辨率敏感，两者结合可提升约8个感知点和0.20中位数相似度的执行效果。

Conclusion: 将表示与transformer归纳偏置对齐，并实现文本和图像间的交叉验证，可在不改变底层模型的情况下获得更准确的指令和更可靠的执行。

Abstract: ARC-AGI and ARC-AGI-2 measure generalization-through-composition on small color-quantized grids, and their prize competitions make progress on these harder held-out tasks a meaningful proxy for systematic generalization. Recent instruction-first systems translate grids into concise natural-language or DSL rules executed in generate-execute-select loops, yet we lack a principled account of how encodings shape model perception and how to separate instruction errors from execution errors. We hypothesize that modality imposes perceptual bottlenecks -- text flattens 2D structure into 1D tokens while images preserve layout but can introduce patch-size aliasing -- thereby shaping which grid features are reliably perceived. To test this, we isolate perception from reasoning across nine text and image modalities using a weighted set-disagreement metric and a two-stage reasoning pipeline, finding that structured text yields precise coordinates on sparse features, images capture 2D shapes yet are resolution-sensitive, and combining them improves execution (about 8 perception points; about 0.20 median similarity). Overall, aligning representations with transformer inductive biases and enabling cross-validation between text and image yields more accurate instructions and more reliable execution without changing the underlying model.

</details>


### [10] [ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset](https://arxiv.org/abs/2511.15718)
*Chen Yang,Ran Le,Yun Xing,Zhenwei An,Zongchao Chen,Wayne Xin Zhao,Yang Song,Tao Zhang*

Main category: cs.AI

TL;DR: ToolMind是一个大规模、高质量的LLM智能体工具使用数据集，包含16万合成数据和20万增强开源数据，通过多智能体框架生成真实用户-助手-工具交互，采用细粒度轮次级过滤确保数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在轨迹层面验证正确性，忽略了轮次级错误在训练中的传播问题，这限制了更强LLM智能体的发展。高质量轨迹数据的稀缺阻碍了LLM智能体的进步。

Method: 基于参数相关性构建函数图，使用多智能体框架模拟真实用户-助手-工具交互，采用细粒度轮次级过滤去除错误或次优步骤，保留高质量推理轨迹。

Result: 在ToolMind上微调的模型在多个基准测试中相比基线有显著改进，证明了数据集的有效性。

Conclusion: ToolMind通过大规模高质量数据生成和细粒度验证机制，解决了LLM智能体训练中的数据质量问题，为开发更强大的工具使用智能体提供了重要支持。

Abstract: Large Language Model (LLM) agents have developed rapidly in recent years to solve complex real-world problems using external tools. However, the scarcity of high-quality trajectories still hinders the development of stronger LLM agents. Most existing works on multi-turn dialogue synthesis validate correctness only at the trajectory level, which may overlook turn-level errors that can propagate during training and degrade model performance. To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances. Our data synthesis pipeline first constructs a function graph based on parameter correlations and then uses a multi-agent framework to simulate realistic user-assistant-tool interactions. Beyond trajectory-level validation, we employ fine-grained turn-level filtering to remove erroneous or suboptimal steps, ensuring that only high-quality reasoning traces are retained. This approach mitigates error amplification during training while preserving self-corrective reasoning signals essential for robust tool-use learning. Models fine-tuned on ToolMind show significant improvements over baselines on several benchmarks.

</details>


### [11] [Chain of Summaries: Summarization Through Iterative Questioning](https://arxiv.org/abs/2511.15719)
*William Brach,Lukas Galke Poech*

Main category: cs.AI

TL;DR: 提出Chain of Summaries (CoS)方法，通过类似黑格尔辩证法的迭代过程生成信息密集的通用摘要，使网页内容更易于LLM消化，在多个数据集上显著优于零样本LLM基线和专业摘要方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在处理外部网页内容时面临的格式不友好和上下文长度限制问题，使网页内容更易于LLM访问和使用。

Method: 采用类似黑格尔辩证法的方法：初始摘要（正题）→通过提问识别局限性（反题）→生成通用摘要（合题），迭代优化摘要质量。

Result: 在TriviaQA、TruthfulQA和SQUAD数据集上，CoS比零样本LLM基线提升高达66%，比BRIO和PEGASUS等专业摘要方法提升高达27%，且使用更少token。

Conclusion: CoS为网站维护者提供了使内容更易于LLM访问的有吸引力的选择，同时保留人工监督的可能性，且对下游LLM具有不可知性。

Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.

</details>


### [12] [Automated Hazard Detection in Construction Sites Using Large Language and Vision-Language Models](https://arxiv.org/abs/2511.15720)
*Islem Sahraoui*

Main category: cs.AI

TL;DR: 该论文提出了一种多模态AI框架，结合文本和图像分析来识别建筑工地的安全隐患。通过两个案例研究评估了大型语言模型和视觉语言模型在自动危险识别方面的能力。


<details>
  <summary>Details</summary>
Motivation: 在建筑工地等安全关键环境中，事故数据通常以多种格式存在（如书面报告、检查记录和现场图像），传统方法难以综合识别危险。

Method: 使用多模态AI框架，结合文本和图像分析。第一个案例研究使用GPT 4o和GPT 4o mini从28,000份OSHA事故报告中提取结构化见解；第二个案例研究使用Molmo 7B和Qwen2 VL 2B模型在ConstructionSite10k数据集上进行规则级安全违规检测。

Result: 尽管Molmo 7B和Qwen2 VL 2B模型规模较小，但在某些提示配置下表现出竞争力，证明了低资源多模态系统用于规则感知安全监控的可行性。

Conclusion: 多模态AI框架能够有效结合文本和视觉数据来识别建筑工地安全隐患，为低成本、可扩展的安全监控系统提供了可行方案。

Abstract: This thesis explores a multimodal AI framework for enhancing construction safety through the combined analysis of textual and visual data. In safety-critical environments such as construction sites, accident data often exists in multiple formats, such as written reports, inspection records, and site imagery, making it challenging to synthesize hazards using traditional approaches. To address this, this thesis proposed a multimodal AI framework that combines text and image analysis to assist in identifying safety hazards on construction sites. Two case studies were consucted to evaluate the capabilities of large language models (LLMs) and vision-language models (VLMs) for automated hazard identification.The first case study introduces a hybrid pipeline that utilizes GPT 4o and GPT 4o mini to extract structured insights from a dataset of 28,000 OSHA accident reports (2000-2025). The second case study extends this investigation using Molmo 7B and Qwen2 VL 2B, lightweight, open-source VLMs. Using the public ConstructionSite10k dataset, the performance of the two models was evaluated on rule-level safety violation detection using natural language prompts. This experiment served as a cost-aware benchmark against proprietary models and allowed testing at scale with ground-truth labels. Despite their smaller size, Molmo 7B and Quen2 VL 2B showed competitive performance in certain prompt configurations, reinforcing the feasibility of low-resource multimodal systems for rule-aware safety monitoring.

</details>


### [13] [Spatial Reasoning in Multimodal Large Language Models: A Survey of Tasks, Benchmarks and Methods](https://arxiv.org/abs/2511.15722)
*Weichen Liu,Qiyao Xue,Haoming Wang,Xiangyu Yin,Boyuan Yang,Wei Gao*

Main category: cs.AI

TL;DR: 本文从认知角度提出空间智能分类法，按推理复杂度组织任务并关联认知功能，分析现有基准、评估方法及提升空间能力的技术，揭示当前模型与人类推理的差距。


<details>
  <summary>Details</summary>
Motivation: 现有研究多按输入模态分类空间推理进展，但空间能力不仅由输入格式决定，需要从认知角度建立更原则性的分类框架来理解MLLMs的空间推理能力。

Method: 引入基于认知视角的分类法，按推理复杂度组织空间任务并映射到认知功能；系统梳理文本、视觉语言和具身环境中的基准测试；分析训练型和推理型提升方法。

Result: 建立了认知导向的空间智能分类框架，识别出现有基准在分类中的分布，揭示了当前模型能力与人类空间推理的关键差距，明确了不同提升方法的互补机制。

Conclusion: 认知视角为跨任务比较提供了原则性框架，有助于指导未来研究填补模型与人类空间推理能力的差距，为研究者提供了全面的领域理解和可行的研究方向。

Abstract: Spatial reasoning, which requires ability to perceive and manipulate spatial relationships in the 3D world, is a fundamental aspect of human intelligence, yet remains a persistent challenge for Multimodal large language models (MLLMs). While existing surveys often categorize recent progress based on input modality (e.g., text, image, video, or 3D), we argue that spatial ability is not solely determined by the input format. Instead, our survey introduces a taxonomy that organizes spatial intelligence from cognitive aspect and divides tasks in terms of reasoning complexity, linking them to several cognitive functions. We map existing benchmarks across text only, vision language, and embodied settings onto this taxonomy, and review evaluation metrics and methodologies for assessing spatial reasoning ability. This cognitive perspective enables more principled cross-task comparisons and reveals critical gaps between current model capabilities and human-like reasoning. In addition, we analyze methods for improving spatial ability, spanning both training-based and reasoning-based approaches. This dual perspective analysis clarifies their respective strengths, uncovers complementary mechanisms. By surveying tasks, benchmarks, and recent advances, we aim to provide new researchers with a comprehensive understanding of the field and actionable directions for future research.

</details>


### [14] [Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer](https://arxiv.org/abs/2511.15741)
*Hyo-Jeong Jang*

Main category: cs.AI

TL;DR: 该论文提出了一种基于一致性引导的跨模态迁移方法，通过将异构模态投影到共享潜在空间来应对多模态学习中的不确定性挑战，在情感识别基准测试中显著提升了模型稳定性、判别能力和对噪声监督的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态学习系统中由于噪声数据、低质量标签和异构模态特性带来的不确定性挑战，特别是在人机交互环境中数据质量、语义可靠性和标注一致性差异较大的问题。

Method: 采用一致性引导的跨模态迁移框架，利用跨模态语义一致性进行鲁棒表示学习，将异构模态投影到共享潜在空间以减少模态差距并揭示支持不确定性估计的结构关系。

Result: 在多模态情感识别基准测试中，该方法显著提高了模型稳定性、判别能力和对噪声或不完整监督的鲁棒性。潜在空间分析显示即使在挑战性条件下也能捕获可靠的跨模态结构。

Conclusion: 该论文通过整合不确定性建模、语义对齐和数据高效监督，为弹性多模态学习提供了统一视角，为开发可靠和自适应的脑机接口系统提供了实用见解。

Abstract: Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.

</details>


### [15] [Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response](https://arxiv.org/abs/2511.15755)
*Philip Drammeh*

Main category: cs.AI

TL;DR: 多智能体编排相比单智能体方法在事件响应中实现了100%可操作建议率，是单智能体方法（1.7%）的80倍改进，并在所有试验中保持零质量方差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）有望加速生产系统中的事件响应，但单智能体方法生成模糊、不可用的建议。

Method: 提出了MyAntFarm.ai，一个可复现的容器化框架，通过348个对照试验比较单智能体副驾驶与多智能体系统在相同事件场景下的表现。

Result: 多智能体编排实现了100%可操作建议率，而单智能体方法仅为1.7%；在行动特异性方面提高了80倍，在解决方案正确性方面提高了140倍。多智能体系统在所有试验中表现出零质量方差。

Conclusion: 多智能体编排从性能优化转变为基于LLM的事件响应的生产就绪要求。引入了决策质量（DQ）这一新指标，捕捉现有LLM指标未解决的有效性、特异性和正确性属性。

Abstract: Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.

</details>


### [16] [Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights](https://arxiv.org/abs/2511.15778)
*Paulina Tworek,Miłosz Bargieł,Yousef Khan,Tomasz Pełech-Pilichowski,Marek Mikołajczyk,Roman Lewandowski,Jose Sousa*

Main category: cs.AI

TL;DR: 比较基于规则的方法和大型语言模型在波兰电子健康记录信息提取中的表现，发现规则方法在年龄和性别提取上更准确，而LLMs在药物识别上表现更好，建议采用混合方法。


<details>
  <summary>Details</summary>
Motivation: 在非英语医疗环境中，从非结构化临床文本中提取结构化信息面临资源稀缺的挑战，需要评估不同NLP方法在真实医院环境中的有效性。

Method: 使用波兰儿童康复医院的电子健康记录，比较基于规则的低计算方法和大型语言模型在提取患者人口统计、临床发现和处方药物信息方面的表现，并评估文本规范化和翻译的影响。

Result: 规则方法在信息检索任务中准确率更高，特别是在年龄和性别提取方面；LLMs在药物名称识别上表现优异，且具有更好的适应性和可扩展性。翻译会导致信息损失。

Conclusion: 建议采用混合方法，结合规则系统的精确性和LLMs的适应性，为真实医院环境提供更可靠和资源高效的临床NLP解决方案。

Abstract: Extracting structured medical insights from unstructured clinical text using Natural Language Processing (NLP) remains an open challenge in healthcare, particularly in non-English contexts where resources are scarce. This study presents a comparative analysis of NLP low-compute rule-based methods and Large Language Models (LLMs) for information extraction from electronic health records (EHR) obtained from the Voivodeship Rehabilitation Hospital for Children in Ameryka, Poland. We evaluate both approaches by extracting patient demographics, clinical findings, and prescribed medications while examining the effects of lack of text normalisation and translation-induced information loss. Results demonstrate that rule-based methods provide higher accuracy in information retrieval tasks, particularly for age and sex extraction. However, LLMs offer greater adaptability and scalability, excelling in drug name recognition. The effectiveness of the LLMs was compared with texts originally in Polish and those translated into English, assessing the impact of translation. These findings highlight the trade-offs between accuracy, normalisation, and computational cost when deploying NLP in healthcare settings. We argue for hybrid approaches that combine the precision of rule-based systems with the adaptability of LLMs, offering a practical path toward more reliable and resource-efficient clinical NLP in real-world hospitals.

</details>


### [17] [IMACT-CXR - An Interactive Multi-Agent Conversational Tutoring System for Chest X-Ray Interpretation](https://arxiv.org/abs/2511.15825)
*Tuan-Anh Le,Anh Mai Vu,David Yang,Akash Awasthi,Hien Van Nguyen*

Main category: cs.AI

TL;DR: IMACT-CXR是一个基于AutoGen的多智能体交互式胸部X光解读教学系统，集成了空间标注、注视分析、知识检索和图像推理功能，通过智能体协作提供个性化教学反馈。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够统一处理学习者标注、注视数据和文本观察的智能教学系统，帮助医学实习生提高胸部X光解读能力，解决传统教学方法的局限性。

Method: 使用AutoGen框架构建多智能体系统，集成边界框标注、注视采样、贝叶斯知识追踪、PubMed证据检索、相似病例匹配和视觉语言推理等功能模块。

Result: 系统实现了响应式教学流程，具有有界延迟、精确控制答案泄露和可扩展性，初步评估显示在定位和诊断推理方面优于基线方法。

Conclusion: IMACT-CXR展示了多智能体系统在医学影像教学中的有效性，为实时住院医师培训部署提供了可行方案。

Abstract: IMACT-CXR is an interactive multi-agent conversational tutor that helps trainees interpret chest X-rays by unifying spatial annotation, gaze analysis, knowledge retrieval, and image-grounded reasoning in a single AutoGen-based workflow. The tutor simultaneously ingests learner bounding boxes, gaze samples, and free-text observations. Specialized agents evaluate localization quality, generate Socratic coaching, retrieve PubMed evidence, suggest similar cases from REFLACX, and trigger NV-Reason-CXR-3B for vision-language reasoning when mastery remains low or the learner explicitly asks. Bayesian Knowledge Tracing (BKT) maintains skill-specific mastery estimates that drive both knowledge reinforcement and case similarity retrieval. A lung-lobe segmentation module derived from a TensorFlow U-Net enables anatomically aware gaze feedback, and safety prompts prevent premature disclosure of ground-truth labels. We describe the system architecture, implementation highlights, and integration with the REFLACX dataset for real DICOM cases. IMACT-CXR demonstrates responsive tutoring flows with bounded latency, precise control over answer leakage, and extensibility toward live residency deployment. Preliminary evaluation shows improved localization and diagnostic reasoning compared to baselines.

</details>


### [18] [Mini Amusement Parks (MAPs): A Testbed for Modelling Business Decisions](https://arxiv.org/abs/2511.15830)
*Stéphane Aroca-Ouellette,Ian Berlot-Attwell,Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Tongqi Zhu,Herin Kang,Kaheer Suleman,Sam Pasupalak*

Main category: cs.AI

TL;DR: 该论文介绍了Mini Amusement Parks (MAPs)模拟器，用于评估智能体在复杂商业环境中的决策能力，发现人类表现远超当前最先进的LLM智能体。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在现实世界决策中面临挑战，但现有基准测试孤立评估各项能力，无法评估整体决策能力。

Method: 开发了MAPs游乐园模拟器，统一了环境建模、长期规划、空间推理等挑战，并提供人类基准和LLM智能体评估。

Result: 人类在简单模式下表现优于AI系统6.5倍，中等模式下优于9.8倍，揭示了AI在长期优化、样本效率学习等方面的弱点。

Conclusion: MAPs为评估适应性决策能力的智能体提供了新的基准基础。

Abstract: Despite rapid progress in artificial intelligence, current systems struggle with the interconnected challenges that define real-world decision making. Practical domains, such as business management, require optimizing an open-ended and multi-faceted objective, actively learning environment dynamics from sparse experience, planning over long horizons in stochastic settings, and reasoning over spatial information. Yet existing human--AI benchmarks isolate subsets of these capabilities, limiting our ability to assess holistic decision-making competence. We introduce Mini Amusement Parks (MAPs), an amusement-park simulator designed to evaluate an agent's ability to model its environment, anticipate long-term consequences under uncertainty, and strategically operate a complex business. We provide human baselines and a comprehensive evaluation of state-of-the-art LLM agents, finding that humans outperform these systems by 6.5x on easy mode and 9.8x on medium mode. Our analysis reveals persistent weaknesses in long-horizon optimization, sample-efficient learning, spatial reasoning, and world modelling. By unifying these challenges within a single environment, MAPs offers a new foundation for benchmarking agents capable of adaptable decision making. Code: https://github.com/Skyfall-Research/MAPs

</details>


### [19] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: Step-Audio-R1是首个成功在音频领域解锁推理能力的模型，通过模态接地推理蒸馏框架，使音频推理能够真正基于声学特征而非产生不相关的推理链。


<details>
  <summary>Details</summary>
Motivation: 尽管推理模型在文本和视觉领域通过扩展思维链取得了显著成功，但音频语言模型始终表现出无推理时性能更好的反常现象，这引发了对音频智能是否真正能从深思中受益的根本问题。

Method: 提出模态接地推理蒸馏（MGRD）框架，使Step-Audio-R1学习生成与音频相关的推理链，这些推理链真正基于声学特征而非产生不连贯的推理。

Result: 模型展现出强大的音频推理能力，超越了Gemini 2.5 Pro，并在涵盖语音、环境声音和音乐的综合音频理解和推理基准测试中达到了与最先进的Gemini 3 Pro相当的性能。

Conclusion: 研究表明，当适当锚定时，推理是一种可跨模态转移的能力，将扩展推理从音频智能的负担转变为强大资产，为构建真正跨所有感官模态深度思考的多模态推理系统开辟了新途径。

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [20] [Decomposing Theory of Mind: How Emotional Processing Mediates ToM Abilities in LLMs](https://arxiv.org/abs/2511.15895)
*Ivan Chulo,Ananya Joshi*

Main category: cs.AI

TL;DR: 本文通过对比激活引导与基线LLMs的激活，使用线性探针分析45种认知行为，发现情感理解而非分析推理是LLMs成功心智理论能力的关键机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明激活引导能显著改善语言模型的心智理论能力，但其内部机制导致不同输出的变化尚不清楚。

Method: 在Gemma-3-4B模型上应用对比激活加法引导，在1000个BigToM前向信念场景中评估，使用线性探针分析45种认知行为的激活差异。

Result: 信念归因任务准确率从32.5%提升至46.7%，这种改善由情感内容处理（情感感知+2.23，情感评价+2.20）介导，同时抑制分析过程（质疑-0.78，收敛思维-1.59）。

Conclusion: LLMs中成功的心智理论能力由情感理解而非分析推理介导。

Abstract: Recent work shows activation steering substantially improves language models' Theory of Mind (ToM) (Bortoletto et al. 2024), yet the mechanisms of what changes occur internally that leads to different outputs remains unclear. We propose decomposing ToM in LLMs by comparing steered versus baseline LLMs' activations using linear probes trained on 45 cognitive actions. We applied Contrastive Activation Addition (CAA) steering to Gemma-3-4B and evaluated it on 1,000 BigToM forward belief scenarios (Gandhi et al. 2023), we find improved performance on belief attribution tasks (32.5\% to 46.7\% accuracy) is mediated by activations processing emotional content : emotion perception (+2.23), emotion valuing (+2.20), while suppressing analytical processes: questioning (-0.78), convergent thinking (-1.59). This suggests that successful ToM abilities in LLMs are mediated by emotional understanding, not analytical reasoning.

</details>


### [21] [Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs](https://arxiv.org/abs/2511.15921)
*Chelsea Zou,Yiheng Yao,Basant Khalil*

Main category: cs.AI

TL;DR: 本文开发了一个用于大型语言模型的自校正框架，通过细粒度不确定性信号（自我评估置信度对齐和词元级熵峰值）实时检测和缓解推理过程中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多步推理中产生幻觉的问题，不仅关注最终答案正确性，更注重中间推理步骤的可靠性和忠实性。

Method: 设计复合奖励函数，惩罚不合理的高置信度和熵峰值，鼓励稳定准确的推理轨迹；通过强化学习策略，利用置信度感知的奖励反馈来塑造模型生成行为。

Result: 实验表明该方法提高了最终答案准确性和推理校准度，消融实验验证了每个信号对性能的独立贡献。

Conclusion: 该方法使模型更具自省能力，不仅改善了结果正确性，还提升了中间推理步骤的一致性和忠实性。

Abstract: This project develops a self correcting framework for large language models (LLMs) that detects and mitigates hallucinations during multi-step reasoning. Rather than relying solely on final answer correctness, our approach leverages fine grained uncertainty signals: 1) self-assessed confidence alignment, and 2) token-level entropy spikes to detect unreliable and unfaithful reasoning in real time. We design a composite reward function that penalizes unjustified high confidence and entropy spikes, while encouraging stable and accurate reasoning trajectories. These signals guide a reinforcement learning (RL) policy that makes the model more introspective and shapes the model's generation behavior through confidence-aware reward feedback, improving not just outcome correctness but the coherence and faithfulness of their intermediate reasoning steps. Experiments show that our method improves both final answer accuracy and reasoning calibration, with ablations validating the individual contribution of each signal.

</details>


### [22] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: JudgeBoard是一个新的评估框架，直接查询模型评估答案正确性，无需额外答案比较。提出MAJ多智能体评估框架，通过多个SLM协作达到LLM级别的判断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge框架依赖与真实标签或其他答案的间接比较，难以实现细粒度和可扩展的推理输出评估。需要直接评估模型判断答案正确性的能力。

Method: 构建JudgeBoard评估管道，直接查询模型评估答案正确性。提出MAJ多智能体判断框架，利用多个具有不同推理特征的SLM通过协作审议来近似LLM级别的判断准确性。

Result: 实验显示SLM和LLM在独立判断任务中存在显著性能差距。MAJ框架显著提高了SLM的可靠性和一致性。在MATH数据集上，使用较小模型作为骨干的MAJ表现与较大模型相当甚至更好。

Conclusion: 多智能体SLM系统在判断任务中可能匹配或超越LLM性能，对可扩展和高效评估具有重要意义。

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [23] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: 论文研究大型语言模型在获取证据后仍无法正确推理的问题，特别是在临床环境中。使用书面暴露疗法指南作为测试平台，发现即使提供权威文本，模型仍会出错。提出了评估推理准确性、一致性和忠实度的框架。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在检索到正确证据后仍无法进行正确推理的问题，特别是在需要遵循结构化协议的临床环境中，确保模型输出与权威指南一致。

Method: 使用书面暴露疗法指南作为测试平台，评估模型对临床医生验证问题的响应，提出评估框架来衡量推理的准确性、一致性和忠实度。

Result: 研究发现即使提供权威文本段落，模型错误仍然存在。检索增强生成可以约束输出，但安全部署需要对推理进行严格评估。

Conclusion: 检索增强生成有潜力约束模型输出，但在临床等高风险环境中安全部署需要像评估检索一样严格评估推理过程。

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [24] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: SpellForger是一个让玩家通过自然语言提示创建自定义法术的游戏，使用BERT模型解析玩家输入并映射到预设法术模板，平衡参数以保持游戏平衡性。


<details>
  <summary>Details</summary>
Motivation: 探索AI作为核心游戏玩法共创工具的应用，目前这一领域尚未充分开发，旨在提供个性化和创造性的独特游戏体验。

Method: 使用监督训练的BERT模型解析玩家自然语言提示，将其映射到预设法术模板并平衡伤害、成本和效果等参数。游戏在Unity引擎中开发，AI后端使用Python。

Result: 预期交付一个功能原型，能够实时生成法术并应用于引人入胜的游戏循环中，验证AI作为直接游戏机制的有效性。

Conclusion: 该研究验证了使用AI作为直接游戏机制的可行性，玩家创造力成为游戏体验的核心，为AI在游戏开发中的创新应用提供了新思路。

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [25] [An Aligned Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size](https://arxiv.org/abs/2511.16045)
*Jorge A. Huertas,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 提出了一种新的约束规划模型用于串行批处理调度问题，该模型无需预定义虚拟批次集合，通过关键对齐参数直接在机器上推理相同族作业序列，获得了更紧凑的公式和更好的求解性能。


<details>
  <summary>Details</summary>
Motivation: 现有约束规划模型依赖预定义的虚拟批次集合，这受到维度灾难影响并增加了问题复杂性。在半导体制造等实际应用中，最小批次大小是常见要求，需要更高效的求解方法。

Method: 开发了不依赖虚拟批次集合的新约束规划模型，使用关键对齐参数直接推理相同族作业序列，并通过定制搜索阶段和增强约束传播器推理水平来改进模型。

Result: 在近5000个实例上的计算实验表明，新模型在最多100个作业的小到中型实例上表现优越，在最多500个作业、10个族、10台机器的大规模实例上，找到的解决方案比现有方法好25%。

Conclusion: 提出的新约束规划模型在串行批处理调度问题上显著优于现有方法，特别是在处理最小批次大小约束时表现出更好的可扩展性和求解质量。

Abstract: In serial batch (s-batch) scheduling, jobs from similar families are grouped into batches and processed sequentially to avoid repetitive setups that are required when processing consecutive jobs of different families. Despite its large success in scheduling, only three Constraint Programming (CP) models have been proposed for this problem considering minimum batch sizes, which is a common requirement in many practical settings, including the ion implantation area in semiconductor manufacturing. These existing CP models rely on a predefined virtual set of possible batches that suffers from the curse of dimensionality and adds complexity to the problem. This paper proposes a novel CP model that does not rely on this virtual set. Instead, it uses key alignment parameters that allow it to reason directly on the sequences of same-family jobs scheduled on the machines, resulting in a more compact formulation. This new model is further improved by exploiting the problem's structure with tailored search phases and strengthened inference levels of the constraint propagators. The extensive computational experiments on nearly five thousand instances compare the proposed models against existing methods in the literature, including mixed-integer programming formulations, tabu search meta-heuristics, and CP approaches. The results demonstrate the superiority of the proposed models on small-to-medium instances with up to 100 jobs, and their ability to find solutions up to 25\% better than the ones produces by existing methods on large-scale instances with up to 500 jobs, 10 families, and 10 machines.

</details>


### [26] [A Hybrid Proactive And Predictive Framework For Edge Cloud Resource Management](https://arxiv.org/abs/2511.16075)
*Hrikshesh Kumar,Anika Garg,Anshul Gupta,Yashika Agarwal*

Main category: cs.AI

TL;DR: 本文提出了一种结合CNN-LSTM时间序列预测和多智能体深度强化学习的混合架构，用于云边缘工作负载资源管理，实现从被动响应到主动预测的转变。


<details>
  <summary>Details</summary>
Motivation: 传统云边缘工作负载资源管理过于被动，依赖静态阈值导致要么资源过度配置造成浪费，要么资源不足导致性能下降。需要转向主动预测性解决方案。

Method: 设计混合架构，将CNN-LSTM模型的时间序列预测嵌入到基于多智能体深度强化学习的编排器中，使AI管理器能够预见未来状态并做出长期规划决策。

Result: 测试表明该系统明显优于传统方法，能够有效解决复杂决策问题，同时平衡成本节约、系统健康和应用程序性能等多个目标。

Conclusion: 通过将预测能力直接嵌入DRL智能体的状态空间，使AI管理器具备预见性，能够在成本节约和系统性能之间找到最佳平衡点，实现平滑的资源管理路径。

Abstract: Old cloud edge workload resource management is too reactive. The problem with relying on static thresholds is that we are either overspending for more resources than needed or have reduced performance because of their lack. This is why we work on proactive solutions. A framework developed for it stops reacting to the problems but starts expecting them. We design a hybrid architecture, combining two powerful tools: the CNN LSTM model for time series forecasting and an orchestrator based on multi agent Deep Reinforcement Learning In fact the novelty is in how we combine them as we embed the predictive forecast from the CNN LSTM directly into the DRL agent state space. That is what makes the AI manager smarter it sees the future, which allows it to make better decisions about a long term plan for where to run tasks That means finding that sweet spot between how much money is saved while keeping the system healthy and apps fast for users That is we have given it eyes in order to see down the road so that it does not have to lurch from one problem to another it finds a smooth path forward Our tests show our system easily beats the old methods It is great at solving tough problems like making complex decisions and juggling multiple goals at once like being cheap fast and reliable

</details>


### [27] [SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent](https://arxiv.org/abs/2511.16108)
*Shiyi Cao,Dacheng Li,Fangzhou Zhao,Shuo Yuan,Sumanth R. Hegde,Connor Chen,Charlie Ruan,Tyler Griggs,Shu Liu,Eric Tang,Richard Liaw,Philipp Moritz,Matei Zaharia,Joseph E. Gonzalez,Ion Stoica*

Main category: cs.AI

TL;DR: SkyRL-Agent是一个高效的多轮长视野智能体训练和评估框架，通过异步调度、轻量级工具集成和灵活后端互操作性，显著提升了训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决智能体训练中的效率问题，特别是多轮长视野任务中的训练成本高和效率低的问题，开发了SkyRL-Agent框架。

Method: 采用优化的异步流水线调度器（1.55倍加速）和基于AST的搜索工具增强训练方法，结合强化学习训练软件工程智能体SA-SWE-32B。

Result: SA-SWE-32B在SWE-Bench Verified上达到39.4% Pass@1，相比之前模型成本降低2倍以上，并能有效泛化到其他智能体任务。

Conclusion: SkyRL-Agent框架通过高效调度和工具集成显著提升了智能体训练效率和性能，展示了良好的可扩展性和泛化能力。

Abstract: We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker.
  Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency. Together, these optimizations enable SA-SWE-32B to reach 39.4% Pass@1 on SWE-Bench Verified with more than 2x cost reduction compared to prior models reaching similar performance. Despite being trained solely on SWE tasks, SA-SWE-32B generalizes effectively to other agentic tasks, including Terminal-Bench, BrowseComp-Plus, and WebArena. We further demonstrate SkyRL-Agent's extensibility through case studies on deep research, computer use, and memory agents, each trained using a different training backend.

</details>


### [28] [Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints](https://arxiv.org/abs/2511.16139)
*Yongnan Jin,Xurui Li,Feng Cao,Liucun Gao,Juanjuan Yao*

Main category: cs.AI

TL;DR: MR-RML是一个通过GPRC实现的多维标准导向的奖励模型学习框架，旨在解决大语言模型在医疗实践中的对齐挑战，包括评估基准与临床需求脱节、难以适应多源医疗标准以及传统奖励模型无法捕捉多维医疗质量标准等问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗实践中的实际应用受到关键对齐挑战的限制：静态评估基准与动态临床认知需求脱节、难以适应不断发展的多源医疗标准、传统奖励模型无法捕捉多维医疗质量标准。

Method: 提出MR-RML框架，包含三个核心创新：(1) "维度-场景-学科"医疗标准系统，将领域标准嵌入完整训练流程；(2) 独立多维奖励模型，分解评估标准，从实时标准评分转向内化奖励建模；(3) 几何投影参考约束，将医疗认知逻辑转化为数学正则化。

Result: 在权威医疗基准Healthbench上的评估显示，相比基础模型Qwen-32B，该方法在完整子集上提升45%，在困难子集上提升85%，在开源大语言模型中达到SOTA水平（完整子集62.7分，困难子集44.7分），并优于大多数闭源模型。

Conclusion: MR-RML框架通过结构化医疗标准系统和多维奖励模型，有效解决了大语言模型在医疗领域的对齐挑战，显著提升了模型在医疗基准上的表现，为医疗AI的实际应用提供了可行方案。

Abstract: The integration of large language models (LLMs) into medical practice holds transformative potential, yet their real-world clinical utility remains limited by critical alignment challenges: (1) a disconnect between static evaluation benchmarks and dynamic clinical cognitive needs, (2) difficulties in adapting to evolving, multi-source medical standards, and (3) the inability of conventional reward models to capture nuanced, multi-dimensional medical quality criteria. To address these gaps, we propose MR-RML (Multidimensional Rubric-oriented Reward Model Learning) via GPRC (Geometric Projection Reference Constraints), a novel alignment framework that integrates medical standards into a structured "Dimensions-Scenarios-Disciplines" matrix to guide data generation and model optimization. MR-RML introduces three core innovations: (1) a "Dimensions-Scenarios-Disciplines" medical standard system that embeds domain standards into the full training pipeline; (2) an independent multi-dimensional reward model that decomposes evaluation criteria, shifting from real-time rubric-based scoring to internalized reward modeling for improved consistency and cost-efficiency; (3) geometric projection reference constraints that transform medical cognitive logic into mathematical regularization, aligning scoring gradients with clinical reasoning and enabling synthetic data-driven training. Through extensive evaluations on the authoritative medical benchmark Healthbench, our method yields substantial performance gains over the base LLM Qwen-32B (45% on the full subset and 85% on Hard subset, respectively). It achieves a SOTA among open-source LLMs with scores of 62.7 (full subset) and 44.7 (hard subset), while also outperforming the majority of closed-source models.

</details>


### [29] [FOOTPASS: A Multi-Modal Multi-Agent Tactical Context Dataset for Play-by-Play Action Spotting in Soccer Broadcast Videos](https://arxiv.org/abs/2511.16183)
*Jeremie Ochin,Raphael Chekroun,Bogdan Stanciulescu,Sotiris Manitsaris*

Main category: cs.AI

TL;DR: 该论文介绍了FOOTPASS数据集，这是首个在足球比赛中进行逐场比赛动作识别的基准数据集，结合计算机视觉输出和战术知识来生成可靠的逐场比赛数据流。


<details>
  <summary>Details</summary>
Motivation: 当前动作识别方法不足以构建可靠的逐场比赛数据，通常只能辅助而非完全自动化标注。同时战术建模、轨迹预测和性能分析等领域需要基于比赛状态和逐场比赛数据，因此需要利用战术知识作为先验来支持基于计算机视觉的预测。

Method: 引入FOOTPASS数据集，支持在多模态、多智能体战术背景下开发球员中心动作识别方法，利用计算机视觉任务输出（如跟踪、识别）和足球战术规律知识。

Result: 创建了首个覆盖整场足球比赛的逐场比赛动作识别基准数据集，能够生成可靠的逐场比赛数据流。

Conclusion: FOOTPASS数据集为数据驱动的体育分析提供了重要输入，通过结合计算机视觉和战术知识实现了更自动化和可靠的逐场比赛数据提取。

Abstract: Soccer video understanding has motivated the creation of datasets for tasks such as temporal action localization, spatiotemporal action detection (STAD), or multiobject tracking (MOT). The annotation of structured sequences of events (who does what, when, and where) used for soccer analytics requires a holistic approach that integrates both STAD and MOT. However, current action recognition methods remain insufficient for constructing reliable play-by-play data and are typically used to assist rather than fully automate annotation. Parallel research has advanced tactical modeling, trajectory forecasting, and performance analysis, all grounded in game-state and play-by-play data. This motivates leveraging tactical knowledge as a prior to support computer-vision-based predictions, enabling more automated and reliable extraction of play-by-play data. We introduce Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS), the first benchmark for play-by-play action spotting over entire soccer matches in a multi-modal, multi-agent tactical context. It enables the development of methods for player-centric action spotting that exploit both outputs from computer-vision tasks (e.g., tracking, identification) and prior knowledge of soccer, including its tactical regularities over long time horizons, to generate reliable play-by-play data streams. These streams form an essential input for data-driven sports analytics.

</details>


### [30] [From Performance to Understanding: A Vision for Explainable Automated Algorithm Design](https://arxiv.org/abs/2511.16201)
*Niki van Stein,Anna V. Kononova,Thomas Bäck*

Main category: cs.AI

TL;DR: 本文提出将自动化算法设计与系统性基准测试相结合的可解释自动化算法设计愿景，通过LLM驱动算法变体发现、可解释基准测试和问题类别描述符三个支柱，实现从盲目搜索到可解释、类别特定算法设计的转变。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的算法设计方法主要关注性能，但缺乏对算法为何有效、哪些组件重要以及设计选择与问题结构关系的理解，需要将自动化与理解相结合。

Method: 构建三支柱框架：LLM驱动的算法变体发现、可解释基准测试（将性能归因于组件和超参数）、问题类别描述符（连接算法行为与景观结构）。

Result: 这些元素形成封闭的知识循环，使发现、解释和泛化相互增强，产生关于优化策略何时及为何成功的可重用科学见解。

Conclusion: 通过集成自动化和理解，该框架将推动领域从盲目搜索转向可解释的类别特定算法设计，在加速进展的同时产生科学洞察。

Abstract: Automated algorithm design is entering a new phase: Large Language Models can now generate full optimisation (meta)heuristics, explore vast design spaces and adapt through iterative feedback. Yet this rapid progress is largely performance-driven and opaque. Current LLM-based approaches rarely reveal why a generated algorithm works, which components matter or how design choices relate to underlying problem structures. This paper argues that the next breakthrough will come not from more automation, but from coupling automation with understanding from systematic benchmarking. We outline a vision for explainable automated algorithm design, built on three pillars: (i) LLM-driven discovery of algorithmic variants, (ii) explainable benchmarking that attributes performance to components and hyperparameters and (iii) problem-class descriptors that connect algorithm behaviour to landscape structure. Together, these elements form a closed knowledge loop in which discovery, explanation and generalisation reinforce each other. We argue that this integration will shift the field from blind search to interpretable, class-specific algorithm design, accelerating progress while producing reusable scientific insight into when and why optimisation strategies succeed.

</details>


### [31] [Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning](https://arxiv.org/abs/2511.16202)
*Pei Yang,Ke Zhang,Ji Wang,Xiao Chen,Yuxin Tang,Eric Yang,Lynn Ai,Bill Shi*

Main category: cs.AI

TL;DR: CRM是一个多智能体协作奖励模型框架，用专业评估者团队替代单一黑盒奖励模型，提高RLHF的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型难以同时优化多个可能冲突的偏好维度（如事实性、帮助性、安全性），且评分透明度有限。

Method: 将偏好评估分解为领域特定的智能体，每个产生部分信号，结合全局评估器；中央聚合器融合这些信号，平衡逐步正确性、多智能体一致性和重复惩罚。

Result: CRM与rewardBench基准结合，为更透明的奖励建模和更稳定的优化提供了实用模块化路径。

Conclusion: 该框架通过多视角奖励塑造，在不需额外人工标注的情况下，实现了更稳健和可解释的强化学习人类反馈。

Abstract: We present CRM (Multi-Agent Collaborative Reward Model), a framework that replaces a single black-box reward model with a coordinated team of specialist evaluators to improve robustness and interpretability in RLHF. Conventional reward models struggle to jointly optimize multiple, sometimes conflicting, preference dimensions (e.g., factuality, helpfulness, safety) and offer limited transparency into why a score is assigned. CRM addresses these issues by decomposing preference evaluation into domain-specific agents that each produce partial signals, alongside global evaluators such as ranker-based and embedding-similarity rewards. A centralized aggregator fuses these signals at each timestep, balancing factors like step-wise correctness, multi-agent agreement, and repetition penalties, yielding a single training reward compatible with standard RL pipelines. The policy is optimized with advantage-based updates (e.g., GAE), while a value model regresses to the aggregated reward, enabling multi-perspective reward shaping without requiring additional human annotations beyond those used to train the evaluators. To support training and assessment, we introduce rewardBench, a benchmark and training suite aligned with the collaborative structure of CRM. Together, CRM and rewardBench provide a practical, modular path to more transparent reward modeling and more stable optimization.

</details>


### [32] [ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025](https://arxiv.org/abs/2511.16205)
*Xu Qiang,Shengyuan Bai,Leqing Chen,Zijing Liu,Yu Li*

Main category: cs.AI

TL;DR: ChemO是一个基于国际化学奥林匹克竞赛的新基准，通过评估等效重构和结构化视觉增强来解决化学问题的自动评估挑战，结合ChemLabs多智能体框架实现了超越人类金牌水平的性能。


<details>
  <summary>Details</summary>
Motivation: 数学和物理的奥林匹克级基准是AI推理的重要测试平台，但化学因其独特的多模态符号语言一直是个开放挑战，需要专门的基准来评估AI的化学推理能力。

Method: 提出ChemO基准，包含评估等效重构（将需要视觉输出的问题转换为计算可处理格式）和结构化视觉增强（分离模型的视觉感知与化学推理能力），并开发ChemLabs分层多智能体框架模拟人类专家协作。

Result: 实验表明，结合结构化视觉增强和多智能体系统能显著提升性能，最佳配置达到93.6分（满分100），超过估计的人类金牌阈值，建立了化学问题自动解决的新最先进水平。

Conclusion: ChemO基准和ChemLabs框架成功解决了化学奥林匹克级问题的自动评估挑战，为AI在复杂化学推理领域的发展提供了重要工具和基准。

Abstract: Olympiad-level benchmarks in mathematics and physics are crucial testbeds for advanced AI reasoning, but chemistry, with its unique multimodal symbolic language, has remained an open challenge. We introduce ChemO, a new benchmark built from the International Chemistry Olympiad (IChO) 2025. ChemO features two key innovations for automated assessment: Assessment-Equivalent Reformulation (AER), which converts problems requiring visual outputs (e.g., drawing molecules) into computationally tractable formats, and Structured Visual Enhancement (SVE), a diagnostic mechanism to disentangle a model's visual perception capabilities from its core chemical reasoning. To tackle this benchmark, we propose ChemLabs, a hierarchical multi-agent framework that mimics human expert collaboration through specialized agents for problem decomposition, perception, reasoning, and auditing. Experiments on state-of-the-art multimodal models demonstrate that combining SVE with our multi-agent system yields dramatic performance gains. Our top configuration achieves a score of 93.6 out of 100, surpassing an estimated human gold medal threshold and establishing a new state-of-the-art in automated chemical problem-solving. ChemO Dataset: https://huggingface.co/datasets/IDEA-AI4SCI/ChemO

</details>


### [33] [FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks](https://arxiv.org/abs/2511.16216)
*Zhen Hao Wong,Jingwen Deng,Hao Liang,Runming He,Chengyu Shen,Wentao Zhang*

Main category: cs.AI

TL;DR: 提出自动化管道从教育文档中提取高质量问答对，结合布局感知OCR和LLM语义解析，为LLM训练提供真实教育内容替代合成数据


<details>
  <summary>Details</summary>
Motivation: 现有指令调优和RL数据集成本高且依赖合成样本导致幻觉和多样性有限，而教材中的高质量问答内容因PDF转换困难未被充分利用

Method: 结合布局感知OCR和LLM语义解析的自动化管道，从教育文档中提取问答对和视觉问答对

Result: 实验显示该方法能产生准确、对齐且低噪声的问答对，支持多样化文档类型

Conclusion: 该方法能规模化利用真实教育内容，为改进推理导向的LLM训练提供实用替代方案

Abstract: The development of Large Language Models (LLMs) increasingly depends on high-quality supervised data, yet existing instruction-tuning and RL datasets remain costly to curate and often rely on synthetic samples that introduce hallucination and limited diversity. At the same time, textbooks and exercise materials contain abundant, high-quality human-authored Question-Answer(QA) content that remains underexploited due to the difficulty of transforming raw PDFs into AI-ready supervision. Although modern OCR and vision-language models can accurately parse document structure, their outputs lack the semantic alignment required for training. We propose an automated pipeline that extracts well-formed QA and visual-QA (VQA) pairs from educational documents by combining layout-aware OCR with LLM-based semantic parsing. Experiments across diverse document types show that the method produces accurate, aligned, and low-noise QA/VQA pairs. This approach enables scalable use of real-world educational content and provides a practical alternative to synthetic data generation for improving reasoning-oriented LLM training. All code and data-processing pipelines are open-sourced at https://github.com/OpenDCAI/DataFlow.

</details>


### [34] [MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering](https://arxiv.org/abs/2511.16283)
*Zhiyuan Li,Haisheng Yu,Guangchuan Guo,Nan Zhou,Jiajun Zhang*

Main category: cs.AI

TL;DR: 本文提出了一个多意图科学问答基准(MuISQA)和一个意图感知检索框架，通过LLM假设答案、分解意图特定查询，并使用RRF重排序来改善多意图问题的证据覆盖。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统通常面向单一意图，导致在复杂科学问题中证据覆盖不完整，无法满足多意图和多跳推理的需求。

Method: 使用LLM假设潜在答案，将其分解为意图特定查询，检索每个意图的支持段落，然后通过RRF聚合和重排序来平衡不同意图的覆盖并减少冗余。

Result: 在MuISQA基准和其他通用RAG数据集上的实验表明，该方法在检索准确性和证据覆盖方面持续优于传统方法。

Conclusion: 提出的意图感知检索框架能有效解决多意图科学问答中的证据覆盖问题，显著提升RAG系统的性能。

Abstract: Complex scientific questions often entail multiple intents, such as identifying gene mutations and linking them to related diseases. These tasks require evidence from diverse sources and multi-hop reasoning, while conventional retrieval-augmented generation (RAG) systems are usually single-intent oriented, leading to incomplete evidence coverage. To assess this limitation, we introduce the Multi-Intent Scientific Question Answering (MuISQA) benchmark, which is designed to evaluate RAG systems on heterogeneous evidence coverage across sub-questions. In addition, we propose an intent-aware retrieval framework that leverages large language models (LLMs) to hypothesize potential answers, decompose them into intent-specific queries, and retrieve supporting passages for each underlying intent. The retrieved fragments are then aggregated and re-ranked via Reciprocal Rank Fusion (RRF) to balance coverage across diverse intents while reducing redundancy. Experiments on both MuISQA benchmark and other general RAG datasets demonstrate that our method consistently outperforms conventional approaches, particularly in retrieval accuracy and evidence coverage.

</details>


### [35] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: OpenMMReasoner是一个完全透明的两阶段多模态推理训练方法，包含监督微调(SFT)和强化学习(RL)阶段，在9个多模态推理基准上相比Qwen2.5-VL-7B-Instruct基线提升了11.6%。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉推理取得了显著进展，但缺乏透明和可复现的数据整理和训练策略仍然是可扩展研究的主要障碍。

Method: 采用两阶段训练方法：SFT阶段使用874K样本的冷启动数据集进行逐步验证，RL阶段使用74K样本跨多个领域进一步优化和稳定推理能力。

Result: 在多个多模态推理基准测试中超越了强基线，证明了数据质量和训练设计对多模态推理性能的关键作用。

Conclusion: 该训练方法为未来大规模多模态推理研究奠定了坚实的实证基础，所有代码、流程和数据均已开源。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [36] [Reducing Instability in Synthetic Data Evaluation with a Super-Metric in MalDataGen](https://arxiv.org/abs/2511.16373)
*Anna Luiza Gomes da Silva,Diego Kreutz,Angelo Diniz,Rodrigo Mansilha,Celso Nobre da Fonseca*

Main category: cs.AI

TL;DR: 本文提出了一个Super-Metric来评估Android恶意软件合成数据的质量，该指标聚合了八个指标，生成单一加权分数，实验证明比传统指标更稳定和一致。


<details>
  <summary>Details</summary>
Motivation: 由于现有指标的不稳定性和缺乏标准化，评估Android恶意软件合成数据质量一直存在挑战。

Method: 在MalDataGen中集成了一个Super-Metric，该指标聚合了八个指标，涵盖四个保真度维度，生成单一加权分数。

Result: 实验涉及十个生成模型和五个平衡数据集，表明Super-Metric比传统指标更稳定和一致，与分类器实际性能的相关性更强。

Conclusion: Super-Metric为评估Android恶意软件合成数据质量提供了更可靠和标准化的方法。

Abstract: Evaluating the quality of synthetic data remains a persistent challenge in the Android malware domain due to instability and the lack of standardization among existing metrics. This work integrates into MalDataGen a Super-Metric that aggregates eight metrics across four fidelity dimensions, producing a single weighted score. Experiments involving ten generative models and five balanced datasets demonstrate that the Super-Metric is more stable and consistent than traditional metrics, exhibiting stronger correlations with the actual performance of classifiers.

</details>


### [37] [An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models](https://arxiv.org/abs/2511.16383)
*Alexander Zadorojniy,Segev Wasserkrug,Eitan Farchi*

Main category: cs.AI

TL;DR: 本文提出了一种基于智能体的优化模型自动验证方法，将软件测试技术扩展到优化建模领域，通过问题级测试API生成、测试用例生成和优化模型特异性变异来验证LLM生成的优化模型是否正确满足自然语言描述的要求。


<details>
  <summary>Details</summary>
Motivation: 随着使用大语言模型从自然语言描述生成优化模型越来越流行，如何验证生成的模型是否正确并满足需求成为一个重要开放问题。现有方法缺乏针对优化模型的自动验证机制。

Method: 提出基于智能体的验证框架，包含多个智能体：首先生成问题级测试API，然后基于该API生成测试用例，最后针对优化模型生成特异性变异来评估测试套件的故障检测能力。

Result: 通过实验证明，该智能体集成方法在软件测试指标——变异覆盖率方面提供了高质量的验证效果。

Conclusion: 该方法成功将软件测试技术扩展到优化建模领域，为LLM生成的优化模型提供了有效的自动验证机制，通过变异覆盖率指标验证了其高质量验证能力。

Abstract: Recently, using Large Language Models (LLMs) to generate optimization models from natural language descriptions has became increasingly popular. However, a major open question is how to validate that the generated models are correct and satisfy the requirements defined in the natural language description. In this work, we propose a novel agent-based method for automatic validation of optimization models that builds upon and extends methods from software testing to address optimization modeling . This method consists of several agents that initially generate a problem-level testing API, then generate tests utilizing this API, and, lastly, generate mutations specific to the optimization model (a well-known software testing technique assessing the fault detection power of the test suite). In this work, we detail this validation framework and show, through experiments, the high quality of validation provided by this agent ensemble in terms of the well-known software testing measure called mutation coverage.

</details>


### [38] [Pharos-ESG: A Framework for Multimodal Parsing, Contextual Narration, and Hierarchical Labeling of ESG Report](https://arxiv.org/abs/2511.16417)
*Yan Chen,Yu Zou,Jialei Zeng,Haoran You,Xiaorui Zhou,Aixi Zhong*

Main category: cs.AI

TL;DR: Pharos-ESG是一个统一框架，通过多模态解析、上下文叙述和分层标注将ESG报告转化为结构化表示，解决了ESG报告因不规则布局和弱结构化内容带来的理解挑战。


<details>
  <summary>Details</summary>
Motivation: ESG报告作为评估企业ESG表现的核心媒介，由于幻灯片式不规则布局导致的混乱阅读顺序和冗长弱结构化内容产生的隐式层次结构，给大规模理解带来了显著挑战。

Method: 该框架集成了基于布局流的阅读顺序建模模块、由目录锚点引导的层次感知分割模块，以及将视觉元素上下文转换为连贯自然语言的多模态聚合管道。

Result: 在标注基准上的广泛实验表明，Pharos-ESG在性能上持续优于专用文档解析系统和通用多模态模型。同时发布了Aurora-ESG数据集，这是首个大规模的ESG报告公共数据集。

Conclusion: Pharos-ESG框架通过丰富的ESG、GRI和情感标签增强了输出，满足了金融研究的分析需求，更好地支持ESG在金融治理和决策中的整合。

Abstract: Environmental, Social, and Governance (ESG) principles are reshaping the foundations of global financial gover- nance, transforming capital allocation architectures, regu- latory frameworks, and systemic risk coordination mecha- nisms. However, as the core medium for assessing corpo- rate ESG performance, the ESG reports present significant challenges for large-scale understanding, due to chaotic read- ing order from slide-like irregular layouts and implicit hier- archies arising from lengthy, weakly structured content. To address these challenges, we propose Pharos-ESG, a uni- fied framework that transforms ESG reports into structured representations through multimodal parsing, contextual nar- ration, and hierarchical labeling. It integrates a reading-order modeling module based on layout flow, hierarchy-aware seg- mentation guided by table-of-contents anchors, and a multi- modal aggregation pipeline that contextually transforms vi- sual elements into coherent natural language. The framework further enriches its outputs with ESG, GRI, and sentiment labels, yielding annotations aligned with the analytical de- mands of financial research. Extensive experiments on anno- tated benchmarks demonstrate that Pharos-ESG consistently outperforms both dedicated document parsing systems and general-purpose multimodal models. In addition, we release Aurora-ESG, the first large-scale public dataset of ESG re- ports, spanning Mainland China, Hong Kong, and U.S. mar- kets, featuring unified structured representations of multi- modal content, enriched with fine-grained layout and seman- tic annotations to better support ESG integration in financial governance and decision-making.

</details>


### [39] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出了一种无需训练的一次性联邦视觉语言模型适应框架TOFA，通过视觉和文本双管道处理多模态信息，解决现有方法在数据异构性、多模态利用不足和额外训练资源需求方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦视觉语言模型适应方法存在通信成本高、易受攻击、多模态信息利用不足、缺乏专门处理数据异构性的策略以及需要额外训练资源等问题，需要开发轻量级的一次性适应方法。

Method: TOFA框架采用视觉和文本双管道：视觉管道使用分层贝叶斯模型学习个性化的类特定原型分布；文本管道评估并全局对齐生成的本地文本提示；引入自适应权重校准机制平衡个性化和鲁棒性。

Result: 在9个不同联邦设置的数据集上进行广泛实验，证明了TOFA方法的有效性。

Conclusion: TOFA是一种无需训练的一次性联邦适应框架，能够充分利用预训练视觉语言模型的多模态特征，有效处理数据异构性，且不需要客户端或服务器端的额外训练资源。

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [40] [From generative AI to the brain: five takeaways](https://arxiv.org/abs/2511.16432)
*Claudius Gros*

Main category: cs.AI

TL;DR: 论文主张深入探讨生成式AI中的生成原则是否也适用于大脑，并讨论了机器学习研究对神经科学的五个启示性概念。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的显著进展源于明确的生成原则，而非晦涩算法。作者认为有必要研究这些原则是否在大脑中同样有效，这对认知神经科学具有重要意义。

Method: 通过分析机器学习研究中的五个关键概念：世界建模的局限性、思维过程生成、注意力机制、神经缩放定律和量化，来探讨机器学习对神经科学的启示。

Result: 论文识别了机器学习研究对理解神经信息处理系统的多个重要贡献，展示了机器学习概念如何为神经科学提供新的研究视角和方法论。

Conclusion: 神经科学可以从机器学习研究中获得重要启示，特别是在生成原则、信息处理机制和系统特性方面，这为理解大脑功能提供了新的理论框架。

Abstract: The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.

</details>


### [41] [PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based Dementia Monitoring](https://arxiv.org/abs/2511.16445)
*Joy Lai,Alex Mihailidis*

Main category: cs.AI

TL;DR: PersonaDrift是一个合成基准测试，用于评估机器学习和统计方法检测日常沟通中渐进变化的能力，特别关注痴呆症患者对数字提醒系统的响应变化。


<details>
  <summary>Details</summary>
Motivation: 痴呆症患者(PLwD)的沟通方式会逐渐变化，但现有计算工具大多无法跟踪这种随时间的行为漂移。

Method: 基于护理人员访谈创建合成用户模型，模拟60天交互日志，注入渐进的情感扁平化和离题回复两种变化，评估多种异常检测方法。

Result: 情感扁平化在低基线变异性的用户中可用简单统计模型检测，而语义漂移需要时序建模和个性化基线。个性化分类器在所有任务中表现优于通用分类器。

Conclusion: 个性化行为上下文对于检测痴呆症患者沟通变化至关重要，PersonaDrift为评估相关方法提供了可扩展的基准框架。

Abstract: People living with dementia (PLwD) often show gradual shifts in how they communicate, becoming less expressive, more repetitive, or drifting off-topic in subtle ways. While caregivers may notice these changes informally, most computational tools are not designed to track such behavioral drift over time. This paper introduces PersonaDrift, a synthetic benchmark designed to evaluate machine learning and statistical methods for detecting progressive changes in daily communication, focusing on user responses to a digital reminder system. PersonaDrift simulates 60-day interaction logs for synthetic users modeled after real PLwD, based on interviews with caregivers. These caregiver-informed personas vary in tone, modality, and communication habits, enabling realistic diversity in behavior. The benchmark focuses on two forms of longitudinal change that caregivers highlighted as particularly salient: flattened sentiment (reduced emotional tone and verbosity) and off-topic replies (semantic drift). These changes are injected progressively at different rates to emulate naturalistic cognitive trajectories, and the framework is designed to be extensible to additional behaviors in future use cases. To explore this novel application space, we evaluate several anomaly detection approaches, unsupervised statistical methods (CUSUM, EWMA, One-Class SVM), sequence models using contextual embeddings (GRU + BERT), and supervised classifiers in both generalized and personalized settings. Preliminary results show that flattened sentiment can often be detected with simple statistical models in users with low baseline variability, while detecting semantic drift requires temporal modeling and personalized baselines. Across both tasks, personalized classifiers consistently outperform generalized ones, highlighting the importance of individual behavioral context.

</details>


### [42] [Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes](https://arxiv.org/abs/2511.16548)
*Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang*

Main category: cs.AI

TL;DR: CLOZE是一个基于大语言模型的框架，用于从临床笔记中自动提取医学实体并整合到分层医学本体中，实现零样本、隐私保护的自动化本体扩展。


<details>
  <summary>Details</summary>
Motivation: 临床笔记作为富含详细患者观察的非结构化文档，为医学本体扩展提供了有价值但未被充分利用的资源，但目前直接利用临床笔记进行本体扩展的研究仍很有限。

Method: 利用预训练大语言模型的强大语言理解和生物医学知识，CLOZE框架能够识别疾病相关概念并捕捉复杂的分层关系，采用零样本方法无需额外训练或标注数据，并通过自动移除受保护健康信息来保护患者隐私。

Result: 实验结果表明CLOZE提供了一个准确、可扩展且隐私保护的本体扩展框架，在生物医学研究和临床信息学中具有广泛应用潜力。

Conclusion: CLOZE框架成功实现了从临床笔记中自动提取医学概念并整合到现有本体中，为零样本、隐私保护的医学本体扩展提供了有效的解决方案。

Abstract: Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.

</details>


### [43] [Consciousness in Artificial Intelligence? A Framework for Classifying Objections and Constraints](https://arxiv.org/abs/2511.16582)
*Andres Campero,Derek Shiller,Jaan Aru,Jonathan Simon*

Main category: cs.AI

TL;DR: 本文开发了一个分类框架，用于对数字人工智能系统意识可能性的挑战进行分类。该框架通过马尔水平识别挑战的粒度级别，并区分挑战的力度等级。


<details>
  <summary>Details</summary>
Motivation: 旨在为数字人工智能系统意识可能性的辩论提供结构化的分析工具，澄清计算功能主义挑战与数字意识挑战之间的区别。

Method: 提出了一个分类学框架，通过马尔水平识别挑战的粒度级别，并将挑战力度分为三个等级：对计算功能主义的挑战、实践性挑战和严格不可能性论证。

Result: 将该框架应用于科学和哲学文献中的14个典型案例，成功区分了不同类型的挑战及其力度等级。

Conclusion: 该框架为数字意识辩论提供了结构化的分析工具，能够有效区分计算功能主义挑战与数字意识挑战，以及不同解析这些挑战的方式。

Abstract: We develop a taxonomical framework for classifying challenges to the possibility of consciousness in digital artificial intelligence systems. This framework allows us to identify the level of granularity at which a given challenge is intended (the levels we propose correspond to Marr's levels) and to disambiguate its degree of force: is it a challenge to computational functionalism that leaves the possibility of digital consciousness open (degree 1), a practical challenge to digital consciousness that suggests improbability without claiming impossibility (degree 2), or an argument claiming that digital consciousness is strictly impossible (degree 3)? We apply this framework to 14 prominent examples from the scientific and philosophical literature. Our aim is not to take a side in the debate, but to provide structure and a tool for disambiguating between challenges to computational functionalism and challenges to digital consciousness, as well as between different ways of parsing such challenges.

</details>


### [44] [You Only Forward Once: An Efficient Compositional Judging Paradigm](https://arxiv.org/abs/2511.16600)
*Tianlong Zhang,Hongwei Xue,Shilin Yan,Di Wu,Chen Xu,Yunyun Yang*

Main category: cs.AI

TL;DR: YOFO是一种基于模板的多模态大语言模型评判方法，通过单次前向传播同时验证所有结构化需求，实现数量级的速度提升并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM评判方法面临基本权衡：适应输出单一分数与MLLM生成性质不匹配且限制细粒度需求理解，而自回归生成评判分析在高吞吐量场景下速度过慢。

Method: 提出YOFO方法，基于自回归模型接受结构化需求模板，在单次推理步骤中通过读取每个需求相关最终标记的logits产生二元是/否决策。

Result: 实验显示YOFO在标准推荐数据集上达到最先进结果，支持依赖感知分析（后续判断基于先前判断），并能从后验思维链中获益。

Conclusion: YOFO通过结构化模板条件化方法解决了MLLM评判的速度与精度权衡问题，在保持可解释性的同时实现数量级加速。

Abstract: Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis-where subsequent judgments are conditioned on previous ones-and further benefits from post-hoc CoT.

</details>


### [45] [Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](https://arxiv.org/abs/2511.16602)
*Yi Zhang,Che Liu,Xiancong Ren,Hanchu Ni,Yingji Zhang,Shuai Zhang,Zeyuan Ding,Jiayu Hu,Haozhe Shan,Junbo Qi,Yan Bai,Dengjie Li,Jiachen Luo,Yidong Wang,Yong Dai,Zenglin Xu,Bin Shen,Qifan Wang,Jian Tang,Xiaozhu Ju*

Main category: cs.AI

TL;DR: DPPO是一个元认知训练框架，通过动态交替监督微调和强化学习来解决具身智能中的数据瓶颈和算法效率问题，在稀疏有限数据下实现自动弱点识别和定向资源分配。


<details>
  <summary>Details</summary>
Motivation: 解决具身智能系统的两个主要挑战：真实世界数据稀缺昂贵的数据瓶颈，以及现有方法资源消耗过大的算法效率问题。

Method: 引入Deliberate Practice Policy Optimization (DPPO)元认知训练框架，动态交替监督微调（能力扩展）和强化学习（技能精炼），实现自动弱点识别和定向资源分配。

Result: 训练出的Pelican-VL 1.0模型相比基础模型性能提升20.3%，在100B参数规模上超越开源模型10.6%。

Conclusion: DPPO是首个系统性缓解数据和资源瓶颈的框架，使社区能够高效构建多功能具身智能体，相关模型和代码已开源。

Abstract: Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.

</details>


### [46] [MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support](https://arxiv.org/abs/2511.16625)
*Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi*

Main category: cs.AI

TL;DR: MedBayes-Lite是一个轻量级的贝叶斯增强框架，用于基于transformer的临床语言模型，旨在产生可靠、不确定性感知的预测。该框架无需重新训练或架构修改，仅增加不到3%的参数开销，通过三个组件集成不确定性量化：贝叶斯嵌入校准、不确定性加权注意力和置信度引导决策塑造。


<details>
  <summary>Details</summary>
Motivation: 尽管transformer在临床决策支持中表现出强大潜力，但在模糊医疗案例中容易过度自信，而校准的不确定性对医疗应用至关重要。需要一种轻量级方法来增强现有模型的可靠性，而无需大量重新训练。

Method: 框架包含三个核心组件：(1)使用蒙特卡洛dropout进行贝叶斯嵌入校准以量化认知不确定性；(2)不确定性加权注意力，对token可靠性进行边缘化；(3)受临床风险最小化启发的置信度引导决策塑造。

Result: 在生物医学QA和临床预测基准测试（MedQA、PubMedQA、MIMIC-III）中，MedBayes-Lite持续改善校准和可信度，将过度自信降低32-48%。在模拟临床环境中，通过标记不确定预测供人工审查，可预防高达41%的诊断错误。

Conclusion: MedBayes-Lite有效实现了可靠的不确定性传播，提高了医疗AI系统的可解释性，证明了其在无需重新训练现有模型的情况下增强临床语言模型可靠性的有效性。

Abstract: We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent. The framework integrates three components: (i) Bayesian Embedding Calibration using Monte Carlo dropout for epistemic uncertainty, (ii) Uncertainty-Weighted Attention that marginalizes over token reliability, and (iii) Confidence-Guided Decision Shaping inspired by clinical risk minimization. Across biomedical QA and clinical prediction benchmarks (MedQA, PubMedQA, MIMIC-III), MedBayes-Lite consistently improves calibration and trustworthiness, reducing overconfidence by 32 to 48 percent. In simulated clinical settings, it can prevent up to 41 percent of diagnostic errors by flagging uncertain predictions for human review. These results demonstrate its effectiveness in enabling reliable uncertainty propagation and improving interpretability in medical AI systems.

</details>


### [47] [Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems](https://arxiv.org/abs/2511.16657)
*Juan C. King,Jose M. Amigo*

Main category: cs.AI

TL;DR: 本文实现了一个用于EUR-USD货币对的高频交易AI系统，整合了基本面和技术面特征，通过机器学习评估预测准确性和交易盈利能力，比较了两种特征类型的预测能力。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对EUR-USD货币对的高频交易AI系统，旨在确定基本面分析和技术分析中哪种方法在预测交易信号方面更有效和可靠。

Method: 整合全面的输入特征集：包括欧元区和美国的关键宏观经济基本面变量（如GDP、失业率），以及技术变量（指标、振荡器、斐波那契水平、价格背离），使用机器学习评估预测准确性并进行历史数据回测。

Result: 通过标准机器学习指标量化预测准确性，通过历史回测模拟评估交易盈利能力和风险表现。

Conclusion: 通过比较分析确定了基本面和技术面特征中哪一类在生成盈利交易信号方面具有更强和更可靠的预测能力。

Abstract: This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is evaluated using standard machine learning metrics to quantify predictive accuracy and backtesting simulations across historical data to assess trading profitability and risk. The study concludes with a comparative analysis to determine which class of input features, fundamental or technical, provides greater and more reliable predictive capacity for generating profitable trading signals.

</details>


### [48] [Cognitive Foundations for Reasoning and Their Manifestation in LLMs](https://arxiv.org/abs/2511.16660)
*Priyanka Kargupta,Shuyue Stella Li,Haocheng Wang,Jinu Lee,Shan Chen,Orevaoghene Ahia,Dean Light,Thomas L. Griffiths,Max Kleiman-Weiner,Jiawei Han,Asli Celikyilmaz,Yulia Tsvetkov*

Main category: cs.AI

TL;DR: 该论文提出了一个包含28个认知元素的分类法，分析了17个模型和人类在推理过程中的行为差异，发现人类使用层次嵌套和元认知监控，而模型依赖浅层前向链式推理。研究开发了测试时推理指导方法，在复杂问题上性能提升高达60%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型能解决复杂问题但在简单变体上失败，表明它们通过不同于人类推理的机制获得正确输出。研究旨在建立认知科学与LLM研究的桥梁，开发基于原则性认知机制而非脆弱伪推理捷径的模型。

Method: 综合认知科学研究构建28个认知元素的分类法，分析17个模型的170K推理轨迹和54个人类思考轨迹，进行大规模行为分析，并开发测试时推理指导方法。

Result: 揭示了系统性结构差异：人类使用层次嵌套和元认知监控，模型依赖浅层前向链式推理；元分析显示研究社区关注易量化行为而忽视元认知控制；开发的推理指导方法在复杂问题上性能提升高达60%。

Conclusion: 通过连接认知科学和LLM研究，为开发基于原则性认知机制的模型奠定了基础，为改进模型能力和大规模测试人类认知理论开辟了新方向。

Abstract: Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [49] [The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems](https://arxiv.org/abs/2511.15862)
*Devang Kulshreshtha,Wanyu Du,Raghav Jain,Srikanth Doss,Hang Su,Sandesh Swamy,Yanjun Qi*

Main category: cs.MA

TL;DR: 本文提出了一个模拟和分析不合作行为如何破坏LLM多智能体系统稳定性的新框架，包含基于博弈论的行为分类和动态模拟流程，在资源管理场景中验证了不合作行为会导致系统快速崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对不合作行为如何影响LLM多智能体系统稳定性的系统研究，需要开发框架来理解和防范这类风险。

Method: 提出包含两个关键组件的框架：(1)基于博弈论的不合作行为分类法；(2)多阶段动态模拟流程，根据智能体状态演化生成和优化不合作行为。

Result: 框架生成真实不合作行为的准确率达96.7%，实验显示合作智能体保持100%系统稳定性，而任何不合作行为都会在1-7轮内导致系统崩溃。

Conclusion: 不合作智能体会显著恶化集体结果，凸显了设计更具韧性多智能体系统的必要性。

Abstract: This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.

</details>
