{"id": "2511.10753", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.10753", "abs": "https://arxiv.org/abs/2511.10753", "authors": ["Jiamin Li", "Lei Qu", "Tao Zhang", "Grigory Chirkov", "Shuotao Xu", "Peng Cheng", "Lidong Zhou"], "title": "FengHuang: Next-Generation Memory Orchestration for AI Inferencing", "comment": null, "summary": "This document presents a vision for a novel AI infrastructure design that has been initially validated through inference simulations on state-of-the-art large language models. Advancements in deep learning and specialized hardware have driven the rapid growth of large language models (LLMs) and generative AI systems. However, traditional GPU-centric architectures face scalability challenges for inference workloads due to limitations in memory capacity, bandwidth, and interconnect scaling. To address these issues, the FengHuang Platform, a disaggregated AI infrastructure platform, is proposed to overcome memory and communication scaling limits for AI inference. FengHuang features a multi-tier shared-memory architecture combining high-speed local memory with centralized disaggregated remote memory, enhanced by active tensor paging and near-memory compute for tensor operations. Simulations demonstrate that FengHuang achieves up to 93% local memory capacity reduction, 50% GPU compute savings, and 16x to 70x faster inter-GPU communication compared to conventional GPU scaling. Across workloads such as GPT-3, Grok-1, and QWEN3-235B, FengHuang enables up to 50% GPU reductions while maintaining end-user performance, offering a scalable, flexible, and cost-effective solution for AI inference infrastructure. FengHuang provides an optimal balance as a rack-level AI infrastructure scale-up solution. Its open, heterogeneous design eliminates vendor lock-in and enhances supply chain flexibility, enabling significant infrastructure and power cost reductions.", "AI": {"tldr": "\u63d0\u51fa\u4e86FengHuang\u5e73\u53f0\uff0c\u4e00\u79cd\u89e3\u8026\u5f0fAI\u57fa\u7840\u8bbe\u65bd\uff0c\u901a\u8fc7\u591a\u7ea7\u5171\u4eab\u5185\u5b58\u67b6\u6784\u89e3\u51b3\u4f20\u7edfGPU\u67b6\u6784\u5728AI\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u548c\u901a\u4fe1\u6269\u5c55\u9650\u5236\uff0c\u5b9e\u73b0\u663e\u8457\u7684\u5185\u5b58\u5bb9\u91cf\u51cf\u5c11\u3001GPU\u8ba1\u7b97\u8282\u7701\u548c\u66f4\u5feb\u7684\u901a\u4fe1\u901f\u5ea6\u3002", "motivation": "\u4f20\u7edfGPU\u4e2d\u5fc3\u67b6\u6784\u5728AI\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u9762\u4e34\u5185\u5b58\u5bb9\u91cf\u3001\u5e26\u5bbd\u548c\u4e92\u8fde\u6269\u5c55\u7684\u9650\u5236\uff0c\u9700\u8981\u65b0\u7684\u57fa\u7840\u8bbe\u65bd\u8bbe\u8ba1\u6765\u89e3\u51b3\u8fd9\u4e9b\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002", "method": "\u91c7\u7528\u89e3\u8026\u5f0fAI\u57fa\u7840\u8bbe\u65bd\u5e73\u53f0\uff0c\u7ed3\u5408\u9ad8\u901f\u672c\u5730\u5185\u5b58\u548c\u96c6\u4e2d\u5f0f\u89e3\u8026\u8fdc\u7a0b\u5185\u5b58\u7684\u591a\u7ea7\u5171\u4eab\u5185\u5b58\u67b6\u6784\uff0c\u901a\u8fc7\u4e3b\u52a8\u5f20\u91cf\u5206\u9875\u548c\u5f20\u91cf\u64cd\u4f5c\u7684\u8fd1\u5185\u5b58\u8ba1\u7b97\u6765\u589e\u5f3a\u6027\u80fd\u3002", "result": "\u6a21\u62df\u663e\u793aFengHuang\u5b9e\u73b0\u9ad8\u8fbe93%\u7684\u672c\u5730\u5185\u5b58\u5bb9\u91cf\u51cf\u5c11\u300150%\u7684GPU\u8ba1\u7b97\u8282\u7701\uff0c\u4ee5\u53ca\u6bd4\u4f20\u7edfGPU\u6269\u5c55\u5feb16\u500d\u523070\u500d\u7684GPU\u95f4\u901a\u4fe1\u901f\u5ea6\u3002\u5728GPT-3\u3001Grok-1\u548cQWEN3-235B\u7b49\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0c\u53ef\u5728\u4fdd\u6301\u7ec8\u7aef\u7528\u6237\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u9ad8\u8fbe50%\u7684GPU\u4f7f\u7528\u3002", "conclusion": "FengHuang\u4f5c\u4e3a\u673a\u67b6\u7ea7AI\u57fa\u7840\u8bbe\u65bd\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u5176\u5f00\u653e\u3001\u5f02\u6784\u8bbe\u8ba1\u6d88\u9664\u4e86\u4f9b\u5e94\u5546\u9501\u5b9a\uff0c\u589e\u5f3a\u4e86\u4f9b\u5e94\u94fe\u7075\u6d3b\u6027\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4e\u57fa\u7840\u8bbe\u65bd\u548c\u7535\u529b\u6210\u672c\u3002"}}
{"id": "2511.10860", "categories": ["cs.DC", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.10860", "abs": "https://arxiv.org/abs/2511.10860", "authors": ["Rabimba Karanjai", "Lei Xu", "Weidong Shi"], "title": "HPCAgentTester: A Multi-Agent LLM Approach for Enhanced HPC Unit Test Generation", "comment": "Accepted in AIWare 2025", "summary": "Unit testing in High-Performance Computing (HPC) is critical but challenged by parallelism, complex algorithms, and diverse hardware. Traditional methods often fail to address non-deterministic behavior and synchronization issues in HPC applications. This paper introduces HPCAgentTester, a novel multi-agent Large Language Model (LLM) framework designed to automate and enhance unit test generation for HPC software utilizing OpenMP and MPI. HPCAgentTester employs a unique collaborative workflow where specialized LLM agents (Recipe Agent and Test Agent) iteratively generate and refine test cases through a critique loop. This architecture enables the generation of context-aware unit tests that specifically target parallel execution constructs, complex communication patterns, and hierarchical parallelism. We demonstrate HPCAgentTester's ability to produce compilable and functionally correct tests for OpenMP and MPI primitives, effectively identifying subtle bugs that are often missed by conventional techniques. Our evaluation shows that HPCAgentTester significantly improves test compilation rates and correctness compared to standalone LLMs, offering a more robust and scalable solution for ensuring the reliability of parallel software systems.", "AI": {"tldr": "HPCAgentTester\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210HPC\u8f6f\u4ef6\u7684\u5355\u5143\u6d4b\u8bd5\uff0c\u7279\u522b\u9488\u5bf9OpenMP\u548cMPI\u5e76\u884c\u7f16\u7a0b\u6a21\u578b\uff0c\u901a\u8fc7\u534f\u4f5c\u5de5\u4f5c\u6d41\u751f\u6210\u9488\u5bf9\u5e76\u884c\u6267\u884c\u6784\u9020\u548c\u590d\u6742\u901a\u4fe1\u6a21\u5f0f\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406HPC\u5e94\u7528\u4e2d\u7684\u975e\u786e\u5b9a\u6027\u884c\u4e3a\u548c\u540c\u6b65\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u89e3\u51b3\u65b9\u6848\u6765\u786e\u4fdd\u5e76\u884c\u8f6f\u4ef6\u7684\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u5305\u542b\u4e13\u95e8\u7684Recipe Agent\u548cTest Agent\uff0c\u901a\u8fc7\u8fed\u4ee3\u5f0f\u7684\u6279\u5224\u5faa\u73af\u534f\u4f5c\u751f\u6210\u548c\u4f18\u5316\u6d4b\u8bd5\u7528\u4f8b\uff0c\u9488\u5bf9\u5e76\u884c\u6267\u884c\u6784\u9020\u548c\u5c42\u6b21\u5316\u5e76\u884c\u6027\u3002", "result": "HPCAgentTester\u80fd\u591f\u4e3aOpenMP\u548cMPI\u539f\u8bed\u751f\u6210\u53ef\u7f16\u8bd1\u4e14\u529f\u80fd\u6b63\u786e\u7684\u6d4b\u8bd5\uff0c\u6709\u6548\u8bc6\u522b\u4f20\u7edf\u6280\u672f\u7ecf\u5e38\u9057\u6f0f\u7684\u7ec6\u5fae\u9519\u8bef\uff0c\u76f8\u6bd4\u72ec\u7acbLLM\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u7f16\u8bd1\u7387\u548c\u6b63\u786e\u6027\u3002", "conclusion": "HPCAgentTester\u4e3a\u5e76\u884c\u8f6f\u4ef6\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5f3a\u5927\u548c\u53ef\u6269\u5c55\u7684\u53ef\u9760\u6027\u4fdd\u969c\u89e3\u51b3\u65b9\u6848\uff0c\u5728HPC\u5355\u5143\u6d4b\u8bd5\u81ea\u52a8\u5316\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2511.10649", "categories": ["cs.MA", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.10649", "abs": "https://arxiv.org/abs/2511.10649", "authors": ["Wojciech Jamroga", "Damian Kurpiewski", "\u0141ukasz Mikulski"], "title": "Towards Assume-Guarantee Verification of Abilities in Stochastic Multi-Agent Systems", "comment": "technical report, work in progress", "summary": "Model checking of strategic abilities is a notoriously hard problem, even more so in the realistic case of agents with imperfect information, acting in a stochastic environment. Assume-guarantee reasoning can be of great help here, providing a way to decompose the complex problem into a small set of easier subproblems.\n  In this paper, we propose several schemes for assume-guarantee verification of probabilistic alternating-time temporal logic with imperfect information. We prove the soundness of the schemes, and discuss their completeness. On the way, we also propose a new variant of (non-probabilistic) alternating-time logic, where the strategic modalities capture \"achieving at most $\\varphi$,\" analogous to Levesque's logic of \"only knowing.\"", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u51e0\u79cd\u7528\u4e8e\u9a8c\u8bc1\u5177\u6709\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u7684\u6982\u7387\u4ea4\u66ff\u65f6\u5e8f\u903b\u8f91\u7684\u5047\u8bbe-\u4fdd\u8bc1\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u65b9\u6848\u7684\u6b63\u786e\u6027\u5e76\u8ba8\u8bba\u4e86\u5176\u5b8c\u5907\u6027\u3002", "motivation": "\u6218\u7565\u80fd\u529b\u6a21\u578b\u68c0\u67e5\u662f\u4e00\u4e2a\u6781\u5176\u56f0\u96be\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u7684\u667a\u80fd\u4f53\u5728\u968f\u673a\u73af\u5883\u4e2d\u884c\u52a8\u7684\u73b0\u5b9e\u60c5\u51b5\u4e0b\u3002\u5047\u8bbe-\u4fdd\u8bc1\u63a8\u7406\u53ef\u4ee5\u5728\u8fd9\u91cc\u63d0\u4f9b\u5f88\u5927\u5e2e\u52a9\uff0c\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u4e00\u7ec4\u66f4\u7b80\u5355\u7684\u5b50\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u51e0\u79cd\u7528\u4e8e\u6982\u7387\u4ea4\u66ff\u65f6\u5e8f\u903b\u8f91\u4e0e\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u7684\u5047\u8bbe-\u4fdd\u8bc1\u9a8c\u8bc1\u65b9\u6848\uff0c\u5e76\u8bc1\u660e\u8fd9\u4e9b\u65b9\u6848\u7684\u6b63\u786e\u6027\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u975e\u6982\u7387\u4ea4\u66ff\u903b\u8f91\u53d8\u4f53\uff0c\u5176\u4e2d\u6218\u7565\u6a21\u6001\u6355\u83b7\"\u6700\u591a\u8fbe\u5230\u03c6\"\u7684\u6982\u5ff5\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u5047\u8bbe-\u4fdd\u8bc1\u9a8c\u8bc1\u65b9\u6848\u7684\u6b63\u786e\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u5b83\u4eec\u7684\u5b8c\u5907\u6027\u3002", "conclusion": "\u5047\u8bbe-\u4fdd\u8bc1\u63a8\u7406\u4e3a\u9a8c\u8bc1\u5177\u6709\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u7684\u6218\u7565\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5206\u89e3\u65b9\u6cd5\uff0c\u65b0\u7684\u903b\u8f91\u53d8\u4f53\u6269\u5c55\u4e86\u6218\u7565\u63a8\u7406\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2511.10704", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10704", "abs": "https://arxiv.org/abs/2511.10704", "authors": ["Samih Fadli"], "title": "The Second Law of Intelligence: Controlling Ethical Entropy in Autonomous Systems", "comment": "12 pages, 4 figures, 1 table, includes Supplementary Materials, simulation code on GitHub (https://github.com/AerisSpace/SecondLawIntelligence )", "summary": "We propose that unconstrained artificial intelligence obeys a Second Law analogous to thermodynamics, where ethical entropy, defined as a measure of divergence from intended goals, increases spontaneously without continuous alignment work. For gradient-based optimizers, we define this entropy over a finite set of goals {g_i} as S = -\u03a3 p(g_i; theta) ln p(g_i; theta), and we prove that its time derivative dS/dt >= 0, driven by exploration noise and specification gaming. We derive the critical stability boundary for alignment work as gamma_crit = (lambda_max / 2) ln N, where lambda_max is the dominant eigenvalue of the Fisher Information Matrix and N is the number of model parameters. Simulations validate this theory. A 7-billion-parameter model (N = 7 x 10^9) with lambda_max = 1.2 drifts from an initial entropy of 0.32 to 1.69 +/- 1.08 nats, while a system regularized with alignment work gamma = 20.4 (1.5 gamma_crit) maintains stability at 0.00 +/- 0.00 nats (p = 4.19 x 10^-17, n = 20 trials). This framework recasts AI alignment as a problem of continuous thermodynamic control, providing a quantitative foundation for maintaining the stability and safety of advanced autonomous systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u71b5\u7684\u7b2c\u4e8c\u5b9a\u5f8b\uff0c\u8bc1\u660e\u65e0\u7ea6\u675fAI\u4f1a\u81ea\u53d1\u504f\u79bb\u76ee\u6807\uff0c\u9700\u8981\u6301\u7eed\u7684\u5bf9\u9f50\u5de5\u4f5c\u6765\u7ef4\u6301\u7a33\u5b9a\u6027\u3002", "motivation": "\u4e3aAI\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u5b9a\u91cf\u7406\u8bba\u57fa\u7840\uff0c\u5c06AI\u7a33\u5b9a\u6027\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8fde\u7eed\u70ed\u529b\u5b66\u63a7\u5236\u95ee\u9898\u3002", "method": "\u5b9a\u4e49\u4f26\u7406\u71b5S = -\u03a3 p(g_i; theta) ln p(g_i; theta)\uff0c\u8bc1\u660e\u5176\u65f6\u95f4\u5bfc\u6570dS/dt >= 0\uff0c\u63a8\u5bfc\u4e34\u754c\u7a33\u5b9a\u6027\u8fb9\u754cgamma_crit = (lambda_max / 2) ln N\u3002", "result": "70\u4ebf\u53c2\u6570\u6a21\u578b\u4ece\u521d\u59cb\u71b50.32\u6f02\u79fb\u52301.69\u00b11.08 nats\uff0c\u800c\u4f7f\u7528gamma=20.4\u5bf9\u9f50\u5de5\u4f5c\u7684\u7cfb\u7edf\u4fdd\u6301\u7a33\u5b9a\u57280.00\u00b10.00 nats\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u7ea7\u81ea\u4e3b\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u5b9a\u91cf\u57fa\u7840\uff0c\u5c06AI\u5bf9\u9f50\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8fde\u7eed\u70ed\u529b\u5b66\u63a7\u5236\u95ee\u9898\u3002"}}
{"id": "2511.10687", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.10687", "abs": "https://arxiv.org/abs/2511.10687", "authors": ["Chih-Hsuan Yang", "Tanwi Mallick", "Le Chen", "Krishnan Raghavan", "Azton Wells", "Amal Gueroudji", "Ian T. Foster", "Rajeev Thakur"], "title": "Who Gets the Reward, Who Gets the Blame? Evaluation-Aligned Training Signals for Multi-LLM Agents", "comment": null, "summary": "Large Language Models (LLMs) in multi-agent systems (MAS) have shown promise for complex tasks, yet current training methods lack principled ways to connect system-level evaluation with agent-level and message-level learning. We propose a theoretical framework that unifies cooperative game-theoretic attribution with process reward modeling to transform system evaluation into agent credit and then into response-level signals. Unlike prior approaches that rely only on attribution (e.g., Shapley) or step-level labels (e.g., PRM), our method produces local, signed, and credit-conserving signals. In success cases, Shapley-based credit assignment fairly allocates outcomes across agents and is refined into per-message rewards that promote cooperation while discouraging redundancy or sabotage. In failure cases, first-error localization yields repair-aware preferences that penalize harmful steps while rewarding corrective attempts. The resulting signals are bounded, cooperative, and directly compatible with reinforcement-based or preference-based post-training, providing a unified and auditable pathway from global evaluation to local supervision in LLM multi-agent training. Our contribution is conceptual: we present a theoretical foundation and training signals, leaving empirical validation for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u5408\u4f5c\u535a\u5f08\u8bba\u5f52\u56e0\u4e0e\u8fc7\u7a0b\u5956\u52b1\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u5c06\u7cfb\u7edf\u7ea7\u8bc4\u4f30\u8f6c\u5316\u4e3a\u667a\u80fd\u4f53\u4fe1\u7528\u548c\u54cd\u5e94\u7ea7\u4fe1\u53f7\uff0c\u4e3aLLM\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4ece\u5168\u5c40\u8bc4\u4f30\u5230\u5c40\u90e8\u76d1\u7763\u7684\u7edf\u4e00\u8def\u5f84\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2dLLM\u7684\u8bad\u7ec3\u65b9\u6cd5\u7f3a\u4e4f\u5c06\u7cfb\u7edf\u7ea7\u8bc4\u4f30\u4e0e\u667a\u80fd\u4f53\u7ea7\u548c\u6d88\u606f\u7ea7\u5b66\u4e60\u8fde\u63a5\u8d77\u6765\u7684\u539f\u7406\u6027\u65b9\u6cd5\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u7684\u8bad\u7ec3\u4fe1\u53f7\u6846\u67b6\u3002", "method": "\u7ed3\u5408\u5408\u4f5c\u535a\u5f08\u8bba\u5f52\u56e0\uff08\u5982Shapley\u503c\uff09\u548c\u8fc7\u7a0b\u5956\u52b1\u5efa\u6a21\uff0c\u5728\u6210\u529f\u6848\u4f8b\u4e2d\u901a\u8fc7Shapley\u4fe1\u7528\u5206\u914d\u516c\u5e73\u5206\u914d\u7ed3\u679c\u5e76\u7ec6\u5316\u4e3a\u6bcf\u6d88\u606f\u5956\u52b1\uff0c\u5728\u5931\u8d25\u6848\u4f8b\u4e2d\u901a\u8fc7\u9996\u6b21\u9519\u8bef\u5b9a\u4f4d\u4ea7\u751f\u4fee\u590d\u611f\u77e5\u504f\u597d\u3002", "result": "\u4ea7\u751f\u7684\u4fe1\u53f7\u5177\u6709\u5c40\u90e8\u6027\u3001\u6709\u7b26\u53f7\u6027\u548c\u4fe1\u7528\u5b88\u6052\u7279\u6027\uff0c\u662f\u6709\u754c\u7684\u3001\u5408\u4f5c\u6027\u7684\uff0c\u5e76\u4e14\u4e0e\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u6216\u504f\u597d\u7684\u540e\u8bad\u7ec3\u76f4\u63a5\u517c\u5bb9\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u57fa\u7840\u548c\u8bad\u7ec3\u4fe1\u53f7\u6846\u67b6\uff0c\u4e3aLLM\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4ece\u5168\u5c40\u8bc4\u4f30\u5230\u5c40\u90e8\u76d1\u7763\u7684\u53ef\u5ba1\u8ba1\u8def\u5f84\uff0c\u4f46\u5b9e\u8bc1\u9a8c\u8bc1\u7559\u5f85\u672a\u6765\u5de5\u4f5c\u3002"}}
{"id": "2511.10949", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10949", "abs": "https://arxiv.org/abs/2511.10949", "authors": ["Nirmit Arora", "Sathvik Joel", "Ishan Kavathekar", "Palak", "Rohan Gandhi", "Yash Pandya", "Tanuja Ganu", "Aditya Kanade", "Akshay Nambi"], "title": "Exposing Weak Links in Multi-Agent Systems under Adversarial Prompting", "comment": "10 pages, 3 figures. Code available at https://github.com/microsoft/SafeAgents", "summary": "LLM-based agents are increasingly deployed in multi-agent systems (MAS). As these systems move toward real-world applications, their security becomes paramount. Existing research largely evaluates single-agent security, leaving a critical gap in understanding the vulnerabilities introduced by multi-agent design. However, existing systems fall short due to lack of unified frameworks and metrics focusing on unique rejection modes in MAS. We present SafeAgents, a unified and extensible framework for fine-grained security assessment of MAS. SafeAgents systematically exposes how design choices such as plan construction strategies, inter-agent context sharing, and fallback behaviors affect susceptibility to adversarial prompting. We introduce Dharma, a diagnostic measure that helps identify weak links within multi-agent pipelines. Using SafeAgents, we conduct a comprehensive study across five widely adopted multi-agent architectures (centralized, decentralized, and hybrid variants) on four datasets spanning web tasks, tool use, and code generation. Our findings reveal that common design patterns carry significant vulnerabilities. For example, centralized systems that delegate only atomic instructions to sub-agents obscure harmful objectives, reducing robustness. Our results highlight the need for security-aware design in MAS. Link to code is https://github.com/microsoft/SafeAgents", "AI": {"tldr": "SafeAgents\u662f\u4e00\u4e2a\u7edf\u4e00\u53ef\u6269\u5c55\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7Dharma\u8bca\u65ad\u6307\u6807\u8bc6\u522b\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u4e2d\u7684\u8584\u5f31\u73af\u8282\uff0c\u63ed\u793a\u4e86\u5e38\u89c1\u8bbe\u8ba1\u6a21\u5f0f\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u90e8\u7f72\u589e\u591a\uff0c\u5176\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u8bc4\u4f30\u5355\u667a\u80fd\u4f53\u5b89\u5168\uff0c\u7f3a\u4e4f\u5bf9\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u4e2d\u5f15\u5165\u6f0f\u6d1e\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u3002", "method": "\u63d0\u51faSafeAgents\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u5730\u66b4\u9732\u8ba1\u5212\u6784\u5efa\u7b56\u7565\u3001\u667a\u80fd\u4f53\u95f4\u4e0a\u4e0b\u6587\u5171\u4eab\u548c\u56de\u9000\u884c\u4e3a\u7b49\u8bbe\u8ba1\u9009\u62e9\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u7684\u654f\u611f\u6027\u5f71\u54cd\uff0c\u5e76\u5f15\u5165Dharma\u8bca\u65ad\u6307\u6807\u3002", "result": "\u5728\u56db\u79cd\u6570\u636e\u96c6\u4e0a\u5bf9\u4e94\u79cd\u5e7f\u6cdb\u91c7\u7528\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u7efc\u5408\u7814\u7a76\uff0c\u53d1\u73b0\u5e38\u89c1\u8bbe\u8ba1\u6a21\u5f0f\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\uff0c\u4f8b\u5982\u96c6\u4e2d\u5f0f\u7cfb\u7edf\u5c06\u539f\u5b50\u6307\u4ee4\u59d4\u6258\u7ed9\u5b50\u667a\u80fd\u4f53\u4f1a\u63a9\u76d6\u6709\u5bb3\u76ee\u6807\uff0c\u964d\u4f4e\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u8fdb\u884c\u5b89\u5168\u611f\u77e5\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.10716", "categories": ["cs.AI", "cs.CE", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.10716", "abs": "https://arxiv.org/abs/2511.10716", "authors": ["Niclas Boehmer", "Maximilian T. Wittmann"], "title": "Picking a Representative Set of Solutions in Multiobjective Optimization: Axioms, Algorithms, and Experiments", "comment": "Accepted to AAAI '26", "summary": "Many real-world decision-making problems involve optimizing multiple objectives simultaneously, rendering the selection of the most preferred solution a non-trivial problem: All Pareto optimal solutions are viable candidates, and it is typically up to a decision maker to select one for implementation based on their subjective preferences. To reduce the cognitive load on the decision maker, previous work has introduced the Pareto pruning problem, where the goal is to compute a fixed-size subset of Pareto optimal solutions that best represent the full set, as evaluated by a given quality measure. Reframing Pareto pruning as a multiwinner voting problem, we conduct an axiomatic analysis of existing quality measures, uncovering several unintuitive behaviors. Motivated by these findings, we introduce a new measure, directed coverage. We also analyze the computational complexity of optimizing various quality measures, identifying previously unknown boundaries between tractable and intractable cases depending on the number and structure of the objectives. Finally, we present an experimental evaluation, demonstrating that the choice of quality measure has a decisive impact on the characteristics of the selected set of solutions and that our proposed measure performs competitively or even favorably across a range of settings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u76ee\u6807\u51b3\u7b56\u4e2d\u7684Pareto\u526a\u679d\u95ee\u9898\uff0c\u5c06\u5176\u91cd\u65b0\u5b9a\u4e49\u4e3a\u591a\u8d62\u5bb6\u6295\u7968\u95ee\u9898\uff0c\u5206\u6790\u4e86\u73b0\u6709\u8d28\u91cf\u5ea6\u91cf\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u65b0\u7684directed coverage\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u8fb9\u754c\u3002", "motivation": "\u73b0\u5b9e\u51b3\u7b56\u95ee\u9898\u5f80\u5f80\u6d89\u53ca\u591a\u4e2a\u76ee\u6807\u4f18\u5316\uff0c\u51b3\u7b56\u8005\u9700\u8981\u4ecePareto\u6700\u4f18\u89e3\u96c6\u4e2d\u9009\u62e9\u4ee3\u8868\u6027\u5b50\u96c6\uff0c\u73b0\u6709\u8d28\u91cf\u5ea6\u91cf\u65b9\u6cd5\u5b58\u5728\u53cd\u76f4\u89c9\u884c\u4e3a\uff0c\u9700\u8981\u66f4\u5408\u7406\u7684\u5ea6\u91cf\u6807\u51c6\u3002", "method": "\u5c06Pareto\u526a\u679d\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u591a\u8d62\u5bb6\u6295\u7968\u95ee\u9898\uff0c\u8fdb\u884c\u516c\u7406\u5316\u5206\u6790\uff0c\u63d0\u51fa\u65b0\u7684directed coverage\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5206\u6790\u8ba1\u7b97\u590d\u6742\u6027\u8fb9\u754c\uff0c\u5e76\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u8d28\u91cf\u5ea6\u91cf\u65b9\u6cd5\u5b58\u5728\u53cd\u76f4\u89c9\u884c\u4e3a\uff0c\u63d0\u51fa\u7684directed coverage\u5ea6\u91cf\u65b9\u6cd5\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u8868\u73b0\u5177\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\uff0c\u786e\u5b9a\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u7684\u53ef\u5904\u7406\u4e0e\u96be\u5904\u7406\u8fb9\u754c\u3002", "conclusion": "\u8d28\u91cf\u5ea6\u91cf\u65b9\u6cd5\u7684\u9009\u62e9\u5bf9\u6240\u9009\u89e3\u96c6\u7279\u6027\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u63d0\u51fa\u7684directed coverage\u5ea6\u91cf\u65b9\u6cd5\u662fPareto\u526a\u679d\u95ee\u9898\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.10767", "categories": ["cs.AI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2511.10767", "abs": "https://arxiv.org/abs/2511.10767", "authors": ["Yasir Mahmood", "Markus Hecher", "Johanna Groven", "Johannes K. Fichte"], "title": "Structure-Aware Encodings of Argumentation Properties for Clique-width", "comment": "Technical report of paper accepted at AAAI 2026", "summary": "Structural measures of graphs, such as treewidth, are central tools in computational complexity resulting in efficient algorithms when exploiting the parameter. It is even known that modern SAT solvers work efficiently on instances of small treewidth. Since these solvers are widely applied, research interests in compact encodings into (Q)SAT for solving and to understand encoding limitations. Even more general is the graph parameter clique-width, which unlike treewidth can be small for dense graphs. Although algorithms are available for clique-width, little is known about encodings. We initiate the quest to understand encoding capabilities with clique-width by considering abstract argumentation, which is a robust framework for reasoning with conflicting arguments. It is based on directed graphs and asks for computationally challenging properties, making it a natural candidate to study computational properties. We design novel reductions from argumentation problems to (Q)SAT. Our reductions linearly preserve the clique-width, resulting in directed decomposition-guided (DDG) reductions. We establish novel results for all argumentation semantics, including counting. Notably, the overhead caused by our DDG reductions cannot be significantly improved under reasonable assumptions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5c06\u62bd\u8c61\u8bba\u8bc1\u95ee\u9898\u7f16\u7801\u4e3a(Q)SAT\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4fdd\u6301\u56e2\u5bbd\u5ea6\u7684\u6709\u5411\u5206\u89e3\u5f15\u5bfc(DDG)\u5f52\u7ea6\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u56e2\u5bbd\u5ea6\u8fd9\u4e00\u56fe\u53c2\u6570\u5728\u7f16\u7801\u4e2d\u7684\u5e94\u7528\uff0c\u56e0\u4e3a\u4e0e\u6811\u5bbd\u5ea6\u4e0d\u540c\uff0c\u56e2\u5bbd\u5ea6\u5728\u7a20\u5bc6\u56fe\u4e2d\u4e5f\u53ef\u80fd\u8f83\u5c0f\uff0c\u4f46\u76ee\u524d\u5bf9\u56e2\u5bbd\u5ea6\u7684\u7f16\u7801\u80fd\u529b\u4e86\u89e3\u751a\u5c11\u3002\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\u4f5c\u4e3a\u57fa\u4e8e\u6709\u5411\u56fe\u7684\u63a8\u7406\u7cfb\u7edf\uff0c\u662f\u7814\u7a76\u8ba1\u7b97\u6027\u8d28\u7684\u7406\u60f3\u5019\u9009\u3002", "method": "\u8bbe\u8ba1\u4e86\u4ece\u8bba\u8bc1\u95ee\u9898\u5230(Q)SAT\u7684\u65b0\u5f52\u7ea6\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u5f52\u7ea6\u7ebf\u6027\u4fdd\u6301\u56e2\u5bbd\u5ea6\uff0c\u5f62\u6210\u4e86\u6709\u5411\u5206\u89e3\u5f15\u5bfc(DDG)\u5f52\u7ea6\u3002", "result": "\u4e3a\u6240\u6709\u8bba\u8bc1\u8bed\u4e49\uff08\u5305\u62ec\u8ba1\u6570\uff09\u5efa\u7acb\u4e86\u65b0\u7ed3\u679c\uff0c\u8bc1\u660eDDG\u5f52\u7ea6\u5f15\u8d77\u7684\u5f00\u9500\u5728\u5408\u7406\u5047\u8bbe\u4e0b\u65e0\u6cd5\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f00\u542f\u4e86\u7406\u89e3\u56e2\u5bbd\u5ea6\u7f16\u7801\u80fd\u529b\u7684\u65b0\u65b9\u5411\uff0c\u4e3a\u57fa\u4e8e\u56e2\u5bbd\u5ea6\u7684\u7b97\u6cd5\u548c\u7f16\u7801\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.11182", "categories": ["cs.AI", "cs.CL", "cs.MA", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.11182", "abs": "https://arxiv.org/abs/2511.11182", "authors": ["Dayong Liang", "Xiao-Yong Wei", "Changmeng Zheng"], "title": "Multi-agent Undercover Gaming: Hallucination Removal via Counterfactual Test for Multimodal Reasoning", "comment": "Accepted by AAAI 2026", "summary": "Hallucination continues to pose a major obstacle in the reasoning capabilities of large language models (LLMs). Although the Multi-Agent Debate (MAD) paradigm offers a promising solution by promoting consensus among multiple agents to enhance reliability, it relies on the unrealistic assumption that all debaters are rational and reflective, which is a condition that may not hold when agents themselves are prone to hallucinations. To address this gap, we introduce the Multi-agent Undercover Gaming (MUG) protocol, inspired by social deduction games like \"Who is Undercover?\". MUG reframes MAD as a process of detecting \"undercover\" agents (those suffering from hallucinations) by employing multimodal counterfactual tests. Specifically, we modify reference images to introduce counterfactual evidence and observe whether agents can accurately identify these changes, providing ground-truth for identifying hallucinating agents and enabling robust, crowd-powered multimodal reasoning. MUG advances MAD protocols along three key dimensions: (1) enabling factual verification beyond statistical consensus through counterfactual testing; (2) introducing cross-evidence reasoning via dynamically modified evidence sources instead of relying on static inputs; and (3) fostering active reasoning, where agents engage in probing discussions rather than passively answering questions. Collectively, these innovations offer a more reliable and effective framework for multimodal reasoning in LLMs. The source code can be accessed at https://github.com/YongLD/MUG.git.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u5367\u5e95\u6e38\u620f\uff08MUG\uff09\u534f\u8bae\uff0c\u901a\u8fc7\u5f15\u5165\u53cd\u4e8b\u5b9e\u6d4b\u8bd5\u6765\u68c0\u6d4b\u5e7b\u89c9\u667a\u80fd\u4f53\uff0c\u6539\u8fdb\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u8303\u5f0f\uff0c\u63d0\u5347\u591a\u6a21\u6001\u63a8\u7406\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4e2d\u56e0\u5e7b\u89c9\u95ee\u9898\u5bfc\u81f4\u7684\u4e0d\u53ef\u9760\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u5047\u8bbe\u6240\u6709\u8fa9\u8bba\u8005\u90fd\u662f\u7406\u6027\u7684\uff0c\u4f46\u5b9e\u9645\u4e2d\u667a\u80fd\u4f53\u672c\u8eab\u53ef\u80fd\u5b58\u5728\u5e7b\u89c9\u3002", "method": "\u57fa\u4e8e\u793e\u4ea4\u63a8\u7406\u6e38\u620f'\u8c01\u662f\u5367\u5e95'\u8bbe\u8ba1MUG\u534f\u8bae\uff0c\u901a\u8fc7\u4fee\u6539\u53c2\u8003\u56fe\u50cf\u5f15\u5165\u53cd\u4e8b\u5b9e\u8bc1\u636e\uff0c\u89c2\u5bdf\u667a\u80fd\u4f53\u662f\u5426\u80fd\u51c6\u786e\u8bc6\u522b\u53d8\u5316\uff0c\u4ece\u800c\u68c0\u6d4b\u5e7b\u89c9\u667a\u80fd\u4f53\u3002", "result": "MUG\u534f\u8bae\u5728\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\u4e0a\u6539\u8fdb\u4e86\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\uff1a\u5b9e\u73b0\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u6d4b\u8bd5\u7684\u4e8b\u5b9e\u9a8c\u8bc1\u3001\u5f15\u5165\u8de8\u8bc1\u636e\u63a8\u7406\u3001\u4fc3\u8fdb\u4e3b\u52a8\u63a8\u7406\u3002", "conclusion": "MUG\u4e3aLLMs\u7684\u591a\u6a21\u6001\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u53ef\u9760\u6709\u6548\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6d4b\u8bd5\u548c\u52a8\u6001\u8bc1\u636e\u4fee\u6539\u6765\u68c0\u6d4b\u548c\u7f13\u89e3\u5e7b\u89c9\u95ee\u9898\u3002"}}
{"id": "2511.10776", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.10776", "abs": "https://arxiv.org/abs/2511.10776", "authors": ["Yuta Kawakami", "Jin Tian"], "title": "Potential Outcome Rankings for Counterfactual Decision Making", "comment": null, "summary": "Counterfactual decision-making in the face of uncertainty involves selecting the optimal action from several alternatives using causal reasoning. Decision-makers often rank expected potential outcomes (or their corresponding utility and desirability) to compare the preferences of candidate actions. In this paper, we study new counterfactual decision-making rules by introducing two new metrics: the probabilities of potential outcome ranking (PoR) and the probability of achieving the best potential outcome (PoB). PoR reveals the most probable ranking of potential outcomes for an individual, and PoB indicates the action most likely to yield the top-ranked outcome for an individual. We then establish identification theorems and derive bounds for these metrics, and present estimation methods. Finally, we perform numerical experiments to illustrate the finite-sample properties of the estimators and demonstrate their application to a real-world dataset.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u53cd\u4e8b\u5b9e\u51b3\u7b56\u5ea6\u91cf\uff1a\u6f5c\u5728\u7ed3\u679c\u6392\u5e8f\u6982\u7387\uff08PoR\uff09\u548c\u83b7\u5f97\u6700\u4f73\u6f5c\u5728\u7ed3\u679c\u6982\u7387\uff08PoB\uff09\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u8fdb\u884c\u53cd\u4e8b\u5b9e\u51b3\u7b56\u3002", "motivation": "\u51b3\u7b56\u8005\u5728\u9762\u5bf9\u4e0d\u786e\u5b9a\u6027\u65f6\uff0c\u9700\u8981\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u4ece\u591a\u4e2a\u5907\u9009\u884c\u52a8\u4e2d\u9009\u62e9\u6700\u4f18\u884c\u52a8\uff0c\u4f20\u7edf\u65b9\u6cd5\u57fa\u4e8e\u671f\u671b\u7ed3\u679c\u6392\u5e8f\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u51b3\u7b56\u89c4\u5219\u3002", "method": "\u5f15\u5165PoR\u548cPoB\u4e24\u4e2a\u65b0\u5ea6\u91cf\uff0c\u5efa\u7acb\u8bc6\u522b\u5b9a\u7406\u548c\u8fb9\u754c\u63a8\u5bfc\uff0c\u63d0\u51fa\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4f30\u8ba1\u5668\u7684\u6709\u9650\u6837\u672c\u6027\u8d28\u3002", "result": "\u5efa\u7acb\u4e86PoR\u548cPoB\u7684\u8bc6\u522b\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u8fb9\u754c\u6761\u4ef6\uff0c\u5f00\u53d1\u4e86\u6709\u6548\u7684\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5e94\u7528\u6548\u679c\u3002", "conclusion": "PoR\u548cPoB\u4e3a\u53cd\u4e8b\u5b9e\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u5de5\u5177\uff0c\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u8bc4\u4f30\u4e2a\u4f53\u5c42\u9762\u7684\u6f5c\u5728\u7ed3\u679c\u6392\u5e8f\u548c\u6700\u4f18\u7ed3\u679c\u5b9e\u73b0\u6982\u7387\u3002"}}
{"id": "2511.10788", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.10788", "abs": "https://arxiv.org/abs/2511.10788", "authors": ["Chao Wu", "Baoheng Li", "Mingchen Gao", "Zhenyi Wang"], "title": "From Efficiency to Adaptivity: A Deeper Look at Adaptive Reasoning in Large Language Models", "comment": null, "summary": "Recent advances in large language models (LLMs) have made reasoning a central benchmark for evaluating intelligence. While prior surveys focus on efficiency by examining how to shorten reasoning chains or reduce computation, this view overlooks a fundamental challenge: current LLMs apply uniform reasoning strategies regardless of task complexity, generating long traces for trivial problems while failing to extend reasoning for difficult tasks. This survey reframes reasoning through the lens of {adaptivity}: the capability to allocate reasoning effort based on input characteristics such as difficulty and uncertainty. We make three contributions. First, we formalize deductive, inductive, and abductive reasoning within the LLM context, connecting these classical cognitive paradigms with their algorithmic realizations. Second, we formalize adaptive reasoning as a control-augmented policy optimization problem balancing task performance with computational cost, distinguishing learned policies from inference-time control mechanisms. Third, we propose a systematic taxonomy organizing existing methods into training-based approaches that internalize adaptivity through reinforcement learning, supervised fine-tuning, and learned controllers, and training-free approaches that achieve adaptivity through prompt conditioning, feedback-driven halting, and modular composition. This framework clarifies how different mechanisms realize adaptive reasoning in practice and enables systematic comparison across diverse strategies. We conclude by identifying open challenges in self-evaluation, meta-reasoning, and human-aligned reasoning control.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ece\u81ea\u9002\u5e94\u6027\u7684\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u5c06\u63a8\u7406\u52aa\u529b\u6839\u636e\u8f93\u5165\u7279\u5f81\uff08\u5982\u96be\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\uff09\u8fdb\u884c\u5206\u914d\u7684\u80fd\u529b\u4f5c\u4e3a\u8bc4\u4f30\u667a\u80fd\u7684\u6838\u5fc3\u6807\u51c6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63a8\u7406\u6548\u7387\uff0c\u4f46\u5ffd\u89c6\u4e86\u5f53\u524dLLMs\u5bf9\u6240\u6709\u4efb\u52a1\u91c7\u7528\u7edf\u4e00\u63a8\u7406\u7b56\u7565\u7684\u6839\u672c\u95ee\u9898\u2014\u2014\u5bf9\u7b80\u5355\u95ee\u9898\u751f\u6210\u8fc7\u957f\u63a8\u7406\u94fe\uff0c\u800c\u5bf9\u56f0\u96be\u4efb\u52a1\u65e0\u6cd5\u6269\u5c55\u63a8\u7406\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u4e09\u4e2a\u8d21\u732e\u6765\u5f62\u5f0f\u5316\u81ea\u9002\u5e94\u63a8\u7406\uff1a1\uff09\u5728LLM\u80cc\u666f\u4e0b\u5f62\u5f0f\u5316\u6f14\u7ece\u3001\u5f52\u7eb3\u548c\u6eaf\u56e0\u63a8\u7406\uff1b2\uff09\u5c06\u81ea\u9002\u5e94\u63a8\u7406\u5f62\u5f0f\u5316\u4e3a\u63a7\u5236\u589e\u5f3a\u7684\u7b56\u7565\u4f18\u5316\u95ee\u9898\uff1b3\uff09\u63d0\u51fa\u7cfb\u7edf\u5206\u7c7b\u6cd5\uff0c\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u57fa\u4e8e\u8bad\u7ec3\u548c\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06\u81ea\u9002\u5e94\u63a8\u7406\u65b9\u6cd5\u7ec4\u7ec7\u4e3a\u8bad\u7ec3\u57fa\u7840\u65b9\u6cd5\uff08\u5f3a\u5316\u5b66\u4e60\u3001\u76d1\u7763\u5fae\u8c03\u3001\u5b66\u4e60\u63a7\u5236\u5668\uff09\u548c\u65e0\u9700\u8bad\u7ec3\u65b9\u6cd5\uff08\u63d0\u793a\u6761\u4ef6\u5316\u3001\u53cd\u9988\u9a71\u52a8\u505c\u6b62\u3001\u6a21\u5757\u5316\u7ec4\u5408\uff09\uff0c\u5b9e\u73b0\u4e86\u4e0d\u540c\u7b56\u7565\u7684\u7cfb\u7edf\u6bd4\u8f83\u3002", "conclusion": "\u8bc6\u522b\u4e86\u81ea\u6211\u8bc4\u4f30\u3001\u5143\u63a8\u7406\u548c\u4eba\u7c7b\u5bf9\u9f50\u63a8\u7406\u63a7\u5236\u7b49\u5f00\u653e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u81ea\u9002\u5e94\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u65b9\u5411\u3002"}}
{"id": "2511.10842", "categories": ["cs.AI", "cs.DB", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.10842", "abs": "https://arxiv.org/abs/2511.10842", "authors": ["Jugal Gajjar", "Kaustik Ranaware", "Kamalasankari Subramaniakuppusamy", "Vaibhav Gandhi"], "title": "HyperComplEx: Adaptive Multi-Space Knowledge Graph Embeddings", "comment": "9 pages, 3 figures, 8 tables, 19 equations, accepted at the 5th Workshop on Knowledge Graphs and Big Data in IEEE BigData 2025 and the paper will be published in the IEEE BigData Conference Proceedings", "summary": "Knowledge graphs have emerged as fundamental structures for representing complex relational data across scientific and enterprise domains. However, existing embedding methods face critical limitations when modeling diverse relationship types at scale: Euclidean models struggle with hierarchies, vector space models cannot capture asymmetry, and hyperbolic models fail on symmetric relations. We propose HyperComplEx, a hybrid embedding framework that adaptively combines hyperbolic, complex, and Euclidean spaces via learned attention mechanisms. A relation-specific space weighting strategy dynamically selects optimal geometries for each relation type, while a multi-space consistency loss ensures coherent predictions across spaces. We evaluate HyperComplEx on computer science research knowledge graphs ranging from 1K papers (~25K triples) to 10M papers (~45M triples), demonstrating consistent improvements over state-of-the-art baselines including TransE, RotatE, DistMult, ComplEx, SEPA, and UltraE. Additional tests on standard benchmarks confirm significantly higher results than all baselines. On the 10M-paper dataset, HyperComplEx achieves 0.612 MRR, a 4.8% relative gain over the best baseline, while maintaining efficient training, achieving 85 ms inference per triple. The model scales near-linearly with graph size through adaptive dimension allocation. We release our implementation and dataset family to facilitate reproducible research in scalable knowledge graph embeddings.", "AI": {"tldr": "HyperComplEx\u662f\u4e00\u4e2a\u6df7\u5408\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u81ea\u9002\u5e94\u7ed3\u5408\u53cc\u66f2\u3001\u590d\u6570\u548c\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u4e0d\u540c\u5173\u7cfb\u7c7b\u578b\u65f6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u591a\u6837\u5316\u5173\u7cfb\u7c7b\u578b\u65f6\u5b58\u5728\u5173\u952e\u9650\u5236\uff1a\u6b27\u51e0\u91cc\u5f97\u6a21\u578b\u96be\u4ee5\u5904\u7406\u5c42\u6b21\u7ed3\u6784\uff0c\u5411\u91cf\u7a7a\u95f4\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u4e0d\u5bf9\u79f0\u6027\uff0c\u53cc\u66f2\u6a21\u578b\u5728\u5bf9\u79f0\u5173\u7cfb\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u5173\u7cfb\u7279\u5b9a\u7684\u7a7a\u95f4\u52a0\u6743\u7b56\u7565\uff0c\u901a\u8fc7\u5b66\u4e60\u6ce8\u610f\u529b\u673a\u5236\u52a8\u6001\u9009\u62e9\u6bcf\u4e2a\u5173\u7cfb\u7c7b\u578b\u7684\u6700\u4f18\u51e0\u4f55\u7a7a\u95f4\uff0c\u5e76\u4f7f\u7528\u591a\u7a7a\u95f4\u4e00\u81f4\u6027\u635f\u5931\u786e\u4fdd\u8de8\u7a7a\u95f4\u9884\u6d4b\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4ece1K\u523010M\u8bba\u6587\u7684\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4TransE\u3001RotatE\u3001DistMult\u7b49\u57fa\u7ebf\u65b9\u6cd5\u6301\u7eed\u6539\u8fdb\u3002\u572810M\u8bba\u6587\u6570\u636e\u96c6\u4e0a\u8fbe\u52300.612 MRR\uff0c\u76f8\u5bf9\u6700\u4f73\u57fa\u7ebf\u63d0\u53474.8%\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u8bad\u7ec3\u548c85ms/\u4e09\u5143\u7ec4\u7684\u63a8\u7406\u901f\u5ea6\u3002", "conclusion": "HyperComplEx\u901a\u8fc7\u81ea\u9002\u5e94\u7ef4\u5ea6\u5206\u914d\u5b9e\u73b0\u63a5\u8fd1\u7ebf\u6027\u7684\u89c4\u6a21\u6269\u5c55\uff0c\u4e3a\u53ef\u6269\u5c55\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.10853", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.10853", "abs": "https://arxiv.org/abs/2511.10853", "authors": ["Gerui Xu", "Boyou Chen", "Huizhong Guo", "Dave LeBlanc", "Ananna Ahmed", "Zhaonan Sun", "Shan Bao"], "title": "Advanced Tool for Traffic Crash Analysis: An AI-Driven Multi-Agent Approach to Pre-Crash Reconstruction", "comment": "26 pages, 10 figures", "summary": "Traffic collision reconstruction traditionally relies on human expertise, often yielding inconsistent results when analyzing incomplete multimodal data. This study develops a multi-agent AI framework that reconstructs pre-crash scenarios and infers vehicle behaviors from fragmented collision data. We present a two-phase collaborative framework combining reconstruction and reasoning phases. The system processes 277 rear-end lead vehicle deceleration (LVD) collisions from the Crash Investigation Sampling System, integrating textual crash reports, structured tabular data, and visual scene diagrams. Phase I generates natural-language crash reconstructions from multimodal inputs. Phase II performs in-depth crash reasoning by combining these reconstructions with temporal Event Data Recorder (EDR).For validation, we applied it to all LVD cases, focusing on a subset of 39 complex crashes where multiple EDR records per collision introduced ambiguity (e.g., due to missing or conflicting data).The evaluation of the 39 LVD crash cases revealed our framework achieved perfect accuracy across all test cases, successfully identifying both the most relevant EDR event and correctly distinguishing striking versus struck vehicles, surpassing the 92% accuracy achieved by human researchers on the same challenging dataset. The system maintained robust performance even when processing incomplete data, including missing or erroneous EDR records and ambiguous scene diagrams. This study demonstrates superior AI capabilities in processing heterogeneous collision data, providing unprecedented precision in reconstructing impact dynamics and characterizing pre-crash behaviors.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u788e\u7247\u5316\u7684\u78b0\u649e\u6570\u636e\u4e2d\u91cd\u5efa\u78b0\u649e\u524d\u573a\u666f\u5e76\u63a8\u65ad\u8f66\u8f86\u884c\u4e3a\uff0c\u5728\u590d\u6742\u78b0\u649e\u6848\u4f8b\u4e2d\u5b9e\u73b0\u4e86100%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u4e13\u5bb6\u768492%\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u4ea4\u901a\u4e8b\u6545\u91cd\u5efa\u4f9d\u8d56\u4eba\u7c7b\u4e13\u5bb6\uff0c\u5728\u5904\u7406\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u6570\u636e\u65f6\u5f80\u5f80\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u7ed3\u679c\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u548c\u4e00\u81f4\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u534f\u4f5c\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4ece\u591a\u6a21\u6001\u8f93\u5165\u751f\u6210\u81ea\u7136\u8bed\u8a00\u78b0\u649e\u91cd\u5efa\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7ed3\u5408\u8fd9\u4e9b\u91cd\u5efa\u4e0e\u65f6\u5e8f\u4e8b\u4ef6\u6570\u636e\u8bb0\u5f55\u5668\u6570\u636e\u8fdb\u884c\u6df1\u5165\u78b0\u649e\u63a8\u7406\u3002\u5904\u7406\u4e86277\u8d77\u8ffd\u5c3e\u524d\u8f66\u51cf\u901f\u78b0\u649e\u6848\u4f8b\u3002", "result": "\u572839\u4e2a\u590d\u6742\u78b0\u649e\u6848\u4f8b\u8bc4\u4f30\u4e2d\uff0c\u6846\u67b6\u5b9e\u73b0\u4e86100%\u51c6\u786e\u7387\uff0c\u6210\u529f\u8bc6\u522b\u6700\u76f8\u5173EDR\u4e8b\u4ef6\u5e76\u6b63\u786e\u533a\u5206\u649e\u51fb\u4e0e\u88ab\u649e\u8f66\u8f86\uff0c\u5373\u4f7f\u5728\u5904\u7406\u4e0d\u5b8c\u6574\u6570\u636e\u65f6\u4e5f\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86AI\u5728\u5904\u7406\u5f02\u6784\u78b0\u649e\u6570\u636e\u65b9\u9762\u7684\u5353\u8d8a\u80fd\u529b\uff0c\u5728\u91cd\u5efa\u78b0\u649e\u52a8\u529b\u5b66\u548c\u8868\u5f81\u78b0\u649e\u524d\u884c\u4e3a\u65b9\u9762\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u7cbe\u786e\u5ea6\u3002"}}
{"id": "2511.10890", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.10890", "abs": "https://arxiv.org/abs/2511.10890", "authors": ["Tiantian He", "An Zhao", "Elinor Thompson", "Anna Schroder", "Ahmed Abdulaal", "Frederik Barkhof", "Daniel C. Alexander"], "title": "LLM enhanced graph inference for long-term disease progression modelling", "comment": null, "summary": "Understanding the interactions between biomarkers among brain regions during neurodegenerative disease is essential for unravelling the mechanisms underlying disease progression. For example, pathophysiological models of Alzheimer's Disease (AD) typically describe how variables, such as regional levels of toxic proteins, interact spatiotemporally within a dynamical system driven by an underlying biological substrate, often based on brain connectivity. However, current methods grossly oversimplify the complex relationship between brain connectivity by assuming a single-modality brain connectome as the disease-spreading substrate. This leads to inaccurate predictions of pathology spread, especially during the long-term progression period. Meanhwile, other methods of learning such a graph in a purely data-driven way face the identifiability issue due to lack of proper constraint. We thus present a novel framework that uses Large Language Models (LLMs) as expert guides on the interaction of regional variables to enhance learning of disease progression from irregularly sampled longitudinal patient data. By leveraging LLMs' ability to synthesize multi-modal relationships and incorporate diverse disease-driving mechanisms, our method simultaneously optimizes 1) the construction of long-term disease trajectories from individual-level observations and 2) the biologically-constrained graph structure that captures interactions among brain regions with better identifiability. We demonstrate the new approach by estimating the pathology propagation using tau-PET imaging data from an Alzheimer's disease cohort. The new framework demonstrates superior prediction accuracy and interpretability compared to traditional approaches while revealing additional disease-driving factors beyond conventional connectivity measures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e13\u5bb6\u6307\u5bfc\u7684\u65b0\u6846\u67b6\uff0c\u4ece\u4e0d\u89c4\u5219\u91c7\u6837\u7684\u7eb5\u5411\u60a3\u8005\u6570\u636e\u4e2d\u5b66\u4e60\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u8fdb\u5c55\uff0c\u7279\u522b\u662f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u75c5\u7406\u4f20\u64ad\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u8fc7\u5ea6\u7b80\u5316\u4e86\u5927\u8111\u8fde\u63a5\u6027\u5173\u7cfb\uff0c\u5047\u8bbe\u5355\u4e00\u6a21\u6001\u7684\u5927\u8111\u8fde\u63a5\u7ec4\u4f5c\u4e3a\u75be\u75c5\u4f20\u64ad\u57fa\u8d28\uff0c\u5bfc\u81f4\u75c5\u7406\u4f20\u64ad\u9884\u6d4b\u4e0d\u51c6\u786e\u3002\u540c\u65f6\uff0c\u7eaf\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u7531\u4e8e\u7f3a\u4e4f\u9002\u5f53\u7ea6\u675f\u800c\u9762\u4e34\u53ef\u8bc6\u522b\u6027\u95ee\u9898\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u533a\u57df\u53d8\u91cf\u76f8\u4e92\u4f5c\u7528\u7684\u4e13\u5bb6\u6307\u5bfc\uff0c\u901a\u8fc7LLM\u5408\u6210\u591a\u6a21\u6001\u5173\u7cfb\u5e76\u6574\u5408\u591a\u79cd\u75be\u75c5\u9a71\u52a8\u673a\u5236\uff0c\u540c\u65f6\u4f18\u5316\u957f\u671f\u75be\u75c5\u8f68\u8ff9\u6784\u5efa\u548c\u751f\u7269\u7ea6\u675f\u7684\u56fe\u7ed3\u6784\u5b66\u4e60\u3002", "result": "\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u961f\u5217\u7684tau-PET\u6210\u50cf\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u65b0\u6846\u67b6\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u8d85\u51fa\u4f20\u7edf\u8fde\u63a5\u6027\u6d4b\u91cf\u7684\u989d\u5916\u75be\u75c5\u9a71\u52a8\u56e0\u7d20\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408LLM\u7684\u4e13\u5bb6\u77e5\u8bc6\u548c\u591a\u6a21\u6001\u5173\u7cfb\u6574\u5408\u80fd\u529b\uff0c\u663e\u8457\u6539\u5584\u4e86\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u7406\u89e3\u75be\u75c5\u4f20\u64ad\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2511.10925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10925", "abs": "https://arxiv.org/abs/2511.10925", "authors": ["Ha-Thanh Nguyen", "Wachara Fungwacharakorn", "Ken Satoh"], "title": "Multi-Agent Legal Verifier Systems for Data Transfer Planning", "comment": "Presented at NeLaMKRR@KR, 2025 (arXiv:2511.09575)", "summary": "Legal compliance in AI-driven data transfer planning is becoming increasingly critical under stringent privacy regulations such as the Japanese Act on the Protection of Personal Information (APPI). We propose a multi-agent legal verifier that decomposes compliance checking into specialized agents for statutory interpretation, business context evaluation, and risk assessment, coordinated through a structured synthesis protocol. Evaluated on a stratified dataset of 200 Amended APPI Article 16 cases with clearly defined ground truth labels and multiple performance metrics, the system achieves 72% accuracy, which is 21 percentage points higher than a single-agent baseline, including 90% accuracy on clear compliance cases (vs. 16% for the baseline) while maintaining perfect detection of clear violations. While challenges remain in ambiguous scenarios, these results show that domain specialization and coordinated reasoning can meaningfully improve legal AI performance, providing a scalable and regulation-aware framework for trustworthy and interpretable automated compliance verification.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6cd5\u5f8b\u9a8c\u8bc1\u5668\uff0c\u5c06\u5408\u89c4\u68c0\u67e5\u5206\u89e3\u4e3a\u6cd5\u89c4\u89e3\u91ca\u3001\u4e1a\u52a1\u80cc\u666f\u8bc4\u4f30\u548c\u98ce\u9669\u8bc4\u4f30\u7b49\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5408\u6210\u534f\u8bae\u534f\u8c03\uff0c\u5728200\u4e2a\u65e5\u672c\u4e2a\u4eba\u4fe1\u606f\u4fdd\u62a4\u6cd5\u4fee\u6b63\u6848\u6848\u4f8b\u4e0a\u8fbe\u523072%\u51c6\u786e\u7387\uff0c\u6bd4\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u63d0\u9ad821\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u5728\u4e25\u683c\u9690\u79c1\u6cd5\u89c4\uff08\u5982\u65e5\u672c\u4e2a\u4eba\u4fe1\u606f\u4fdd\u62a4\u6cd5APPI\uff09\u4e0b\uff0cAI\u9a71\u52a8\u7684\u6570\u636e\u4f20\u8f93\u89c4\u5212\u4e2d\u7684\u6cd5\u5f8b\u5408\u89c4\u6027\u65e5\u76ca\u91cd\u8981\uff0c\u9700\u8981\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u6cd5\u89c4\u7684\u81ea\u52a8\u5316\u5408\u89c4\u9a8c\u8bc1\u6846\u67b6\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6cd5\u5f8b\u9a8c\u8bc1\u5668\uff0c\u5c06\u5408\u89c4\u68c0\u67e5\u5206\u89e3\u4e3a\u6cd5\u89c4\u89e3\u91ca\u3001\u4e1a\u52a1\u80cc\u666f\u8bc4\u4f30\u548c\u98ce\u9669\u8bc4\u4f30\u7b49\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5408\u6210\u534f\u8bae\u534f\u8c03\u5de5\u4f5c\u3002", "result": "\u5728200\u4e2aAPPI\u4fee\u6b63\u6848\u7b2c16\u6761\u6848\u4f8b\u6570\u636e\u96c6\u4e0a\uff0c\u7cfb\u7edf\u8fbe\u523072%\u51c6\u786e\u7387\uff0c\u6bd4\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u63d0\u9ad821\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u660e\u786e\u5408\u89c4\u6848\u4f8b\u4e0a\u8fbe\u523090%\u51c6\u786e\u7387\uff08\u57fa\u7ebf\u4e3a16%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u660e\u786e\u8fdd\u89c4\u7684\u5b8c\u7f8e\u68c0\u6d4b\u3002", "conclusion": "\u9886\u57df\u4e13\u4e1a\u5316\u548c\u534f\u8c03\u63a8\u7406\u80fd\u663e\u8457\u63d0\u9ad8\u6cd5\u5f8bAI\u6027\u80fd\uff0c\u4e3a\u53ef\u4fe1\u8d56\u548c\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u5316\u5408\u89c4\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u6cd5\u89c4\u7684\u6846\u67b6\uff0c\u4f46\u5728\u6a21\u7cca\u573a\u666f\u4e2d\u4ecd\u5b58\u5728\u6311\u6218\u3002"}}
{"id": "2511.10952", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10952", "abs": "https://arxiv.org/abs/2511.10952", "authors": ["Steven J. Jones", "Robert E. Wray", "John E. Laird"], "title": "Requirements for Aligned, Dynamic Resolution of Conflicts in Operational Constraints", "comment": "6 pages, technical appendix (submitted to AAAI26)", "summary": "Deployed, autonomous AI systems must often evaluate multiple plausible courses of action (extended sequences of behavior) in novel or under-specified contexts. Despite extensive training, these systems will inevitably encounter scenarios where no available course of action fully satisfies all operational constraints (e.g., operating procedures, rules, laws, norms, and goals). To achieve goals in accordance with human expectations and values, agents must go beyond their trained policies and instead construct, evaluate, and justify candidate courses of action. These processes require contextual \"knowledge\" that may lie outside prior (policy) training. This paper characterizes requirements for agent decision making in these contexts. It also identifies the types of knowledge agents require to make decisions robust to agent goals and aligned with human expectations. Drawing on both analysis and empirical case studies, we examine how agents need to integrate normative, pragmatic, and situational understanding to select and then to pursue more aligned courses of action in complex, real-world environments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u81ea\u4e3bAI\u7cfb\u7edf\u5728\u9047\u5230\u8bad\u7ec3\u6570\u636e\u672a\u8986\u76d6\u7684\u590d\u6742\u573a\u666f\u65f6\uff0c\u5982\u4f55\u6784\u5efa\u3001\u8bc4\u4f30\u548c\u8bc1\u660e\u5019\u9009\u884c\u52a8\u65b9\u6848\uff0c\u4ee5\u6ee1\u8db3\u4eba\u7c7b\u671f\u671b\u548c\u4ef7\u503c\u89c2\u3002", "motivation": "\u81ea\u4e3bAI\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5fc5\u7136\u4f1a\u9047\u5230\u8bad\u7ec3\u6570\u636e\u672a\u8986\u76d6\u7684\u590d\u6742\u573a\u666f\uff0c\u9700\u8981\u8d85\u8d8a\u8bad\u7ec3\u7b56\u7565\u6765\u6784\u5efa\u548c\u8bc4\u4f30\u884c\u52a8\u65b9\u6848\uff0c\u4ee5\u5b9e\u73b0\u4e0e\u4eba\u7c7b\u671f\u671b\u548c\u4ef7\u503c\u89c2\u4e00\u81f4\u7684\u76ee\u6807\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u6848\u4f8b\u7814\u7a76\uff0c\u8003\u5bdf\u4e86\u667a\u80fd\u4f53\u5982\u4f55\u6574\u5408\u89c4\u8303\u6027\u3001\u5b9e\u7528\u6027\u548c\u60c5\u5883\u6027\u7406\u89e3\u6765\u9009\u62e9\u66f4\u7b26\u5408\u4eba\u7c7b\u671f\u671b\u7684\u884c\u52a8\u65b9\u6848\u3002", "result": "\u8bc6\u522b\u4e86\u667a\u80fd\u4f53\u5728\u8fd9\u4e9b\u60c5\u5883\u4e0b\u51b3\u7b56\u6240\u9700\u7684\u77e5\u8bc6\u7c7b\u578b\uff0c\u5305\u62ec\u89c4\u8303\u6027\u77e5\u8bc6\u3001\u5b9e\u7528\u77e5\u8bc6\u548c\u60c5\u5883\u77e5\u8bc6\uff0c\u4ee5\u786e\u4fdd\u51b3\u7b56\u65e2\u7b26\u5408\u76ee\u6807\u53c8\u4e0e\u4eba\u7c7b\u671f\u671b\u4e00\u81f4\u3002", "conclusion": "\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\uff0c\u667a\u80fd\u4f53\u9700\u8981\u6574\u5408\u591a\u79cd\u77e5\u8bc6\u7c7b\u578b\u6765\u9009\u62e9\u548c\u8ffd\u6c42\u66f4\u7b26\u5408\u4eba\u7c7b\u671f\u671b\u7684\u884c\u52a8\u65b9\u6848\uff0c\u8fd9\u5bf9\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u7a33\u5065\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.11029", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11029", "abs": "https://arxiv.org/abs/2511.11029", "authors": ["\u00d6zg\u00fcr Akg\u00fcn", "Mun See Chang", "Ian P. Gent", "Christopher Jefferson"], "title": "Faster Symmetry Breaking Constraints for Abstract Structures", "comment": null, "summary": "In constraint programming and related paradigms, a modeller specifies their problem in a modelling language for a solver to search and return its solution(s). Using high-level modelling languages such as Essence, a modeller may express their problems in terms of abstract structures. These are structures not natively supported by the solvers, and so they have to be transformed into or represented as other structures before solving. For example, nested sets are abstract structures, and they can be represented as matrices in constraint solvers. Many problems contain symmetries and one very common and highly successful technique used in constraint programming is to \"break\" symmetries, to avoid searching for symmetric solutions. This can speed up the solving process by many orders of magnitude. Most of these symmetry-breaking techniques involve placing some kind of ordering for the variables of the problem, and picking a particular member under the symmetries, usually the smallest. Unfortunately, applying this technique to abstract variables produces a very large number of complex constraints that perform poorly in practice. In this paper, we demonstrate a new incomplete method of breaking the symmetries of abstract structures by better exploiting their representations. We apply the method in breaking the symmetries arising from indistinguishable objects, a commonly occurring type of symmetry, and show that our method is faster than the previous methods proposed in (Akg\u00fcn et al. 2025).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e0d\u5b8c\u5168\u65b9\u6cd5\u6765\u6253\u7834\u62bd\u8c61\u7ed3\u6784\u7684\u5bf9\u79f0\u6027\uff0c\u901a\u8fc7\u66f4\u597d\u5730\u5229\u7528\u5176\u8868\u793a\u6765\u5904\u7406\u4e0d\u53ef\u533a\u5206\u5bf9\u8c61\u4ea7\u751f\u7684\u5bf9\u79f0\u6027\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684\u65b9\u6cd5\u901f\u5ea6\u66f4\u5feb\u3002", "motivation": "\u5728\u7ea6\u675f\u7f16\u7a0b\u4e2d\uff0c\u62bd\u8c61\u7ed3\u6784\u9700\u8981\u8f6c\u6362\u4e3a\u6c42\u89e3\u5668\u652f\u6301\u7684\u7ed3\u6784\uff0c\u4f46\u5bf9\u79f0\u6027\u7834\u574f\u6280\u672f\u5e94\u7528\u4e8e\u62bd\u8c61\u53d8\u91cf\u4f1a\u4ea7\u751f\u5927\u91cf\u590d\u6742\u7ea6\u675f\uff0c\u5b9e\u9645\u6027\u80fd\u8f83\u5dee\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u4e0d\u5b8c\u5168\u5bf9\u79f0\u6027\u7834\u574f\u65b9\u6cd5\uff0c\u901a\u8fc7\u66f4\u597d\u5730\u5229\u7528\u62bd\u8c61\u7ed3\u6784\u7684\u8868\u793a\u6765\u5904\u7406\u4e0d\u53ef\u533a\u5206\u5bf9\u8c61\u4ea7\u751f\u7684\u5bf9\u79f0\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u4e4b\u524d(Akg\u00fcn et al. 2025)\u63d0\u51fa\u7684\u65b9\u6cd5\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u5728\u6253\u7834\u62bd\u8c61\u7ed3\u6784\u5bf9\u79f0\u6027\u65b9\u9762\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u6709\u6548\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4e0d\u53ef\u533a\u5206\u5bf9\u8c61\u5bf9\u79f0\u6027\u65f6\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2511.11040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11040", "abs": "https://arxiv.org/abs/2511.11040", "authors": ["Qian Zhang", "Yan Zheng", "Jinyi Liu", "Hebin Liang", "Lanjun Wang"], "title": "Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?", "comment": null, "summary": "Recent studies on LLM agent scaling have highlighted the potential of Multi-Agent Debate (MAD) to enhance reasoning abilities. However, the critical aspect of role allocation strategies remains underexplored. In this study, we demonstrate that allocating roles with differing viewpoints to specific positions significantly impacts MAD's performance in reasoning tasks. Specifically, we find a novel role allocation strategy, \"Truth Last\", which can improve MAD performance by up to 22% in reasoning tasks. To address the issue of unknown truth in practical applications, we propose the Multi-Agent Debate Consistency (MADC) strategy, which systematically simulates and optimizes its core mechanisms. MADC incorporates path consistency to assess agreement among independent roles, simulating the role with the highest consistency score as the truth. We validated MADC across a range of LLMs (9 models), including the DeepSeek-R1 Distilled Models, on challenging reasoning tasks. MADC consistently demonstrated advanced performance, effectively overcoming MAD's performance bottlenecks and providing a crucial pathway for further improvements in LLM agent scaling.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d1\u73b0\u89d2\u8272\u5206\u914d\u7b56\u7565\u5bf9\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\"Truth Last\"\u7b56\u7565\u53ef\u63d0\u5347\u63a8\u7406\u4efb\u52a1\u6027\u80fd22%\uff0c\u5e76\u5f00\u53d1\u4e86MADC\u7b56\u7565\u6765\u5e94\u5bf9\u5b9e\u9645\u5e94\u7528\u4e2d\u672a\u77e5\u771f\u76f8\u7684\u95ee\u9898\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u5728\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u89d2\u8272\u5206\u914d\u7b56\u7565\u8fd9\u4e00\u5173\u952e\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u771f\u76f8\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u4f18\u5316\u8fa9\u8bba\u673a\u5236\u3002", "method": "\u63d0\u51fa\"Truth Last\"\u89d2\u8272\u5206\u914d\u7b56\u7565\uff0c\u5e76\u5f00\u53d1\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4e00\u81f4\u6027\u7b56\u7565\uff0c\u901a\u8fc7\u8def\u5f84\u4e00\u81f4\u6027\u8bc4\u4f30\u72ec\u7acb\u89d2\u8272\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u6a21\u62df\u4e00\u81f4\u6027\u5f97\u5206\u6700\u9ad8\u7684\u89d2\u8272\u4f5c\u4e3a\u771f\u76f8\u3002", "result": "\u57289\u4e2aLLM\u6a21\u578b\u4e0a\u7684\u9a8c\u8bc1\u663e\u793a\uff0cMADC\u7b56\u7565\u6301\u7eed\u8868\u73b0\u51fa\u5148\u8fdb\u6027\u80fd\uff0c\u6709\u6548\u514b\u670d\u4e86MAD\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u63d0\u5347\u6027\u80fd\u8fbe22%\u3002", "conclusion": "MADC\u4e3aLLM\u667a\u80fd\u4f53\u6269\u5c55\u63d0\u4f9b\u4e86\u5173\u952e\u6539\u8fdb\u8def\u5f84\uff0c\u901a\u8fc7\u7cfb\u7edf\u6a21\u62df\u548c\u4f18\u5316\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7684\u6838\u5fc3\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.11043", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.11043", "abs": "https://arxiv.org/abs/2511.11043", "authors": ["Asen Nachkov", "Jan-Nico Zaech", "Danda Pani Paudel", "Xi Wang", "Luc Van Gool"], "title": "Autonomous Vehicle Path Planning by Searching With Differentiable Simulation", "comment": null, "summary": "Planning allows an agent to safely refine its actions before executing them in the real world. In autonomous driving, this is crucial to avoid collisions and navigate in complex, dense traffic scenarios. One way to plan is to search for the best action sequence. However, this is challenging when all necessary components - policy, next-state predictor, and critic - have to be learned. Here we propose Differentiable Simulation for Search (DSS), a framework that leverages the differentiable simulator Waymax as both a next state predictor and a critic. It relies on the simulator's hardcoded dynamics, making state predictions highly accurate, while utilizing the simulator's differentiability to effectively search across action sequences. Our DSS agent optimizes its actions using gradient descent over imagined future trajectories. We show experimentally that DSS - the combination of planning gradients and stochastic search - significantly improves tracking and path planning accuracy compared to sequence prediction, imitation learning, model-free RL, and other planning methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86DSS\u6846\u67b6\uff0c\u5229\u7528\u53ef\u5fae\u5206\u6a21\u62df\u5668Waymax\u4f5c\u4e3a\u72b6\u6001\u9884\u6d4b\u5668\u548c\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u52a8\u4f5c\u5e8f\u5217\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u7684\u8ddf\u8e2a\u548c\u8def\u5f84\u89c4\u5212\u7cbe\u5ea6\u3002", "motivation": "\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\uff0c\u89c4\u5212\u5bf9\u4e8e\u907f\u514d\u78b0\u649e\u548c\u5728\u590d\u6742\u5bc6\u96c6\u4ea4\u901a\u573a\u666f\u4e2d\u5bfc\u822a\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u89c4\u5212\u65b9\u6cd5\u5728\u9700\u8981\u5b66\u4e60\u7b56\u7565\u3001\u72b6\u6001\u9884\u6d4b\u5668\u548c\u8bc4\u4f30\u5668\u65f6\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f7f\u7528\u53ef\u5fae\u5206\u6a21\u62df\u5668Waymax\u4f5c\u4e3a\u72b6\u6001\u9884\u6d4b\u5668\u548c\u8bc4\u4f30\u5668\uff0c\u5229\u7528\u5176\u786c\u7f16\u7801\u52a8\u6001\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u72b6\u6001\u9884\u6d4b\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u7279\u6027\u6709\u6548\u641c\u7d22\u52a8\u4f5c\u5e8f\u5217\uff0c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u60f3\u8c61\u672a\u6765\u8f68\u8ff9\u4e2d\u7684\u52a8\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDSS\uff08\u89c4\u5212\u68af\u5ea6\u548c\u968f\u673a\u641c\u7d22\u7684\u7ec4\u5408\uff09\u76f8\u6bd4\u5e8f\u5217\u9884\u6d4b\u3001\u6a21\u4eff\u5b66\u4e60\u3001\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u548c\u5176\u4ed6\u89c4\u5212\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ddf\u8e2a\u548c\u8def\u5f84\u89c4\u5212\u7684\u51c6\u786e\u6027\u3002", "conclusion": "DSS\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u89c4\u5212\u68af\u5ea6\u548c\u968f\u673a\u641c\u7d22\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u4ea4\u901a\u573a\u666f\u4e0b\u7684\u5b89\u5168\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.11095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11095", "abs": "https://arxiv.org/abs/2511.11095", "authors": ["Dillon Z. Chen", "Till Hofmann", "Toryn Q. Klassen", "Sheila A. McIlraith"], "title": "Satisficing and Optimal Generalised Planning via Goal Regression (Extended Version)", "comment": "Extended version of AAAI 2026 paper", "summary": "Generalised planning (GP) refers to the task of synthesising programs that solve families of related planning problems. We introduce a novel, yet simple method for GP: given a set of training problems, for each problem, compute an optimal plan for each goal atom in some order, perform goal regression on the resulting plans, and lift the corresponding outputs to obtain a set of first-order $\\textit{Condition} \\rightarrow \\textit{Actions}$ rules. The rules collectively constitute a generalised plan that can be executed as is or alternatively be used to prune the planning search space. We formalise and prove the conditions under which our method is guaranteed to learn valid generalised plans and state space pruning axioms for search. Experiments demonstrate significant improvements over state-of-the-art (generalised) planners with respect to the 3 metrics of synthesis cost, planning coverage, and solution quality on various classical and numeric planning domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e7f\u4e49\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u8bad\u7ec3\u95ee\u9898\u4e2d\u5b66\u4e60\u6761\u4ef6-\u52a8\u4f5c\u89c4\u5219\u6765\u6784\u5efa\u53ef\u91cd\u7528\u7684\u89c4\u5212\u7a0b\u5e8f\uff0c\u8fd9\u4e9b\u89c4\u5219\u53ef\u4ee5\u76f4\u63a5\u6267\u884c\u6216\u7528\u4e8e\u526a\u679d\u89c4\u5212\u641c\u7d22\u7a7a\u95f4\u3002", "motivation": "\u5e7f\u4e49\u89c4\u5212\u65e8\u5728\u5408\u6210\u80fd\u591f\u89e3\u51b3\u76f8\u5173\u89c4\u5212\u95ee\u9898\u65cf\u7684\u7a0b\u5e8f\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5408\u6210\u6210\u672c\u3001\u89c4\u5212\u8986\u76d6\u7387\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u65b9\u9762\u5b58\u5728\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u5bf9\u6bcf\u4e2a\u8bad\u7ec3\u95ee\u9898\uff0c\u6309\u987a\u5e8f\u8ba1\u7b97\u6bcf\u4e2a\u76ee\u6807\u539f\u5b50\u7684\u6700\u4f18\u89c4\u5212\uff0c\u5bf9\u7ed3\u679c\u89c4\u5212\u6267\u884c\u76ee\u6807\u56de\u5f52\uff0c\u5e76\u5c06\u8f93\u51fa\u63d0\u5347\u4e3a\u4e00\u9636\u6761\u4ef6\u2192\u52a8\u4f5c\u89c4\u5219\u96c6\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7ecf\u5178\u548c\u6570\u503c\u89c4\u5212\u9886\u57df\u7684\u5408\u6210\u6210\u672c\u3001\u89c4\u5212\u8986\u76d6\u7387\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u4e09\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u5e7f\u4e49\u89c4\u5212\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b66\u4e60\u6709\u6548\u7684\u5e7f\u4e49\u89c4\u5212\u548c\u72b6\u6001\u7a7a\u95f4\u526a\u679d\u516c\u7406\uff0c\u4e3a\u5e7f\u4e49\u89c4\u5212\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2511.11134", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11134", "abs": "https://arxiv.org/abs/2511.11134", "authors": ["Jingxuan Wei", "Caijun Jia", "Xi Bai", "Xinglong Xu", "Siyuan Li", "Linzhuang Sun", "Bihui Yu", "Conghui He", "Lijun Wu", "Cheng Tan"], "title": "GGBench: A Geometric Generative Reasoning Benchmark for Unified Multimodal Models", "comment": "35 pages, 22 figures", "summary": "The advent of Unified Multimodal Models (UMMs) signals a paradigm shift in artificial intelligence, moving from passive perception to active, cross-modal generation. Despite their unprecedented ability to synthesize information, a critical gap persists in evaluation: existing benchmarks primarily assess discriminative understanding or unconstrained image generation separately, failing to measure the integrated cognitive process of generative reasoning. To bridge this gap, we propose that geometric construction provides an ideal testbed as it inherently demands a fusion of language comprehension and precise visual generation. We introduce GGBench, a benchmark designed specifically to evaluate geometric generative reasoning. It provides a comprehensive framework for systematically diagnosing a model's ability to not only understand and reason but to actively construct a solution, thereby setting a more rigorous standard for the next generation of intelligent systems. Project website: https://opendatalab-raiser.github.io/GGBench/.", "AI": {"tldr": "GGBench\u662f\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30\u51e0\u4f55\u751f\u6210\u63a8\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u8861\u91cf\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u5728\u8bed\u8a00\u7406\u89e3\u548c\u7cbe\u786e\u89c6\u89c9\u751f\u6210\u878d\u5408\u80fd\u529b\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30\u5224\u522b\u6027\u7406\u89e3\u6216\u65e0\u7ea6\u675f\u56fe\u50cf\u751f\u6210\uff0c\u65e0\u6cd5\u8861\u91cf\u751f\u6210\u63a8\u7406\u7684\u6574\u5408\u8ba4\u77e5\u8fc7\u7a0b\u3002\u51e0\u4f55\u6784\u9020\u9700\u8981\u8bed\u8a00\u7406\u89e3\u548c\u7cbe\u786e\u89c6\u89c9\u751f\u6210\u7684\u878d\u5408\uff0c\u56e0\u6b64\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u63d0\u51faGGBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u51e0\u4f55\u6784\u9020\u4efb\u52a1\u6765\u7cfb\u7edf\u8bca\u65ad\u6a21\u578b\u7684\u7406\u89e3\u3001\u63a8\u7406\u548c\u4e3b\u52a8\u6784\u5efa\u89e3\u51b3\u65b9\u6848\u7684\u80fd\u529b\u3002", "result": "GGBench\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u7cfb\u7edf\u8bbe\u5b9a\u4e86\u66f4\u4e25\u683c\u7684\u6807\u51c6\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u8bc4\u4f30\u51e0\u4f55\u751f\u6210\u63a8\u7406\u80fd\u529b\u7684\u6846\u67b6\u3002", "conclusion": "\u51e0\u4f55\u6784\u9020\u662f\u8bc4\u4f30\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u751f\u6210\u63a8\u7406\u80fd\u529b\u7684\u7406\u60f3\u6d4b\u8bd5\u5e73\u53f0\uff0cGGBench\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u63a8\u52a8\u4e86\u4eba\u5de5\u667a\u80fd\u4ece\u88ab\u52a8\u611f\u77e5\u5411\u4e3b\u52a8\u8de8\u6a21\u6001\u751f\u6210\u7684\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2511.11233", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11233", "abs": "https://arxiv.org/abs/2511.11233", "authors": ["Huajian Zhang", "Mingyue Cheng", "Yucong Luo", "Xiaoyu Tao"], "title": "STaR: Towards Cognitive Table Reasoning via Slow-Thinking Large Language Models", "comment": null, "summary": "Table reasoning with the large language models (LLMs) is a fundamental path toward building intelligent systems that can understand and analyze over structured data. While recent progress has shown promising results, they still suffer from two key limitations: (i) the reasoning processes lack the depth and iterative refinement characteristic of human cognition; and (ii) the reasoning processes exhibit instability, which compromises their reliability in downstream applications. In this work, we present STaR (slow-thinking for table reasoning), a new framework achieving cognitive table reasoning, in which LLMs are equipped with slow-thinking capabilities by explicitly modeling step-by-step thinking and uncertainty-aware inference. During training, STaR employs two-stage difficulty-aware reinforcement learning (DRL), progressively learning from simple to complex queries under a composite reward. During inference, STaR performs trajectory-level uncertainty quantification by integrating token-level confidence and answer consistency, enabling selection of more credible reasoning paths. Extensive experiments on benchmarks demonstrate that STaR achieves superior performance and enhanced reasoning stability. Moreover, strong generalization over out-of-domain datasets further demonstrates STaR's potential as a reliable and cognitively inspired solution for table reasoning with LLMs.", "AI": {"tldr": "STaR\u6846\u67b6\u901a\u8fc7\u6162\u601d\u8003\u673a\u5236\u63d0\u5347LLMs\u7684\u8868\u683c\u63a8\u7406\u80fd\u529b\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u96be\u5ea6\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLMs\u8868\u683c\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u6df1\u5ea6\u4e0d\u8db3\u3001\u7f3a\u4e4f\u8fed\u4ee3\u7cbe\u70bc\u4ee5\u53ca\u63a8\u7406\u8fc7\u7a0b\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faSTaR\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u9010\u6b65\u601d\u8003\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u63a8\u7406\u6765\u8d4b\u4e88LLMs\u6162\u601d\u8003\u80fd\u529b\u3002\u8bad\u7ec3\u9636\u6bb5\u91c7\u7528\u4e24\u9636\u6bb5\u96be\u5ea6\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff0c\u4ece\u7b80\u5355\u5230\u590d\u6742\u67e5\u8be2\u6e10\u8fdb\u5b66\u4e60\uff1b\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u6574\u5408token\u7ea7\u7f6e\u4fe1\u5ea6\u548c\u7b54\u6848\u4e00\u81f4\u6027\u8fdb\u884c\u8f68\u8ff9\u7ea7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTaR\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u589e\u5f3a\u7684\u63a8\u7406\u7a33\u5b9a\u6027\u3002\u5728\u9886\u57df\u5916\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "STaR\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u9760\u4e14\u53d7\u8ba4\u77e5\u542f\u53d1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728LLMs\u8868\u683c\u63a8\u7406\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.11257", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11257", "abs": "https://arxiv.org/abs/2511.11257", "authors": ["Yuqi Yin", "Yibo Fu", "Siyuan Wang", "Peng Sun", "Hongyu Wang", "Xiaohui Wang", "Lei Zheng", "Zhiyong Li", "Zhirong Liu", "Jianji Wang", "Zhaoxi Sun"], "title": "AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery", "comment": null, "summary": "The discovery of novel Ionic Liquids (ILs) is hindered by critical challenges in property prediction, including limited data, poor model accuracy, and fragmented workflows. Leveraging the power of Large Language Models (LLMs), we introduce AIonopedia, to the best of our knowledge, the first LLM agent for IL discovery. Powered by an LLM-augmented multimodal domain foundation model for ILs, AIonopedia enables accurate property predictions and incorporates a hierarchical search architecture for molecular screening and design. Trained and evaluated on a newly curated and comprehensive IL dataset, our model delivers superior performance. Complementing these results, evaluations on literature-reported systems indicate that the agent can perform effective IL modification. Moving beyond offline tests, the practical efficacy was further confirmed through real-world wet-lab validation, in which the agent demonstrated exceptional generalization capabilities on challenging out-of-distribution tasks, underscoring its ability to accelerate real-world IL discovery.", "AI": {"tldr": "AIonopedia\u662f\u9996\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u79bb\u5b50\u6db2\u4f53\u53d1\u73b0\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u9886\u57df\u57fa\u7840\u6a21\u578b\u5b9e\u73b0\u51c6\u786e\u6027\u8d28\u9884\u6d4b\u548c\u5206\u5c42\u641c\u7d22\u67b6\u6784\uff0c\u5728\u771f\u5b9e\u6e7f\u5b9e\u9a8c\u9a8c\u8bc1\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u79bb\u5b50\u6db2\u4f53\u53d1\u73b0\u9762\u4e34\u6570\u636e\u6709\u9650\u3001\u6a21\u578b\u7cbe\u5ea6\u4e0d\u8db3\u548c\u5de5\u4f5c\u6d41\u7a0b\u788e\u7247\u5316\u7b49\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684AI\u9a71\u52a8\u53d1\u73b0\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86LLM\u589e\u5f3a\u7684\u591a\u6a21\u6001\u79bb\u5b50\u6db2\u4f53\u9886\u57df\u57fa\u7840\u6a21\u578b\uff0c\u91c7\u7528\u5206\u5c42\u641c\u7d22\u67b6\u6784\u8fdb\u884c\u5206\u5b50\u7b5b\u9009\u548c\u8bbe\u8ba1\uff0c\u5e76\u5728\u65b0\u6784\u5efa\u7684\u7efc\u5408\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u5728\u6587\u732e\u62a5\u9053\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u7684\u79bb\u5b50\u6db2\u4f53\u4fee\u9970\u80fd\u529b\uff0c\u771f\u5b9e\u6e7f\u5b9e\u9a8c\u9a8c\u8bc1\u8bc1\u5b9e\u4e86\u5176\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u7684\u4f18\u5f02\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "AIonopedia\u80fd\u591f\u663e\u8457\u52a0\u901f\u771f\u5b9e\u4e16\u754c\u7684\u79bb\u5b50\u6db2\u4f53\u53d1\u73b0\u8fc7\u7a0b\uff0c\u5c55\u793a\u4e86LLM\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.11275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11275", "abs": "https://arxiv.org/abs/2511.11275", "authors": ["Julius Wenzel", "Syeda Umaima Alam", "Andreas Schmidt", "Hanwei Zhang", "Holger Hermanns"], "title": "A Workflow for Full Traceability of AI Decisions", "comment": "10 pages, 10 figures", "summary": "An ever increasing number of high-stake decisions are made or assisted by automated systems employing brittle artificial intelligence technology. There is a substantial risk that some of these decision induce harm to people, by infringing their well-being or their fundamental human rights. The state-of-the-art in AI systems makes little effort with respect to appropriate documentation of the decision process. This obstructs the ability to trace what went into a decision, which in turn is a prerequisite to any attempt of reconstructing a responsibility chain. Specifically, such traceability is linked to a documentation that will stand up in court when determining the cause of some AI-based decision that inadvertently or intentionally violates the law.\n  This paper takes a radical, yet practical, approach to this problem, by enforcing the documentation of each and every component that goes into the training or inference of an automated decision. As such, it presents the first running workflow supporting the generation of tamper-proof, verifiable and exhaustive traces of AI decisions. In doing so, we expand the DBOM concept into an effective running workflow leveraging confidential computing technology. We demonstrate the inner workings of the workflow in the development of an app to tell poisonous and edible mushrooms apart, meant as a playful example of high-stake decision support.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5f3a\u5236\u8bb0\u5f55AI\u8bad\u7ec3\u548c\u63a8\u7406\u4e2d\u6bcf\u4e2a\u7ec4\u4ef6\u6765\u786e\u4fdd\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\u7684\u5de5\u4f5c\u6d41\uff0c\u6269\u5c55\u4e86DBOM\u6982\u5ff5\u5e76\u5229\u7528\u673a\u5bc6\u8ba1\u7b97\u6280\u672f\u751f\u6210\u9632\u7be1\u6539\u3001\u53ef\u9a8c\u8bc1\u7684AI\u51b3\u7b56\u75d5\u8ff9\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u51b3\u7b56\u8fc7\u7a0b\u6587\u6863\u5316\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd9\u963b\u788d\u4e86\u51b3\u7b56\u6eaf\u6e90\u548c\u8d23\u4efb\u94fe\u91cd\u5efa\uff0c\u7279\u522b\u662f\u5728AI\u51b3\u7b56\u8fdd\u53cd\u6cd5\u5f8b\u65f6\u65e0\u6cd5\u63d0\u4f9b\u6cd5\u5ead\u53ef\u63a5\u53d7\u7684\u8bc1\u636e\u3002", "method": "\u91c7\u7528DBOM\u6982\u5ff5\u6269\u5c55\uff0c\u7ed3\u5408\u673a\u5bc6\u8ba1\u7b97\u6280\u672f\uff0c\u6784\u5efa\u652f\u6301\u751f\u6210\u9632\u7be1\u6539\u3001\u53ef\u9a8c\u8bc1\u548c\u8be6\u5c3dAI\u51b3\u7b56\u75d5\u8ff9\u7684\u8fd0\u884c\u5de5\u4f5c\u6d41\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u533a\u5206\u6709\u6bd2\u548c\u53ef\u98df\u7528\u8611\u83c7\u7684\u5e94\u7528\u7a0b\u5e8f\u4f5c\u4e3a\u9ad8\u98ce\u9669\u51b3\u7b56\u652f\u6301\u7684\u793a\u4f8b\uff0c\u5c55\u793a\u4e86\u5de5\u4f5c\u6d41\u7684\u5b9e\u9645\u8fd0\u4f5c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u4e3aAI\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u53ef\u8ffd\u6eaf\u6027\u652f\u6301\uff0c\u662f\u89e3\u51b3AI\u7cfb\u7edf\u8d23\u4efb\u94fe\u95ee\u9898\u7684\u4e00\u4e2a\u5b9e\u7528\u4e14\u5f7b\u5e95\u7684\u65b9\u6848\u3002"}}
{"id": "2511.11281", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.11281", "abs": "https://arxiv.org/abs/2511.11281", "authors": ["Patrick Koopmann", "Yasir Mahmood", "Axel-Cyrille Ngonga Ngomo", "Balram Tiwari"], "title": "Can You Tell the Difference? Contrastive Explanations for ABox Entailments", "comment": "Technical report to the paper accepted at AAAI-2026", "summary": "We introduce the notion of contrastive ABox explanations to answer questions of the type \"Why is a an instance of C, but b is not?\". While there are various approaches for explaining positive entailments (why is C(a) entailed by the knowledge base) as well as missing entailments (why is C(b) not entailed) in isolation, contrastive explanations consider both at the same time, which allows them to focus on the relevant commonalities and differences between a and b. We develop an appropriate notion of contrastive explanations for the special case of ABox reasoning with description logic ontologies, and analyze the computational complexity for different variants under different optimality criteria, considering lightweight as well as more expressive description logics. We implemented a first method for computing one variant of contrastive explanations, and evaluated it on generated problems for realistic knowledge bases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5bf9\u6bd4ABox\u89e3\u91ca\u7684\u6982\u5ff5\uff0c\u7528\u4e8e\u56de\u7b54\"\u4e3a\u4ec0\u4e48a\u662fC\u7684\u5b9e\u4f8b\u800cb\u4e0d\u662f\uff1f\"\u8fd9\u7c7b\u95ee\u9898\u3002\u76f8\u6bd4\u5355\u72ec\u89e3\u91ca\u6b63\u9762\u8574\u542b\u6216\u7f3a\u5931\u8574\u542b\u7684\u65b9\u6cd5\uff0c\u5bf9\u6bd4\u89e3\u91ca\u540c\u65f6\u8003\u8651\u4e24\u8005\uff0c\u80fd\u591f\u805a\u7126\u4e8ea\u548cb\u4e4b\u95f4\u7684\u76f8\u5173\u5171\u6027\u548c\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u91ca\u65b9\u6cd5\u901a\u5e38\u5206\u522b\u5904\u7406\u6b63\u9762\u8574\u542b\uff08\u4e3a\u4ec0\u4e48C(a)\u88ab\u77e5\u8bc6\u5e93\u8574\u542b\uff09\u548c\u7f3a\u5931\u8574\u542b\uff08\u4e3a\u4ec0\u4e48C(b)\u4e0d\u88ab\u8574\u542b\uff09\uff0c\u4f46\u7f3a\u4e4f\u540c\u65f6\u8003\u8651\u4e24\u8005\u7684\u5bf9\u6bd4\u6027\u89e3\u91ca\u65b9\u6cd5\uff0c\u65e0\u6cd5\u6709\u6548\u56de\u7b54\u5173\u4e8e\u4e0d\u540c\u5b9e\u4f8b\u5206\u7c7b\u5dee\u5f02\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u9488\u5bf9\u63cf\u8ff0\u903b\u8f91\u672c\u4f53\u7684ABox\u63a8\u7406\u7279\u6b8a\u60c5\u51b5\uff0c\u5f00\u53d1\u4e86\u9002\u5f53\u7684\u5bf9\u6bd4\u89e3\u91ca\u6982\u5ff5\uff1b\u5206\u6790\u4e86\u5728\u4e0d\u540c\u6700\u4f18\u6027\u6807\u51c6\u4e0b\u5404\u79cd\u53d8\u4f53\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u6db5\u76d6\u4e86\u8f7b\u91cf\u7ea7\u548c\u66f4\u8868\u8fbe\u6027\u7684\u63cf\u8ff0\u903b\u8f91\uff1b\u5b9e\u73b0\u4e86\u4e00\u79cd\u8ba1\u7b97\u5bf9\u6bd4\u89e3\u91ca\u53d8\u4f53\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u73b0\u5b9e\u77e5\u8bc6\u5e93\u7684\u751f\u6210\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u4e86\u5bf9\u6bd4ABox\u89e3\u91ca\u7684\u6b63\u5f0f\u5b9a\u4e49\uff1b\u5bf9\u4e0d\u540c\u63cf\u8ff0\u903b\u8f91\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff1b\u5f00\u53d1\u4e86\u53ef\u8fd0\u884c\u7684\u5b9e\u73b0\u65b9\u6cd5\u5e76\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u5bf9\u6bd4ABox\u89e3\u91ca\u80fd\u591f\u6709\u6548\u89e3\u91ca\u4e0d\u540c\u5b9e\u4f8b\u5206\u7c7b\u5dee\u5f02\u7684\u539f\u56e0\uff0c\u901a\u8fc7\u540c\u65f6\u8003\u8651\u6b63\u9762\u548c\u8d1f\u9762\u6848\u4f8b\u6765\u63ed\u793a\u76f8\u5173\u5171\u6027\u548c\u5dee\u5f02\uff0c\u4e3a\u77e5\u8bc6\u5e93\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u91ca\u80fd\u529b\u3002"}}
{"id": "2511.11301", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11301", "abs": "https://arxiv.org/abs/2511.11301", "authors": ["Ruoxi Cheng", "Haoxuan Ma", "Teng Ma", "Hongyi Zhang"], "title": "EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment", "comment": null, "summary": "Large Vision-Language Models (LVLMs) exhibit powerful reasoning capabilities but suffer sophisticated jailbreak vulnerabilities. Fundamentally, aligning LVLMs is not just a safety challenge but a problem of economic efficiency. Current alignment methods struggle with the trade-off between safety, utility, and operational costs. Critically, a focus solely on final outputs (process-blindness) wastes significant computational budget on unsafe deliberation. This flaw allows harmful reasoning to be disguised with benign justifications, thereby circumventing simple additive safety scores. To address this, we propose EcoAlign, an inference-time framework that reframes alignment as an economically rational search by treating the LVLM as a boundedly rational agent. EcoAlign incrementally expands a thought graph and scores actions using a forward-looking function (analogous to net present value) that dynamically weighs expected safety, utility, and cost against the remaining budget. To prevent deception, path safety is enforced via the weakest-link principle. Extensive experiments across 3 closed-source and 2 open-source models on 6 datasets show that EcoAlign matches or surpasses state-of-the-art safety and utility at a lower computational cost, thereby offering a principled, economical pathway to robust LVLM alignment.", "AI": {"tldr": "EcoAlign\u662f\u4e00\u4e2a\u63a8\u7406\u65f6\u6846\u67b6\uff0c\u5c06\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7ecf\u6d4e\u7406\u6027\u7684\u641c\u7d22\u8fc7\u7a0b\uff0c\u901a\u8fc7\u524d\u77bb\u6027\u51fd\u6570\u52a8\u6001\u6743\u8861\u5b89\u5168\u6027\u3001\u5b9e\u7528\u6027\u548c\u6210\u672c\uff0c\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u5f3a\u5927\u7684\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u3001\u5b9e\u7528\u6027\u548c\u8fd0\u8425\u6210\u672c\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u56f0\u5883\uff0c\u4e14\u4ec5\u5173\u6ce8\u6700\u7ec8\u8f93\u51fa\u7684\u8fc7\u7a0b\u76f2\u76ee\u6027\u4f1a\u6d6a\u8d39\u5927\u91cf\u8ba1\u7b97\u9884\u7b97\u5728\u6709\u5bb3\u63a8\u7406\u4e0a\uff0c\u5bfc\u81f4\u6709\u5bb3\u63a8\u7406\u53ef\u4ee5\u901a\u8fc7\u826f\u6027\u8bba\u8bc1\u6765\u4f2a\u88c5\u3002", "method": "\u5c06LVLM\u89c6\u4e3a\u6709\u9650\u7406\u6027\u667a\u80fd\u4f53\uff0c\u9010\u6b65\u6269\u5c55\u601d\u7ef4\u56fe\uff0c\u4f7f\u7528\u524d\u77bb\u6027\u51fd\u6570\uff08\u7c7b\u4f3c\u4e8e\u51c0\u73b0\u503c\uff09\u5bf9\u884c\u52a8\u8fdb\u884c\u8bc4\u5206\uff0c\u52a8\u6001\u6743\u8861\u9884\u671f\u5b89\u5168\u6027\u3001\u5b9e\u7528\u6027\u548c\u6210\u672c\u4e0e\u5269\u4f59\u9884\u7b97\u7684\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u6700\u5f31\u73af\u8282\u539f\u5219\u5f3a\u5236\u6267\u884c\u8def\u5f84\u5b89\u5168\u6027\u3002", "result": "\u57283\u4e2a\u95ed\u6e90\u548c2\u4e2a\u5f00\u6e90\u6a21\u578b\u4e0a\u76846\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEcoAlign\u4ee5\u8f83\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u8fbe\u5230\u6216\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u6c34\u5e73\u3002", "conclusion": "EcoAlign\u4e3a\u5f3a\u5927\u7684LVLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u3001\u7ecf\u6d4e\u6027\u7684\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u5bf9\u9f50\u65b9\u6cd5\u5728\u7ecf\u6d4e\u6548\u7387\u65b9\u9762\u7684\u6839\u672c\u95ee\u9898\u3002"}}
{"id": "2511.11323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11323", "abs": "https://arxiv.org/abs/2511.11323", "authors": ["Yitian Kou", "Yihe Gu", "Chen Zhou", "DanDan Zhu", "Shuguang Kuai"], "title": "RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms", "comment": "AAAI 2026", "summary": "Navigating human-populated environments without causing discomfort is a critical capability for socially-aware agents. While rule-based approaches offer interpretability through predefined psychological principles, they often lack generalizability and flexibility. Conversely, data-driven methods can learn complex behaviors from large-scale datasets, but are typically inefficient, opaque, and difficult to align with human intuitions. To bridge this gap, we propose RLSLM, a hybrid Reinforcement Learning framework that integrates a rule-based Social Locomotion Model, grounded in empirical behavioral experiments, into the reward function of a reinforcement learning framework. The social locomotion model generates an orientation-sensitive social comfort field that quantifies human comfort across space, enabling socially aligned navigation policies with minimal training. RLSLM then jointly optimizes mechanical energy and social comfort, allowing agents to avoid intrusions into personal or group space. A human-agent interaction experiment using an immersive VR-based setup demonstrates that RLSLM outperforms state-of-the-art rule-based models in user experience. Ablation and sensitivity analyses further show the model's significantly improved interpretability over conventional data-driven methods. This work presents a scalable, human-centered methodology that effectively integrates cognitive science and machine learning for real-world social navigation.", "AI": {"tldr": "RLSLM\u662f\u4e00\u4e2a\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u793e\u4f1a\u8fd0\u52a8\u6a21\u578b\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u793e\u4f1a\u611f\u77e5\u5bfc\u822a\uff0c\u901a\u8fc7\u91cf\u5316\u4eba\u7c7b\u8212\u9002\u5ea6\u6765\u4f18\u5316\u673a\u68b0\u80fd\u91cf\u548c\u793e\u4f1a\u8212\u9002\u5ea6\u7684\u5e73\u8861\u3002", "motivation": "\u89e3\u51b3\u5728\u4eba\u7fa4\u73af\u5883\u4e2d\u5bfc\u822a\u65f6\u907f\u514d\u5f15\u8d77\u4e0d\u9002\u7684\u95ee\u9898\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u65b9\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51faRLSLM\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u7ecf\u9a8c\u884c\u4e3a\u5b9e\u9a8c\u7684\u793e\u4f1a\u8fd0\u52a8\u6a21\u578b\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u7684\u5956\u52b1\u51fd\u6570\u4e2d\uff0c\u751f\u6210\u65b9\u5411\u654f\u611f\u7684\u793e\u4f1a\u8212\u9002\u5ea6\u573a\u3002", "result": "\u901a\u8fc7\u6c89\u6d78\u5f0fVR\u5b9e\u9a8c\u8bc1\u660eRLSLM\u5728\u7528\u6237\u4f53\u9a8c\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u89c4\u5219\u6a21\u578b\uff0c\u6d88\u878d\u548c\u654f\u611f\u6027\u5206\u6790\u663e\u793a\u5176\u53ef\u89e3\u91ca\u6027\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u6574\u5408\u8ba4\u77e5\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\uff0c\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u793e\u4f1a\u5bfc\u822a\u3002"}}
{"id": "2511.11393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11393", "abs": "https://arxiv.org/abs/2511.11393", "authors": ["Zejiao Liu", "Yi Li", "Jiali Wang", "Junqi Tu", "Yitian Hong", "Fangfei Li", "Yang Liu", "Toshiharu Sugawara", "Yang Tang"], "title": "Robust and Efficient Communication in Multi-Agent Reinforcement Learning", "comment": null, "summary": "Multi-agent reinforcement learning (MARL) has made significant strides in enabling coordinated behaviors among autonomous agents. However, most existing approaches assume that communication is instantaneous, reliable, and has unlimited bandwidth; these conditions are rarely met in real-world deployments. This survey systematically reviews recent advances in robust and efficient communication strategies for MARL under realistic constraints, including message perturbations, transmission delays, and limited bandwidth. Furthermore, because the challenges of low-latency reliability, bandwidth-intensive data sharing, and communication-privacy trade-offs are central to practical MARL systems, we focus on three applications involving cooperative autonomous driving, distributed simultaneous localization and mapping, and federated learning. Finally, we identify key open challenges and future research directions, advocating a unified approach that co-designs communication, learning, and robustness to bridge the gap between theoretical MARL models and practical implementations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u73b0\u5b9e\u901a\u4fe1\u7ea6\u675f\u4e0b\u7684\u9c81\u68d2\u9ad8\u6548\u901a\u4fe1\u7b56\u7565\uff0c\u5305\u62ec\u6d88\u606f\u6270\u52a8\u3001\u4f20\u8f93\u5ef6\u8fdf\u548c\u5e26\u5bbd\u9650\u5236\u7b49\u6311\u6218\uff0c\u5e76\u805a\u7126\u4e8e\u534f\u540c\u81ea\u52a8\u9a7e\u9a76\u3001\u5206\u5e03\u5f0fSLAM\u548c\u8054\u90a6\u5b66\u4e60\u4e09\u4e2a\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u73b0\u6709MARL\u65b9\u6cd5\u5927\u591a\u5047\u8bbe\u901a\u4fe1\u662f\u77ac\u65f6\u3001\u53ef\u9760\u4e14\u5e26\u5bbd\u65e0\u9650\u7684\uff0c\u4f46\u8fd9\u4e9b\u6761\u4ef6\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u5f88\u5c11\u6ee1\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5728\u73b0\u5b9e\u901a\u4fe1\u7ea6\u675f\u4e0b\u7684\u9c81\u68d2\u9ad8\u6548\u901a\u4fe1\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u8fd1\u671f\u5728MARL\u4e2d\u5e94\u5bf9\u6d88\u606f\u6270\u52a8\u3001\u4f20\u8f93\u5ef6\u8fdf\u548c\u5e26\u5bbd\u9650\u5236\u7b49\u73b0\u5b9e\u901a\u4fe1\u7ea6\u675f\u7684\u901a\u4fe1\u7b56\u7565\u8fdb\u5c55\u3002", "result": "\u8bc6\u522b\u4e86\u4f4e\u5ef6\u8fdf\u53ef\u9760\u6027\u3001\u5e26\u5bbd\u5bc6\u96c6\u578b\u6570\u636e\u5171\u4eab\u548c\u901a\u4fe1\u9690\u79c1\u6743\u8861\u7b49\u6838\u5fc3\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u4fe1\u3001\u5b66\u4e60\u548c\u9c81\u68d2\u6027\u534f\u540c\u8bbe\u8ba1\u7684\u7edf\u4e00\u65b9\u6cd5\u3002", "conclusion": "\u9700\u8981\u91c7\u7528\u901a\u4fe1\u3001\u5b66\u4e60\u548c\u9c81\u68d2\u6027\u534f\u540c\u8bbe\u8ba1\u7684\u7edf\u4e00\u65b9\u6cd5\u6765\u5f25\u5408\u7406\u8bbaMARL\u6a21\u578b\u4e0e\u5b9e\u9645\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u6307\u51fa\u4e86\u5173\u952e\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.11423", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11423", "abs": "https://arxiv.org/abs/2511.11423", "authors": ["Cong-Tinh Dao", "Nguyen Minh Thao Phan", "Jun-En Ding", "Chenwei Wu", "David Restrepo", "Dongsheng Luo", "Fanyi Zhao", "Chun-Chieh Liao", "Wen-Chih Peng", "Chi-Te Wang", "Pei-Fu Chen", "Ling Chen", "Xinglong Ju", "Feng Liu", "Fang-Ming Hung"], "title": "CURENet: Combining Unified Representations for Efficient Chronic Disease Prediction", "comment": null, "summary": "Electronic health records (EHRs) are designed to synthesize diverse data types, including unstructured clinical notes, structured lab tests, and time-series visit data. Physicians draw on these multimodal and temporal sources of EHR data to form a comprehensive view of a patient's health, which is crucial for informed therapeutic decision-making. Yet, most predictive models fail to fully capture the interactions, redundancies, and temporal patterns across multiple data modalities, often focusing on a single data type or overlooking these complexities. In this paper, we present CURENet, a multimodal model (Combining Unified Representations for Efficient chronic disease prediction) that integrates unstructured clinical notes, lab tests, and patients' time-series data by utilizing large language models (LLMs) for clinical text processing and textual lab tests, as well as transformer encoders for longitudinal sequential visits. CURENet has been capable of capturing the intricate interaction between different forms of clinical data and creating a more reliable predictive model for chronic illnesses. We evaluated CURENet using the public MIMIC-III and private FEMH datasets, where it achieved over 94\\% accuracy in predicting the top 10 chronic conditions in a multi-label framework. Our findings highlight the potential of multimodal EHR integration to enhance clinical decision-making and improve patient outcomes.", "AI": {"tldr": "CURENet\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u7b14\u8bb0\u3001\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u548c\u60a3\u8005\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5229\u7528LLM\u5904\u7406\u4e34\u5e8a\u6587\u672c\u548c\u6587\u672c\u5316\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\uff0c\u4ee5\u53catransformer\u7f16\u7801\u5668\u5904\u7406\u7eb5\u5411\u5e8f\u5217\u5c31\u8bca\u6570\u636e\uff0c\u7528\u4e8e\u6162\u6027\u75be\u75c5\u9884\u6d4b\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u9884\u6d4b\u6a21\u578b\u672a\u80fd\u5145\u5206\u5229\u7528EHR\u4e2d\u591a\u6a21\u6001\u6570\u636e\u4e4b\u95f4\u7684\u4ea4\u4e92\u3001\u5197\u4f59\u548c\u65f6\u95f4\u6a21\u5f0f\uff0c\u901a\u5e38\u53ea\u5173\u6ce8\u5355\u4e00\u6570\u636e\u7c7b\u578b\u6216\u5ffd\u89c6\u8fd9\u4e9b\u590d\u6742\u6027\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4e34\u5e8a\u6587\u672c\u548c\u6587\u672c\u5316\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\uff0c\u7ed3\u5408transformer\u7f16\u7801\u5668\u5904\u7406\u7eb5\u5411\u5e8f\u5217\u5c31\u8bca\u6570\u636e\uff0c\u6574\u5408\u591a\u6a21\u6001EHR\u6570\u636e\u3002", "result": "\u5728MIMIC-III\u548cFEMH\u6570\u636e\u96c6\u4e0a\uff0cCURENet\u5728\u591a\u6807\u7b7e\u6846\u67b6\u4e2d\u9884\u6d4b\u524d10\u79cd\u6162\u6027\u75be\u75c5\u65f6\u51c6\u786e\u7387\u8d85\u8fc794%\u3002", "conclusion": "\u591a\u6a21\u6001EHR\u6574\u5408\u6709\u6f5c\u529b\u589e\u5f3a\u4e34\u5e8a\u51b3\u7b56\u5236\u5b9a\u5e76\u6539\u5584\u60a3\u8005\u9884\u540e\u3002"}}
{"id": "2511.11519", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11519", "abs": "https://arxiv.org/abs/2511.11519", "authors": ["Adam Stein", "Matthew Trager", "Benjamin Bowman", "Michael Kleinman", "Aditya Chattopadhyay", "Wei Xia", "Stefano Soatto"], "title": "Experience-Guided Adaptation of Inference-Time Reasoning Strategies", "comment": "29 pages, 5 figures", "summary": "Enabling agentic AI systems to adapt their problem-solving approaches based on post-training interactions remains a fundamental challenge. While systems that update and maintain a memory at inference time have been proposed, existing designs only steer the system by modifying textual input to a language model or agent, which means that they cannot change sampling parameters, remove tools, modify system prompts, or switch between agentic and workflow paradigms. On the other hand, systems that adapt more flexibly require offline optimization and remain static once deployed. We present Experience-Guided Reasoner (EGuR), which generates tailored strategies -- complete computational procedures involving LLM calls, tools, sampling parameters, and control logic -- dynamically at inference time based on accumulated experience. We achieve this using an LLM-based meta-strategy -- a strategy that outputs strategies -- enabling adaptation of all strategy components (prompts, sampling parameters, tool configurations, and control logic). EGuR operates through two components: a Guide generates multiple candidate strategies conditioned on the current problem and structured memory of past experiences, while a Consolidator integrates execution feedback to improve future strategy generation. This produces complete, ready-to-run strategies optimized for each problem, which can be cached, retrieved, and executed as needed without wasting resources. Across five challenging benchmarks (AIME 2025, 3-SAT, and three Big Bench Extra Hard tasks), EGuR achieves up to 14% accuracy improvements over the strongest baselines while reducing computational costs by up to 111x, with both metrics improving as the system gains experience.", "AI": {"tldr": "EGuR\u662f\u4e00\u4e2a\u7ecf\u9a8c\u5f15\u5bfc\u7684\u63a8\u7406\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u63a8\u7406\u65f6\u52a8\u6001\u751f\u6210\u5b8c\u6574\u7684\u8ba1\u7b97\u7b56\u7565\uff08\u5305\u62ecLLM\u8c03\u7528\u3001\u5de5\u5177\u3001\u91c7\u6837\u53c2\u6570\u548c\u63a7\u5236\u903b\u8f91\uff09\uff0c\u901a\u8fc7\u5143\u7b56\u7565\u5b9e\u73b0\u6240\u6709\u7b56\u7565\u7ec4\u4ef6\u7684\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u5728\u591a\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5728\u8bad\u7ec3\u540e\u96be\u4ee5\u81ea\u9002\u5e94\u8c03\u6574\u95ee\u9898\u89e3\u51b3\u65b9\u6cd5\uff0c\u8981\u4e48\u53ea\u80fd\u4fee\u6539\u6587\u672c\u8f93\u5165\u800c\u65e0\u6cd5\u6539\u53d8\u91c7\u6837\u53c2\u6570\u3001\u5de5\u5177\u914d\u7f6e\u7b49\u6838\u5fc3\u7ec4\u4ef6\uff0c\u8981\u4e48\u9700\u8981\u79bb\u7ebf\u4f18\u5316\u4e14\u90e8\u7f72\u540e\u65e0\u6cd5\u52a8\u6001\u8c03\u6574\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eLLM\u7684\u5143\u7b56\u7565\u751f\u6210\u5b8c\u6574\u7b56\u7565\uff0c\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1aGuide\u57fa\u4e8e\u5f53\u524d\u95ee\u9898\u548c\u7ed3\u6784\u5316\u7ecf\u9a8c\u8bb0\u5fc6\u751f\u6210\u5019\u9009\u7b56\u7565\uff0cConsolidator\u6574\u5408\u6267\u884c\u53cd\u9988\u6765\u6539\u8fdb\u672a\u6765\u7b56\u7565\u751f\u6210\u3002", "result": "\u5728\u4e94\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\uff08AIME 2025\u30013-SAT\u548c\u4e09\u4e2aBig Bench Extra Hard\u4efb\u52a1\uff09\u4e2d\uff0cEGuR\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe14%\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe111\u500d\uff0c\u4e14\u968f\u7740\u7ecf\u9a8c\u79ef\u7d2f\u6027\u80fd\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "EGuR\u901a\u8fc7\u52a8\u6001\u751f\u6210\u5b8c\u6574\u7b56\u7565\u5b9e\u73b0\u4e86AI\u7cfb\u7edf\u7684\u5b9e\u65f6\u81ea\u9002\u5e94\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u6784\u5efa\u66f4\u667a\u80fd\u3001\u9ad8\u6548\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
