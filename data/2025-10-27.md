<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 22]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.DC](#cs.DC) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Fuzzy numbers revisited: operations on extensional fuzzy numbers](https://arxiv.org/abs/2510.20861)
*Krzysztof Siminski*

Main category: cs.AI

TL;DR: 本文提出了一种新的模糊数表示方法——外延模糊数，以解决传统模糊数运算中的计算复杂性和结果特征不一致问题，并定义了相关运算和关系运算符。


<details>
  <summary>Details</summary>
Motivation: 传统模糊数运算存在计算复杂度高、运算结果不保持原有特征、模糊度扩散等问题，限制了模糊数的应用范围。

Method: 采用外延模糊数表示方法，定义了外延模糊数的运算规则和关系运算符（=、>、>=、<、<=），并通过C++实现验证。

Result: 提出的方法能够有效降低计算复杂度，保持运算结果的特征一致性，并通过应用实例验证了方法的有效性。

Conclusion: 外延模糊数方法为解决传统模糊数运算问题提供了新的思路，具有实际应用价值，相关代码已在GitHub开源。

Abstract: Fuzzy numbers are commonly represented with fuzzy sets. Their objective is to
better represent imprecise data. However, operations on fuzzy numbers are not
as straightforward as maths on crisp numbers. Commonly, the Zadeh's extension
rule is applied to elaborate a result. This can produce two problems: (1) high
computational complexity and (2) for some fuzzy sets and some operations the
results is not a fuzzy set with the same features (eg. multiplication of two
triangular fuzzy sets does not produce a triangular fuzzy set). One more
problem is the fuzzy spread -- fuzziness of the result increases with the
number of operations. These facts can severely limit the application field of
fuzzy numbers. In this paper we would like to revisite this problem with a
different kind of fuzzy numbers -- extensional fuzzy numbers. The paper defines
operations on extensional fuzzy numbers and relational operators (=, >, >=, <,
<=) for them. The proposed approach is illustrated with several applicational
examples. The C++ implementation is available from a public GitHub repository.

</details>


### [2] [CXRAgent: Director-Orchestrated Multi-Stage Reasoning for Chest X-Ray Interpretation](https://arxiv.org/abs/2510.21324)
*Jinhui Lou,Yan Yang,Zhou Yu,Zhenqi Fu,Weidong Han,Qingming Huang,Jun Yu*

Main category: cs.AI

TL;DR: 本文提出CXRAgent，一种基于LLM的导演编排多阶段智能体，用于胸部X光片分析。该智能体通过工具调用、诊断规划和协作决策三个阶段，结合视觉证据验证和专家团队协作，提升CXR诊断的适应性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有CXR分析模型难以适应新的诊断任务和复杂推理场景，现有智能体往往依赖单一诊断流程且缺乏工具可靠性评估机制，限制了其适应性和可信度。

Method: 提出导演编排的三阶段方法：1) 工具调用阶段，通过证据驱动验证器对工具输出进行标准化和验证；2) 诊断规划阶段，根据任务需求和中间发现制定诊断计划并组建专家团队；3) 协作决策阶段，整合专家见解和上下文记忆形成证据支持的诊断结论。

Result: 在各种CXR解释任务上的实验表明，CXRAgent表现出强大的性能，能提供视觉证据，并能很好地泛化到不同复杂度的临床任务。

Conclusion: CXRAgent通过多阶段协作和证据验证机制，显著提升了CXR诊断的适应性和可信度，为自动医学图像分析提供了新的解决方案。

Abstract: Chest X-ray (CXR) plays a pivotal role in clinical diagnosis, and a variety
of task-specific and foundation models have been developed for automatic CXR
interpretation. However, these models often struggle to adapt to new diagnostic
tasks and complex reasoning scenarios. Recently, LLM-based agent models have
emerged as a promising paradigm for CXR analysis, enhancing model's capability
through tool coordination, multi-step reasoning, and team collaboration, etc.
However, existing agents often rely on a single diagnostic pipeline and lack
mechanisms for assessing tools' reliability, limiting their adaptability and
credibility. To this end, we propose CXRAgent, a director-orchestrated,
multi-stage agent for CXR interpretation, where a central director coordinates
the following stages: (1) Tool Invocation: The agent strategically orchestrates
a set of CXR-analysis tools, with outputs normalized and verified by the
Evidence-driven Validator (EDV), which grounds diagnostic outputs with visual
evidence to support reliable downstream diagnosis; (2) Diagnostic Planning:
Guided by task requirements and intermediate findings, the agent formulates a
targeted diagnostic plan. It then assembles an expert team accordingly,
defining member roles and coordinating their interactions to enable adaptive
and collaborative reasoning; (3) Collaborative Decision-making: The agent
integrates insights from the expert team with accumulated contextual memories,
synthesizing them into an evidence-backed diagnostic conclusion. Experiments on
various CXR interpretation tasks show that CXRAgent delivers strong
performance, providing visual evidence and generalizes well to clinical tasks
of different complexity. Code and data are valuable at this
\href{https://github.com/laojiahuo2003/CXRAgent/}{link}.

</details>


### [3] [Epistemic Deference to AI](https://arxiv.org/abs/2510.21043)
*Benjamin Lange*

Main category: cs.AI

TL;DR: 该论文探讨了何时应该优先采纳AI输出而非人类专家判断，提出了AI优先主义观点及其替代方案——基于全证据的AI遵从观。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于确定AI系统何时应被视为人工认知权威，以及如何合理处理AI输出与人类独立认知判断之间的关系。

Method: 作者基于社会认识论框架，分析AI优先主义的经典反对意见，并发展出基于全证据的AI遵从理论。

Result: 研究发现AI优先主义存在放大形式的反对意见，而全证据观点能更好地平衡AI权威与人类认知参与。

Conclusion: 结论支持基于全证据的AI遵从观，认为AI输出应作为贡献性理由而非完全替代人类独立认知，这在高风险情境中尤为重要。

Abstract: When should we defer to AI outputs over human expert judgment? Drawing on
recent work in social epistemology, I motivate the idea that some AI systems
qualify as Artificial Epistemic Authorities (AEAs) due to their demonstrated
reliability and epistemic superiority. I then introduce AI Preemptionism, the
view that AEA outputs should replace rather than supplement a user's
independent epistemic reasons. I show that classic objections to preemptionism
- such as uncritical deference, epistemic entrenchment, and unhinging epistemic
bases - apply in amplified form to AEAs, given their opacity, self-reinforcing
authority, and lack of epistemic failure markers. Against this, I develop a
more promising alternative: a total evidence view of AI deference. According to
this view, AEA outputs should function as contributory reasons rather than
outright replacements for a user's independent epistemic considerations. This
approach has three key advantages: (i) it mitigates expertise atrophy by
keeping human users engaged, (ii) it provides an epistemic case for meaningful
human oversight and control, and (iii) it explains the justified mistrust of AI
when reliability conditions are unmet. While demanding in practice, this
account offers a principled way to determine when AI deference is justified,
particularly in high-stakes contexts requiring rigorous reliability.

</details>


### [4] [From Questions to Queries: An AI-powered Multi-Agent Framework for Spatial Text-to-SQL](https://arxiv.org/abs/2510.21045)
*Ali Khosravi Kazazi,Zhenlong Li,M. Naser Lessani,Guido Cervone*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体框架，用于将自然语言问题准确转换为空间SQL查询，通过专门的智能体协作和程序化验证机制，显著提升了空间查询的准确性和语义对齐度。


<details>
  <summary>Details</summary>
Motivation: SQL的复杂性和PostGIS等工具中地理空间函数的专业性为非专家分析空间数据设置了重大障碍。虽然大语言模型在自然语言转SQL方面有潜力，但单智能体方法在处理空间查询的语义和语法复杂性方面存在困难。

Method: 提出了一个多智能体框架，包括知识库（含程序化模式分析和语义增强）、上下文检索嵌入以及协作多智能体流水线。流水线包含实体提取、元数据检索、查询逻辑制定、SQL生成和审查智能体（执行程序化和语义验证）。

Result: 在非空间的KaggleDBQA基准测试中，系统在审查智能体审查和修正后达到81.2%的总体准确率（272个问题中的221个）。对于空间查询，系统达到87.7%的总体准确率（90个问题中的79个），相比没有审查智能体时的76.7%有显著提升。

Conclusion: 该工作使空间分析更加易于访问，为空间文本到SQL系统提供了强大、可推广的基础，推动了自主GIS的发展。

Abstract: The complexity of Structured Query Language (SQL) and the specialized nature
of geospatial functions in tools like PostGIS present significant barriers to
non-experts seeking to analyze spatial data. While Large Language Models (LLMs)
offer promise for translating natural language into SQL (Text-to-SQL),
single-agent approaches often struggle with the semantic and syntactic
complexities of spatial queries. To address this, we propose a multi-agent
framework designed to accurately translate natural language questions into
spatial SQL queries. The framework integrates several innovative components,
including a knowledge base with programmatic schema profiling and semantic
enrichment, embeddings for context retrieval, and a collaborative multi-agent
pipeline as its core. This pipeline comprises specialized agents for entity
extraction, metadata retrieval, query logic formulation, SQL generation, and a
review agent that performs programmatic and semantic validation of the
generated SQL to ensure correctness (self-verification). We evaluate our system
using both the non-spatial KaggleDBQA benchmark and a new, comprehensive
SpatialQueryQA benchmark that includes diverse geometry types, predicates, and
three levels of query complexity. On KaggleDBQA, the system achieved an overall
accuracy of 81.2% (221 out of 272 questions) after the review agent's review
and corrections. For spatial queries, the system achieved an overall accuracy
of 87.7% (79 out of 90 questions), compared with 76.7% without the review
agent. Beyond accuracy, results also show that in some instances the system
generates queries that are more semantically aligned with user intent than
those in the benchmarks. This work makes spatial analysis more accessible, and
provides a robust, generalizable foundation for spatial Text-to-SQL systems,
advancing the development of autonomous GIS.

</details>


### [5] [MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning](https://arxiv.org/abs/2510.21093)
*Siyong Chen,Jinbo Wen,Jiawen Kang,Tenghui Huang,Xumin Huang,Yuanjia Su,Hudan Pan,Zishao Zhong,Dusit Niyato,Shengli Xie,Dong In Kim*

Main category: cs.AI

TL;DR: MedAlign是一个针对医学视觉问答的新型框架，通过多模态直接偏好优化、检索感知专家混合架构和联邦治理机制，解决大型视觉语言模型在临床部署中的幻觉、推理效率和多机构协作问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在智能医疗领域具有潜力，但面临三个关键挑战：产生基于视觉证据的幻觉答案、固定深度推理的低效性以及多机构协作的困难。

Method: 提出多模态直接偏好优化目标来显式对齐偏好学习与视觉上下文；设计检索感知专家混合架构，利用图像和文本相似性将查询路由到专门的上下文增强LVLM专家；采用联邦治理机制，让选定的专家基于本地元认知不确定性估计器执行迭代链式思维推理。

Result: 在三个代表性Med-VQA数据集上的广泛实验表明，MedAlign实现了最先进的性能，比强检索增强基线在F1分数上提高了11.85%，同时与固定深度CoT方法相比平均推理长度减少了51.60%。

Conclusion: MedAlign框架有效解决了LVLM在医疗应用中的关键挑战，通过视觉对齐、高效推理和多机构协作机制，为临床服务部署提供了可行方案。

Abstract: Recently, large models have shown significant potential for smart healthcare.
However, the deployment of Large Vision-Language Models (LVLMs) for clinical
services is currently hindered by three critical challenges: a tendency to
hallucinate answers not grounded in visual evidence, the inefficiency of
fixed-depth reasoning, and the difficulty of multi-institutional collaboration.
To address these challenges, in this paper, we develop MedAlign, a novel
framework to ensure visually accurate LVLM responses for Medical Visual
Question Answering (Med-VQA). Specifically, we first propose a multimodal
Direct Preference Optimization (mDPO) objective to explicitly align preference
learning with visual context. We then design a Retrieval-Aware
Mixture-of-Experts (RA-MoE) architecture that utilizes image and text
similarity to route queries to a specialized and context-augmented LVLM (i.e.,
an expert), thereby mitigating hallucinations in LVLMs. To achieve adaptive
reasoning and facilitate multi-institutional collaboration, we propose a
federated governance mechanism, where the selected expert, fine-tuned on
clinical datasets based on mDPO, locally performs iterative Chain-of-Thought
(CoT) reasoning via the local meta-cognitive uncertainty estimator. Extensive
experiments on three representative Med-VQA datasets demonstrate that MedAlign
achieves state-of-the-art performance, outperforming strong retrieval-augmented
baselines by up to $11.85\%$ in F1-score, and simultaneously reducing the
average reasoning length by $51.60\%$ compared with fixed-depth CoT approaches.

</details>


### [6] [NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge](https://arxiv.org/abs/2510.21144)
*Hanyu Zhu,Lance Fiondella,Jiawei Yuan,Kai Zeng,Long Jiao*

Main category: cs.AI

TL;DR: 本文提出NeuroGenPoisoning攻击框架，通过分析LLM内部神经元归因和遗传优化来生成对抗性外部知识，有效实现RAG系统的大规模知识投毒攻击。


<details>
  <summary>Details</summary>
Motivation: 现有RAG投毒攻击主要关注检索内容或提示结构的迭代操作，忽略了模型内部表示动态和神经元级敏感性，且未充分考虑与强参数化知识的知识冲突问题。

Method: 首先识别与上下文投毒知识强烈相关的毒害响应神经元，然后使用遗传算法进化对抗性段落以最大化激活这些神经元，并通过观察到的归因信号重用有前景但最初未成功的外部知识变体。

Result: 在多个模型和数据集上的实验结果表明，该方法能持续实现超过90%的人口覆盖成功率，同时保持流畅性，并有效解决知识冲突问题。

Conclusion: NeuroGenPoisoning框架通过神经元归因引导的投毒能够有效解决知识冲突，实现大规模有效的RAG知识投毒攻击。

Abstract: Retrieval-Augmented Generation (RAG) empowers Large Language Models (LLMs) to
dynamically integrate external knowledge during inference, improving their
factual accuracy and adaptability. However, adversaries can inject poisoned
external knowledge to override the model's internal memory. While existing
attacks iteratively manipulate retrieval content or prompt structure of RAG,
they largely ignore the model's internal representation dynamics and
neuron-level sensitivities. The underlying mechanism of RAG poisoning has not
been fully studied and the effect of knowledge conflict with strong parametric
knowledge in RAG is not considered. In this work, we propose NeuroGenPoisoning,
a novel attack framework that generates adversarial external knowledge in RAG
guided by LLM internal neuron attribution and genetic optimization. Our method
first identifies a set of Poison-Responsive Neurons whose activation strongly
correlates with contextual poisoning knowledge. We then employ a genetic
algorithm to evolve adversarial passages that maximally activate these neurons.
Crucially, our framework enables massive-scale generation of effective poisoned
RAG knowledge by identifying and reusing promising but initially unsuccessful
external knowledge variants via observed attribution signals. At the same time,
Poison-Responsive Neurons guided poisoning can effectively resolves knowledge
conflict. Experimental results across models and datasets demonstrate
consistently achieving high Population Overwrite Success Rate (POSR) of over
90% while preserving fluency. Empirical evidence shows that our method
effectively resolves knowledge conflict.

</details>


### [7] [How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation](https://arxiv.org/abs/2510.21148)
*Yang Zhao,Pu Wang,Hao Frank Yang*

Main category: cs.AI

TL;DR: EGO-Prompt是一个自动化框架，用于优化大语言模型的提示设计和推理过程，通过进化图优化和语义因果图来提升领域特定任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，为大语言模型设计最优提示和推理过程是必要且具有挑战性的。如何整合领域知识、提高推理效率，并为领域专家提供精炼的知识整合提示是尚未解决的关键任务。

Method: EGO-Prompt从人类专家构建的通用提示和容错初始语义因果图开始，通过两步骤的因果引导文本梯度过程进行自动优化：首先生成每个实例的确定性推理指导，然后使LLM能够有效利用该指导与原始输入。迭代优化算法使用基于真实数据的文本梯度进一步精炼SCG和推理机制。

Result: 在公共卫生、交通和人类行为等真实世界任务中测试，EGO-Prompt比最先进方法实现了7.32%-12.61%的F1分数提升，并使小模型以不到20%的成本达到大模型的性能水平。

Conclusion: EGO-Prompt能够有效优化提示设计和推理过程，显著提升LLM在领域特定任务中的性能，同时输出精炼的领域特定语义因果图以提高可解释性。

Abstract: Designing optimal prompts and reasoning processes for large language models
(LLMs) on domain-specific tasks is both necessary and challenging in real-world
applications. Determining how to integrate domain knowledge, enhance reasoning
efficiency, and even provide domain experts with refined knowledge integration
hints are particularly crucial yet unresolved tasks. In this research, we
propose Evolutionary Graph Optimization for Prompting (EGO-Prompt), an
automated framework to designing better prompts, efficient reasoning processes
and providing enhanced causal-informed process. EGO-Prompt begins with a
general prompt and fault-tolerant initial Semantic Causal Graph (SCG)
descriptions, constructed by human experts, which is then automatically refined
and optimized to guide LLM reasoning. Recognizing that expert-defined SCGs may
be partial or imperfect and that their optimal integration varies across LLMs,
EGO-Prompt integrates a novel causal-guided textual gradient process in two
steps: first, generating nearly deterministic reasoning guidance from the SCG
for each instance, and second, adapting the LLM to effectively utilize the
guidance alongside the original input. The iterative optimization algorithm
further refines both the SCG and the reasoning mechanism using textual
gradients with ground-truth. We tested the framework on real-world public
health, transportation and human behavior tasks. EGO-Prompt achieves
7.32%-12.61% higher F1 than cutting-edge methods, and allows small models to
reach the performence of larger models at under 20% of the original cost. It
also outputs a refined, domain-specific SCG that improves interpretability.

</details>


### [8] [String Seed of Thought: Prompting LLMs for Distribution-Faithful and Diverse Generation](https://arxiv.org/abs/2510.21150)
*Kou Misaki,Takuya Akiba*

Main category: cs.AI

TL;DR: SSoT是一种新颖的提示方法，通过让LLM先生成随机字符串来增加熵，然后从中提取随机性来选择答案，显著提升了LLM在概率指令跟随任务中的表现。


<details>
  <summary>Details</summary>
Motivation: LLM在需要单一确定性答案的任务中表现出色，但在概率指令跟随任务中表现不佳，存在偏见问题，影响需要非确定性行为的应用（如人类行为模拟、内容多样化、多人游戏）和响应多样性。

Method: 提出SSoT提示方法：首先让LLM输出随机字符串生成足够熵，然后通过操作该字符串提取随机性来推导最终答案，在保持多样性的同时遵循特定约束。

Result: SSoT显著提升了LLM的PIF性能，接近伪随机数生成器的理想性能。在NoveltyBench上的实验表明SSoT还能增强开放任务的响应多样性。

Conclusion: SSoT是一种简单有效的提示方法，能够改善LLM在概率指令跟随任务中的表现，同时增强响应多样性，适用于需要非确定性行为的各种应用场景。

Abstract: We introduce String Seed of Thought (SSoT), a novel prompting method for LLMs
that improves Probabilistic Instruction Following (PIF). We define PIF as a
task requiring an LLM to select its answer from a predefined set of options,
each associated with a specific probability, such that the empirical
distribution of the generated answers aligns with the target distribution when
prompted multiple times. While LLMs excel at tasks with single, deterministic
answers, they often fail at PIF, exhibiting biases problematic for applications
requiring non-deterministic behaviors, such as human-behavior simulation,
content diversification, and multiplayer games. It also harms the diversity of
generated responses, a crucial factor in test-time scaling, by causing the
outputs to collapse into a limited set of answers. To address this, we propose
SSoT, a simple prompting method that instructs an LLM to first output a random
string to generate sufficient entropy. SSoT also instructs the LLM to extract
randomness by manipulating this string to derive a final answer, thereby
preserving diversity while adhering to specific constraints. We demonstrate
that SSoT significantly improves the PIF performance of LLMs, approaching the
ideal performance of a pseudo-random number generator. Furthermore, our
experiments on NoveltyBench show SSoT's benefits extend beyond closed-set tasks
to open-ended tasks by enhancing response diversity.

</details>


### [9] [Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models](https://arxiv.org/abs/2510.21175)
*Yujin Jo,Taesup Kim*

Main category: cs.AI

TL;DR: NuSA-CL是一个轻量级、无内存的持续学习框架，通过低秩适应和约束权重更新在参数近似零空间内，有效保护预训练视觉语言模型的零样本能力，同时实现竞争性的持续学习性能。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型在现实部署中面临分布漂移和新任务挑战，静态零样本能力不足，需要持续学习方法在不遗忘已有知识的情况下适应新环境。

Method: 采用低秩适应技术，将任务特定的权重更新约束在当前模型参数的近似零空间内，最小化对已学知识的干扰，避免灾难性遗忘。

Result: 实验表明该框架不仅有效保护零样本迁移能力，还在持续学习基准测试中达到高度竞争性性能。

Conclusion: NuSA-CL为现实应用中持续演化的零样本视觉语言模型提供了一个实用且可扩展的解决方案。

Abstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated
remarkable zero-shot generalization, enabling deployment in a wide range of
real-world tasks without additional task-specific training. However, in real
deployment scenarios with evolving environments or emerging classes, these
models inevitably face distributional shifts and novel tasks. In such contexts,
static zero-shot capabilities are insufficient, and there is a growing need for
continual learning methods that allow models to adapt over time while avoiding
catastrophic forgetting. We introduce NuSA-CL (Null Space Adaptation for
Continual Learning), a lightweight memory-free continual learning framework
designed to address this challenge. NuSA-CL employs low-rank adaptation and
constrains task-specific weight updates to lie within an approximate null space
of the model's current parameters. This strategy minimizes interference with
previously acquired knowledge, effectively preserving the zero-shot
capabilities of the original model. Unlike methods relying on replay buffers or
costly distillation, NuSA-CL imposes minimal computational and memory overhead,
making it practical for deployment in resource-constrained, real-world
continual learning environments. Experiments show that our framework not only
effectively preserves zero-shot transfer capabilities but also achieves highly
competitive performance on continual learning benchmarks. These results
position NuSA-CL as a practical and scalable solution for continually evolving
zero-shot VLMs in real-world applications.

</details>


### [10] [OutboundEval: A Dual-Dimensional Benchmark for Expert-Level Intelligent Outbound Evaluation of Xbench's Professional-Aligned Series](https://arxiv.org/abs/2510.21244)
*Pengyu Xu,Shijia Li,Ao Sun,Feng Zhang,Yahan Li,Bo Wu,Zhanyu Ma,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Rui Wang,Yang Liu,Xiaobo Hu,Fan Yang,Jia Zheng,Guanghua Yao*

Main category: cs.AI

TL;DR: OutboundEval是一个评估大语言模型在专业级智能外呼场景中表现的综合性基准，通过结构化框架解决了现有方法的三个关键限制：数据集多样性不足、用户模拟不真实和评估指标不准确。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法存在三个主要问题：数据集多样性和类别覆盖不足、用户模拟不现实、评估指标不准确，这限制了LLM在专业外呼场景中的可靠评估。

Method: 1) 设计涵盖6个主要业务领域和30个子场景的基准，包含场景特定流程分解、加权评分和领域自适应指标；2) 开发大模型驱动的用户模拟器，生成多样化、角色丰富的虚拟用户；3) 引入动态评估方法，结合自动化和人工评估。

Result: 在12个最先进的LLM上的实验揭示了专家级任务完成度和交互流畅性之间的权衡，为构建可靠、类人的外呼AI系统提供了实用见解。

Conclusion: OutboundEval为专业应用中LLM的基准测试建立了实用、可扩展且面向领域的新标准。

Abstract: We propose OutboundEval, a comprehensive benchmark for evaluating large
language models (LLMs) in expert-level intelligent outbound calling scenarios.
Unlike existing methods that suffer from three key limitations - insufficient
dataset diversity and category coverage, unrealistic user simulation, and
inaccurate evaluation metrics - OutboundEval addresses these issues through a
structured framework. First, we design a benchmark spanning six major business
domains and 30 representative sub-scenarios, each with scenario-specific
process decomposition, weighted scoring, and domain-adaptive metrics. Second,
we develop a large-model-driven User Simulator that generates diverse,
persona-rich virtual users with realistic behaviors, emotional variability, and
communication styles, providing a controlled yet authentic testing environment.
Third, we introduce a dynamic evaluation method that adapts to task variations,
integrating automated and human-in-the-loop assessment to measure task
execution accuracy, professional knowledge application, adaptability, and user
experience quality. Experiments on 12 state-of-the-art LLMs reveal distinct
trade-offs between expert-level task completion and interaction fluency,
offering practical insights for building reliable, human-like outbound AI
systems. OutboundEval establishes a practical, extensible, and domain-oriented
standard for benchmarking LLMs in professional applications.

</details>


### [11] [Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems](https://arxiv.org/abs/2510.21254)
*Victoria J. Hodge,Colin Paterson,Ibrahim Habli*

Main category: cs.AI

TL;DR: 本文综述了自主系统中OOD检测技术，分析了其在安全保证中的重要性、挑战因素、可用技术方法，并讨论了集成OOD检测时的注意事项和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI自主系统能力的扩展，在安全关键领域需要严格的验证方法。OOD检测能够处理系统生命周期中的新颖和不确定情况，对安全保证至关重要。

Method: 采用文献综述方法，首先定义相关概念，分析OOD产生原因和挑战因素，识别ML开发生命周期中可用的OOD检测技术，并讨论集成注意事项。

Result: 识别了一系列可在ML开发生命周期中使用的OOD检测技术，提出了在生命周期中支持安全保证论证的应用建议，并指出了系统工程师需要注意的注意事项。

Conclusion: OOD检测对自主系统的安全开发和运行至关重要，但仍面临挑战，需要进一步研究来支持跨领域应用的安全保证。

Abstract: The operational capabilities and application domains of AI-enabled autonomous
systems have expanded significantly in recent years due to advances in robotics
and machine learning (ML). Demonstrating the safety of autonomous systems
rigorously is critical for their responsible adoption but it is challenging as
it requires robust methodologies that can handle novel and uncertain situations
throughout the system lifecycle, including detecting out-of-distribution (OoD)
data. Thus, OOD detection is receiving increased attention from the research,
development and safety engineering communities. This comprehensive review
analyses OOD detection techniques within the context of safety assurance for
autonomous systems, in particular in safety-critical domains. We begin by
defining the relevant concepts, investigating what causes OOD and exploring the
factors which make the safety assurance of autonomous systems and OOD detection
challenging. Our review identifies a range of techniques which can be used
throughout the ML development lifecycle and we suggest areas within the
lifecycle in which they may be used to support safety assurance arguments. We
discuss a number of caveats that system and safety engineers must be aware of
when integrating OOD detection into system lifecycles. We conclude by outlining
the challenges and future work necessary for the safe development and operation
of autonomous systems across a range of domains and applications.

</details>


### [12] [Investigating Scale Independent UCT Exploration Factor Strategies](https://arxiv.org/abs/2510.21275)
*Robin Schmöcker,Christoph Schnell,Alexander Dockhorn*

Main category: cs.AI

TL;DR: 本文提出并评估了多种自适应选择UCT探索常数λ的策略，推荐使用新提出的λ=2σ方法，其中σ是搜索树中所有状态-动作对Q值的经验标准差。


<details>
  <summary>Details</summary>
Motivation: UCT算法对游戏奖励尺度不鲁棒，特别是在具有密集奖励的游戏中使用手动选择的奖励尺度时，会导致不同游戏中节点的Q值跨度不同。

Method: 评估了文献中提出的以及五种新的λ策略，包括选择λ作为搜索树中所有状态-动作对Q值经验标准差的两倍。

Result: 新提出的λ=2σ策略在广泛任务中优于现有λ策略，无论是在单一参数值还是优化所有可用参数后的峰值性能方面。

Conclusion: 推荐使用λ=2σ作为UCT探索常数，该方法对游戏奖励尺度具有鲁棒性且性能优越。

Abstract: The Upper Confidence Bounds For Trees (UCT) algorithm is not agnostic to the
reward scale of the game it is applied to. For zero-sum games with the sparse
rewards of $\{-1,0,1\}$ at the end of the game, this is not a problem, but many
games often feature dense rewards with hand-picked reward scales, causing a
node's Q-value to span different magnitudes across different games. In this
paper, we evaluate various strategies for adaptively choosing the UCT
exploration constant $\lambda$, called $\lambda$-strategies, that are agnostic
to the game's reward scale. These $\lambda$-strategies include those proposed
in the literature as well as five new strategies. Given our experimental
results, we recommend using one of our newly suggested $\lambda$-strategies,
which is to choose $\lambda$ as $2 \cdot \sigma$ where $\sigma$ is the
empirical standard deviation of all state-action pairs' Q-values of the search
tree. This method outperforms existing $\lambda$-strategies across a wide range
of tasks both in terms of a single parameter value and the peak performances
obtained by optimizing all available parameters.

</details>


### [13] [When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large Reasoning Models with Chain-of-Guardrails](https://arxiv.org/abs/2510.21285)
*Yingzhi Mao,Chunkang Zhang,Junxiang Wang,Xinyan Guan,Boxi Cao,Yaojie Lu,Hongyu Lin,Xianpei Han,Le Sun*

Main category: cs.AI

TL;DR: 大型推理模型存在安全风险，作者发现自我越狱现象并提出链式护栏训练框架，在保持推理能力的同时显著提升安全性


<details>
  <summary>Details</summary>
Motivation: 现有安全缓解策略依赖启发式安全信号注入，往往抑制推理能力且无法解决安全与推理的权衡问题

Method: 提出链式护栏训练框架，重新组合或回溯不安全的推理步骤，引导模型回到安全轨迹同时保持有效推理链

Result: 在多个推理和安全基准测试中，CoG显著提升了当前大型推理模型的安全性，同时保持相当的推理能力

Conclusion: CoG框架有效解决了安全与推理的权衡问题，显著优于先前存在严重权衡问题的方法

Abstract: Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex
reasoning tasks but remain vulnerable to severe safety risks, including harmful
content generation and jailbreak attacks. Existing mitigation strategies rely
on injecting heuristic safety signals during training, which often suppress
reasoning ability and fail to resolve the safety-reasoning trade-off. To
systematically investigate this issue, we analyze the reasoning trajectories of
diverse LRMs and uncover a phenomenon we term Self-Jailbreak, where models
override their own risk assessments and justify responding to unsafe prompts.
This finding reveals that LRMs inherently possess the ability to reject unsafe
queries, but this ability is compromised, resulting in harmful outputs.
Building on these insights, we propose the Chain-of-Guardrail (CoG), a training
framework that recomposes or backtracks unsafe reasoning steps, steering the
model back onto safe trajectories while preserving valid reasoning chains.
Extensive experiments across multiple reasoning and safety benchmarks
demonstrate that CoG substantially improves the safety of current LRMs while
preserving comparable reasoning ability, significantly outperforming prior
methods that suffer from severe safety-reasoning trade-offs.

</details>


### [14] [Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT Articles](https://arxiv.org/abs/2510.21293)
*Siddharth Mehrotra,Jin Huang,Xuelong Fu,Roel Dobbe,Clara I. Sánchez,Maarten de Rijke*

Main category: cs.AI

TL;DR: 本文通过范围综述分析了AIES和FAccT会议中可信AI研究的现状，发现当前研究过度关注技术属性而忽视社会技术维度，提出了结合技术严谨性与社会文化因素的跨学科方法。


<details>
  <summary>Details</summary>
Motivation: 当前可信AI研究主要采用技术中心方法，过度关注可靠性、鲁棒性和公平性等技术属性，而忽视了理解真实世界环境中AI可信度所需的社会技术维度。

Method: 对AIES和FAccT会议论文集进行范围综述，系统分析可信度在不同研究领域中的定义、操作化和应用方式，重点关注概念化方法、测量方法、验证技术、应用领域和基础价值观。

Result: 研究发现虽然透明度、问责制和鲁棒性等技术属性的定义取得了显著进展，但当前研究往往过度强调技术精度而牺牲社会伦理考量，AI系统的社会技术性质仍较少被探索，可信度成为由有权定义者塑造的有争议概念。

Conclusion: 需要采用结合技术严谨性与社会、文化和制度考量的跨学科方法来推进可信AI，为AI伦理社区提出了采纳整体框架的可操作措施，以真正解决AI系统与社会之间的复杂互动，促进惠及所有利益相关者的负责任技术发展。

Abstract: Background: Trustworthy AI serves as a foundational pillar for two major AI
ethics conferences: AIES and FAccT. However, current research often adopts
techno-centric approaches, focusing primarily on technical attributes such as
reliability, robustness, and fairness, while overlooking the sociotechnical
dimensions critical to understanding AI trustworthiness in real-world contexts.
  Objectives: This scoping review aims to examine how the AIES and FAccT
communities conceptualize, measure, and validate AI trustworthiness,
identifying major gaps and opportunities for advancing a holistic understanding
of trustworthy AI systems.
  Methods: We conduct a scoping review of AIES and FAccT conference proceedings
to date, systematically analyzing how trustworthiness is defined,
operationalized, and applied across different research domains. Our analysis
focuses on conceptualization approaches, measurement methods, verification and
validation techniques, application areas, and underlying values.
  Results: While significant progress has been made in defining technical
attributes such as transparency, accountability, and robustness, our findings
reveal critical gaps. Current research often predominantly emphasizes technical
precision at the expense of social and ethical considerations. The
sociotechnical nature of AI systems remains less explored and trustworthiness
emerges as a contested concept shaped by those with the power to define it.
  Conclusions: An interdisciplinary approach combining technical rigor with
social, cultural, and institutional considerations is essential for advancing
trustworthy AI. We propose actionable measures for the AI ethics community to
adopt holistic frameworks that genuinely address the complex interplay between
AI systems and society, ultimately promoting responsible technological
development that benefits all stakeholders.

</details>


### [15] [Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning](https://arxiv.org/abs/2510.21302)
*Sanghyun Ahn,Wonje Choi,Junyong Lee,Jinwoo Park,Honguk Woo*

Main category: cs.AI

TL;DR: 提出了一种结合符号验证和交互验证的神经符号具身任务规划框架，通过在代码生成过程中加入探索性代码来获取缺失观察，提升动态和部分可观测环境中的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代码即策略方法在动态或部分可观测环境中存在环境接地不足的问题，导致任务成功率较低，需要改进代码生成的环境接地能力。

Method: 采用神经符号具身任务规划框架，包含显式符号验证和交互验证过程，生成探索性代码与环境交互获取缺失观察，同时保持任务相关状态。

Result: 在RLBench和真实世界动态部分可观测场景中，相比代码即策略基线任务成功率提升46.2%，任务相关动作可执行性达到86.8%以上。

Conclusion: 该框架通过增强代码生成的环境接地能力，显著提高了动态环境中任务规划的可靠性。

Abstract: Recent advances in large language models (LLMs) have enabled the automatic
generation of executable code for task planning and control in embodied agents
such as robots, demonstrating the potential of LLM-based embodied intelligence.
However, these LLM-based code-as-policies approaches often suffer from limited
environmental grounding, particularly in dynamic or partially observable
settings, leading to suboptimal task success rates due to incorrect or
incomplete code generation. In this work, we propose a neuro-symbolic embodied
task planning framework that incorporates explicit symbolic verification and
interactive validation processes during code generation. In the validation
phase, the framework generates exploratory code that actively interacts with
the environment to acquire missing observations while preserving task-relevant
states. This integrated process enhances the grounding of generated code,
resulting in improved task reliability and success rates in complex
environments. We evaluate our framework on RLBench and in real-world settings
across dynamic, partially observable scenarios. Experimental results
demonstrate that our framework improves task success rates by 46.2% over
Code-as-Policies baselines and attains over 86.8% executability of
task-relevant actions, thereby enhancing the reliability of task planning in
dynamic environments.

</details>


### [16] [Magellan: Guided MCTS for Latent Space Exploration and Novelty Generation](https://arxiv.org/abs/2510.21341)
*Lufan Chang*

Main category: cs.AI

TL;DR: Magellan框架通过蒙特卡洛树搜索和分层引导系统，解决了LLM在创意生成中依赖高概率概念的局限性，显著提升了科学想法的合理性和创新性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成创新想法时往往局限于训练数据中的常见概念，现有的搜索方法如思维树依赖不可靠的自评估启发式方法，存在根本性限制。

Method: 使用蒙特卡洛树搜索，结合分层引导系统：语义罗盘向量提供长期方向指导，景观感知价值函数替代有缺陷的自评估，平衡内在连贯性、外在新颖性和叙事进展。

Result: 广泛实验表明，Magellan在生成科学想法方面显著优于ReAct和思维树等强基线方法，在合理性和创新性方面表现更优。

Conclusion: 对于创意发现，有原则的引导搜索比无约束的自主性更有效，这为LLM成为创新中更有能力的合作伙伴铺平了道路。

Abstract: Large Language Models (LLMs) often struggle with generating truly innovative
ideas, typically defaulting to high-probability, familiar concepts within their
training data's "gravity wells." While advanced search-based methods like Tree
of Thoughts (ToT) attempt to mitigate this, they are fundamentally limited by
their reliance on unprincipled, inconsistent self-evaluation heuristics to
guide exploration. To address this gap, we introduce \textbf{Magellan}, a novel
framework that reframes creative generation as a principled, guided exploration
of an LLM's latent conceptual space. At its core, Magellan employs Monte Carlo
Tree Search (MCTS) governed by a hierarchical guidance system. For long-range
direction, a "semantic compass" vector, formulated via orthogonal projection,
steers the search towards relevant novelty. For local, step-by-step decisions,
a landscape-aware value function replaces flawed self-evaluation with an
explicit reward structure that balances intrinsic coherence, extrinsic novelty,
and narrative progress. Extensive experiments demonstrate that Magellan
significantly outperforms strong baselines, including ReAct and ToT, in
generating scientific ideas with superior plausibility and innovation. Our work
shows that for creative discovery, a principled, guided search is more
effective than unconstrained agency, paving the way for LLMs to become more
capable partners in innovation.

</details>


### [17] [AutoOpt: A Dataset and a Unified Framework for Automating Optimization Problem Solving](https://arxiv.org/abs/2510.21436)
*Ankur Sinha,Shobhit Arora,Dhaval Pujara*

Main category: cs.AI

TL;DR: AutoOpt-11k是一个包含11,000多个手写和印刷数学优化模型图像的数据集，配套开发了AutoOpt框架，通过深度学习模型自动识别数学表达式并生成优化代码，最终求解优化问题。


<details>
  <summary>Details</summary>
Motivation: 为解决数学优化问题求解过程中需要人工干预和专业知识的问题，开发自动化优化求解框架，减少人工参与并提高求解效率。

Method: 开发三模块框架：M1使用深度学习模型进行数学表达式识别生成LaTeX代码；M2使用微调的小型LLM将LaTeX转换为PYOMO脚本；M3使用双层优化分解方法求解优化问题。

Result: MER模型在BLEU得分上优于ChatGPT、Gemini和Nougat；BOBD方法在复杂测试问题上比内点算法和遗传算法表现更好。

Conclusion: AutoOpt框架实现了从图像到优化问题求解的端到端自动化，在复杂优化问题上表现出优越性能，为自动化优化求解提供了有效解决方案。

Abstract: This study presents AutoOpt-11k, a unique image dataset of over 11,000
handwritten and printed mathematical optimization models corresponding to
single-objective, multi-objective, multi-level, and stochastic optimization
problems exhibiting various types of complexities such as non-linearity,
non-convexity, non-differentiability, discontinuity, and high-dimensionality.
The labels consist of the LaTeX representation for all the images and modeling
language representation for a subset of images. The dataset is created by 25
experts following ethical data creation guidelines and verified in two-phases
to avoid errors. Further, we develop AutoOpt framework, a machine learning
based automated approach for solving optimization problems, where the user just
needs to provide an image of the formulation and AutoOpt solves it efficiently
without any further human intervention. AutoOpt framework consists of three
Modules: (i) M1 (Image_to_Text)- a deep learning model performs the
Mathematical Expression Recognition (MER) task to generate the LaTeX code
corresponding to the optimization formulation in image; (ii) M2 (Text_to_Text)-
a small-scale fine-tuned LLM generates the PYOMO script (optimization modeling
language) from LaTeX code; (iii) M3 (Optimization)- a Bilevel Optimization
based Decomposition (BOBD) method solves the optimization formulation described
in the PYOMO script. We use AutoOpt-11k dataset for training and testing of
deep learning models employed in AutoOpt. The deep learning model for MER task
(M1) outperforms ChatGPT, Gemini and Nougat on BLEU score metric. BOBD method
(M3), which is a hybrid approach, yields better results on complex test
problems compared to common approaches, like interior-point algorithm and
genetic algorithm.

</details>


### [18] [Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning](https://arxiv.org/abs/2510.21560)
*Yuxuan Yang,Hussein Sibai*

Main category: cs.AI

TL;DR: 该论文提出了一种使用隐式对比学习（ICL）训练神经控制屏障函数（CBF）的方法，通过专家演示数据来学习安全约束，避免需要明确指定失败状态集的困难。


<details>
  <summary>Details</summary>
Motivation: 在关键领域运行的自主系统中，安全是基本要求。传统CBF设计需要明确指定失败状态集，但在许多实际场景中（如自动驾驶中的跟车问题），失败状态集难以形式化定义，而生成专家演示数据相对容易。

Method: 使用ICL训练约束函数来分类系统状态为安全（属于与未指定失败集不相交的受控前向不变集）和不安全（属于该集合的补集），然后用该函数标注新的模拟轨迹来训练神经CBF。

Result: 在四个不同环境中进行实证评估，表明该方法优于现有基线方法，并且与使用真实安全标签训练的神经CBF达到相当的性能。

Conclusion: 通过ICL从专家演示中学习安全约束是一种有效的神经CBF训练方法，能够在不明确指定失败状态集的情况下实现系统安全控制。

Abstract: Safety is a fundamental requirement for autonomous systems operating in
critical domains. Control barrier functions (CBFs) have been used to design
safety filters that minimally alter nominal controls for such systems to
maintain their safety. Learning neural CBFs has been proposed as a data-driven
alternative for their computationally expensive optimization-based synthesis.
However, it is often the case that the failure set of states that should be
avoided is non-obvious or hard to specify formally, e.g., tailgating in
autonomous driving, while a set of expert demonstrations that achieve the task
and avoid the failure set is easier to generate. We use ICL to train a
constraint function that classifies the states of the system under
consideration to safe, i.e., belong to a controlled forward invariant set that
is disjoint from the unspecified failure set, and unsafe ones, i.e., belong to
the complement of that set. We then use that function to label a new set of
simulated trajectories to train our neural CBF. We empirically evaluate our
approach in four different environments, demonstrating that it outperforms
existing baselines and achieves comparable performance to a neural CBF trained
with the same data but annotated with ground-truth safety labels.

</details>


### [19] [Huxley-Gödel Machine: Human-Level Coding Agent Development by an Approximation of the Optimal Self-Improving Machine](https://arxiv.org/abs/2510.21614)
*Wenyi Wang,Piotr Piękos,Li Nanbo,Firas Laakom,Yimeng Chen,Mateusz Ostaszewski,Mingchen Zhuge,Jürgen Schmidhuber*

Main category: cs.AI

TL;DR: 本文提出了Huxley-Gödel Machine (HGM)方法，通过引入CMP指标来评估智能体的自我改进潜力，解决了传统基于编码基准性能的自我改进方法中存在的Metaproductivity-Performance Mismatch问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于编码基准性能的自我改进方法假设更高的基准性能意味着更好的后续自我改进潜力，但作者发现这种假设存在不匹配问题，即智能体的自我改进潜力与其编码基准性能之间存在差异。

Method: 提出CMP指标来聚合智能体后代的基准性能作为其自我改进潜力的指示器，并基于此构建Huxley-Gödel Machine (HGM)方法，通过估计CMP来指导自我修改树的搜索。

Result: 在SWE-bench Verified和Polyglot数据集上，HGM优于先前的自我改进编码智能体开发方法，同时使用更少的实际时间。优化后的智能体在SWE-bench Lite上达到人类水平性能，匹配人类工程化编码智能体的最佳官方检查结果。

Conclusion: HGM方法通过正确评估智能体的自我改进潜力，实现了更有效的自我改进过程，并展示了强大的跨数据集和大语言模型的迁移能力。

Abstract: Recent studies operationalize self-improvement through coding agents that
edit their own codebases. They grow a tree of self-modifications through
expansion strategies that favor higher software engineering benchmark
performance, assuming that this implies more promising subsequent
self-modifications. However, we identify a mismatch between the agent's
self-improvement potential (metaproductivity) and its coding benchmark
performance, namely the Metaproductivity-Performance Mismatch. Inspired by
Huxley's concept of clade, we propose a metric ($\mathrm{CMP}$) that aggregates
the benchmark performances of the descendants of an agent as an indicator of
its potential for self-improvement. We show that, in our self-improving coding
agent development setting, access to the true $\mathrm{CMP}$ is sufficient to
simulate how the G\"odel Machine would behave under certain assumptions. We
introduce the Huxley-G\"odel Machine (HGM), which, by estimating $\mathrm{CMP}$
and using it as guidance, searches the tree of self-modifications. On SWE-bench
Verified and Polyglot, HGM outperforms prior self-improving coding agent
development methods while using less wall-clock time. Last but not least, HGM
demonstrates strong transfer to other coding datasets and large language
models. The agent optimized by HGM on SWE-bench Verified with GPT-5-mini and
evaluated on SWE-bench Lite with GPT-5 achieves human-level performance,
matching the best officially checked results of human-engineered coding agents.
Our code is available at https://github.com/metauto-ai/HGM.

</details>


### [20] [DeepAgent: A General Reasoning Agent with Scalable Toolsets](https://arxiv.org/abs/2510.21618)
*Xiaoxi Li,Wenxiang Jiao,Jiarui Jin,Guanting Dong,Jiajie Jin,Yinuo Wang,Hao Wang,Yutao Zhu,Ji-Rong Wen,Yuan Lu,Zhicheng Dou*

Main category: cs.AI

TL;DR: DeepAgent是一个端到端的深度推理智能体，通过自主思考、工具发现和行动执行在单一连贯推理过程中完成任务。它引入自主记忆折叠机制压缩交互历史，并使用ToolPO强化学习策略高效学习通用工具使用。


<details>
  <summary>Details</summary>
Motivation: 现有智能体框架通常遵循预定义工作流，限制了自主性和全局任务完成能力。现实世界任务需要外部工具和长时程交互，但现有方法面临上下文长度爆炸和交互历史累积的挑战。

Method: 提出DeepAgent框架，包含自主记忆折叠机制（将过去交互压缩为结构化记忆）和ToolPO强化学习策略（利用LLM模拟API并通过工具调用优势归因分配细粒度信用）。

Result: 在8个基准测试（包括通用工具使用任务和下游应用）上，DeepAgent在标记工具和开放集工具检索场景中均优于基线方法。

Conclusion: 这项工作朝着为现实世界应用构建更通用和有能力智能体迈出了一步。

Abstract: Large reasoning models have demonstrated strong problem-solving abilities,
yet real-world tasks often require external tools and long-horizon
interactions. Existing agent frameworks typically follow predefined workflows,
which limit autonomous and global task completion. In this paper, we introduce
DeepAgent, an end-to-end deep reasoning agent that performs autonomous
thinking, tool discovery, and action execution within a single, coherent
reasoning process. To address the challenges of long-horizon interactions,
particularly the context length explosion from multiple tool calls and the
accumulation of interaction history, we introduce an autonomous memory folding
mechanism that compresses past interactions into structured episodic, working,
and tool memories, reducing error accumulation while preserving critical
information. To teach general-purpose tool use efficiently and stably, we
develop an end-to-end reinforcement learning strategy, namely ToolPO, that
leverages LLM-simulated APIs and applies tool-call advantage attribution to
assign fine-grained credit to the tool invocation tokens. Extensive experiments
on eight benchmarks, including general tool-use tasks (ToolBench, API-Bank,
TMDB, Spotify, ToolHop) and downstream applications (ALFWorld, WebShop, GAIA,
HLE), demonstrate that DeepAgent consistently outperforms baselines across both
labeled-tool and open-set tool retrieval scenarios. This work takes a step
toward more general and capable agents for real-world applications. The code
and demo are available at https://github.com/RUC-NLPIR/DeepAgent.

</details>


### [21] [CMOMgen: Complex Multi-Ontology Alignment via Pattern-Guided In-Context Learning](https://arxiv.org/abs/2510.21656)
*Marta Contreiras Silva,Daniel Faria,Catia Pesquita*

Main category: cs.AI

TL;DR: CMOMgen是首个端到端的复杂多本体匹配策略，能够生成完整且语义合理的映射，无需对目标本体或实体数量设限。该方法使用检索增强生成技术选择相关类别并过滤匹配参考映射作为示例，在三个生物医学任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 构建全面知识图谱需要使用多个本体来完全将数据置于领域上下文中。简单成对等价映射无法提供相关但不相交本体的完整语义集成，需要复杂多本体匹配来建立更细微的等价关系和本体层次结构上的来源信息。

Method: CMOMgen采用检索增强生成策略，选择相关类别来组成映射，并过滤匹配参考映射作为示例以增强上下文学习。该方法不限制目标本体或实体的数量。

Result: 在三个生物医学任务中，CMOMgen在类别选择方面优于基线方法，F1分数至少达到63%，在两个任务中优于所有基线和消融版本，在第三个任务中排名第二。对非参考映射的手动评估显示46%的映射获得最高分。

Conclusion: CMOMgen能够构建语义合理的映射，在复杂多本体匹配任务中表现出色，证明了专用策略的有效性。

Abstract: Constructing comprehensive knowledge graphs requires the use of multiple
ontologies in order to fully contextualize data into a domain. Ontology
matching finds equivalences between concepts interconnecting ontologies and
creating a cohesive semantic layer. While the simple pairwise state of the art
is well established, simple equivalence mappings cannot provide full semantic
integration of related but disjoint ontologies. Complex multi-ontology matching
(CMOM) aligns one source entity to composite logical expressions of multiple
target entities, establishing more nuanced equivalences and provenance along
the ontological hierarchy.
  We present CMOMgen, the first end-to-end CMOM strategy that generates
complete and semantically sound mappings, without establishing any restrictions
on the number of target ontologies or entities. Retrieval-Augmented Generation
selects relevant classes to compose the mapping and filters matching reference
mappings to serve as examples, enhancing In-Context Learning. The strategy was
evaluated in three biomedical tasks with partial reference alignments. CMOMgen
outperforms baselines in class selection, demonstrating the impact of having a
dedicated strategy. Our strategy also achieves a minimum of 63% in F1-score,
outperforming all baselines and ablated versions in two out of three tasks and
placing second in the third. Furthermore, a manual evaluation of non-reference
mappings showed that 46% of the mappings achieve the maximum score, further
substantiating its ability to construct semantically sound mappings.

</details>


### [22] [A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection](https://arxiv.org/abs/2510.21679)
*Gaku Morio,Harri Rowlands,Dominik Stammbach,Christopher D. Manning,Peter Henderson*

Main category: cs.AI

TL;DR: 该研究提出了一个专家标注的视频广告数据集，用于分析能源公司公关活动中的框架类型，特别关注绿色创新等环境信息的识别，为多模态分析提供基准。


<details>
  <summary>Details</summary>
Motivation: 企业公关活动存在言行不一的问题，如石油天然气公司的"漂绿"行为。理解大规模框架及其变化有助于分析公关活动的目标和性质。

Method: 构建专家标注的视频广告数据集，包含13种框架类型，覆盖50多家公司和20个国家，专门用于评估视觉语言模型。

Result: 基线实验显示GPT-4.1检测环境信息的F1分数为79%，而最佳模型在识别绿色创新框架方面仅达到46% F1分数。

Conclusion: 该数据集为能源领域战略沟通的多模态分析研究做出贡献，同时揭示了视觉语言模型在处理隐含框架、不同长度视频和隐含文化背景等方面的挑战。

Abstract: Companies spend large amounts of money on public relations campaigns to
project a positive brand image. However, sometimes there is a mismatch between
what they say and what they do. Oil & gas companies, for example, are accused
of "greenwashing" with imagery of climate-friendly initiatives. Understanding
the framing, and changes in framing, at scale can help better understand the
goals and nature of public relations campaigns. To address this, we introduce a
benchmark dataset of expert-annotated video ads obtained from Facebook and
YouTube. The dataset provides annotations for 13 framing types for more than 50
companies or advocacy groups across 20 countries. Our dataset is especially
designed for the evaluation of vision-language models (VLMs), distinguishing it
from past text-only framing datasets. Baseline experiments show some promising
results, while leaving room for improvement for future work: GPT-4.1 can detect
environmental messages with 79% F1 score, while our best model only achieves
46% F1 score on identifying framing around green innovation. We also identify
challenges that VLMs must address, such as implicit framing, handling videos of
various lengths, or implicit cultural backgrounds. Our dataset contributes to
research in multimodal analysis of strategic communication in the energy
sector.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [23] [HIKMA: Human-Inspired Knowledge by Machine Agents through a Multi-Agent Framework for Semi-Autonomous Scientific Conferences](https://arxiv.org/abs/2510.21370)
*Zain Ul Abideen Tariq,Mahmood Al-Zubaidi,Uzair Shah,Marco Agus,Mowafa Househ*

Main category: cs.MA

TL;DR: HIKMA半自主会议是首个通过将人工智能端到端整合到学术出版和展示流程中重新构想学术交流的实验。该框架展示了AI如何支持而非取代传统学术实践，同时保持知识产权保护、透明度和完整性。


<details>
  <summary>Details</summary>
Motivation: 重新构想学术交流，探索人工智能在学术出版和展示流程中的端到端集成，研究AI如何支持传统学术实践并解决AI作者身份、问责制等问题。

Method: 设计并实施了HIKMA框架，包括AI数据集策划、基于AI的手稿生成、AI辅助同行评审、AI驱动修订、AI会议展示和AI档案传播，结合语言模型、结构化研究流程和领域保障措施。

Result: 会议作为测试平台和概念验证，为AI赋能学术研究提供了机会和挑战的见解，同时探讨了AI作者身份、问责制以及人机协作在研究中的作用。

Conclusion: HIKMA展示了AI可以支持传统学术实践而不取代它们，同时保持知识产权保护、透明度和完整性，为人机协作在学术研究中的未来发展提供了重要参考。

Abstract: HIKMA Semi-Autonomous Conference is the first experiment in reimagining
scholarly communication through an end-to-end integration of artificial
intelligence into the academic publishing and presentation pipeline. This paper
presents the design, implementation, and evaluation of the HIKMA framework,
which includes AI dataset curation, AI-based manuscript generation, AI-assisted
peer review, AI-driven revision, AI conference presentation, and AI archival
dissemination. By combining language models, structured research workflows, and
domain safeguards, HIKMA shows how AI can support - not replace traditional
scholarly practices while maintaining intellectual property protection,
transparency, and integrity. The conference functions as a testbed and proof of
concept, providing insights into the opportunities and challenges of AI-enabled
scholarship. It also examines questions about AI authorship, accountability,
and the role of human-AI collaboration in research.

</details>


### [24] [ColorEcosystem: Powering Personalized, Standardized, and Trustworthy Agentic Service in massive-agent Ecosystem](https://arxiv.org/abs/2510.21566)
*Fangwen Wu,Zheng Wu,Jihong Wang,Yunku Chen,Ruiguang Pei,Heyuan Huang,Xin Liao,Xingyu Lou,Huarong Deng,Zhihui Fu,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang,Jun Wang*

Main category: cs.MA

TL;DR: ColorEcosystem是一个面向大规模智能体生态系统的蓝图，旨在解决个性化体验缺失、标准化不足和不可信行为等问题，通过智能体载体、智能体商店和智能体审计三个核心组件实现个性化、标准化和可信的智能体服务。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型智能体的快速发展，智能体服务管理从单智能体系统发展到多智能体系统，再到大规模智能体生态系统。当前大规模智能体生态系统面临服务体验非个性化、缺乏标准化和不可信行为等日益严峻的挑战。

Method: ColorEcosystem包含三个关键组件：智能体载体利用用户特定数据创建数字孪生，提供个性化服务体验；智能体商店作为集中化、标准化的平台管理多样化智能体服务；智能体审计基于对开发者和用户活动的监督，确保服务提供者和用户的完整性和可信度。

Result: 通过分析挑战、过渡形式和实践考量，ColorEcosystem有望为大规模智能体生态系统提供个性化、标准化和可信的智能体服务。同时，部分功能已实现并在GitHub上开源。

Conclusion: ColorEcosystem为解决大规模智能体生态系统中的关键问题提供了一个可行的蓝图，通过其三个核心组件能够有效实现个性化、标准化和可信的智能体服务管理。

Abstract: With the rapid development of (multimodal) large language model-based agents,
the landscape of agentic service management has evolved from single-agent
systems to multi-agent systems, and now to massive-agent ecosystems. Current
massive-agent ecosystems face growing challenges, including impersonal service
experiences, a lack of standardization, and untrustworthy behavior. To address
these issues, we propose ColorEcosystem, a novel blueprint designed to enable
personalized, standardized, and trustworthy agentic service at scale.
Concretely, ColorEcosystem consists of three key components: agent carrier,
agent store, and agent audit. The agent carrier provides personalized service
experiences by utilizing user-specific data and creating a digital twin, while
the agent store serves as a centralized, standardized platform for managing
diverse agentic services. The agent audit, based on the supervision of
developer and user activities, ensures the integrity and credibility of both
service providers and users. Through the analysis of challenges, transitional
forms, and practical considerations, the ColorEcosystem is poised to power
personalized, standardized, and trustworthy agentic service across
massive-agent ecosystems. Meanwhile, we have also implemented part of
ColorEcosystem's functionality, and the relevant code is open-sourced at
https://github.com/opas-lab/color-ecosystem.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [25] [Lincoln AI Computing Survey (LAICS) and Trends](https://arxiv.org/abs/2510.20931)
*Albert Reuther,Peter Michaleas,Michael Jones,Vijay Gadepally,Jeremy Kepner*

Main category: cs.DC

TL;DR: 本文是对过去七年AI加速器和处理器调查的更新，重点关注生成式AI模型训练和推理的计算系统，收集并总结了当前商用加速器的峰值性能和功耗数据。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI模型受到广泛关注，对训练和推理计算系统的需求增加，需要更新AI加速器调查以反映最新发展。

Method: 延续传统方法，收集公开宣布的商用加速器峰值性能和功耗数据，在散点图上绘制并分析趋势，按市场细分进行分组展示，并对新增加速器进行描述和架构分类。

Result: 提供了当前商用AI加速器的性能-功耗散点图分析，识别了市场细分趋势，并对新增加速器进行了系统分类和描述。

Conclusion: 这项多年度调查持续跟踪AI计算系统发展，为理解生成式AI时代计算硬件演进提供了有价值的参考框架。

Abstract: In the past year, generative AI (GenAI) models have received a tremendous
amount of attention, which in turn has increased attention to computing systems
for training and inference for GenAI. Hence, an update to this survey is due.
This paper is an update of the survey of AI accelerators and processors from
past seven years, which is called the Lincoln AI Computing Survey -- LAICS
(pronounced "lace"). This multi-year survey collects and summarizes the current
commercial accelerators that have been publicly announced with peak performance
and peak power consumption numbers. In the same tradition of past papers of
this survey, the performance and power values are plotted on a scatter graph,
and a number of dimensions and observations from the trends on this plot are
again discussed and analyzed. Market segments are highlighted on the scatter
plot, and zoomed plots of each segment are also included. A brief description
of each of the new accelerators that have been added in the survey this year is
included, and this update features a new categorization of computing
architectures that implement each of the accelerators.

</details>


### [26] [Towards Straggler-Resilient Split Federated Learning: An Unbalanced Update Approach](https://arxiv.org/abs/2510.21155)
*Dandan Liang,Jianing Zhang,Evan Chen,Zhe Li,Rui Li,Haibo Yang*

Main category: cs.DC

TL;DR: MU-SplitFed提出了一种抗慢节点影响的Split Federated Learning算法，通过不平衡更新机制解耦训练进度与慢节点延迟，在零阶优化中实现线性加速。


<details>
  <summary>Details</summary>
Motivation: Split Federated Learning结合了联邦学习的并行性和分割学习的计算卸载优势，但面临分布式系统中常见的慢节点问题。由于分割服务器和客户端之间的依赖关系，服务器模型更新需要等待客户端激活，这种同步要求导致显著的时间延迟，使慢节点成为系统可扩展性和效率的关键瓶颈。

Method: 提出MU-SplitFed算法，通过不平衡更新机制使服务器在每个客户端轮次中执行τ次本地更新，从而解耦训练进度与慢节点延迟。该方法在零阶优化框架下运行，通过自适应调整τ值来有效缓解慢节点影响。

Result: 对于非凸目标函数，MU-SplitFed实现了O(√(d/(τT)))的收敛速率，在通信轮次上实现了τ倍的线性加速。实验表明，在存在慢节点的情况下，MU-SplitFed始终优于基线方法，并通过自适应调整τ有效减轻了慢节点的影响。

Conclusion: MU-SplitFed通过简单而有效的不平衡更新机制成功解决了Split Federated Learning中的慢节点问题，显著提高了系统的可扩展性和训练效率，为分布式边缘学习提供了实用的解决方案。

Abstract: Split Federated Learning (SFL) enables scalable training on edge devices by
combining the parallelism of Federated Learning (FL) with the computational
offloading of Split Learning (SL). Despite its great success, SFL suffers
significantly from the well-known straggler issue in distributed learning
systems. This problem is exacerbated by the dependency between Split Server and
clients: the Split Server side model update relies on receiving activations
from clients. Such synchronization requirement introduces significant time
latency, making straggler a critical bottleneck to the scalability and
efficiency of the system. To mitigate this problem, we propose MU-SplitFed, a
straggler-resilient SFL algorithm in zeroth-order optimization that decouples
training progress from straggler delays via a simple yet effective unbalanced
update mechanism.
  By enabling the server to perform $\tau$ local updates per client round,
MU-SplitFed achieves a convergence rate of $O(\sqrt{d/(\tau T)})$ for
non-convex objectives, demonstrating a linear speedup of $\tau$ in
communication rounds. Experiments demonstrate that MU-SplitFed consistently
outperforms baseline methods with the presence of stragglers and effectively
mitigates their impact through adaptive tuning of $\tau$. The code for this
project is available at https://github.com/Johnny-Zip/MU-SplitFed.

</details>


### [27] [From SLA to vendor-neutral metrics: An intelligent knowledge-based approach for multi-cloud SLA-based broker](https://arxiv.org/abs/2510.21173)
*Víctor Rampérez,Javier Soriano,David Lizcano,Shadi Aljawarneh,Juan A. Lara*

Main category: cs.DC

TL;DR: 提出一个智能知识系统，将高级SLA自动转换为供应商中立指标，解决多云环境中的供应商锁定问题，并通过IaaS和PaaS用例验证了方案有效性。


<details>
  <summary>Details</summary>
Motivation: 当前云提供商将确保服务水平协议(SLA)合规的责任推给消费者，但消费者缺乏专业知识。不同云提供商使用不同的低层指标，导致SLA策略绑定特定提供商，阻碍多云环境的优势发挥。

Method: 1. 提出智能知识系统，自动将高级SLA转换为供应商中立指标条件；2. 定义供应商中立指标集并说明如何在各云提供商中测量；3. 在由主流云提供商组成的多云环境中进行IaaS和PaaS用例验证。

Result: 评估表明，通过两种解决方案的互补性，云消费者可以在多个应用领域中自动透明地利用多云环境，这一结论得到了研究中咨询的云专家的认可。

Conclusion: 该解决方案成功解决了多云环境中的SLA翻译问题，使消费者能够跨越不同云提供商自动实施SLA合规策略，打破了供应商锁定限制。

Abstract: Cloud computing has been consolidated as a support for the vast majority of
current and emerging technologies. However, there are some barriers that
prevent the exploitation of the full potential of this technology. First, the
major cloud providers currently put the onus of implementing the mechanisms
that ensure compliance with the desired service levels on cloud consumers.
However, consumers do not have the required expertise. Since each cloud
provider exports a different set of low-level metrics, the strategies defined
to ensure compliance with the established service-level agreement (SLA) are
bound to a particular cloud provider. This fosters provider lock-in and
prevents consumers from benefiting from the advantages of multi-cloud
environments. This paper presents a solution to the problem of automatically
translating SLAs into objectives expressed as metrics that can be measured
across multiple cloud providers. First, we propose an intelligent
knowledge-based system capable of automatically translating high-level SLAs
defined by cloud consumers into a set of conditions expressed as vendor-neutral
metrics, providing feedback to cloud consumers (intelligent tutoring system).
Secondly, we present the set of vendor-neutral metrics and explain how they can
be measured for the different cloud providers. Finally, we report a validation
based on two use cases (IaaS and PaaS) in a multi-cloud environment formed by
leading cloud providers. This evaluation has demonstrated that, thanks to the
complementarity of the two solutions, cloud consumers can automatically and
transparently exploit the multi-cloud in many application domains, as endorsed
by the cloud experts consulted in the course of this study.

</details>


### [28] [Arbitration-Free Consistency is Available (and Vice Versa)](https://arxiv.org/abs/2510.21304)
*Hagit Attiya,Constantin Enea,Enrique Román-Calvo*

Main category: cs.DC

TL;DR: 该论文提出了一个通用的语义框架，将操作语义和一致性模型结合在存储规范中，并证明了仲裁自由一致性定理，揭示了仲裁自由是区分无协调一致性和需要同步行为的基本属性。


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统中可用性和一致性之间存在基本张力，现有理论只覆盖了极端情况，缺乏对对象语义和一致性模型组合的精确解释，需要发展一个通用框架来系统分析各种存储规范。

Method: 开发了一个通用的语义框架，将操作语义和一致性模型结合在存储规范中，涵盖广泛的对象类型和一致性模型，并在该框架内证明仲裁自由一致性定理。

Result: 证明了仲裁自由一致性定理：对象规范在一致性模型下允许可用实现的充要条件是该规范是仲裁自由的，即不需要总仲裁顺序来解决可见性或读取依赖关系。

Conclusion: 仲裁自由是区分无协调一致性和需要同步行为的基本属性，该定理统一并推广了先前的结果，为分布式存储系统设计提供了理论基础。

Abstract: The fundamental tension between \emph{availability} and \emph{consistency}
shapes the design of distributed storage systems. Classical results capture
extreme points of this trade-off: the CAP theorem shows that strong models like
linearizability preclude availability under partitions, while weak models like
causal consistency remain implementable without coordination. These theorems
apply to simple read-write interfaces, leaving open a precise explanation of
the combinations of object semantics and consistency models that admit
available implementations.
  This paper develops a general semantic framework in which storage
specifications combine operation semantics and consistency models. The
framework encompasses a broad range of objects (key-value stores, counters,
sets, CRDTs, and transactional databases) and consistency models (from causal
consistency and sequential consistency to snapshot isolation and transactional
and non-transactional SQL).
  Within this framework, we prove the \emph{Arbitration-Free Consistency} (AFC)
theorem, showing that an object specification within a consistency model admits
an available implementation if and only if it is \emph{arbitration-free}, that
is, it does not require a total arbitration order to resolve visibility or read
dependencies.
  The AFC theorem unifies and generalizes previous results, revealing
arbitration-freedom as the fundamental property that delineates
coordination-free consistency from inherently synchronized behavior.

</details>


### [29] [LIDC: A Location Independent Multi-Cluster Computing Framework for Data Intensive Science](https://arxiv.org/abs/2510.21373)
*Sankalpa Timilsina,Susmit Shannigrahi*

Main category: cs.DC

TL;DR: 本文提出了一种基于语义名称的去中心化控制平面，用于在地理分布的Kubernetes集群上部署计算任务，解决了集中式控制器在多组织协作中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于Kubernetes的集中式计算任务部署方法在多组织协作环境中存在不足，且工作流通常需要针对单一平台的手动配置，无法适应基础设施的动态变化。

Method: 使用语义名称来匹配计算请求与Kubernetes服务端点，实现去中心化的控制平面，使计算任务部署与位置无关。

Result: 该方法使计算作业的部署独立于位置，允许任何具有足够资源的集群执行计算；同时支持动态计算部署，无需预先了解集群位置或预定义配置。

Conclusion: 基于语义名称的去中心化控制平面为地理分布计算集群提供了灵活、动态的计算任务部署解决方案。

Abstract: Scientific communities are increasingly using geographically distributed
computing platforms. The current methods of compute placement predominantly use
logically centralized controllers such as Kubernetes (K8s) to match tasks to
available resources. However, this centralized approach is unsuitable in
multi-organizational collaborations. Furthermore, workflows often need to use
manual configurations tailored for a single platform and cannot adapt to
dynamic changes across infrastructure. Our work introduces a decentralized
control plane for placing computations on geographically dispersed compute
clusters using semantic names. We assign semantic names to computations to
match requests with named Kubernetes (K8s) service endpoints. We show that this
approach provides multiple benefits. First, it allows placement of
computational jobs to be independent of location, enabling any cluster with
sufficient resources to execute the computation. Second, it facilitates dynamic
compute placement without requiring prior knowledge of cluster locations or
predefined configurations.

</details>


### [30] [On Reduction and Synthesis of Petri's Cycloids](https://arxiv.org/abs/2510.21493)
*Rüdiger Valk,Daniel Moldt*

Main category: cs.DC

TL;DR: 本文研究循环体（cycloids）这种特殊Petri网的结构，定义其归约系统并证明不可约循环体的性质，提出从Petri网结构合成循环体参数的方法，用于高效的循环体同构判定。


<details>
  <summary>Details</summary>
Motivation: 循环体是Petri一般系统理论的基础，用于建模动作和事件过程。为进一步研究其结构特性，需要建立归约系统和参数合成方法。

Method: 定义循环体的归约系统（类似重写系统），证明不可约循环体的性质，推导从Petri网结构合成循环体参数的方法。

Result: 开发了高效的循环体同构判定程序，实现了从网结构到循环体参数的合成。

Conclusion: 通过归约系统和参数合成方法，深化了对循环体结构的理解，并为循环体同构判定提供了有效工具。

Abstract: Cycloids are particular Petri nets for modelling processes of actions and
events, belonging to the fundaments of Petri's general systems theory. Defined
by four parameters they provide an algebraic formalism to describe strongly
synchronized sequential processes. To further investigate their structure,
reduction systems of cycloids are defined in the style of rewriting systems and
properties of irreducible cycloids are proved. In particular the synthesis of
cycloid parameters from their Petri net structure is derived, leading to an
efficient method for a decision procedure for cycloid isomorphism.

</details>


### [31] [Distributed $(Δ+1)$-Coloring in Graphs of Bounded Neighborhood Independence](https://arxiv.org/abs/2510.21549)
*Marc Fuchs,Fabian Kuhn*

Main category: cs.DC

TL;DR: 本文改进了在邻域独立数为θ的图中(Δ+1)-染色的确定性分布式算法复杂度，从2^O(√logΔ)提升到(θ·logΔ)^O(loglogΔ/logloglogΔ)轮，当θ为Δ的多对数时达到准多对数时间。


<details>
  <summary>Details</summary>
Motivation: 分布式着色问题是分布式图算法中的核心问题之一，其中(Δ+1)-顶点着色的确定性复杂度是该领域最重要的开放问题之一。本文旨在在邻域独立性较小的特殊图类中改进确定性复杂度。

Method: 针对邻域独立性θ为常数的图（如线图），改进现有的(Δ+1)-着色算法，利用图的邻域独立性特性来优化算法复杂度。

Result: 在邻域独立性为θ的图中，(Δ+1)-着色可以在(θ·logΔ)^O(loglogΔ/logloglogΔ)+O(log* n)轮内完成，当θ为Δ的多对数时达到准多对数时间。

Conclusion: 本文显著改进了在邻域独立性较小图中的(Δ+1)-着色确定性复杂度，同时指出超图边着色的现有方法在秩≥3时失效。

Abstract: The distributed coloring problem is arguably one of the key problems studied
in the area of distributed graph algorithms. The most standard variant of the
problem asks for a proper vertex coloring of a graph with $\Delta+1$ colors,
where $\Delta$ is the maximum degree of the graph. Despite an immense amount of
work on distributed coloring problems in the distributed setting, determining
the deterministic complexity of $(\Delta+1)$-coloring in the standard message
passing model remains one of the most important open questions of the area. In
this paper, we aim to improve our understanding of the deterministic complexity
of $(\Delta+1)$-coloring as a function of $\Delta$ in a special family of
graphs for which significantly faster algorithms are already known. The
neighborhood independence $\theta$ of a graph is the maximum number of pairwise
non-adjacent neighbors of some node of the graph. In general, in graphs of
neighborhood independence $\theta=O(1)$ (e.g., line graphs), it is known that
$(\Delta+1)$-coloring can be solved in $2^{O(\sqrt{\log\Delta})}+O(\log^* n)$
rounds. In the present paper, we significantly improve this result, and we show
that in graphs of neighborhood independence $\theta$, a $(\Delta+1)$-coloring
can be computed in $(\theta\cdot\log\Delta)^{O(\log\log\Delta /
\log\log\log\Delta)}+O(\log^* n)$ rounds and thus in quasipolylogarithmic time
in $\Delta$ as long as $\theta$ is at most polylogarithmic in $\Delta$. We also
show that the known approach that leads to a polylogarithmic in $\Delta$
algorithm for $(2\Delta-1)$-edge coloring already fails for edge colorings of
hypergraphs of rank at least $3$.

</details>
