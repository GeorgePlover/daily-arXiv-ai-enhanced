{"id": "2511.04685", "categories": ["cs.AI", "math.OC", "90-04", "F.2.2"], "pdf": "https://arxiv.org/pdf/2511.04685", "abs": "https://arxiv.org/abs/2511.04685", "authors": ["Daniela Guericke", "Rolf van der Hulst", "Asal Karimpour", "Ieke Schrader", "Matthias Walter"], "title": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024", "comment": "23 pages, 2 figures, 10 tables", "summary": "We report about the algorithm, implementation and results submitted to the\nIntegrated Healthcare Timetabling Competition 2024 by Team Twente, which scored\nthird in the competition. Our approach combines mixed-integer programming,\nconstraint programming and simulated annealing in a 3-phase solution approach\nbased on decomposition into subproblems. Next to describing our approach and\ndescribing our design decisions, we share our insights and, for the first time,\nlower bounds on the optimal solution values for the benchmark instances. We\nfinally highlight open problems for which we think that addressing them could\nimprove our approach even further."}
{"id": "2511.04855", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04855", "abs": "https://arxiv.org/abs/2511.04855", "authors": ["Vojtech Franc", "Jakub Paplham"], "title": "Epistemic Reject Option Prediction", "comment": null, "summary": "In high-stakes applications, predictive models must not only produce accurate\npredictions but also quantify and communicate their uncertainty. Reject-option\nprediction addresses this by allowing the model to abstain when prediction\nuncertainty is high. Traditional reject-option approaches focus solely on\naleatoric uncertainty, an assumption valid only when large training data makes\nthe epistemic uncertainty negligible. However, in many practical scenarios,\nlimited data makes this assumption unrealistic. This paper introduces the\nepistemic reject-option predictor, which abstains in regions of high epistemic\nuncertainty caused by insufficient data. Building on Bayesian learning, we\nredefine the optimal predictor as the one that minimizes expected regret -- the\nperformance gap between the learned model and the Bayes-optimal predictor with\nfull knowledge of the data distribution. The model abstains when the regret for\na given input exceeds a specified rejection cost. To our knowledge, this is the\nfirst principled framework that enables learning predictors capable of\nidentifying inputs for which the training data is insufficient to make reliable\ndecisions."}
{"id": "2511.04880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04880", "abs": "https://arxiv.org/abs/2511.04880", "authors": ["Yu Bai", "Yukai Miao", "Dawei Wang", "Li Chen", "Fei Long", "Rundi Zhai", "Dan Li", "Yanyu Ren", "Tianfeng Liu", "Hongtao Xie", "Ce Yang", "Xuhui Cai"], "title": "DMA: Online RAG Alignment with Human Feedback", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems often rely on static retrieval,\nlimiting adaptation to evolving intent and content drift. We introduce Dynamic\nMemory Alignment (DMA), an online learning framework that systematically\nincorporates multi-granularity human feedback to align ranking in interactive\nsettings. DMA organizes document-, list-, and response-level signals into a\ncoherent learning pipeline: supervised training for pointwise and listwise\nrankers, policy optimization driven by response-level preferences, and\nknowledge distillation into a lightweight scorer for low-latency serving.\nThroughout this paper, memory refers to the model's working memory, which is\nthe entire context visible to the LLM for In-Context Learning.\n  We adopt a dual-track evaluation protocol mirroring deployment: (i)\nlarge-scale online A/B ablations to isolate the utility of each feedback\nsource, and (ii) few-shot offline tests on knowledge-intensive benchmarks.\nOnline, a multi-month industrial deployment further shows substantial\nimprovements in human engagement. Offline, DMA preserves competitive\nfoundational retrieval while yielding notable gains on conversational QA\n(TriviaQA, HotpotQA). Taken together, these results position DMA as a\nprincipled approach to feedback-driven, real-time adaptation in RAG without\nsacrificing baseline capability."}
{"id": "2511.04898", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04898", "abs": "https://arxiv.org/abs/2511.04898", "authors": ["Yule Wen", "Yixin Ye", "Yanzhe Zhang", "Diyi Yang", "Hao Zhu"], "title": "Real-Time Reasoning Agents in Evolving Environments", "comment": "30 pages", "summary": "Agents in the real world must make not only logical but also timely\njudgments. This requires continuous awareness of the dynamic environment:\nhazards emerge, opportunities arise, and other agents act, while the agent's\nreasoning is still unfolding. Despite advances in language model reasoning,\nexisting approaches fail to account for this dynamic nature. We introduce\nreal-time reasoning as a new problem formulation for agents in evolving\nenvironments and build Real-Time Reasoning Gym to demonstrate it. We study two\nparadigms for deploying language models in agents: (1) reactive agents, which\nemploy language models with bounded reasoning computation for rapid responses,\nand (2) planning agents, which allow extended reasoning computation for complex\nproblems. Our experiments show that even state-of-the-art models struggle with\nmaking logical and timely judgments in either paradigm. To address this\nlimitation, we propose AgileThinker, which simultaneously engages both\nreasoning paradigms. AgileThinker consistently outperforms agents engaging only\none reasoning paradigm as the task difficulty and time pressure rise,\neffectively balancing reasoning depth and response latency. Our work\nestablishes real-time reasoning as a critical testbed for developing practical\nagents and provides a foundation for research in temporally constrained AI\nsystems, highlighting a path toward real-time capable agents."}
{"id": "2511.04853", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04853", "abs": "https://arxiv.org/abs/2511.04853", "authors": ["Nuno dos Santos Fernandes", "Pedro Tomás", "Nuno Roma", "Frank Winklmeier", "Patricia Conde-Muíño"], "title": "Marionette: Data Structure Description and Management for Heterogeneous Computing", "comment": "5 pages, 2 figures. To be published as a short paper accepted by the\n  24th International Symposium on Parallel and Distributed Computing (ISPDC)", "summary": "Adapting large, object-oriented C++ codebases for hardware acceleration might\nbe extremely challenging, particularly when targeting heterogeneous platforms\nsuch as GPUs. Marionette is a C++17 library designed to address this by\nenabling flexible, efficient, and portable data structure definitions. It\ndecouples data layout from the description of the interface, supports multiple\nmemory management strategies, and provides efficient data transfers and\nconversions across devices, all of this with minimal runtime overhead due to\nthe compile-time nature of its abstractions. By allowing interfaces to be\naugmented with arbitrary functions, Marionette maintains compatibility with\nexisting code and offers a streamlined interface that supports both\nstraightforward and advanced use cases. This paper outlines its design, usage,\nand performance, including a CUDA-based case study demonstrating its efficiency\nand flexibility."}
{"id": "2511.05269", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05269", "abs": "https://arxiv.org/abs/2511.05269", "authors": ["Ishan Kavathekar", "Hemang Jain", "Ameya Rathod", "Ponnurangam Kumaraguru", "Tanuja Ganu"], "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems", "comment": "Accepted at ICML 2025 MAS Workshop. This version includes additional\n  experiments and analysis", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities as\nautonomous agents through tool use, planning, and decision-making abilities,\nleading to their widespread adoption across diverse tasks. As task complexity\ngrows, multi-agent LLM systems are increasingly used to solve problems\ncollaboratively. However, safety and security of these systems remains largely\nunder-explored. Existing benchmarks and datasets predominantly focus on\nsingle-agent settings, failing to capture the unique vulnerabilities of\nmulti-agent dynamics and co-ordination. To address this gap, we introduce\n$\\textbf{T}$hreats and $\\textbf{A}$ttacks in $\\textbf{M}$ulti-$\\textbf{A}$gent\n$\\textbf{S}$ystems ($\\textbf{TAMAS}$), a benchmark designed to evaluate the\nrobustness and safety of multi-agent LLM systems. TAMAS includes five distinct\nscenarios comprising 300 adversarial instances across six attack types and 211\ntools, along with 100 harmless tasks. We assess system performance across ten\nbackbone LLMs and three agent interaction configurations from Autogen and\nCrewAI frameworks, highlighting critical challenges and failure modes in\ncurrent multi-agent deployments. Furthermore, we introduce Effective Robustness\nScore (ERS) to assess the tradeoff between safety and task effectiveness of\nthese frameworks. Our findings show that multi-agent systems are highly\nvulnerable to adversarial attacks, underscoring the urgent need for stronger\ndefenses. TAMAS provides a foundation for systematically studying and improving\nthe safety of multi-agent LLM systems."}
{"id": "2511.04956", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04956", "abs": "https://arxiv.org/abs/2511.04956", "authors": ["Maria Mahbub", "Vanessa Lama", "Sanjay Das", "Brian Starks", "Christopher Polchek", "Saffell Silvers", "Lauren Deck", "Prasanna Balaprakash", "Tirthankar Ghosal"], "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "comment": null, "summary": "High-Risk Property (HRP) classification is critical at U.S. Department of\nEnergy (DOE) sites, where inventories include sensitive and often dual-use\nequipment. Compliance must track evolving rules designated by various export\ncontrol policies to make transparent and auditable decisions. Traditional\nexpert-only workflows are time-consuming, backlog-prone, and struggle to keep\npace with shifting regulatory boundaries. We demo ORCHID, a modular agentic\nsystem for HRP classification that pairs retrieval-augmented generation (RAG)\nwith human oversight to produce policy-based outputs that can be audited. Small\ncooperating agents, retrieval, description refiner, classifier, validator, and\nfeedback logger, coordinate via agent-to-agent messaging and invoke tools\nthrough the Model Context Protocol (MCP) for model-agnostic on-premise\noperation. The interface follows an Item to Evidence to Decision loop with\nstep-by-step reasoning, on-policy citations, and append-only audit bundles\n(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID\nimproves accuracy and traceability over a non-agentic baseline while deferring\nuncertain items to Subject Matter Experts (SMEs). The demonstration shows\nsingle item submission, grounded citations, SME feedback capture, and\nexportable audit artifacts, illustrating a practical path to trustworthy LLM\nassistance in sensitive DOE compliance workflows."}
{"id": "2511.05053", "categories": ["cs.DC", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.05053", "abs": "https://arxiv.org/abs/2511.05053", "authors": ["Wakuto Matsumi", "Riaz-Ul-Haque Mian"], "title": "Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs", "comment": null, "summary": "Machine learning based on neural networks has advanced rapidly, but the high\nenergy consumption required for training and inference remains a major\nchallenge. Hyperdimensional Computing (HDC) offers a lightweight,\nbrain-inspired alternative that enables high parallelism but often suffers from\nlower accuracy on complex visual tasks. To overcome this, hybrid accelerators\ncombining HDC and Convolutional Neural Networks (CNNs) have been proposed,\nthough their adoption is limited by poor generalizability and programmability.\nThe rise of open-source RISC-V architectures has created new opportunities for\ndomain-specific GPU design. Unlike traditional proprietary GPUs, emerging\nRISC-V-based GPUs provide flexible, programmable platforms suitable for custom\ncomputation models such as HDC. In this study, we design and implement custom\nGPU instructions optimized for HDC operations, enabling efficient processing\nfor hybrid HDC-CNN workloads. Experimental results using four types of custom\nHDC instructions show a performance improvement of up to 56.2 times in\nmicrobenchmark tests, demonstrating the potential of RISC-V GPUs for\nenergy-efficient, high-performance computing."}
{"id": "2511.05182", "categories": ["cs.AI", "cs.CY", "H.4.2; I.2.3; I.2.6; I.2.8; J.7"], "pdf": "https://arxiv.org/pdf/2511.05182", "abs": "https://arxiv.org/abs/2511.05182", "authors": ["Johan Schubert", "Patrik Hansen", "Pontus Hörling", "Ronnie Johansson"], "title": "Autonomous generation of different courses of action in mechanized combat operations", "comment": "In Proceedings of the 30th International Command and Control Research\n  & Technology Symposium, Stockholm, Sweden, 3-6 November 2025, paper 009", "summary": "In this paper, we propose a methodology designed to support decision-making\nduring the execution phase of military ground combat operations, with a focus\non one's actions. This methodology generates and evaluates recommendations for\nvarious courses of action for a mechanized battalion, commencing with an\ninitial set assessed by their anticipated outcomes. It systematically produces\nthousands of individual action alternatives, followed by evaluations aimed at\nidentifying alternative courses of action with superior outcomes. These\nalternatives are appraised in light of the opponent's status and actions,\nconsidering unit composition, force ratios, types of offense and defense, and\nanticipated advance rates. Field manuals evaluate battle outcomes and\nadvancement rates. The processes of generation and evaluation work\nconcurrently, yielding a variety of alternative courses of action. This\napproach facilitates the management of new course generation based on\npreviously evaluated actions. As the combat unfolds and conditions evolve,\nrevised courses of action are formulated for the decision-maker within a\nsequential decision-making framework."}
{"id": "2511.05067", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.05067", "abs": "https://arxiv.org/abs/2511.05067", "authors": ["Giuseppe Esposito", "Juan-David Guerrero-Balaguera", "Josie Esteban Rodriguez Condia", "Matteo Sonza Reorda", "Marco Barbiero", "Rossella Fortuna"], "title": "GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters", "comment": null, "summary": "Graphics Processing Units (GPUs) are specialized accelerators in data centers\nand high-performance computing (HPC) systems, enabling the fast execution of\ncompute-intensive applications, such as Convolutional Neural Networks (CNNs).\nHowever, sustained workloads can impose significant stress on GPU components,\nraising reliability concerns due to potential faults that corrupt the\nintermediate application computations, leading to incorrect results. Estimating\nthe stress induced by an application is thus crucial to predict reliability\n(with\\,special\\,emphasis\\,on\\,aging\\,effects). In this work, we combine online\ntelemetry parameters and hardware performance counters to assess GPU stress\ninduced by different applications. The experimental results indicate the stress\ninduced by a parallel workload can be estimated by combining telemetry data and\nPerformance Counters that reveal the efficiency in the resource usage of the\ntarget workload. For this purpose the selected performance counters focus on\nmeasuring the i) throughput, ii) amount of issued instructions and iii) stall\nevents."}
{"id": "2511.05311", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Raphaël Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities."}
{"id": "2511.05375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05375", "abs": "https://arxiv.org/abs/2511.05375", "authors": ["Sijie Yang", "Jiatong Li", "Filip Biljecki"], "title": "Reasoning Is All You Need for Urban Planning AI", "comment": "Submitted to AAAI 2026 Workshop AI4UP", "summary": "AI has proven highly successful at urban planning analysis -- learning\npatterns from data to predict future conditions. The next frontier is\nAI-assisted decision-making: agents that recommend sites, allocate resources,\nand evaluate trade-offs while reasoning transparently about constraints and\nstakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,\nReAct, and multi-agent collaboration frameworks -- now make this vision\nachievable.\n  This position paper presents the Agentic Urban Planning AI Framework for\nreasoning-capable planning agents that integrates three cognitive layers\n(Perception, Foundation, Reasoning) with six logic components (Analysis,\nGeneration, Verification, Evaluation, Collaboration, Decision) through a\nmulti-agents collaboration framework. We demonstrate why planning decisions\nrequire explicit reasoning capabilities that are value-based (applying\nnormative principles), rule-grounded (guaranteeing constraint satisfaction),\nand explainable (generating transparent justifications) -- requirements that\nstatistical learning alone cannot fulfill. We compare reasoning agents with\nstatistical learning, present a comprehensive architecture with benchmark\nevaluation metrics, and outline critical research challenges. This framework\nshows how AI agents can augment human planners by systematically exploring\nsolution spaces, verifying regulatory compliance, and deliberating over\ntrade-offs transparently -- not replacing human judgment but amplifying it with\ncomputational reasoning capabilities."}
{"id": "2511.05053", "categories": ["cs.DC", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.05053", "abs": "https://arxiv.org/abs/2511.05053", "authors": ["Wakuto Matsumi", "Riaz-Ul-Haque Mian"], "title": "Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs", "comment": null, "summary": "Machine learning based on neural networks has advanced rapidly, but the high\nenergy consumption required for training and inference remains a major\nchallenge. Hyperdimensional Computing (HDC) offers a lightweight,\nbrain-inspired alternative that enables high parallelism but often suffers from\nlower accuracy on complex visual tasks. To overcome this, hybrid accelerators\ncombining HDC and Convolutional Neural Networks (CNNs) have been proposed,\nthough their adoption is limited by poor generalizability and programmability.\nThe rise of open-source RISC-V architectures has created new opportunities for\ndomain-specific GPU design. Unlike traditional proprietary GPUs, emerging\nRISC-V-based GPUs provide flexible, programmable platforms suitable for custom\ncomputation models such as HDC. In this study, we design and implement custom\nGPU instructions optimized for HDC operations, enabling efficient processing\nfor hybrid HDC-CNN workloads. Experimental results using four types of custom\nHDC instructions show a performance improvement of up to 56.2 times in\nmicrobenchmark tests, demonstrating the potential of RISC-V GPUs for\nenergy-efficient, high-performance computing."}
{"id": "2511.05269", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05269", "abs": "https://arxiv.org/abs/2511.05269", "authors": ["Ishan Kavathekar", "Hemang Jain", "Ameya Rathod", "Ponnurangam Kumaraguru", "Tanuja Ganu"], "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems", "comment": "Accepted at ICML 2025 MAS Workshop. This version includes additional\n  experiments and analysis", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities as\nautonomous agents through tool use, planning, and decision-making abilities,\nleading to their widespread adoption across diverse tasks. As task complexity\ngrows, multi-agent LLM systems are increasingly used to solve problems\ncollaboratively. However, safety and security of these systems remains largely\nunder-explored. Existing benchmarks and datasets predominantly focus on\nsingle-agent settings, failing to capture the unique vulnerabilities of\nmulti-agent dynamics and co-ordination. To address this gap, we introduce\n$\\textbf{T}$hreats and $\\textbf{A}$ttacks in $\\textbf{M}$ulti-$\\textbf{A}$gent\n$\\textbf{S}$ystems ($\\textbf{TAMAS}$), a benchmark designed to evaluate the\nrobustness and safety of multi-agent LLM systems. TAMAS includes five distinct\nscenarios comprising 300 adversarial instances across six attack types and 211\ntools, along with 100 harmless tasks. We assess system performance across ten\nbackbone LLMs and three agent interaction configurations from Autogen and\nCrewAI frameworks, highlighting critical challenges and failure modes in\ncurrent multi-agent deployments. Furthermore, we introduce Effective Robustness\nScore (ERS) to assess the tradeoff between safety and task effectiveness of\nthese frameworks. Our findings show that multi-agent systems are highly\nvulnerable to adversarial attacks, underscoring the urgent need for stronger\ndefenses. TAMAS provides a foundation for systematically studying and improving\nthe safety of multi-agent LLM systems."}
