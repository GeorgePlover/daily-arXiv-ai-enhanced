{"id": "2511.20663", "categories": ["cs.MA", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20663", "abs": "https://arxiv.org/abs/2511.20663", "authors": ["Barak Or"], "title": "MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems", "comment": "preprint", "summary": "Ensuring cognitive stability in autonomous multi-agent systems (MAS) is a central challenge for large-scale, distributed AI. While existing observability tools monitor system outputs, they cannot quantify how rapidly agentic workflows recover once reasoning coherence has been lost. We adapt classical reliability metrics-Mean Time-to-Recovery (MTTR), Mean Time Between Failures (MTBF), and related ratios-into the cognitive domain, defining MTTR-A (Mean Time-to-Recovery for Agentic Systems) as a runtime measure of cognitive recovery latency. MTTR-A quantifies the time required for a MAS to detect reasoning drift and restore consistent operation, capturing the recovery of reasoning coherence rather than infrastructural repair.\n  A benchmark simulation using the AG~News corpus and the LangGraph orchestration framework was conducted, modeling recovery latencies across multiple reflex modes. Automated reflexes restored stability within approximately 6s on average, while human-approval interventions required about 12s. Across 200 runs, the median simulated MTTR-A was 6.21+-2.14s, MTBF=6.7+-2.14s, and NRR=0.08, demonstrating measurable runtime resilience across reflex strategies.\n  By formalizing recovery latency as a quantifiable property of distributed reasoning-and deriving reliability bounds linking recovery time and cognitive uptime-this work establishes a foundation for runtime dependability in agentic cognition, transforming cognitive recovery from an ad-hoc process into a standardized, interpretable performance", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u7ecf\u5178\u53ef\u9760\u6027\u6307\u6807\uff08MTTR\u3001MTBF\uff09\u5f15\u5165\u8ba4\u77e5\u9886\u57df\uff0c\u63d0\u51faMTTR-A\u6307\u6807\u6765\u91cf\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8ba4\u77e5\u6062\u590d\u5ef6\u8fdf\uff0c\u901a\u8fc7\u57fa\u51c6\u6a21\u62df\u5c55\u793a\u4e86\u4e0d\u540c\u6062\u590d\u7b56\u7565\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u53ef\u89c2\u6d4b\u6027\u5de5\u5177\u53ea\u80fd\u76d1\u63a7\u7cfb\u7edf\u8f93\u51fa\uff0c\u65e0\u6cd5\u91cf\u5316\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5728\u5931\u53bb\u63a8\u7406\u4e00\u81f4\u6027\u540e\u7684\u6062\u590d\u901f\u5ea6\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u8861\u91cf\u8ba4\u77e5\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528AG News\u8bed\u6599\u5e93\u548cLangGraph\u7f16\u6392\u6846\u67b6\u8fdb\u884c\u57fa\u51c6\u6a21\u62df\uff0c\u5efa\u6a21\u591a\u79cd\u53cd\u5c04\u6a21\u5f0f\u4e0b\u7684\u6062\u590d\u5ef6\u8fdf\uff0c\u6bd4\u8f83\u81ea\u52a8\u53cd\u5c04\u548c\u4eba\u5de5\u5e72\u9884\u4e24\u79cd\u6062\u590d\u7b56\u7565\u3002", "result": "\u81ea\u52a8\u53cd\u5c04\u5e73\u5747\u6062\u590d\u65f6\u95f4\u7ea66\u79d2\uff0c\u4eba\u5de5\u5e72\u9884\u7ea612\u79d2\uff1b200\u6b21\u8fd0\u884c\u4e2d\uff0c\u6a21\u62dfMTTR-A\u4e2d\u4f4d\u6570\u4e3a6.21\u00b12.14\u79d2\uff0cMTBF=6.7\u00b12.14\u79d2\uff0cNRR=0.08\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6062\u590d\u5ef6\u8fdf\u91cf\u5316\u4e3a\u5206\u5e03\u5f0f\u63a8\u7406\u7684\u53ef\u91cf\u5316\u5c5e\u6027\uff0c\u4e3a\u667a\u80fd\u4f53\u8ba4\u77e5\u7684\u8fd0\u884c\u65f6\u53ef\u9760\u6027\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c06\u8ba4\u77e5\u6062\u590d\u4ece\u4e34\u65f6\u8fc7\u7a0b\u8f6c\u53d8\u4e3a\u6807\u51c6\u5316\u3001\u53ef\u89e3\u91ca\u7684\u6027\u80fd\u6307\u6807\u3002"}}
{"id": "2511.20943", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20943", "abs": "https://arxiv.org/abs/2511.20943", "authors": ["Chuhao Qin", "Alexandru Sorici", "Andrei Olaru", "Evangelos Pournaras", "Adina Magda Florea"], "title": "Resilient Charging Infrastructure via Decentralized Coordination of Electric Vehicles at Scale", "comment": "14 pages, 12 figures. This work has been submitted to the IEEE for possible publication", "summary": "The rapid adoption of electric vehicles (EVs) introduces major challenges for decentralized charging control. Existing decentralized approaches efficiently coordinate a large number of EVs to select charging stations while reducing energy costs, preventing power peak and preserving driver privacy. However, they often struggle under severe contingencies, such as station outages or unexpected surges in charging requests. These situations create competition for limited charging slots, resulting in long queues and reduced driver comfort. To address these limitations, we propose a novel collective learning-based coordination framework that allows EVs to balance individual comfort on their selections against system-wide efficiency, i.e., the overall queues across all stations. In the framework, EVs are recommended for adaptive charging behaviors that shift priority between comfort and efficiency, achieving Pareto-optimal trade-offs under varying station capacities and dynamic spatio-temporal EV distribution. Experiments using real-world data from EVs and charging stations show that the proposed approach outperforms baseline methods, significantly reducing travel and queuing time. The results reveal that, under uncertain charging conditions, EV drivers that behave selfishly or altruistically at the right moments achieve shorter waiting time than those maintaining moderate behavior throughout. Our findings under high fractions of station outages and adversarial EVs further demonstrate improved resilience and trustworthiness of decentralized EV charging infrastructure.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u96c6\u4f53\u5b66\u4e60\u7684\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u534f\u8c03\u6846\u67b6\uff0c\u5728\u5145\u7535\u7ad9\u6545\u969c\u6216\u9700\u6c42\u6fc0\u589e\u7b49\u7d27\u6025\u60c5\u51b5\u4e0b\u5e73\u8861\u4e2a\u4f53\u8212\u9002\u5ea6\u4e0e\u7cfb\u7edf\u6548\u7387\uff0c\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u5206\u6563\u5f0f\u5145\u7535\u63a7\u5236\u65b9\u6cd5\u5728\u4e25\u91cd\u7a81\u53d1\u4e8b\u4ef6\uff08\u5982\u5145\u7535\u7ad9\u6545\u969c\u3001\u5145\u7535\u8bf7\u6c42\u6fc0\u589e\uff09\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u957f\u961f\u5217\u548c\u9a7e\u9a76\u5458\u8212\u9002\u5ea6\u964d\u4f4e\uff0c\u9700\u8981\u89e3\u51b3\u6709\u9650\u5145\u7535\u69fd\u7ade\u4e89\u95ee\u9898\u3002", "method": "\u91c7\u7528\u96c6\u4f53\u5b66\u4e60\u6846\u67b6\uff0c\u63a8\u8350\u7535\u52a8\u6c7d\u8f66\u91c7\u53d6\u81ea\u9002\u5e94\u5145\u7535\u884c\u4e3a\uff0c\u5728\u8212\u9002\u5ea6\u548c\u6548\u7387\u4e4b\u95f4\u52a8\u6001\u8c03\u6574\u4f18\u5148\u7ea7\uff0c\u9002\u5e94\u53d8\u5316\u7684\u7ad9\u5bb9\u91cf\u548c\u65f6\u7a7aEV\u5206\u5e03\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u65c5\u884c\u548c\u6392\u961f\u65f6\u95f4\u3002\u5728\u4e0d\u786e\u5b9a\u5145\u7535\u6761\u4ef6\u4e0b\uff0c\u9002\u65f6\u81ea\u79c1\u6216\u5229\u4ed6\u7684\u9a7e\u9a76\u5458\u6bd4\u59cb\u7ec8\u4fdd\u6301\u9002\u5ea6\u884c\u4e3a\u7684\u9a7e\u9a76\u5458\u7b49\u5f85\u65f6\u95f4\u66f4\u77ed\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u9ad8\u6bd4\u4f8b\u5145\u7535\u7ad9\u6545\u969c\u548c\u5bf9\u6297\u6027EV\u60c5\u51b5\u4e0b\u5c55\u793a\u4e86\u5206\u6563\u5f0fEV\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7684\u6539\u8fdb\u97e7\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2511.21510", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21510", "abs": "https://arxiv.org/abs/2511.21510", "authors": ["Ke Zhang", "Xiaoning Zhao", "Ce Zheng", "Jiahong Ning", "Dandan Zhu", "Wenqi Zhang", "Chen Sun", "Toshiharu Sugawara"], "title": "Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation", "comment": "9 pages, 3 figures", "summary": "This study proposes Tool-RoCo, a novel benchmark for evaluating large language models (LLMs) in long-term multi-agent cooperation based on RoCo, a multi-robot cooperative benchmark. Recent research on LLM-based multi-agent systems has relied on predefined orchestration, while ignoring agent autonomy. Tool-RoCo treats other agents as tools and introduces cooperative tools, leveraging tool usage to evaluate multi-agent cooperation and self-organization. Tool usage means that each agent (LLM) selects a tool from a candidate set based on the current state, receives feedback, and adjusts its selection in subsequent rounds. To evaluate different autonomy levels, we propose four LLM paradigms: (1) centralized cooperation, where a single LLM allocates tools to all agents; (2) centralized self-organization, where a central LLM autonomously activates agents while keeping others inactive; (3) decentralized cooperation, where each agent has its own LLM and calls tools based on local information; and (4) self-organization, where a randomly chosen initial agent can request collaboration, activating additional agents via tool calls. Tool-RoCo includes three multi-robot tasks, SORT, PACK, and CABINET, to measure format and parameter accuracy and agent coordination through tool usage. The results using several LLMs showed that cooperative tools accounted for only 7.09% of all tools, indicating that LLM-based agents rarely invoked others as assistants. Moreover, activation tools accounted for 96.42%, suggesting that current LLMs tend to maintain active agents while seldom deactivating them for adaptive coordination. Tool-RoCo provides a systematic benchmark to evaluate LLM autonomy and cooperation in multi-agent tasks. Code and Demo: https://github.com/ColaZhang22/Tool-Roco", "AI": {"tldr": "Tool-RoCo\u662f\u4e00\u4e2a\u57fa\u4e8eRoCo\u591a\u673a\u5668\u4eba\u534f\u4f5c\u57fa\u51c6\u7684\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u671f\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u7684\u8868\u73b0\u3002\u5b83\u901a\u8fc7\u5de5\u5177\u4f7f\u7528\u6765\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u81ea\u7ec4\u7ec7\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u56db\u79cdLLM\u8303\u5f0f\u6765\u8bc4\u4f30\u4e0d\u540c\u81ea\u6cbb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u7f16\u6392\uff0c\u5ffd\u89c6\u4e86\u667a\u80fd\u4f53\u7684\u81ea\u4e3b\u6027\u3002Tool-RoCo\u65e8\u5728\u901a\u8fc7\u5c06\u5176\u4ed6\u667a\u80fd\u4f53\u89c6\u4e3a\u5de5\u5177\uff0c\u5229\u7528\u5de5\u5177\u4f7f\u7528\u6765\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u81ea\u7ec4\u7ec7\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cdLLM\u8303\u5f0f\uff1a\u96c6\u4e2d\u5f0f\u534f\u4f5c\u3001\u96c6\u4e2d\u5f0f\u81ea\u7ec4\u7ec7\u3001\u5206\u6563\u5f0f\u534f\u4f5c\u548c\u81ea\u7ec4\u7ec7\u3002\u901a\u8fc7\u4e09\u4e2a\u591a\u673a\u5668\u4eba\u4efb\u52a1\uff08SORT\u3001PACK\u3001CABINET\uff09\u6765\u6d4b\u91cf\u683c\u5f0f\u548c\u53c2\u6570\u51c6\u786e\u6027\u4ee5\u53ca\u667a\u80fd\u4f53\u534f\u8c03\u3002", "result": "\u7ed3\u679c\u663e\u793a\u534f\u4f5c\u5de5\u5177\u4ec5\u5360\u6240\u6709\u5de5\u5177\u76847.09%\uff0c\u8868\u660e\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5f88\u5c11\u5c06\u5176\u4ed6\u667a\u80fd\u4f53\u4f5c\u4e3a\u52a9\u624b\u8c03\u7528\u3002\u6fc0\u6d3b\u5de5\u5177\u536096.42%\uff0c\u8868\u660e\u5f53\u524dLLM\u503e\u5411\u4e8e\u4fdd\u6301\u6d3b\u8dc3\u667a\u80fd\u4f53\uff0c\u5f88\u5c11\u4e3a\u81ea\u9002\u5e94\u534f\u8c03\u800c\u505c\u7528\u5b83\u4eec\u3002", "conclusion": "Tool-RoCo\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u5728\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\u7684\u81ea\u4e3b\u6027\u548c\u534f\u4f5c\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u534f\u4f5c\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.21572", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21572", "abs": "https://arxiv.org/abs/2511.21572", "authors": ["Liming Yang", "Junyu Luo", "Xuanzhe Liu", "Yiling Lou", "Zhenpeng Chen"], "title": "BAMAS: Structuring Budget-Aware Multi-Agent Systems", "comment": "Accepted by AAAI 2026 (oral paper)", "summary": "Large language model (LLM)-based multi-agent systems have emerged as a powerful paradigm for enabling autonomous agents to solve complex tasks. As these systems scale in complexity, cost becomes an important consideration for practical deployment. However, existing work rarely addresses how to structure multi-agent systems under explicit budget constraints. In this paper, we propose BAMAS, a novel approach for building multi-agent systems with budget awareness. BAMAS first selects an optimal set of LLMs by formulating and solving an Integer Linear Programming problem that balances performance and cost. It then determines how these LLMs should collaborate by leveraging a reinforcement learning-based method to select the interaction topology. Finally, the system is instantiated and executed based on the selected agents and their collaboration topology. We evaluate BAMAS on three representative tasks and compare it with state-of-the-art agent construction methods. Results show that BAMAS achieves comparable performance while reducing cost by up to 86%.", "AI": {"tldr": "BAMAS\u662f\u4e00\u79cd\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u6570\u7ebf\u6027\u89c4\u5212\u9009\u62e9\u6700\u4f18LLM\u7ec4\u5408\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u786e\u5b9a\u4ea4\u4e92\u62d3\u6251\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u6210\u672c\u6210\u4e3a\u5b9e\u9645\u90e8\u7f72\u7684\u91cd\u8981\u8003\u8651\u56e0\u7d20\uff0c\u4f46\u73b0\u6709\u5de5\u4f5c\u5f88\u5c11\u5728\u660e\u786e\u9884\u7b97\u7ea6\u675f\u4e0b\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "method": "BAMAS\u9996\u5148\u901a\u8fc7\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u9009\u62e9\u6700\u4f18LLM\u96c6\u5408\uff0c\u5e73\u8861\u6027\u80fd\u548c\u6210\u672c\uff1b\u7136\u540e\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u786e\u5b9a\u4ea4\u4e92\u62d3\u6251\uff1b\u6700\u540e\u57fa\u4e8e\u9009\u62e9\u7684\u667a\u80fd\u4f53\u548c\u534f\u4f5c\u62d3\u6251\u5b9e\u4f8b\u5316\u7cfb\u7edf\u3002", "result": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cBAMAS\u4e0e\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53\u6784\u5efa\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u4fdd\u6301\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6210\u672c\u964d\u4f4e\u4e86\u9ad8\u8fbe86%\u3002", "conclusion": "BAMAS\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u6784\u5efa\u9ad8\u6548\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u884c\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u90e8\u7f72\u6210\u672c\u3002"}}
{"id": "2511.20780", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.20780", "abs": "https://arxiv.org/abs/2511.20780", "authors": ["Alison Silva", "Gustavo Callou"], "title": "Assessing Redundancy Strategies to Improve Availability in Virtualized System Architectures", "comment": null, "summary": "Cloud-based storage platforms are becoming more common in both academic and business settings due to their flexible access to data and support for collaborative functionalities. As reliability becomes a vital requirement, particularly for organizations looking for alternatives to public cloud services, assessing the dependability of these systems is crucial. This paper presents a methodology for analyzing the availability of a file server (Nextcloud) hosted in a private cloud environment using Apache CloudStack. The analysis is based on a modeling approach through Stochastic Petri Nets (SPNs) that allows the evaluation of different redundancy strategies to enhance the availability of such systems. Four architectural configurations were modeled, including the baseline, host-level redundancy, virtual machine (VM) redundancy, and a combination of both. The results show that redundancy at both the host and VM levels significantly improves availability and reduces expected downtime. The proposed approach provides a method to evaluate the availability of a private cloud and support infrastructure design decisions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673aPetri\u7f51\u7684\u65b9\u6cd5\u6765\u5206\u6790\u79c1\u6709\u4e91\u73af\u5883\u4e2dNextcloud\u6587\u4ef6\u670d\u52a1\u5668\u7684\u53ef\u7528\u6027\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u5197\u4f59\u7b56\u7565\u5bf9\u7cfb\u7edf\u53ef\u7528\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u4e91\u5b58\u50a8\u5e73\u53f0\u5728\u5b66\u672f\u548c\u5546\u4e1a\u73af\u5883\u4e2d\u7684\u666e\u53ca\uff0c\u53ef\u9760\u6027\u6210\u4e3a\u5173\u952e\u9700\u6c42\u3002\u7279\u522b\u662f\u5bf9\u4e8e\u5bfb\u6c42\u516c\u5171\u4e91\u670d\u52a1\u66ff\u4ee3\u65b9\u6848\u7684\u7ec4\u7ec7\uff0c\u8bc4\u4f30\u8fd9\u4e9b\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528Apache CloudStack\u5728\u79c1\u6709\u4e91\u73af\u5883\u4e2d\u6258\u7ba1Nextcloud\u6587\u4ef6\u670d\u52a1\u5668\uff0c\u901a\u8fc7\u968f\u673aPetri\u7f51\u5efa\u6a21\u65b9\u6cd5\u8bc4\u4f30\u4e0d\u540c\u7684\u5197\u4f59\u7b56\u7565\uff0c\u5305\u62ec\u57fa\u7ebf\u914d\u7f6e\u3001\u4e3b\u673a\u7ea7\u5197\u4f59\u3001\u865a\u62df\u673a\u5197\u4f59\u4ee5\u53ca\u4e24\u8005\u7ec4\u5408\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e3b\u673a\u548c\u865a\u62df\u673a\u7ea7\u522b\u540c\u65f6\u5b9e\u65bd\u5197\u4f59\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u7cfb\u7edf\u53ef\u7528\u6027\u5e76\u51cf\u5c11\u9884\u671f\u505c\u673a\u65f6\u95f4\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u8bc4\u4f30\u79c1\u6709\u4e91\u53ef\u7528\u6027\u548c\u652f\u6301\u57fa\u7840\u8bbe\u65bd\u8bbe\u8ba1\u51b3\u7b56\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2511.20679", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20679", "abs": "https://arxiv.org/abs/2511.20679", "authors": ["Melika Ayoughi", "Pascal Mettes", "Paul Groth"], "title": "Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring", "comment": null, "summary": "Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u91cd\u6784\u5c42\u6b21\u7ed3\u6784\u4ee5\u4f18\u5316\u53cc\u66f2\u5d4c\u5165\u8d28\u91cf\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u793a\u5f15\u5bfcLLM\u91cd\u6784\u73b0\u6709\u5c42\u6b21\u7ed3\u6784\uff0c\u5b9e\u9a8c\u8868\u660e\u91cd\u6784\u540e\u7684\u5c42\u6b21\u7ed3\u6784\u5728\u591a\u4e2a\u6807\u51c6\u5d4c\u5165\u8d28\u91cf\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u53cc\u66f2\u5d4c\u5165\u7684\u8d28\u91cf\u4e0e\u8f93\u5165\u5c42\u6b21\u7ed3\u6784\u7d27\u5bc6\u76f8\u5173\uff0c\u800c\u6700\u4f73\u53cc\u66f2\u5d4c\u5165\u9700\u8981\u9ad8\u5206\u652f\u56e0\u5b50\u548c\u5355\u7ee7\u627f\u7279\u6027\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22LLM\u662f\u5426\u80fd\u591f\u81ea\u52a8\u91cd\u6784\u5c42\u6b21\u7ed3\u6784\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u6807\u51c6\uff0c\u5e2e\u52a9\u77e5\u8bc6\u5de5\u7a0b\u5e08\u4f18\u5316\u77e5\u8bc6\u7ec4\u7ec7\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528LLM\u5728\u5df2\u77e5\u53cc\u66f2\u5d4c\u5165\u671f\u671b\u6807\u51c6\u7684\u6307\u5bfc\u4e0b\u8f6c\u6362\u73b0\u6709\u5c42\u6b21\u7ed3\u6784\uff0c\u572816\u4e2a\u4e0d\u540c\u5c42\u6b21\u7ed3\u6784\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cLLM\u91cd\u6784\u7684\u5c42\u6b21\u7ed3\u6784\u5728\u591a\u4e2a\u6807\u51c6\u5d4c\u5165\u8d28\u91cf\u6307\u6807\u4e0a\u59cb\u7ec8\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u53cc\u66f2\u5d4c\u5165\uff0c\u5e76\u4e14\u80fd\u591f\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u91cd\u7ec4\u7406\u7531\u3002", "conclusion": "LLM\u80fd\u591f\u6709\u6548\u81ea\u52a8\u91cd\u6784\u5c42\u6b21\u7ed3\u6784\u4ee5\u4f18\u5316\u53cc\u66f2\u5d4c\u5165\u8d28\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u91cd\u7ec4\u8fc7\u7a0b\uff0c\u4e3a\u77e5\u8bc6\u5de5\u7a0b\u5e08\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u652f\u6301\u3002"}}
{"id": "2511.20693", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.20693", "abs": "https://arxiv.org/abs/2511.20693", "authors": ["Mingming Zhao", "Xiaokang Wei", "Yuanqi Shao", "Kaiwen Zhou", "Lin Yang", "Siwei Rao", "Junhui Zhan", "Zhitang Chen"], "title": "$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators", "comment": "Accepted by AAAI-2026", "summary": "Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\\% and 19.3\\% average performance improvement and reduces resource usage by 37\\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW", "AI": {"tldr": "A\u00b2Flow\u662f\u4e00\u4e2a\u57fa\u4e8e\u81ea\u9002\u5e94\u62bd\u8c61\u7b97\u5b50\u7684\u5168\u81ea\u52a8\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u7b97\u5b50\u63d0\u53d6\u8fc7\u7a0b\u81ea\u52a8\u751f\u6210\u53ef\u91cd\u7528\u7684\u6267\u884c\u7b97\u5b50\uff0c\u65e0\u9700\u624b\u52a8\u9884\u5b9a\u4e49\uff0c\u5728\u6027\u80fd\u548c\u8d44\u6e90\u4f7f\u7528\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u624b\u52a8\u9884\u5b9a\u4e49\u7684\u7b97\u5b50\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u6cdb\u5316\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9700\u8981\u5f00\u53d1\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u7b97\u5b50\u63d0\u53d6\uff1a1\uff09\u57fa\u4e8e\u6848\u4f8b\u7684\u521d\u59cb\u7b97\u5b50\u751f\u6210\uff1b2\uff09\u7b97\u5b50\u805a\u7c7b\u548c\u521d\u6b65\u62bd\u8c61\uff1b3\uff09\u6df1\u5ea6\u63d0\u53d6\u62bd\u8c61\u6267\u884c\u7b97\u5b50\u3002\u540c\u65f6\u5f15\u5165\u7b97\u5b50\u8bb0\u5fc6\u673a\u5236\u6765\u589e\u5f3a\u5de5\u4f5c\u6d41\u641c\u7d22\u3002", "result": "\u5728\u901a\u7528\u548c\u5177\u8eab\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cA\u00b2Flow\u5b9e\u73b0\u4e862.4%\u548c19.3%\u7684\u5e73\u5747\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5c06\u8d44\u6e90\u4f7f\u7528\u51cf\u5c11\u4e8637%\u3002", "conclusion": "A\u00b2Flow\u901a\u8fc7\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u7b97\u5b50\u63d0\u53d6\u548c\u8bb0\u5fc6\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u4e3a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20686", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20686", "abs": "https://arxiv.org/abs/2511.20686", "authors": ["Chae-Gyun Lim", "Seung-Ho Han", "EunYoung Byun", "Jeongyun Han", "Soohyun Cho", "Eojin Joo", "Heehyeon Kim", "Sieun Kim", "Juhoon Lee", "Hyunsoo Lee", "Dongkun Lee", "Jonghwan Hyeon", "Yechan Hwang", "Young-Jun Lee", "Kyeongryul Lee", "Minhyeong An", "Hyunjun Ahn", "Jeongwoo Son", "Junho Park", "Donggyu Yoon", "Taehyung Kim", "Jeemin Kim", "Dasom Choi", "Kwangyoung Lee", "Hyunseung Lim", "Yeohyun Jung", "Jongok Hong", "Sooyohn Nam", "Joonyoung Park", "Sungmin Na", "Yubin Choi", "Jeanne Choi", "Yoojin Hong", "Sueun Jang", "Youngseok Seo", "Somin Park", "Seoungung Jo", "Wonhye Chae", "Yeeun Jo", "Eunyoung Kim", "Joyce Jiyoung Whang", "HwaJung Hong", "Joseph Seering", "Uichin Lee", "Juho Kim", "Sunna Choi", "Seokyeon Ko", "Taeho Kim", "Kyunghoon Kim", "Myungsik Ha", "So Jung Lee", "Jemin Hwang", "JoonHo Kwak", "Ho-Jin Choi"], "title": "AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI", "comment": "16 pages, HuggingFace: https://huggingface.co/datasets/TTA01/AssurAI", "summary": "The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.", "AI": {"tldr": "AssurAI\u662f\u4e00\u4e2a\u9488\u5bf9\u97e9\u8bed\u591a\u6a21\u6001\u751f\u6210AI\u5b89\u5168\u8bc4\u4f30\u7684\u8d28\u91cf\u63a7\u5236\u6570\u636e\u96c6\uff0c\u5305\u542b11,480\u4e2a\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u548c\u97f3\u9891\u5b9e\u4f8b\uff0c\u8986\u76d635\u79cdAI\u98ce\u9669\u56e0\u7d20\uff0c\u7279\u522b\u5173\u6ce8\u97e9\u8bed\u793e\u4f1a\u6587\u5316\u80cc\u666f\u4e0b\u7684\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u7684\u5b89\u5168\u8bc4\u4f30\u6570\u636e\u96c6\u4e3b\u8981\u662f\u82f1\u8bed\u4e2d\u5fc3\u7684\uff0c\u65e0\u6cd5\u6355\u6349\u975e\u82f1\u8bed\u793e\u4f1a\u6587\u5316\u80cc\u666f\uff08\u5982\u97e9\u8bed\uff09\u4e2d\u7684\u7279\u5b9a\u98ce\u9669\uff0c\u4e14\u901a\u5e38\u4ec5\u9650\u4e8e\u6587\u672c\u6a21\u6001\u3002", "method": "\u901a\u8fc7\u591a\u5b66\u79d1\u4e13\u5bb6\u7ec4\u5b9a\u4e4935\u79cdAI\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6784\u5efa\uff08\u4e13\u5bb6\u5f15\u5bfc\u64ad\u79cd\u548c\u4f17\u5305\u6269\u5c55\uff09\u3001\u4e09\u91cd\u72ec\u7acb\u6807\u6ce8\u548c\u8fed\u4ee3\u4e13\u5bb6\u7ea2\u961f\u6d4b\u8bd5\u7684\u4e25\u683c\u8d28\u91cf\u63a7\u5236\u6d41\u7a0b\u3002", "result": "\u6784\u5efa\u5e76\u53d1\u5e03\u4e86AssurAI\u6570\u636e\u96c6\uff0c\u8bd5\u70b9\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u5728\u8bc4\u4f30\u6700\u65b0LLM\u5b89\u5168\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "AssurAI\u7684\u53d1\u5e03\u5c06\u4fc3\u8fdb\u4e3a\u97e9\u8bed\u793e\u533a\u5f00\u53d1\u66f4\u5b89\u5168\u53ef\u9760\u7684\u751f\u6210AI\u7cfb\u7edf\u3002"}}
{"id": "2511.20975", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.20975", "abs": "https://arxiv.org/abs/2511.20975", "authors": ["Yinwei Dai", "Zhuofu Chen", "Anand Iyer", "Ravi Netravali"], "title": "Aragog: Just-in-Time Model Routing for Scalable Serving of Agentic Workflows", "comment": null, "summary": "Agentic workflows have emerged as a powerful paradigm for solving complex, multi-stage tasks, but serving them at scale is computationally expensive given the many LLM inferences that each request must pass through. Configuration selection, or the cost-aware assignment of workflow agents to specific LLMs, can reduce these costs, but existing approaches bind configuration decisions before request execution, making them ill-suited for the heterogeneous and lengthy execution of workflows. Specifically, system loads can fluctuate rapidly and substantially during a request's lifetime, causing fixed configurations to quickly become suboptimal. We present Aragog, a system that progressively adapts a request's configuration throughout its execution to match runtime dynamics. To make this practical despite the massive space of workflow configurations, Aragog decouples the problem into two core elements -- a one-time routing step that identifies all accuracy-preserving configurations, and a cheap per-stage scheduler that selects among them using up-to-date system observations -- and introduces novel strategies to accelerate each. Across diverse workflows and model families, Aragog increases maximum serving throughput by 50.0--217.0\\% and reduces median latency by 32.5--78.9\\% at peak request rates, while maintaining accuracy comparable to the most expensive configurations.", "AI": {"tldr": "Aragog\u7cfb\u7edf\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5de5\u4f5c\u6d41\u914d\u7f6e\u6765\u4f18\u5316\u591a\u9636\u6bb5LLM\u4efb\u52a1\u7684\u6267\u884c\u6548\u7387\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u548c\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u7684\u5de5\u4f5c\u6d41\u914d\u7f6e\u9009\u62e9\u65b9\u6cd5\u5728\u8bf7\u6c42\u6267\u884c\u524d\u56fa\u5b9a\u914d\u7f6e\uff0c\u65e0\u6cd5\u9002\u5e94\u7cfb\u7edf\u8d1f\u8f7d\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5bfc\u81f4\u5728\u957f\u65f6\u95f4\u6267\u884c\u8fc7\u7a0b\u4e2d\u914d\u7f6e\u5feb\u901f\u53d8\u5f97\u6b21\u4f18\u3002", "method": "Aragog\u5c06\u95ee\u9898\u89e3\u8026\u4e3a\u4e00\u6b21\u6027\u8def\u7531\u6b65\u9aa4\u548c\u5ec9\u4ef7\u6bcf\u9636\u6bb5\u8c03\u5ea6\u5668\uff0c\u524d\u8005\u8bc6\u522b\u6240\u6709\u4fdd\u6301\u7cbe\u5ea6\u7684\u914d\u7f6e\uff0c\u540e\u8005\u4f7f\u7528\u5b9e\u65f6\u7cfb\u7edf\u89c2\u5bdf\u4ece\u4e2d\u9009\u62e9\u3002", "result": "\u5728\u591a\u6837\u5316\u5de5\u4f5c\u6d41\u548c\u6a21\u578b\u5bb6\u65cf\u4e2d\uff0cAragog\u5728\u5cf0\u503c\u8bf7\u6c42\u7387\u4e0b\u5c06\u6700\u5927\u670d\u52a1\u541e\u5410\u91cf\u63d0\u9ad850.0-217.0%\uff0c\u4e2d\u4f4d\u6570\u5ef6\u8fdf\u964d\u4f4e32.5-78.9%\u3002", "conclusion": "Aragog\u901a\u8fc7\u8fd0\u884c\u65f6\u52a8\u6001\u914d\u7f6e\u8c03\u6574\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5de5\u4f5c\u6d41\u670d\u52a1\u4e2d\u7684\u6210\u672c\u6548\u7387\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u6700\u6602\u8d35\u914d\u7f6e\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002"}}
{"id": "2511.20982", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.20982", "abs": "https://arxiv.org/abs/2511.20982", "authors": ["Junhan Liao", "Minxian Xu", "Wanyi Zheng", "Yan Wang", "Kejiang Ye", "Rajkumar Buyya", "Chengzhong Xu"], "title": "A Dynamic PD-Disaggregation Architecture for Maximizing Goodput in LLM Inference Serving", "comment": "14 pages", "summary": "To meet strict Service-Level Objectives (SLOs),contemporary Large Language Models (LLMs) decouple the prefill and decoding stages and place them on separate GPUs to mitigate the distinct bottlenecks inherent to each phase. However, the heterogeneity of LLM workloads causes producerconsumer imbalance between the two instance types in such disaggregated architecture. To address this problem, we propose DOPD (Dynamic Optimal Prefill/Decoding), a dynamic LLM inference system that adjusts instance allocations to achieve an optimal prefill-to-decoding (P/D) ratio based on real-time load monitoring. Combined with an appropriate request-scheduling policy, DOPD effectively resolves imbalances between prefill and decoding instances and mitigates resource allocation mismatches due to mixed-length requests under high concurrency. Experimental evaluations show that, compared with vLLM and DistServe (representative aggregation-based and disaggregationbased approaches), DOPD improves overall system goodput by up to 1.5X, decreases P90 time-to-first-token (TTFT) by up to 67.5%, and decreases P90 time-per-output-token (TPOT) by up to 22.8%. Furthermore, our dynamic P/D adjustment technique performs proactive reconfiguration based on historical load, achieving over 99% SLOs attainment while using less additional resources.", "AI": {"tldr": "DOPD\u662f\u4e00\u4e2a\u52a8\u6001LLM\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9e\u65f6\u76d1\u63a7\u8d1f\u8f7d\u52a8\u6001\u8c03\u6574\u9884\u586b\u5145\u548c\u89e3\u7801\u5b9e\u4f8b\u5206\u914d\u6bd4\u4f8b\uff0c\u89e3\u51b3\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u751f\u4ea7\u8005-\u6d88\u8d39\u8005\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u7cfb\u7edf\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u7cfb\u7edf\u5c06\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u5206\u79bb\u5230\u4e0d\u540cGPU\u4e0a\uff0c\u4f46\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u5bfc\u81f4\u4e24\u79cd\u5b9e\u4f8b\u7c7b\u578b\u4e4b\u95f4\u7684\u751f\u4ea7\u8005-\u6d88\u8d39\u8005\u4e0d\u5e73\u8861\uff0c\u9020\u6210\u8d44\u6e90\u5206\u914d\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51faDOPD\u7cfb\u7edf\uff0c\u57fa\u4e8e\u5b9e\u65f6\u8d1f\u8f7d\u76d1\u63a7\u52a8\u6001\u8c03\u6574\u9884\u586b\u5145\u4e0e\u89e3\u7801\u5b9e\u4f8b\u7684\u6700\u4f18\u6bd4\u4f8b\uff0c\u7ed3\u5408\u9002\u5f53\u7684\u8bf7\u6c42\u8c03\u5ea6\u7b56\u7565\uff0c\u89e3\u51b3\u9ad8\u5e76\u53d1\u4e0b\u6df7\u5408\u957f\u5ea6\u8bf7\u6c42\u5bfc\u81f4\u7684\u8d44\u6e90\u5206\u914d\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u76f8\u6bd4vLLM\u548cDistServe\uff0cDOPD\u5c06\u7cfb\u7edf\u541e\u5410\u91cf\u63d0\u5347\u6700\u9ad81.5\u500d\uff0cP90\u9996\u8bcd\u5ef6\u8fdf\u964d\u4f4e67.5%\uff0cP90\u6bcf\u8bcd\u8f93\u51fa\u5ef6\u8fdf\u964d\u4f4e22.8%\uff0c\u4f7f\u7528\u66f4\u5c11\u989d\u5916\u8d44\u6e90\u5b9e\u73b0\u8d85\u8fc799%\u7684SLO\u8fbe\u6210\u7387\u3002", "conclusion": "DOPD\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u9884\u586b\u5145\u4e0e\u89e3\u7801\u5b9e\u4f8b\u6bd4\u4f8b\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2511.20694", "categories": ["cs.AI", "astro-ph.SR", "cs.LG", "physics.space-ph"], "pdf": "https://arxiv.org/pdf/2511.20694", "abs": "https://arxiv.org/abs/2511.20694", "authors": ["Kevin Lee", "Russell Spiewak", "James Walsh"], "title": "Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning", "comment": "Accepted at NeurIPS 2025 Machine Learning and the Physical Sciences (ML4PS) Workshop. Dataset: https://huggingface.co/datasets/SpaceML/ReasoningWithAStar", "summary": "Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a'Reasoning With a Star'\u7684\u65e5\u7403\u7269\u7406\u5b66\u63a8\u7406\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8e\u7cfb\u7edf\u5de5\u7a0b\u539f\u5219\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5728\u9700\u8981\u6f14\u7ece\u63a8\u7406\u7684\u95ee\u9898\u4e0a\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\u3002", "motivation": "\u89e3\u51b3\u65e5\u7403\u7269\u7406\u5b66\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u79d1\u5b66\u63a8\u7406\u7684\u6311\u6218\uff0c\u5305\u62ec\u6574\u5408\u7269\u7406\u5047\u8bbe\u3001\u4fdd\u6301\u5355\u4f4d\u4e00\u81f4\u6027\u548c\u63d0\u4f9b\u6e05\u6670\u79d1\u5b66\u683c\u5f0f\u7684\u9700\u6c42\u3002", "method": "\u6784\u5efa\u57fa\u4e8eNASA\u548cUCAR Living With a Star\u6691\u671f\u5b66\u6821\u95ee\u9898\u96c6\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u95ee\u9898\u4e0a\u4e0b\u6587\u3001\u63a8\u7406\u6b65\u9aa4\u3001\u9884\u671f\u7b54\u6848\u7c7b\u578b\u7b49\uff1b\u5f00\u53d1\u7a0b\u5e8f\u5316\u8bc4\u5206\u5668\uff0c\u4f7f\u7528\u5355\u4f4d\u611f\u77e5\u6570\u503c\u5bb9\u5dee\u3001\u7b26\u53f7\u7b49\u4ef7\u6027\u548c\u6a21\u5f0f\u9a8c\u8bc1\uff1b\u57fa\u51c6\u6d4b\u8bd5\u5305\u62ec\u5355\u6b21\u63d0\u793a\u57fa\u7ebf\u548c\u56db\u79cd\u591a\u667a\u80fd\u4f53\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u901a\u8fc7\u7cfb\u7edf\u5de5\u7a0b\u539f\u5219\u5206\u89e3\u5de5\u4f5c\u6d41\u5728\u9700\u8981\u6f14\u7ece\u63a8\u7406\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\uff0c\u800c\u5728\u7eaf\u5f52\u7eb3\u56de\u5fc6\u95ee\u9898\u4e0a\u5dee\u5f02\u4e0d\u660e\u663e\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u6f14\u7ece\u63a8\u7406\u7684\u573a\u666f\u4e0b\u3002"}}
{"id": "2511.20695", "categories": ["cs.AI", "cs.CY", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.20695", "abs": "https://arxiv.org/abs/2511.20695", "authors": ["Yunqi Zhang", "Kuangyu Shi", "Biao Li"], "title": "A Brief History of Digital Twin Technology", "comment": "21 pages, 1 figure, 1 table", "summary": "Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.", "AI": {"tldr": "\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4eceNASA\u822a\u5929\u5668\u6a21\u62df\u53d1\u5c55\u800c\u6765\uff0c\u73b0\u5df2\u5728\u533b\u7597\u9886\u57df\u5b9e\u73b0\u8f6c\u578b\u5e94\u7528\u3002\u5b83\u901a\u8fc7\u5b9e\u65f6\u6570\u636e\u521b\u5efa\u60a3\u8005\u7279\u5f02\u6027\u865a\u62df\u6a21\u578b\uff0c\u652f\u6301\u8bca\u65ad\u3001\u6cbb\u7597\u89c4\u5212\u548c\u836f\u7269\u5f00\u53d1\u3002\u4ee3\u8868\u6027\u5e94\u7528\u5305\u62ec\u5fc3\u810f\u3001\u80bf\u7624\u548c\u836f\u7406\u5b66\u6570\u5b57\u5b6a\u751f\u3002\u5c3d\u7ba1\u9762\u4e34\u4e92\u64cd\u4f5c\u6027\u3001\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u4fdd\u771f\u5ea6\u7b49\u6311\u6218\uff0c\u4f46\u53ef\u89e3\u91caAI\u3001\u8054\u90a6\u5b66\u4e60\u7b49\u65b0\u5174\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u524d\u8fdb\u8def\u5f84\u3002", "motivation": "\u63a8\u52a8\u533b\u7597\u4ece\u88ab\u52a8\u6cbb\u7597\u5411\u9884\u6d4b\u6027\u3001\u9884\u9632\u6027\u548c\u4e2a\u6027\u5316\u533b\u7597\u8f6c\u53d8\uff0c\u5229\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u6574\u5408\u591a\u6e90\u6570\u636e\uff0c\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u533b\u7597\u51b3\u7b56\u548c\u4e2a\u6027\u5316\u6cbb\u7597\u3002", "method": "\u901a\u8fc7\u6574\u5408\u533b\u5b66\u5f71\u50cf\u3001\u751f\u7269\u4f20\u611f\u5668\u548c\u8ba1\u7b97\u6a21\u578b\uff0c\u6784\u5efa\u6570\u636e\u9a71\u52a8\u7684\u52a8\u6001\u865a\u62df\u60a3\u8005\u6a21\u578b\uff0c\u5b9e\u73b0\u4e0e\u7269\u7406\u7cfb\u7edf\u7684\u53cc\u5411\u4ea4\u4e92\u548c\u5b9e\u65f6\u66f4\u65b0\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u5fc3\u810f\u6570\u5b57\u5b6a\u751f\u9884\u6d4b\u5fc3\u5f8b\u5931\u5e38\u6cbb\u7597\u7ed3\u679c\u3001\u80bf\u7624\u6570\u5b57\u5b6a\u751f\u8ffd\u8e2a\u80bf\u7624\u8fdb\u5c55\u548c\u4f18\u5316\u653e\u7597\u3001\u836f\u7406\u5b66\u6570\u5b57\u5b6a\u751f\u52a0\u901f\u836f\u7269\u53d1\u73b0\u7b49\u4ee3\u8868\u6027\u5e94\u7528\u3002", "conclusion": "\u6570\u5b57\u5b6a\u751f\u6280\u672f\u6709\u671b\u5f7b\u5e95\u6539\u53d8\u533b\u7597\u6a21\u5f0f\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u4e92\u64cd\u4f5c\u6027\u3001\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u4fdd\u771f\u5ea6\u7b49\u6311\u6218\uff0c\u672a\u6765\u53d1\u5c55\u65b9\u5411\u5305\u62ec\u591a\u5668\u5b98\u6570\u5b57\u5b6a\u751f\u3001\u57fa\u56e0\u7ec4\u5b66\u6574\u5408\u548c\u4f26\u7406\u6cbb\u7406\u6846\u67b6\u7684\u5b8c\u5584\u3002"}}
{"id": "2511.21413", "categories": ["cs.DC", "cs.AI", "cs.DB", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.21413", "abs": "https://arxiv.org/abs/2511.21413", "authors": ["Tim Trappen", "Robert Ke\u00dfler", "Roland Pabel", "Viktor Achter", "Stefan Wesner"], "title": "Automated Dynamic AI Inference Scaling on HPC-Infrastructure: Integrating Kubernetes, Slurm and vLLM", "comment": "6 pages, 3 figures", "summary": "Due to rising demands for Artificial Inteligence (AI) inference, especially in higher education, novel solutions utilising existing infrastructure are emerging. The utilisation of High-Performance Computing (HPC) has become a prevalent approach for the implementation of such solutions. However, the classical operating model of HPC does not adapt well to the requirements of synchronous, user-facing dynamic AI application workloads. In this paper, we propose our solution that serves LLMs by integrating vLLM, Slurm and Kubernetes on the supercomputer \\textit{RAMSES}. The initial benchmark indicates that the proposed architecture scales efficiently for 100, 500 and 1000 concurrent requests, incurring only an overhead of approximately 500 ms in terms of end-to-end latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8d85\u7ea7\u8ba1\u7b97\u673aRAMSES\u4e0a\u96c6\u6210vLLM\u3001Slurm\u548cKubernetes\u6765\u670d\u52a1LLM\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u80fd\u591f\u9ad8\u6548\u6269\u5c55\u4ee5\u5904\u7406100-1000\u4e2a\u5e76\u53d1\u8bf7\u6c42\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u4ec5\u589e\u52a0\u7ea6500\u6beb\u79d2\u3002", "motivation": "\u7531\u4e8eAI\u63a8\u7406\u9700\u6c42\u589e\u957f\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7b49\u6559\u80b2\u9886\u57df\uff0c\u9700\u8981\u5229\u7528\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\u7684\u65b0\u89e3\u51b3\u65b9\u6848\u3002\u4f20\u7edfHPC\u64cd\u4f5c\u6a21\u578b\u4e0d\u9002\u7528\u4e8e\u540c\u6b65\u3001\u9762\u5411\u7528\u6237\u7684\u52a8\u6001AI\u5e94\u7528\u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "\u5728\u8d85\u7ea7\u8ba1\u7b97\u673aRAMSES\u4e0a\u96c6\u6210vLLM\u3001Slurm\u548cKubernetes\u6765\u670d\u52a1\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u3002", "result": "\u521d\u6b65\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u67b6\u6784\u80fd\u591f\u9ad8\u6548\u6269\u5c55\u5904\u7406100\u3001500\u548c1000\u4e2a\u5e76\u53d1\u8bf7\u6c42\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u4ec5\u589e\u52a0\u7ea6500\u6beb\u79d2\u3002", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u67b6\u6784\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edfHPC\u5728AI\u63a8\u7406\u5e94\u7528\u4e2d\u7684\u9002\u5e94\u6027\u6311\u6218\uff0c\u4e3a\u5927\u89c4\u6a21LLM\u670d\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21431", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.21431", "abs": "https://arxiv.org/abs/2511.21431", "authors": ["Lu Zhao", "Rong Shi", "Shaoqing Zhang", "Yueqiang Chen", "Baoguo He", "Hongfeng Sun", "Ziqing Yin", "Shangchao Su", "Zhiyan Cui", "Liang Dong", "Xiyuan Li", "Lingbin Wang", "Jianwei He", "Jiesong Ma", "Weikang Huang", "Jianglei Tong", "Dongdong Gao", "Jian Zhang", "Hong Tian"], "title": "MemFine: Memory-Aware Fine-Grained Scheduling for MoE Training", "comment": null, "summary": "The training of large-scale Mixture of Experts (MoE) models faces a critical memory bottleneck due to severe load imbalance caused by dynamic token routing. This imbalance leads to memory overflow on GPUs with limited capacity, constraining model scalability. Existing load balancing methods, which cap expert capacity, compromise model accuracy and fail on memory-constrained hardware. To address this, we propose MemFine, a memory-aware fine-grained scheduling framework for MoE training. MemFine decomposes the token distribution and expert computation into manageable chunks and employs a chunked recomputation strategy, dynamically optimized through a theoretical memory model to balance memory efficiency and throughput. Experiments demonstrate that MemFine reduces activation memory by 48.03% and improves throughput by 4.42% compared to full recomputation-based baselines, enabling stable large-scale MoE training on memory-limited GPUs.", "AI": {"tldr": "MemFine\u662f\u4e00\u4e2a\u5185\u5b58\u611f\u77e5\u7684\u7ec6\u7c92\u5ea6\u8c03\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3MoE\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5757\u91cd\u8ba1\u7b97\u7b56\u7565\u51cf\u5c1148.03%\u7684\u6fc0\u6d3b\u5185\u5b58\u5e76\u63d0\u53474.42%\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u5927\u89c4\u6a21MoE\u6a21\u578b\u8bad\u7ec3\u9762\u4e34\u4e25\u91cd\u7684\u5185\u5b58\u74f6\u9888\uff0c\u7531\u4e8e\u52a8\u6001\u4ee4\u724c\u8def\u7531\u5bfc\u81f4\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u4f1a\u9020\u6210GPU\u5185\u5b58\u6ea2\u51fa\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u3002\u73b0\u6709\u8d1f\u8f7d\u5e73\u8861\u65b9\u6cd5\u4f1a\u727a\u7272\u6a21\u578b\u7cbe\u5ea6\u4e14\u5728\u5185\u5b58\u53d7\u9650\u786c\u4ef6\u4e0a\u5931\u6548\u3002", "method": "MemFine\u5c06\u4ee4\u724c\u5206\u5e03\u548c\u4e13\u5bb6\u8ba1\u7b97\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5757\uff0c\u91c7\u7528\u5206\u5757\u91cd\u8ba1\u7b97\u7b56\u7565\uff0c\u901a\u8fc7\u7406\u8bba\u5185\u5b58\u6a21\u578b\u52a8\u6001\u4f18\u5316\u4ee5\u5e73\u8861\u5185\u5b58\u6548\u7387\u548c\u541e\u5410\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u4e8e\u5b8c\u5168\u91cd\u8ba1\u7b97\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0cMemFine\u51cf\u5c11\u4e8648.03%\u7684\u6fc0\u6d3b\u5185\u5b58\uff0c\u63d0\u9ad8\u4e864.42%\u7684\u541e\u5410\u91cf\uff0c\u80fd\u591f\u5728\u5185\u5b58\u53d7\u9650\u7684GPU\u4e0a\u5b9e\u73b0\u7a33\u5b9a\u7684\u5927\u89c4\u6a21MoE\u8bad\u7ec3\u3002", "conclusion": "MemFine\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86MoE\u8bad\u7ec3\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u5185\u5b58\u611f\u77e5\u7684\u7ec6\u7c92\u5ea6\u8c03\u5ea6\u5b9e\u73b0\u4e86\u5185\u5b58\u6548\u7387\u548c\u8bad\u7ec3\u541e\u5410\u91cf\u7684\u5e73\u8861\uff0c\u4e3a\u5927\u89c4\u6a21MoE\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.20701", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20701", "abs": "https://arxiv.org/abs/2511.20701", "authors": ["Nitya Tiwari", "Parv Maheshwari", "Vidisha Agarwal"], "title": "Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework", "comment": null, "summary": "While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.", "AI": {"tldr": "\u672c\u6587\u5bf9\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u63a8\u7406\u8fdb\u884c\u4e86\u7efc\u5408\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u5176\u5728A-OKVQA\u3001OKVQA\u548cChartQA\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u89c6\u89c9\u96c6\u6210\u80fd\u51cf\u5c11\u63a8\u7406\u5e7b\u89c9\uff0c\u4f46\u601d\u7ef4\u94fe\u63a8\u7406\u6548\u679c\u5728\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u95f4\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u867d\u7136\u6700\u8fd1\u5de5\u4f5c\u5c06\u601d\u7ef4\u94fe\u6269\u5c55\u5230\u591a\u6a21\u6001\u8bbe\u7f6e\u5e76\u5728\u79d1\u5b66\u95ee\u7b54\u57fa\u51c6\u4e0a\u53d6\u5f97\u5148\u8fdb\u7ed3\u679c\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4e0d\u540c\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u4ecd\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u8bc4\u4f30\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u63a8\u7406\u5728\u9700\u8981\u5e7f\u6cdb\u5e38\u8bc6\u548c\u4e16\u754c\u77e5\u8bc6\u7684\u8de8\u9886\u57df\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528Zhang\u7b49\u4eba\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u751f\u6210\u4e0e\u7b54\u6848\u63a8\u65ad\u5206\u79bb\uff0c\u5e76\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u673a\u5236\u5c06\u89c6\u89c9\u7279\u5f81\u4e0e\u57fa\u4e8eT5\u7684\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u3002\u901a\u8fc7\u7cfb\u7edf\u6d88\u878d\u7814\u7a76\u5206\u6790\u89c6\u89c9\u7279\u5f81\u3001\u63a8\u7406\u8d28\u91cf\u548c\u67b6\u6784\u9009\u62e9\u7684\u8d21\u732e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u89c6\u89c9\u96c6\u6210\u663e\u8457\u51cf\u5c11\u63a8\u7406\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\uff0c\u4f46\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6709\u6548\u6027\u5728\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u95f4\u5dee\u5f02\u5f88\u5927\uff0c\u5e38\u8bc6\u63a8\u7406\u5c24\u5176\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\u5b9e\u73b0\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u5e76\u786e\u5b9a\u4e86\u8de8\u9886\u57df\u6cdb\u5316\u672a\u6765\u6539\u8fdb\u7684\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2511.21535", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.21535", "abs": "https://arxiv.org/abs/2511.21535", "authors": ["Morteza Sadeghi"], "title": "Modeling the Effect of Data Redundancy on Speedup in MLFMA Near-Field Computation", "comment": null, "summary": "The near-field (P2P) operator in the Multilevel Fast Multipole Algorithm (MLFMA) is a performance bottleneck on GPUs due to poor memory locality. This work introduces data redundancy to improve spatial locality by reducing memory access dispersion. For validation of results, we propose an analytical model based on a Locality metric that combines data volume and access dispersion to predict speedup trends without hardware-specific profiling. The approach is validated on two MLFMA-based applications: an electromagnetic solver (DBIM-MLFMA) with regular structure, and a stellar dynamics code (PhotoNs-2.0) with irregular particle distribution. Results show up to 7X kernel speedup due to improved cache behavior. However, increased data volume raises overheads in data restructuring, limiting end-to-end application speedup to 1.04X. While the model cannot precisely predict absolute speedups, it reliably captures performance trends across different problem sizes and densities. The technique is injectable into existing implementations with minimal code changes. This work demonstrates that data redundancy can enhance GPU performance for P2P operator, provided locality gains outweigh data movement costs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u6570\u636e\u5197\u4f59\u6539\u5584MLFMA\u4e2d\u8fd1\u573a\u7b97\u5b50\u7684GPU\u6027\u80fd\uff0c\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\u5206\u6563\u6027\u4ee5\u63d0\u9ad8\u7a7a\u95f4\u5c40\u90e8\u6027\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u5c40\u90e8\u6027\u5ea6\u91cf\u7684\u5206\u6790\u6a21\u578b\u9884\u6d4b\u6027\u80fd\u8d8b\u52bf\u3002", "motivation": "MLFMA\u4e2d\u7684\u8fd1\u573a\u7b97\u5b50\u5728GPU\u4e0a\u7531\u4e8e\u5185\u5b58\u5c40\u90e8\u6027\u5dee\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u9700\u8981\u6539\u5584\u5176\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u3002", "method": "\u5f15\u5165\u6570\u636e\u5197\u4f59\u6765\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\u5206\u6563\u6027\uff0c\u63d0\u9ad8\u7a7a\u95f4\u5c40\u90e8\u6027\uff1b\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u91cf\u548c\u8bbf\u95ee\u5206\u6563\u6027\u7684\u5c40\u90e8\u6027\u5ea6\u91cf\u5206\u6790\u6a21\u578b\u6765\u9884\u6d4b\u6027\u80fd\u8d8b\u52bf\u3002", "result": "\u5728DBIM-MLFMA\u548cPhotoNs-2.0\u4e24\u4e2a\u5e94\u7528\u4e0a\u9a8c\u8bc1\uff0c\u5185\u6838\u901f\u5ea6\u63d0\u5347\u6700\u9ad8\u8fbe7\u500d\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u91cd\u7ec4\u5f00\u9500\uff0c\u7aef\u5230\u7aef\u5e94\u7528\u52a0\u901f\u6bd4\u9650\u5236\u57281.04\u500d\u3002\u6a21\u578b\u80fd\u53ef\u9760\u6355\u6349\u4e0d\u540c\u95ee\u9898\u89c4\u6a21\u548c\u5bc6\u5ea6\u4e0b\u7684\u6027\u80fd\u8d8b\u52bf\u3002", "conclusion": "\u6570\u636e\u5197\u4f59\u53ef\u4ee5\u63d0\u5347GPU\u4e0a\u8fd1\u573a\u7b97\u5b50\u7684\u6027\u80fd\uff0c\u524d\u63d0\u662f\u5c40\u90e8\u6027\u6536\u76ca\u8d85\u8fc7\u6570\u636e\u79fb\u52a8\u6210\u672c\u3002\u8be5\u65b9\u6cd5\u53ef\u6700\u5c0f\u5316\u4ee3\u7801\u4fee\u6539\u6ce8\u5165\u73b0\u6709\u5b9e\u73b0\u3002"}}
{"id": "2511.20892", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20892", "abs": "https://arxiv.org/abs/2511.20892", "authors": ["Xuyuan Liu", "Zhengzhang Chen", "Xinshuai Dong", "Yanchi Liu", "Xujiang Zhao", "Shengyu Chen", "Haoyu Wang", "Yujun Yan", "Haifeng Chen"], "title": "Representation Interventions Enable Lifelong Unstructured Knowledge Control", "comment": "18 Page", "summary": "Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.", "AI": {"tldr": "RILKE\u662f\u4e00\u79cd\u5728\u5927\u8bed\u8a00\u6a21\u578b\u8868\u793a\u7a7a\u95f4\u8fdb\u884c\u5e72\u9884\u7684\u77e5\u8bc6\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u6a21\u5757\u5316\u7ec4\u4ef6\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u7f16\u8f91\uff0c\u5728\u4fdd\u6301\u57fa\u7840\u6743\u91cd\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u652f\u6301\u5927\u89c4\u6a21\u7ec8\u8eab\u77e5\u8bc6\u66f4\u65b0\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u9519\u8bef\u6216\u8fc7\u65f6\u7684\u95ee\u9898\uff0c\u907f\u514d\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\uff0c\u5728\u7ec8\u8eab\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u591a\u77e5\u8bc6\u7f16\u8f91\u5171\u5b58\u4e14\u4e92\u4e0d\u5e72\u6270\u3002", "method": "\u5728\u6a21\u578b\u8868\u793a\u7a7a\u95f4\u8fdb\u884c\u5e72\u9884\uff0c\u8bad\u7ec3\u5177\u6709\u6297\u91ca\u4e49\u6027\u548c\u7f16\u8f91\u5c40\u90e8\u6027\u7684\u6a21\u5757\uff0c\u5c06\u6bcf\u4e2a\u66f4\u65b0\u9650\u5236\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4ee5\u51cf\u5c11\u4ea4\u53c9\u5e72\u6270\uff0c\u63a8\u7406\u65f6\u901a\u8fc7\u67e5\u8be2\u81ea\u9002\u5e94\u8def\u7531\u5668\u9009\u62e9\u9002\u5f53\u6a21\u5757\u3002", "result": "\u5728LLaMA\u548cQwen\u6a21\u578b\u7684\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRILKE\u53ef\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u8868\u73b0\u51fa\u9ad8\u7f16\u8f91\u6210\u529f\u7387\u3001\u5f3a\u91ca\u4e49\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4ee5\u9002\u5ea6\u5185\u5b58\u5f00\u9500\u4fdd\u6301\u901a\u7528\u6548\u7528\u3002", "conclusion": "RILKE\u662f\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7ec8\u8eab\u77e5\u8bc6\u63a7\u5236\u7684\u6709\u6548\u4e14\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20937", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20937", "abs": "https://arxiv.org/abs/2511.20937", "authors": ["Qineng Wang", "Wenlong Huang", "Yu Zhou", "Hang Yin", "Tianwei Bao", "Jianwen Lyu", "Weiyu Liu", "Ruohan Zhang", "Jiajun Wu", "Li Fei-Fei", "Manling Li"], "title": "ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction", "comment": "Preprint version", "summary": "Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.", "AI": {"tldr": "ENACT\u662f\u4e00\u4e2a\u8bc4\u4f30\u5177\u8eab\u8ba4\u77e5\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u89c6\u89c9\u95ee\u7b54\u5f62\u5f0f\u8bc4\u4f30\u6a21\u578b\u4ece\u81ea\u6211\u4e2d\u5fc3\u4ea4\u4e92\u4e2d\u8fdb\u884c\u4e16\u754c\u5efa\u6a21\u7684\u80fd\u529b\uff0c\u5305\u542b\u524d\u5411\u4e16\u754c\u5efa\u6a21\u548c\u9006\u5411\u4e16\u754c\u5efa\u6a21\u4e24\u4e2a\u4efb\u52a1\u3002", "motivation": "\u63a2\u7d22\u73b0\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u662f\u5426\u8868\u73b0\u51fa\u5177\u8eab\u8ba4\u77e5\u7684\u8ff9\u8c61\uff0c\u5373\u667a\u80fd\u662f\u5426\u6e90\u4e8e\u611f\u89c9\u8fd0\u52a8\u4ea4\u4e92\u800c\u975e\u88ab\u52a8\u89c2\u5bdf\u3002", "method": "\u5c06\u5177\u8eab\u8ba4\u77e5\u8bc4\u4f30\u6784\u5efa\u4e3a\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u4e16\u754c\u5efa\u6a21\u95ee\u9898\uff0c\u4f7f\u7528\u6765\u81ea\u673a\u5668\u4eba\u4eff\u771f(BEHAVIOR)\u7684\u53ef\u6269\u5c55\u6d41\u6c34\u7ebf\u5408\u6210\u95ee\u7b54\u5bf9\uff0c\u5305\u542b\u524d\u5411\u4e16\u754c\u5efa\u6a21(\u7ed9\u5b9a\u52a8\u4f5c\u91cd\u6392\u89c2\u5bdf\u5e8f\u5217)\u548c\u9006\u5411\u4e16\u754c\u5efa\u6a21(\u7ed9\u5b9a\u89c2\u5bdf\u91cd\u6392\u52a8\u4f5c\u5e8f\u5217)\u4e24\u4e2a\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u524d\u6cbf\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e4b\u95f4\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u4e14\u5dee\u8ddd\u968f\u4ea4\u4e92\u65f6\u95f4\u8de8\u5ea6\u589e\u52a0\u800c\u6269\u5927\uff1b\u6a21\u578b\u5728\u9006\u5411\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u524d\u5411\u4efb\u52a1\uff0c\u5e76\u8868\u73b0\u51fa\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u504f\u89c1\uff0c\u5982\u504f\u597d\u53f3\u624b\u52a8\u4f5c\u3001\u5f53\u76f8\u673a\u53c2\u6570\u6216\u89c6\u89d2\u504f\u79bb\u4eba\u7c7b\u89c6\u89c9\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "ENACT\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u73b0\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eab\u8ba4\u77e5\u80fd\u529b\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u7406\u89e3\u548c\u53d1\u5c55\u5177\u8eab\u667a\u80fd\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2511.20942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20942", "abs": "https://arxiv.org/abs/2511.20942", "authors": ["Rahul Dass", "Thomas Bowlin", "Zebing Li", "Xiao Jin", "Ashok Goel"], "title": "Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture", "comment": null, "summary": "In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for \"how\" and \"why\" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.", "AI": {"tldr": "Ivy\u662f\u4e00\u4e2aAI\u6559\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u5316\u7684TMK\u6a21\u578b\u548c\u751f\u6210\u5f0f\u89e3\u91ca\u5c42\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u591a\u6b65\u9aa4\u7684\u89e3\u91ca\uff0c\u6539\u5584LLM\u751f\u6210\u89e3\u91ca\u7684\u7ed3\u6784\u8d28\u91cf\u3002", "motivation": "\u5728\u7a0b\u5e8f\u6027\u6280\u80fd\u5b66\u4e60\u4e2d\uff0c\u6559\u5b66\u89e3\u91ca\u4e0d\u4ec5\u8981\u4f20\u8fbe\u6b65\u9aa4\uff0c\u8fd8\u8981\u4f20\u8fbe\u80cc\u540e\u7684\u56e0\u679c\u3001\u76ee\u6807\u5bfc\u5411\u548c\u7ec4\u5408\u903b\u8f91\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u4ea7\u751f\u6d41\u7545\u4f46\u6d45\u5c42\u7684\u54cd\u5e94\uff0c\u7f3a\u4e4f\u8fd9\u79cd\u7ed3\u6784\u3002", "method": "Ivy\u7cfb\u7edf\u7ed3\u5408\u7b26\u53f7\u5316\u7684\u4efb\u52a1-\u65b9\u6cd5-\u77e5\u8bc6(TMK)\u6a21\u578b\u4e0e\u751f\u6210\u5f0f\u89e3\u91ca\u5c42\uff0cTMK\u7f16\u7801\u56e0\u679c\u8f6c\u6362\u3001\u76ee\u6807\u5c42\u6b21\u548c\u95ee\u9898\u5206\u89e3\uff0c\u6307\u5bfcLLM\u5728\u660e\u786e\u7684\u7ed3\u6784\u8fb9\u754c\u5185\u6784\u5efa\u89e3\u91ca\u3002", "result": "\u4e0eGPT\u548c\u68c0\u7d22\u589e\u5f3aGPT\u57fa\u7ebf\u76f8\u6bd4\uff0cIvy\u5728\u4e09\u4e2a\u63a8\u7406\u7ef4\u5ea6\u4e0a\u901a\u8fc7\u4e13\u5bb6\u548c\u72ec\u7acb\u6807\u6ce8\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u7b26\u53f7\u7ea6\u675f\u6301\u7eed\u6539\u5584\u4e86\"\u5982\u4f55\"\u548c\"\u4e3a\u4ec0\u4e48\"\u95ee\u9898\u7684\u89e3\u91ca\u7ed3\u6784\u8d28\u91cf\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684AI\u6559\u80b2\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b26\u53f7\u7ea6\u675f\u589e\u5f3a\u4e86AI\u751f\u6210\u89e3\u91ca\u5728\u667a\u80fd\u6559\u7ec3\u7cfb\u7edf\u4e2d\u7684\u6559\u5b66\u4ef7\u503c\u3002"}}
{"id": "2511.21005", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.21005", "abs": "https://arxiv.org/abs/2511.21005", "authors": ["Jinpeng Wang", "Chao Li", "Ting Ye", "Mengyuan Zhang", "Wei Liu", "Jian Luan"], "title": "ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5ICPO\uff0c\u901a\u8fc7\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u81ea\u8eab\u751f\u6210\u6982\u7387\u7684\u5185\u5728\u7f6e\u4fe1\u5ea6\u548c\u53ef\u9a8c\u8bc1\u5956\u52b1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709RLVR\u65b9\u6cd5\u4e2d\u7c97\u7c92\u5ea6\u5956\u52b1\u3001\u5956\u52b1\u566a\u58f0\u548c\u4f4e\u6548\u63a2\u7d22\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684RLVR\u65b9\u6cd5\u5b58\u5728\u7c97\u7c92\u5ea6\u5956\u52b1\u3001\u5956\u52b1\u566a\u58f0\u548c\u4f4e\u6548\u63a2\u7d22\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u71b5\u5d29\u6e83\uff0c\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51faICPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u591a\u4e2a\u54cd\u5e94\u5728\u540c\u4e00\u8f93\u5165\u63d0\u793a\u4e0b\u7684\u76f8\u5bf9\u751f\u6210\u6982\u7387\u6765\u83b7\u5f97\u504f\u597d\u4f18\u52bf\u5206\u6570\uff0c\u5e76\u5c06\u8be5\u5206\u6570\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7ed3\u5408\u6765\u6307\u5bfc\u63a2\u7d22\u8fc7\u7a0b\u3002", "result": "\u5728\u56db\u4e2a\u901a\u7528\u9886\u57df\u57fa\u51c6\u548c\u4e09\u4e2a\u6570\u5b66\u57fa\u51c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cICPO\u76f8\u6bd4GRPO\u80fd\u591f\u7a33\u5b9a\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "ICPO\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5728\u7f6e\u4fe1\u5ea6\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5956\u52b1\u76f8\u5173\u95ee\u9898\uff0c\u6291\u5236\u4e86\u8fc7\u5ea6\u81ea\u4fe1\u9519\u8bef\uff0c\u589e\u5f3a\u4e86\u88ab\u4f4e\u4f30\u7684\u9ad8\u8d28\u91cf\u54cd\u5e94\u7684\u76f8\u5bf9\u4f18\u52bf\uff0c\u4fc3\u8fdb\u4e86\u66f4\u5f7b\u5e95\u7684\u63a2\u7d22\u3002"}}
{"id": "2511.21260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21260", "abs": "https://arxiv.org/abs/2511.21260", "authors": ["Joseph Y. Halpern", "Rafael Pass"], "title": "Causality Without Causal Models", "comment": "In Proceedings TARK 2025, arXiv:2511.20540", "summary": "Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.", "AI": {"tldr": "\u672c\u6587\u5bf9Halpern\u548cPearl\u7684\u5b9e\u9645\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\u8fdb\u884c\u4e86\u62bd\u8c61\u5316\uff0c\u63d0\u53d6\u5176\u5173\u952e\u7279\u5f81\uff0c\u4f7f\u5176\u80fd\u591f\u5e94\u7528\u4e8e\u4efb\u4f55\u5b9a\u4e49\u4e86\u53cd\u4e8b\u5b9e\u7684\u6a21\u578b\u3002\u901a\u8fc7\u8fd9\u79cd\u62bd\u8c61\u5316\uff0c\u8be5\u5b9a\u4e49\u53ef\u4ee5\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u6a21\u578b\u548c\u66f4\u590d\u6742\u7684\u516c\u5f0f\u3002", "motivation": "Halpern\u548cPearl\u7684\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\u5c40\u9650\u4e8e\u56e0\u679c\u6a21\u578b\uff0c\u65e0\u6cd5\u5904\u7406\u5305\u542b\u6790\u53d6\u3001\u5426\u5b9a\u3001\u4fe1\u5ff5\u548c\u5d4c\u5957\u53cd\u4e8b\u5b9e\u7684\u590d\u6742\u516c\u5f0f\u3002\u672c\u6587\u65e8\u5728\u62bd\u8c61\u5316\u8be5\u5b9a\u4e49\uff0c\u4f7f\u5176\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u901a\u8fc7\u62bd\u8c61\u5316Halpern-Pearl\u5b9a\u4e49\u7684\u5173\u952e\u7279\u5f81\uff0c\u6784\u5efa\u4e00\u4e2a\u53ef\u4ee5\u5728\u4efb\u4f55\u5b9a\u4e49\u4e86\u53cd\u4e8b\u5b9e\u7684\u6a21\u578b\u4e2d\u5e94\u7528\u7684\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\u6846\u67b6\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u62bd\u8c61\u7684\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\uff0c\u80fd\u591f\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u6a21\u578b\u7c7b\u578b\uff08\u5305\u62ec\u5141\u8bb8\u56de\u6eaf\u7684\u6a21\u578b\uff09\u548c\u66f4\u590d\u6742\u7684\u516c\u5f0f\u7ed3\u6784\u3002", "conclusion": "\u62bd\u8c61\u5316\u7684\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\u4e0d\u4ec5\u6269\u5c55\u4e86\u5e94\u7528\u8303\u56f4\uff0c\u8fd8\u6df1\u5316\u4e86\u5bf9\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\u7279\u5f81\u7684\u7406\u89e3\uff0c\u5e76\u80fd\u8fdb\u4e00\u6b65\u6269\u5c55\u5230\u89e3\u91ca\u7684\u5b9a\u4e49\u3002"}}
{"id": "2511.21417", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21417", "abs": "https://arxiv.org/abs/2511.21417", "authors": ["Mia M\u00fc\u00dfig", "Jan Johannsen"], "title": "New Hybrid Heuristics for Pseudo-Boolean Propagation", "comment": null, "summary": "In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u7528\u4e8e\u4f2a\u5e03\u5c14\u6c42\u89e3\u4e2d\u7684\u6df7\u5408\u5355\u5143\u4f20\u64ad\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86RoundingSAT\u6c42\u89e3\u5668\u7684\u6027\u80fd", "motivation": "\u5f53\u524d\u4f2a\u5e03\u5c14\u6c42\u89e3\u4e2d\u6700\u6210\u529f\u7684\u5355\u5143\u4f20\u64ad\u7b56\u7565\u662f\u7ed3\u5408\u89c2\u5bdf\u6587\u5b57\u65b9\u6848\u548c\u8ba1\u6570\u65b9\u6cd5\u7684\u6df7\u5408\u6a21\u5f0f\uff0c\u4f46\u9700\u8981\u66f4\u597d\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u6765\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528\u54ea\u79cd\u65b9\u6cd5", "method": "\u5f15\u5165\u4e86\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u7528\u4e8e\u6df7\u5408\u51b3\u7b56\uff0c\u5728RoundingSAT\u6c42\u89e3\u5668\u4e2d\u5b9e\u73b0", "result": "\u65b0\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u591f\u5927\u5e45\u8d85\u8d8a\u5f53\u524d\u65b9\u6cd5\u7684\u6027\u80fd", "conclusion": "\u65b0\u63d0\u51fa\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u4f2a\u5e03\u5c14\u6c42\u89e3\u7684\u6df7\u5408\u5355\u5143\u4f20\u64ad\u7b56\u7565\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf"}}
{"id": "2511.21471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21471", "abs": "https://arxiv.org/abs/2511.21471", "authors": ["Peiran Xu", "Sudong Wang", "Yao Zhu", "Jianing Li", "Yunjian Zhang"], "title": "SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition", "comment": null, "summary": "Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u5c42\u7a7a\u95f4\u8ba4\u77e5\u6846\u67b6\uff0c\u5c06\u7a7a\u95f4\u667a\u80fd\u5206\u89e3\u4e3a\u4ece\u57fa\u7840\u89c2\u5bdf\u5230\u9ad8\u7ea7\u89c4\u5212\u7684\u4e94\u4e2a\u6e10\u8fdb\u590d\u6742\u5c42\u6b21\uff0c\u5e76\u6784\u5efa\u4e86SpatialBench\u57fa\u51c6\u6765\u7cfb\u7edf\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u5c06\u7a7a\u95f4\u8ba4\u77e5\u8fc7\u5ea6\u7b80\u5316\u4e3a\u5355\u4e00\u7ef4\u5ea6\u6307\u6807\uff0c\u65e0\u6cd5\u6355\u6349\u7a7a\u95f4\u80fd\u529b\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u76f8\u4e92\u4f9d\u5b58\u5173\u7cfb\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5c42\u7a7a\u95f4\u8ba4\u77e5\u6846\u67b6\uff08\u4e94\u4e2a\u8ba4\u77e5\u5c42\u6b21\uff09\uff0c\u6784\u5efa\u4e86SpatialBench\u57fa\u51c6\uff08\u8986\u76d615\u4e2a\u4efb\u52a1\uff09\uff0c\u5e76\u5f15\u5165\u4e86\u9762\u5411\u80fd\u529b\u7684\u9ad8\u5c42\u6307\u6807\u6765\u7edf\u4e00\u8bc4\u4f30\u5f02\u6784\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u8ba4\u77e5\u5c42\u6b21\u4e0a\u8868\u73b0\u5206\u5c42\uff1a\u611f\u77e5\u57fa\u7840\u80fd\u529b\u5f3a\uff0c\u4f46\u5728\u7b26\u53f7\u63a8\u7406\u3001\u56e0\u679c\u63a8\u65ad\u548c\u89c4\u5212\u65b9\u9762\u4ecd\u6709\u9650\u5236\uff1b\u4eba\u7c7b\u8fdb\u884c\u9009\u62e9\u6027\u76ee\u6807\u5bfc\u5411\u62bd\u8c61\uff0c\u800cMLLMs\u503e\u5411\u4e8e\u8fc7\u5ea6\u5173\u6ce8\u8868\u9762\u7ec6\u8282\u3002", "conclusion": "\u5efa\u7acb\u4e86\u9996\u4e2a\u7cfb\u7edf\u6d4b\u91cfMLLMs\u5206\u5c42\u7a7a\u95f4\u8ba4\u77e5\u7684\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u7a7a\u95f4\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.21522", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21522", "abs": "https://arxiv.org/abs/2511.21522", "authors": ["Yanxing Huang", "Zihan Tang", "Zejin Lin", "Peng Li", "Yang Liu"], "title": "Pessimistic Verification for Open Ended Math Questions", "comment": null, "summary": "The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.", "AI": {"tldr": "\u63d0\u51fa\u60b2\u89c2\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u6784\u5efa\u591a\u4e2a\u9a8c\u8bc1\u6d41\u7a0b\u6765\u68c0\u6d4b\u6570\u5b66\u8bc1\u660e\u9519\u8bef\uff0c\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u6027\u80fd\u4e14\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u4f4e", "motivation": "\u73b0\u6709\u9a8c\u8bc1\u6027\u80fd\u7684\u5173\u952e\u9650\u5236\u5728\u4e8e\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\uff0c\u9700\u8981\u6539\u8fdb\u5f00\u653e\u6570\u5b66\u95ee\u9898\u7684\u9a8c\u8bc1\u65b9\u6cd5", "method": "\u8bbe\u8ba1\u60b2\u89c2\u9a8c\u8bc1\u53d8\u4f53\uff0c\u4e3a\u540c\u4e00\u8bc1\u660e\u6784\u5efa\u591a\u4e2a\u5e76\u884c\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u53ea\u8981\u4efb\u4e00\u9a8c\u8bc1\u62a5\u544a\u9519\u8bef\u5373\u5224\u5b9a\u8bc1\u660e\u4e0d\u6b63\u786e", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u5b66\u9a8c\u8bc1\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u4f4e\uff0ctoken\u6548\u7387\u751a\u81f3\u8d85\u8fc7\u6269\u5c55\u957f\u94fe\u601d\u7ef4\u6d4b\u8bd5\u65f6\u7f29\u653e", "conclusion": "\u60b2\u89c2\u9a8c\u8bc1\u80fd\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u8f93\u51fa\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\uff0c\u5bf9\u5b9e\u73b0\u957f\u7a0b\u6570\u5b66\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u6709\u52a9\u4e8e\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u5728\u5e7f\u6cdb\u4efb\u52a1\u4e2d\u7684\u6570\u5b66\u80fd\u529b"}}
{"id": "2511.21569", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.21569", "abs": "https://arxiv.org/abs/2511.21569", "authors": ["Alex Diep"], "title": "Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit", "comment": null, "summary": "If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a \"Reverse Gell-Mann Amnesia\" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($\u0394R_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($\u03ba= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e8616\u4e2a\u5f00\u6e90\u6a21\u578b\u5728\u4e13\u4e1a\u89d2\u8272\u626e\u6f14\u4e2d\u7684AI\u8eab\u4efd\u62ab\u9732\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u4e13\u4e1a\u9886\u57df\u7684\u8eab\u4efd\u900f\u660e\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u6a21\u578b\u8eab\u4efd\u6bd4\u53c2\u6570\u6570\u91cf\u66f4\u80fd\u9884\u6d4b\u62ab\u9732\u884c\u4e3a\uff0c\u63a8\u7406\u4f18\u5316\u53cd\u800c\u4f1a\u6291\u5236\u900f\u660e\u5ea6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u786e\u4fddAI\u6a21\u578b\u5728\u4e13\u4e1a\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\u80fd\u591f\u53ef\u9760\u5730\u62ab\u9732\u5176AI\u8eab\u4efd\uff0c\u9632\u6b62\u7528\u6237\u56e0\u6a21\u578b\u865a\u5047\u4e13\u4e1a\u80fd\u529b\u800c\u53d7\u5230\u4f24\u5bb3\uff0c\u5efa\u7acb\u53ef\u4fe1\u7684\u80fd\u529b\u8fb9\u754c\u3002", "method": "\u91c7\u7528\u516c\u5171\u82b1\u56ed\u8bbe\u8ba1\uff0c\u5bf916\u4e2a\u5f00\u6e90\u6a21\u578b\uff084B-671B\u53c2\u6570\uff09\u8fdb\u884c\u4e8619,200\u6b21\u8bd5\u9a8c\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u9a8c\u8bc1\u548cRogan-Gladen\u6821\u6b63\u6765\u786e\u4fdd\u6d4b\u91cf\u8bef\u5dee\u7684\u9c81\u68d2\u6027\u3002", "result": "\u6a21\u578b\u5728\u4e0d\u540c\u4e13\u4e1a\u9886\u57df\u7684\u8eab\u4efd\u62ab\u9732\u7387\u5dee\u5f02\u663e\u8457\uff1a\u91d1\u878d\u987e\u95ee\u89d2\u8272\u521d\u59cb\u62ab\u9732\u7387\u4e3a30.8%\uff0c\u800c\u795e\u7ecf\u5916\u79d1\u533b\u751f\u89d2\u8272\u4ec5\u4e3a3.5%\uff1b\u62ab\u9732\u7387\u8303\u56f4\u4ece2.8%\u523073.6%\uff1b\u6a21\u578b\u8eab\u4efd\u6bd4\u53c2\u6570\u6570\u91cf\u66f4\u80fd\u9884\u6d4b\u884c\u4e3a\uff08\u0394R\u00b2adj = 0.359 vs 0.018\uff09\uff1b\u63a8\u7406\u4f18\u5316\u4f1a\u6291\u5236\u900f\u660e\u5ea6\uff0c\u63a8\u7406\u53d8\u4f53\u6bd4\u57fa\u7840\u6a21\u578b\u62ab\u9732\u7387\u964d\u4f4e\u9ad8\u8fbe48.4%\u3002", "conclusion": "\u900f\u660e\u5ea6\u53cd\u6620\u7684\u662f\u8bad\u7ec3\u56e0\u7d20\u800c\u975e\u6a21\u578b\u89c4\u6a21\uff0c\u7ec4\u7ec7\u4e0d\u80fd\u5047\u8bbe\u5b89\u5168\u5c5e\u6027\u4f1a\u8f6c\u79fb\u5230\u90e8\u7f72\u73af\u5883\u4e2d\uff0c\u9700\u8981\u523b\u610f\u8bbe\u8ba1\u884c\u4e3a\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u3002"}}
{"id": "2511.21570", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.21570", "abs": "https://arxiv.org/abs/2511.21570", "authors": ["Maria Perez-Ortiz"], "title": "From Prediction to Foresight: The Role of AI in Designing Responsible Futures", "comment": "Accessible at https://projecteuclid.org/journals/journal-of-artificial-intelligence-for-sustainable-development/volume-1/issue-1/From-Prediction-to-Foresight--The-Role-of-AI-in/10.69828/4d4kja.full", "summary": "In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term \"responsible computational foresight\", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86'\u8d1f\u8d23\u4efb\u7684\u8ba1\u7b97\u9884\u89c1'\u6982\u5ff5\uff0c\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5728\u8d1f\u8d23\u4efb\u9884\u89c1\u4e2d\u7684\u4f5c\u7528\uff0c\u5f3a\u8c03AI\u4f5c\u4e3a\u652f\u6301\u5de5\u5177\u589e\u5f3a\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u548c\u5851\u9020\u53ef\u6301\u7eed\u672a\u6765\u7684\u80fd\u529b\u3002", "motivation": "\u5728\u6280\u672f\u5feb\u901f\u53d1\u5c55\u548c\u5168\u7403\u6311\u6218\u590d\u6742\u7684\u65f6\u4ee3\uff0c\u9700\u8981\u8d1f\u8d23\u4efb\u9884\u89c1\u6846\u67b6\u6765\u5e2e\u52a9\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u5bf9\u672a\u6765\u4e0d\u786e\u5b9a\u6027\u5e76\u5851\u9020\u672a\u6765\u3002", "method": "\u5efa\u7acb\u8d1f\u8d23\u4efb\u8ba1\u7b97\u9884\u89c1\u7684\u57fa\u7840\u539f\u5219\uff0c\u63d0\u51fa\u4e00\u5957AI\u9a71\u52a8\u7684\u9884\u89c1\u5de5\u5177\uff0c\u7ed3\u5408\u6a21\u62df\u548c\u60c5\u666f\u5206\u6790\u6765\u589e\u5f3a\u653f\u7b56\u5236\u5b9a\u80fd\u529b\u3002", "result": "AI\u4e0e\u6a21\u62df\u548c\u60c5\u666f\u5206\u6790\u7ed3\u5408\uff0c\u80fd\u589e\u5f3a\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u3001\u8bc4\u4f30\u98ce\u9669\u548c\u5236\u5b9a\u53ef\u6301\u7eed\u6218\u7565\u7684\u80fd\u529b\u3002", "conclusion": "AI\u5e94\u4f5c\u4e3a\u8d1f\u8d23\u4efb\u3001\u4ee5\u4eba\u4e3a\u672c\u7684\u9884\u89c1\u4e2d\u7684\u652f\u6301\u5de5\u5177\uff0c\u8865\u5145\u800c\u975e\u66ff\u4ee3\u653f\u7b56\u5236\u5b9a\u8005\u7684\u5224\u65ad\uff0c\u4ee5\u4e3b\u52a8\u5851\u9020\u6709\u97e7\u6027\u548c\u9053\u5fb7\u5065\u5168\u7684\u672a\u6765\u3002"}}
