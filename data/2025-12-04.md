<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 4]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [AGENTSAFE: A Unified Framework for Ethical Assurance and Governance in Agentic AI](https://arxiv.org/abs/2512.03180)
*Rafflesia Khan,Declan Joyce,Mansura Habiba*

Main category: cs.MA

TL;DR: AGENTSAFE是一个针对LLM智能体系统的实用治理框架，将AI风险库转化为设计、运行时和审计控制，提供端到端的风险识别和保障机制。


<details>
  <summary>Details</summary>
Motivation: LLM智能体的快速部署带来了新的风险类别，包括自主规划、多步骤工具集成和涌现交互等能力。现有的治理框架要么是静态分类驱动，缺乏从风险识别到操作保障的端到端流程，特别是针对智能体平台。

Method: 提出AGENTSAFE框架，通过分析智能体循环（计划->行动->观察->反思）和工具链，将风险映射到扩展了智能体特定漏洞的结构化分类法中。引入安全约束机制，限制风险行为，将高影响行动升级到人工监督，并通过涵盖安全、隐私、公平性和系统安全的预部署场景库评估系统。

Result: AGENTSAFE在部署期间通过语义遥测、动态授权、异常检测和中断机制确保持续治理。通过加密追溯和组织控制加强来源和问责，实现可测量、可审计的智能体AI系统全生命周期保障。

Conclusion: 本文的主要贡献包括：(1) 将风险分类法转化为可操作的设计、运行时和审计控制的统一治理框架；(2) 提供可测量预部署保障的智能体安全评估方法；(3) 一套运行时治理和问责机制，制度化智能体AI生态系统的信任。

Abstract: The rapid deployment of large language model (LLM)-based agents introduces a new class of risks, driven by their capacity for autonomous planning, multi-step tool integration, and emergent interactions. It raises some risk factors for existing governance approaches as they remain fragmented: Existing frameworks are either static taxonomies driven; however, they lack an integrated end-to-end pipeline from risk identification to operational assurance, especially for an agentic platform. We propose AGENTSAFE, a practical governance framework for LLM-based agentic systems. The framework operationalises the AI Risk Repository into design, runtime, and audit controls, offering a governance framework for risk identification and assurance. The proposed framework, AGENTSAFE, profiles agentic loops (plan -> act -> observe -> reflect) and toolchains, and maps risks onto structured taxonomies extended with agent-specific vulnerabilities. It introduces safeguards that constrain risky behaviours, escalates high-impact actions to human oversight, and evaluates systems through pre-deployment scenario banks spanning security, privacy, fairness, and systemic safety. During deployment, AGENTSAFE ensures continuous governance through semantic telemetry, dynamic authorization, anomaly detection, and interruptibility mechanisms. Provenance and accountability are reinforced through cryptographic tracing and organizational controls, enabling measurable, auditable assurance across the lifecycle of agentic AI systems. The key contributions of this paper are: (1) a unified governance framework that translates risk taxonomies into actionable design, runtime, and audit controls; (2) an Agent Safety Evaluation methodology that provides measurable pre-deployment assurance; and (3) a set of runtime governance and accountability mechanisms that institutionalise trust in agentic AI ecosystems.

</details>


### [2] [A Gossip-Enhanced Communication Substrate for Agentic AI: Toward Decentralized Coordination in Large-Scale Multi-Agent Systems](https://arxiv.org/abs/2512.03285)
*Nafiul I. Khan,Mansura Habiba,Rafflesia Khan*

Main category: cs.MA

TL;DR: 论文探讨将gossip协议作为智能体通信的补充机制，以解决大规模自适应系统中结构化通信协议的局限性，支持去中心化、容错的知识传播和协调。


<details>
  <summary>Details</summary>
Motivation: 随着智能体平台规模扩大，智能体需要超越固定角色和预定义工具链，实现灵活去中心化协调。现有结构化通信协议（如直接消息传递或MCP式工具调用）虽然可靠，但难以支持大规模自适应系统所需的涌现和群体智能。

Method: 重新审视gossip协议作为智能体通信的补充基础。gossip机制在分布式系统中以其去中心化和容错特性著称，能够提供可扩展、自适应的知识传播，填补结构化协议无法高效处理的空白。

Result: 分析了gossip如何支持上下文丰富的状态传播、不确定性下的弹性协调以及涌现的全局意识。同时识别了语义相关性、时间陈旧性、快速变化环境中行动一致性保障有限等挑战。

Conclusion: 本文提出了将gossip集成到多智能体通信栈的研究议程，认为gossip对于未来需要保持鲁棒性、自适应性和自组织性的智能体生态系统至关重要，而非提出完整框架。

Abstract: As agentic platforms scale, agents are moving beyond fixed roles and predefined toolchains, creating an urgent need for flexible and decentralized coordination. Current structured communication protocols such as direct agent-to-agent messaging or MCP-style tool calls offer reliability, but they struggle to support the emergent and swarm-like intelligence required in large adaptive systems. Distributed agents must learn continuously, share context fluidly, and coordinate without depending solely on central planners.
  This paper revisits gossip protocols as a complementary substrate for agentic communication. Gossip mechanisms, long valued in distributed systems for their decentralized and fault-tolerant properties, provide scalable and adaptive diffusion of knowledge and fill gaps that structured protocols alone cannot efficiently address. However, gossip also introduces challenges, including semantic relevance, temporal staleness, and limited guarantees on action consistency in rapidly changing environments.
  We examine how gossip can support context-rich state propagation, resilient coordination under uncertainty, and emergent global awareness. We also outline open problems around semantic filtering, trust, and knowledge decay. Rather than proposing a complete framework, this paper presents a research agenda for integrating gossip into multi-agent communication stacks and argues that gossip is essential for future agentic ecosystems that must remain robust, adaptive, and self-organizing as their scale and autonomy increase.

</details>


### [3] [Local Dominance in Mixed-Strength Populations -- Fast Maximal Independent Set](https://arxiv.org/abs/2512.03303)
*Michael Luby,Sandy Irani*

Main category: cs.MA

TL;DR: 研究混合强度智能体在局部支配竞争中的快速收敛问题，扩展Luby MIS协议到非均匀强度分布，证明混合强度下仍能快速收敛，但动态特性与均匀强度情况有本质差异。


<details>
  <summary>Details</summary>
Motivation: 许多自然和工程系统中，智能体通过局部竞争形成支配关系，这些竞争受内在强度差异影响，常能快速收敛到稳定支配模式。现有Luby MIS协议为均匀强度智能体提供了快速收敛的理论解释，但现实中的智能体通常具有混合强度，需要研究这种更真实情况下的收敛特性。

Method: 提出混合强度智能体模型，每个智能体从自身分布中抽取强度值。扩展Luby MIS协议，使每个智能体重复从自身分布生成强度值，而非统一均匀分布。通过理论分析证明该扩展协议仍能快速收敛，并构造特定种群和强度分布展示异质性如何改变动态特性。

Result: 证明混合强度智能体模型下，扩展的Luby MIS协议仍能快速收敛到稳定支配模式，为观察到的自然过程快速收敛提供形式化验证。同时发现异质性显著改变过程动态：与均匀强度情况不同，每轮不一定消除恒定比例的边，构造了进展速度渐近更慢的实例，展示内在强度不对称如何产生质变全局行为。

Conclusion: 混合强度智能体在局部支配竞争中仍能快速收敛，但异质性会显著改变收敛动态特性。研究为理解现实世界中非均匀强度个体的快速支配模式形成提供了理论框架，揭示了强度分布异质性对全局行为的定性影响。

Abstract: In many natural and engineered systems, agents interact through local contests that determine which individuals become dominant within their neighborhoods. These interactions are shaped by inherent differences in strength, and they often lead to stable dominance patterns that emerge surprisingly quickly relative to the size of the population. This motivates the search for simple mathematical models that capture both heterogeneous agent strength and rapid convergence to stable local dominance.
  A widely studied abstraction of local dominance is the Maximal Independent Set (MIS) problem. In the Luby MIS protocol that provably converges quickly to an MIS, each agent repeatedly generates a strength value chosen uniformly and becomes locally dominant if its value is smaller than those of its neighbors. This provides a theoretical explanation for fast dominance convergence in populations of equal-strength agents and naturally raises the question of whether fast convergence also holds in the more realistic setting where agents are inherently mixed-strength.
  To investigate this question, we introduce the mixed-strength agents model, in which each agent draws its strength from its own distribution. We prove that the extension of the Luby MIS protocol where each agent repeatedly generates a strength value from its own distribution still exhibits fast dominance convergence, providing formal confirmation of the rapid convergence observed in many mixed-strength natural processes.
  We also show that heterogeneity can significantly change the dynamics of the process. In contrast to the equal-strength setting, a constant fraction of edges need not be eliminated per round. We construct a population and strength profile in which progress per round is asymptotically smaller, illustrating how inherent strength asymmetry produces qualitatively different global behavior.

</details>


### [4] [SRPG: Semantically Reconstructed Privacy Guard for Zero-Trust Privacy in Educational Multi-Agent Systems](https://arxiv.org/abs/2512.03694)
*Shuang Guo,Zihui Li*

Main category: cs.MA

TL;DR: SRPG是一种用于教育多智能体系统的隐私保护机制，通过双流重建机制在保护未成年人个人身份信息的同时保持数学教学效果。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的多智能体系统能够实现个性化教育，但存在通过非结构化对话泄露未成年人个人身份信息的风险。现有的隐私保护方法难以平衡安全性和实用性：基于角色的访问控制无法处理非结构化文本，而简单的掩码会破坏教学上下文。

Method: 提出SRPG隐私保护机制，采用双流重建机制：严格的净化流确保零PII泄露，上下文重建流（由LLM驱动）恢复数学逻辑。这种方法将教学内容与私人数据解耦，同时保持教学效果。

Result: 在MathDial数据集上的测试显示，SRPG在不同模型上均有效；使用GPT-4o时，实现了0.0000攻击成功率（零泄露）和0.8267精确匹配率，远优于零信任纯LLM基线的0.2138。

Conclusion: SRPG能够有效保护未成年人隐私，同时不牺牲数学教学质量，为教育多智能体系统提供了实用的隐私保护解决方案。

Abstract: Multi-Agent Systems (MAS) with large language models (LLMs) enable personalized education but risk leaking minors personally identifiable information (PII) via unstructured dialogue. Existing privacy methods struggle to balance security and utility: role-based access control fails on unstructured text, while naive masking destroys pedagogical context. We propose SRPG, a privacy guard for educational MAS, using a Dual-Stream Reconstruction Mechanism: a strict sanitization stream ensures zero PII leakage, and a context reconstruction stream (LLM driven) recovers mathematical logic. This decouples instructional content from private data, preserving teaching efficacy. Tests on MathDial show SRPG works across models; with GPT-4o, it achieves 0.0000 Attack Success Rate (ASR) (zero leakage) and 0.8267 Exact Match, far outperforming the zero trust Pure LLM baseline (0.2138). SRPG effectively protects minors privacy without sacrificing mathematical instructional quality.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [5] [Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas](https://arxiv.org/abs/2512.03565)
*Luis Gall,Samuel James Newcome,Fabio Alexander Gratl,Markus Mühlhäußer,Manish Kumar Mishra,Hans-Joachim Bungartz*

Main category: cs.DC

TL;DR: 该论文研究了在AutoPas粒子模拟库中，通过SIMD向量化技术优化分子间成对力计算的方法，重点关注粒子值加载到向量寄存器的顺序对性能和能耗的影响。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟在原子尺度上为物理过程提供宝贵见解，但计算成本高。先前研究表明最优MD算法可能在运行时变化，因此需要研究如何通过SIMD向量化优化粒子相互作用计算，特别是考虑粒子密度和邻居识别算法等模拟特定参数的影响。

Method: 1. 探索多种SIMD向量化技术，优化粒子间成对力计算；2. 研究粒子值加载到向量寄存器的不同顺序；3. 分析粒子密度和邻居识别算法等模拟参数的影响；4. 扩展AutoPas的动态调优机制，使其能在运行时选择最优向量化顺序。

Result: 基准测试表明，在运行时考虑不同的粒子相互作用顺序，相比AutoPas先前的方法，能够显著提高力计算的性能。

Conclusion: 通过动态选择最优的SIMD向量化顺序，可以显著提升分子动力学模拟中力计算的性能，特别是在考虑模拟特定参数（如粒子密度和邻居识别算法）的情况下。这为AutoPas库提供了更高效的计算能力。

Abstract: Molecular Dynamics simulations can help scientists to gather valuable insights for physical processes on an atomic scale. This work explores various techniques for SIMD vectorization to improve the pairwise force calculation between molecules in the scope of the particle simulation library AutoPas. The focus lies on the order in which particle values are loaded into vector registers to achieve the most optimal performance regarding execution time or energy consumption.
  As previous work indicates that the optimal MD algorithm can change during runtime, this paper investigates simulation-specific parameters like particle density and the impact of the neighbor identification algorithms, which distinguishes this work from related projects. Furthermore, AutoPas' dynamic tuning mechanism is extended to choose the optimal vectorization order during runtime.
  The benchmarks show that considering different particle interaction orders during runtime can lead to a considerable performance improvement for the force calculation compared to AutoPas' previous approach.

</details>


### [6] [On the Challenges of Energy-Efficiency Analysis in HPC Systems: Evaluating Synthetic Benchmarks and Gromacs](https://arxiv.org/abs/2512.03697)
*Rafael Ravedutti Lucio Machado,Jan Eitzinger,Georg Hager,Gerhard Wellein*

Main category: cs.DC

TL;DR: 该论文讨论了在Fritz和Alex HPC集群上分析合成基准测试和Gromacs软件包能效时遇到的挑战，使用Intel Ice Lake/Sapphire Rapids CPU和Nvidia A40/A100 GPU进行实验，揭示了实验和分析过程中的问题并提出了最佳实践建议。


<details>
  <summary>Details</summary>
Motivation: 研究高性能计算集群上能效分析的挑战，特别是在使用不同硬件架构（CPU和GPU）和软件工具进行能效测量时遇到的问题，旨在为未来的能效分析研究提供指导。

Method: 在Fritz和Alex HPC集群上使用MPI并行化，在完整的Intel Ice Lake和Sapphire Rapids CPU插槽以及Nvidia A40和A100 GPU上运行合成基准测试和Gromacs软件包，使用Likwid和Nvidia分析工具进行指标测量。

Result: 展示了使用Likwid和Nvidia分析工具获得的能效指标和测量结果，揭示了在实验和分析过程中遇到的各种挑战和陷阱，包括工具使用、数据收集和结果解释方面的问题。

Conclusion: 论文总结了在高性能计算环境中进行能效分析时面临的挑战，并提出了未来能效分析研究的最佳实践建议，为研究人员提供了有价值的经验教训和指导。

Abstract: This paper discusses the challenges encountered when analyzing the energy efficiency of synthetic benchmarks and the Gromacs package on the Fritz and Alex HPC clusters. Experiments were conducted using MPI parallelism on full sockets of Intel Ice Lake and Sapphire Rapids CPUs, as well as Nvidia A40 and A100 GPUs. The metrics and measurements obtained with the Likwid and Nvidia profiling tools are presented, along with the results. The challenges and pitfalls encountered during experimentation and analysis are revealed and discussed. Best practices for future energy efficiency analysis studies are suggested.

</details>


### [7] [Acceleration of Parallel Tempering for Markov Chain Monte Carlo methods](https://arxiv.org/abs/2512.03825)
*Aingeru Ramos,Jose A Pascual,Javier Navaridas,Ivan Coluzza*

Main category: cs.DC

TL;DR: 本文提出了并行回火Metropolis-Hastings算法的并行实现，使用OpenMP和CUDA分别在CPU和GPU上进行并行化，显著提升了采样效率。


<details>
  <summary>Details</summary>
Motivation: 传统MCMC方法在处理复杂构型空间时采样精度不足，而并行回火技术虽然提高了精度但计算成本显著增加，需要通过并行化来克服这一瓶颈。

Method: 开发了并行回火Metropolis-Hastings算法的并行实现，使用OpenMP在CPU多核上进行并行化，同时使用CUDA在GPU上进行并行加速。

Result: 使用48核CPU的OpenMP版本实现了52倍加速，CUDA版本实现了986倍加速，为未来量子实现提供了基准比较。

Conclusion: 并行化技术显著提升了MCMC/PT算法的计算效率，使得能够研究更大规模的模型，并为量子实现提供了性能基准。

Abstract: Markov Chain Monte Carlo methods are algorithms used to sample probability distributions, commonly used to sample the Boltzmann distribution of physical/chemical models (e.g., protein folding, Ising model, etc.). This allows us to study their properties by sampling the most probable states of those systems. However, the sampling capabilities of these methods are not sufficiently accurate when handling complex configuration spaces. This has resulted in the development of new techniques that improve sampling accuracy, usually at the expense of increasing the computational cost. One of such techniques is Parallel Tempering which improves accuracy by running several replicas which periodically exchange their states. Computationally, this imposes a significant slow-down, which can be counteracted by means of parallelization. These schemes enable MCMC/PT techniques to be run more effectively and allow larger models to be studied. In this work, we present a parallel implementation of Metropolis-Hastings with Parallel Tempering, using OpenMP and CUDA for the parallelization in modern CPUs and GPUs, respectively. The results show a maximum speed-up of 52x using OpenMP with 48 cores, and of 986x speed-up with the CUDA version. Furthermore, the results serve as a basic benchmark to compare a future quantum implementation of the same algorithm.

</details>


### [8] [OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference](https://arxiv.org/abs/2512.03927)
*Liujianfu Wang,Yuyang Du,Yuchen Pan,Soung Chang Liew,Jiacheng Liu,Kexin Chen*

Main category: cs.DC

TL;DR: OD-MoE是一个分布式MoE推理框架，通过完全按需加载专家参数，消除了专家缓存需求，使MoE模型能够在GPU内存小于1GB的边缘设备上运行。


<details>
  <summary>Details</summary>
Motivation: 混合专家模型在内存受限的边缘设备上部署面临挑战。现有的专家卸载方法虽然将专家参数存储在CPU内存中，但GPU内存中保留的专家缓存利用率较低，无法在资源极度受限的边缘设备上有效运行。

Method: OD-MoE采用两种关键技术：1) 在分布式边缘节点间并行化专家加载和专家计算；2) 超准确的仿真预测器，在专家计算进行时提前多层预测专家激活。通过这些创新，OD-MoE能够在专家激活前即时将目标专家加载到分布式节点，并在使用后立即驱逐，释放GPU内存供后续专家使用。

Result: 实验结果显示：1) OD-MoE达到99.94%的专家激活预测准确率，远超现有方法；2) 仅使用1/3的GPU内存就能实现完全GPU缓存MoE部署约75%的解码速度；3) 能够在GPU内存小于1GB的边缘节点上运行MoE推理。

Conclusion: OD-MoE通过消除专家缓存需求，使MoE模型能够在低成本边缘设备上实际部署，为LLM时代边缘物联网设备的MoE应用铺平了道路。

Abstract: Mixture-of-Experts (MoE), while offering significant advantages as a Large Language Model (LLM) architecture, faces substantial challenges when deployed on low-cost edge devices with tight memory constraints. Expert offloading mitigates this issue by storing expert parameters in CPU memory and caching a subset of popular experts in GPU memory. Although this approach improves GPU memory utilization by caching only the likely-used experts, the GPU memory reserved for expert caching is underutilized compared with dense LLMs. This paper presents OD-MoE, a distributed MoE inference framework that obviates the need for expert caches via fully on-demand expert loading. OD-MoE is built upon two key mechanisms: 1) parallelizing expert loading and expert computation across distributed edge nodes, and 2) an ultra-accurate emulative predictor that forecasts expert activations multiple layers ahead while expert computation is ongoing. With these innovations, OD-MoE dynamically loads each target expert to one of the distributed nodes just-in-time before its activation and promptly evicts it afterward, freeing GPU memory for subsequent experts. We comprehensively benchmark OD-MoE against state-of-the-art MoE offloading systems on a ten-node testbed. Experimental results show that: 1) OD-MoE achieves 99.94% expert activation prediction accuracy, substantially surpassing all existing methods; and 2) OD-MoE delivers approximately 75% of the decoding speed of a fully GPU-cached MoE deployment while using only 1/3 of the GPU memory. More importantly, by eliminating the need for expert caches, OD-MoE enables MoE inference on edge nodes with less-than-1GB GPU memory, paving the way for practical MoE deployment of low-cost IoT devices at the edge in the LLM era.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation](https://arxiv.org/abs/2512.03048)
*Austin Spizzirri*

Main category: cs.AI

TL;DR: 本文主张将AI对齐重新构想为通过过程性、多智能体、发展性机制构建具有熵减和理性响应能力的智能体，而非编码固定的人类价值观内容。


<details>
  <summary>Details</summary>
Motivation: 传统基于内容的价值观规范方法存在"规范陷阱"问题，由于事实-价值鸿沟、价值多元主义和扩展框架问题的结合，导致内容规范在结构上不稳定。需要寻找更可靠的AI对齐方法。

Method: 提出三个哲学贡献：1) 阐述"规范陷阱"论证；2) 提出"熵减"作为理解多智能体对齐动态的信息论框架；3) 基于相容论指导控制理论建立真实与模拟道德能力的功能区分，并设计具身实验范式和验证机制。

Result: 建立了AI对齐的新理论框架，该框架能够生成关于人工系统中价值涌现和道德能动性的具体、可证伪预测，但实证验证仍在进行中。

Conclusion: AI对齐应转向过程性、发展性的多智能体架构方法，通过熵减机制实现智能体间的状态对齐，而非试图编码固定的价值观内容。这为AI对齐研究提供了新的哲学基础和方法论方向。

Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.

</details>


### [10] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 提出Weight-Calculatism认知架构，基于逻辑原子和基本操作构建可解释的AGI系统，通过权重计算模型实现透明推理和价值对齐。


<details>
  <summary>Details</summary>
Motivation: 当前AI范式作为"经验架构师"面临可解释性和价值对齐的根本挑战，需要建立基于第一原理的认知架构来构建可信赖的通用人工智能。

Method: 提出Weight-Calculatism架构，将认知分解为不可分割的逻辑原子和两个基本操作：指向和比较。决策通过可解释的权重计算模型（权重=收益×概率）形式化，所有值可追溯到可审计的初始权重集。实现基于图算法计算引擎和全局工作空间工作流。

Result: 该架构实现了透明、类人的推理，并在前所未有场景中表现出稳健学习能力，为构建可信赖和对齐的AGI奠定了实践和理论基础。

Conclusion: Weight-Calculatism是基于第一原理的认知架构，通过原子分解实现根本可解释性、内在通用性和可追溯价值对齐，为AGI发展提供了可行路径。

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [11] [When Do Symbolic Solvers Enhance Reasoning in Large Language Models?](https://arxiv.org/abs/2512.03272)
*Zhiyuan He,Dingmin Wang*

Main category: cs.AI

TL;DR: 本文探讨了符号求解器集成方法何时能增强传统长思维链推理，发现该方法仅在问题需要有限隐式推理但涉及充分搜索空间时有效，特别是在需要重复回溯的约束满足问题上表现显著提升。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长思维链在复杂推理任务上表现良好，但这种方法可能导致大量token开销，甚至因"过度思考"产生冗长推理链而导致错误答案。符号求解器集成方法利用LLM的代码生成能力将推理任务转化为可执行代码，然后用符号求解器解决，但何时这种方法能增强传统长思维链仍是一个开放问题。

Method: 采用符号求解器集成方法，利用LLM的代码生成能力将推理任务翻译成可执行代码，然后使用符号求解器解决。通过实验比较传统长思维链方法与符号求解器集成方法在不同类型问题上的表现。

Result: 实验结果显示：1) 符号求解器集成方法仅在问题需要有限隐式推理但涉及充分搜索空间时有效；2) 最新LLM（如GPT-4o）在推理深度较浅的演绎问题上表现更好；3) 符号求解器集成方法在需要重复回溯的约束满足问题上显著提升LLM性能；4) 当提供声明性示例时，即使是CodeLlama-13B也能在困难的斑马谜题上超越GPT-4o。

Conclusion: 符号求解器集成方法在特定类型的问题上能有效增强传统长思维链推理，特别是在需要大量搜索和回溯的约束满足问题上。该方法为LLM推理提供了有前景的补充途径，但需要根据问题类型选择合适的方法。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models "overthink" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.

</details>


### [12] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 该研究探讨了主动推理中偏好分布的四种定义方式及其对智能体性能的影响，通过在网格世界导航任务中的实验比较发现，目标塑造能提升性能但会牺牲环境动态学习。


<details>
  <summary>Details</summary>
Motivation: 主动推理使用期望自由能作为规划决策目标，但文献中很少关注偏好分布应如何指定以及不同指定方式如何影响主动推理智能体的推理和学习性能。

Method: 考虑了四种定义偏好分布的方式：硬目标与软目标、涉及或不涉及目标塑造（中间目标），在网格世界导航任务中比较了四种智能体的性能。

Result: 目标塑造能实现最佳整体性能（促进利用），但会牺牲对环境转移动态的学习（阻碍探索）。

Conclusion: 偏好分布的定义方式对主动推理智能体的性能有显著影响，目标塑造在提升性能的同时会限制探索能力，需要在利用和探索之间进行权衡。

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [13] [Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia](https://arxiv.org/abs/2512.03318)
*Chandler Smith,Marwa Abdulhai,Manfred Diaz,Marko Tesic,Rakshit S. Trivedi,Alexander Sasha Vezhnevets,Lewis Hammond,Jesse Clifton,Minsuk Chang,Edgar A. Duéñez-Guzmán,John P. Agapiou,Jayd Matyas,Danny Karmon,Akash Kundu,Aliaksei Korshuk,Ananya Ananya,Arrasy Rahman,Avinaash Anand Kulandaivel,Bain McHale,Beining Zhang,Buyantuev Alexander,Carlos Saith Rodriguez Rojas,Caroline Wang,Chetan Talele,Chenao Liu,Chichen Lin,Diana Riazi,Di Yang Shi,Emanuel Tewolde,Elizaveta Tennant,Fangwei Zhong,Fuyang Cui,Gang Zhao,Gema Parreño Piqueras,Hyeonggeun Yun,Ilya Makarov,Jiaxun Cui,Jebish Purbey,Jim Dilkes,Jord Nguyen,Lingyun Xiao,Luis Felipe Giraldo,Manuela Chacon-Chamorro,Manuel Sebastian Rios Beltran,Marta Emili García Segura,Mengmeng Wang,Mogtaba Alim,Nicanor Quijano,Nico Schiavone,Olivia Macmillan-Scott,Oswaldo Peña,Peter Stone,Ram Mohan Rao Kadiyala,Rolando Fernandez,Ruben Manrique,Sunjia Lu,Sheila A. McIlraith,Shamika Dhuri,Shuqing Shi,Siddhant Gupta,Sneheel Sarangi,Sriram Ganapathi Subramanian,Taehun Cha,Toryn Q. Klassen,Wenming Tu,Weijian Fan,Wu Ruiyang,Xue Feng,Yali Du,Yang Liu,Yiding Wang,Yipeng Kang,Yoonchang Sung,Yuxuan Chen,Zhaowei Zhang,Zhihan Wang,Zhiqiang Wu,Ziang Chen,Zilong Zheng,Zixia Jia,Ziyan Wang,Dylan Hadfield-Menell,Natasha Jaques,Tim Baarslag,Jose Hernandez-Orallo,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 论文提出了一种评估LLM智能体在零样本混合动机环境中合作能力的方法，使用Concordia自然语言多智能体模拟环境，发现当前智能体在需要说服和规范执行的场景中存在显著能力差距。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在社交互动中展现出强大能力，并越来越多地部署在与人类和人工智能体互动的场景中。然而，现有评估方法无法衡量这些能力在新颖社交情境中的泛化能力，这代表了LLM智能体发展的关键前沿。

Method: 引入了一种评估LLM智能体在零样本混合动机环境中合作能力的方法，使用Concordia自然语言多智能体模拟环境。该方法通过测试智能体在不同合作伙伴和情境中识别和利用互利机会的能力来衡量一般合作智能。

Result: 基于NeurIPS 2024 Concordia竞赛的实证结果显示，当前智能体能力与实现可靠合作所需的稳健泛化之间存在显著差距，特别是在需要说服和规范执行的场景中。

Conclusion: LLM智能体在合作能力方面仍有重要改进空间，特别是在处理复杂社交情境时。需要开发更强大的方法来评估和提高智能体在多样化社交环境中的合作能力。

Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.

</details>


### [14] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 提出了一种通信受限的多智能体强化学习框架，通过区分有损和无损消息，利用双重互信息估计器量化通信影响，并在多个基准测试中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中通信通常存在损耗问题，现有多智能体强化学习通信方法由于可扩展性和鲁棒性有限，难以应用于复杂动态的真实环境。

Method: 提出广义通信约束模型统一描述不同场景的通信条件，作为学习先验区分有损和无损消息；使用双重互信息估计器解耦有损和无损消息对分布式决策的影响；引入通信约束多智能体强化学习框架，将通信消息影响量化到全局奖励中。

Result: 在多个通信受限基准测试中验证了方法的有效性。

Conclusion: 提出的通信约束多智能体强化学习框架能够有效处理现实世界中的通信损耗问题，提高系统在复杂动态环境中的适应性和鲁棒性。

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [15] [EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths](https://arxiv.org/abs/2512.03571)
*Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng*

Main category: cs.AI

TL;DR: 本文提出了一种新的智能体编程方法PAN，通过分离核心工作流逻辑和推理时策略，使用Python框架EnCompass实现，让程序员能快速改进智能体可靠性并轻松切换不同推理策略。


<details>
  <summary>Details</summary>
Motivation: 当前智能体编程方法通常将核心工作流逻辑和推理时策略（如树搜索）耦合在一起，这种耦合限制了程序员的灵活性和实验能力，难以独立调整不同组件。

Method: 提出"概率天使非确定性"（PAN）编程模型，分离工作流和推理策略；实现EnCompass框架，使用Python装饰器将智能体工作流程序编译为搜索空间。

Result: 通过三个案例研究证明，该框架让程序员能用少量额外代码快速改进智能体可靠性，并轻松在不同推理时策略之间切换。

Conclusion: PAN编程模型和EnCompass框架提供了一种解耦智能体设计的有效方法，提高了编程灵活性和实验效率，为LLM-based智能体开发提供了新范式。

Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

</details>


### [16] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule是一个用于零售品类和定价优化的自动化业务规则生成框架，通过LLM解析非结构化文本、博弈论约束优化和可解释决策蒸馏，解决理论模型与现实经济复杂性之间的系统性错位问题。


<details>
  <summary>Details</summary>
Motivation: 现有理论模型与现实经济复杂性之间存在系统性错位，具体表现为三个关键差距：1) 非结构化文本数据模态不匹配阻碍准确客户画像；2) 动态特征纠缠挑战非线性价格弹性和时变属性建模；3) 多层次业务约束导致操作不可行性。

Method: 采用三层架构：1) 混合知识融合引擎使用LLM深度语义解析非结构化文本，将分销协议和销售评估转化为结构化特征；2) 博弈论约束优化机制通过双边效用函数动态协调供应链利益，在层次约束下编码制造商-分销商利润再分配；3) 可解释决策蒸馏接口利用LLM引导的符号回归优化定价策略和可审计业务规则，将经济先验作为硬约束嵌入数学表达式搜索。

Result: 在真实零售环境中验证框架，相比系统性B2C基线实现更高利润，同时确保操作可行性。

Conclusion: 建立了一个闭环管道，统一了非结构化知识注入、多智能体优化和可解释策略合成，为真实经济智能提供解决方案。

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [17] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo是一个基于多智能体角色协作的系统，通过四个专门化的LLM智能体（探索者、利用者、批评者、整合者）协同设计高质量启发式算法，在组合优化问题的自动启发式设计中取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自动启发式设计研究通常只考虑单一角色，限制了启发式算法的多样性和质量。需要一种能够通过多角色协作来增强启发式设计多样性和质量的新方法。

Method: 提出RoCo多智能体角色协作系统，包含四个专门化的LLM智能体：探索者（创造性、多样性驱动）、利用者（保守性、效率导向）、批评者（评估进化步骤并提供反馈）、整合者（平衡创新与利用）。这些智能体通过结构化多轮过程进行交互，包含反馈、精炼和精英变异，同时考虑短期和长期反思。

Result: 在五种不同组合优化问题的白盒和黑盒设置下进行实验，RoCo表现出优越性能，生成的启发式算法在两种场景下均优于现有方法（包括ReEvo和HSEvo）。

Conclusion: 基于角色的协作范式为鲁棒且高性能的自动启发式设计建立了新标准，通过多角色协同工作显著提升了启发式设计的多样性和质量。

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [18] [Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.03783)
*Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng*

Main category: cs.AI

TL;DR: Omni-AutoThink是一个自适应推理框架，通过动态调整模型推理深度来解决现有Omni模型推理行为僵化的问题，包含自适应监督微调和自适应强化学习两个阶段，并在多模态基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有Omni模型在推理行为上存在僵化问题：对于简单问题过度推理，而在需要推理时又无法有效推理。需要一种能够根据任务难度动态调整推理深度的自适应推理框架。

Method: 提出两阶段框架：1) 自适应监督微调阶段，使用大规模推理增强数据赋予Omni模型基本推理能力；2) 自适应强化学习阶段，基于任务复杂度和奖励反馈优化推理行为。同时构建了涵盖文本、文本-音频、文本-视觉、文本-音频-视觉多模态的自适应推理基准。

Result: 实验结果表明，该框架相比先前基线显著提升了自适应推理性能。所有基准数据和代码将公开发布。

Conclusion: Omni-AutoThink通过动态调整推理深度有效解决了Omni模型推理行为僵化问题，在多模态自适应推理任务上取得了显著改进。

Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

</details>


### [19] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 该研究为基于大语言模型的工业自动化智能体开发了一个标准化基准测试平台，包含可执行模拟环境和五个复杂度类别的Blocksworld问题，通过MCP协议实现不同架构的无缝集成评估。


<details>
  <summary>Details</summary>
Motivation: 工业自动化需要能够适应变化任务和环境的灵活控制策略，基于大语言模型的智能体具有自适应规划和执行的潜力，但缺乏系统比较的标准化基准。

Method: 引入包含可执行模拟环境的基准测试平台，采用Blocksworld问题并提供五个复杂度类别，通过集成模型上下文协议（MCP）作为标准化工具接口，使不同智能体架构无需特定修改即可连接和评估。

Result: 通过单智能体实现展示了基准测试的适用性，建立了用于比较基于大语言模型的规划和执行方法的定量指标。

Conclusion: 该基准测试平台为评估和比较基于大语言模型的工业自动化智能体提供了标准化框架，促进了自适应规划和执行方法的研究与发展。

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>
