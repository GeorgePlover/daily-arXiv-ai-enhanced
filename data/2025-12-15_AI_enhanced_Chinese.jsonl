{"id": "2512.10974", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10974", "abs": "https://arxiv.org/abs/2512.10974", "authors": ["Sohan Kumar Pande", "Sanjaya Kumar Panda", "Preeti Ranjan Sahu"], "title": "An Efficient Approach for Energy Conservation in Cloud Computing Environment", "comment": null, "summary": "Recent trends of technology have explored a numerous applications of cloud services, which require a significant amount of energy. In the present scenario, most of the energy sources are limited and have a greenhouse effect on the environment. Therefore, it is the need of the hour that the energy consumed by the cloud service providers must be reduced and it is a great challenge to the research community to develop energy-efficient algorithms. To design the same, some researchers tried to maximize the average resource utilization, whereas some researchers tried to minimize the makespan. However, they have not considered different types of resources that are present in the physical machines. In this paper, we propose a task scheduling algorithm, which tries to improve utilization of resources (like CPU, disk, I/O) explicitly, which in turn increases the utilization of active resources. For this, the proposed algorithm uses a fitness value, which is a function of CPU, disk and I/O utilization, and processing time of the task. To demonstrate the performance of the proposed algorithm, extensive simulations are performed on both proposed algorithm and existing algorithm MaxUtil using synthetic datasets. From the simulation results, it can be observed that the proposed algorithm is a better energy-efficient algorithm and consumes less energy than the MaxUtil algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eCPU\u3001\u78c1\u76d8\u548cI/O\u5229\u7528\u7387\u7684\u591a\u8d44\u6e90\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u901a\u8fc7\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u6765\u964d\u4f4e\u4e91\u670d\u52a1\u80fd\u8017", "motivation": "\u4e91\u670d\u52a1\u80fd\u8017\u5de8\u5927\uff0c\u4f20\u7edf\u80fd\u6e90\u6709\u9650\u4e14\u5bf9\u73af\u5883\u6709\u6e29\u5ba4\u6548\u5e94\uff0c\u9700\u8981\u5f00\u53d1\u8282\u80fd\u7b97\u6cd5\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6700\u5927\u5316\u5e73\u5747\u8d44\u6e90\u5229\u7528\u7387\u6216\u6700\u5c0f\u5316\u5b8c\u5de5\u65f6\u95f4\uff0c\u4f46\u672a\u5145\u5206\u8003\u8651\u7269\u7406\u673a\u4e2d\u4e0d\u540c\u7c7b\u578b\u7684\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u901a\u8fc7\u9002\u5e94\u5ea6\u51fd\u6570\u663e\u5f0f\u4f18\u5316CPU\u3001\u78c1\u76d8\u548cI/O\u7b49\u8d44\u6e90\u7684\u5229\u7528\u7387\u3002\u9002\u5e94\u5ea6\u503c\u662fCPU\u3001\u78c1\u76d8\u3001I/O\u5229\u7528\u7387\u548c\u4efb\u52a1\u5904\u7406\u65f6\u95f4\u7684\u51fd\u6570\u3002", "result": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u96c6\u8fdb\u884c\u4eff\u771f\uff0c\u5c06\u63d0\u51fa\u7684\u7b97\u6cd5\u4e0e\u73b0\u6709MaxUtil\u7b97\u6cd5\u6bd4\u8f83\u3002\u7ed3\u679c\u663e\u793a\u63d0\u51fa\u7684\u7b97\u6cd5\u662f\u66f4\u597d\u7684\u8282\u80fd\u7b97\u6cd5\uff0c\u6bd4MaxUtil\u7b97\u6cd5\u6d88\u8017\u66f4\u5c11\u7684\u80fd\u91cf\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u4f18\u5316\u591a\u79cd\u8d44\u6e90\u5229\u7528\u7387\uff0c\u63d0\u51fa\u7684\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u6d3b\u8dc3\u8d44\u6e90\u5229\u7528\u7387\uff0c\u4ece\u800c\u964d\u4f4e\u4e91\u670d\u52a1\u80fd\u8017\uff0c\u4e3a\u89e3\u51b3\u4e91\u8ba1\u7b97\u7684\u80fd\u6e90\u6548\u7387\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.10977", "categories": ["cs.DC", "cs.AR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.10977", "abs": "https://arxiv.org/abs/2512.10977", "authors": ["Alec M. Hammond", "Aram Markosyan", "Aman Dontula", "Simon Mahns", "Zacharias Fisches", "Dmitrii Pedchenko", "Keyur Muzumdar", "Natacha Supper", "Mark Saroufim", "Joe Isaacson", "Laura Wang", "Warren Hunt", "Kaustubh Gondkar", "Roman Levenstein", "Gabriel Synnaeve", "Richard Li", "Jacob Kahn", "Ajit Mathews"], "title": "Agentic Operator Generation for ML ASICs", "comment": null, "summary": "We present TritorX, an agentic AI system designed to generate functionally correct Triton PyTorch ATen kernels at scale for emerging accelerator platforms. TritorX integrates open-source large language models with a custom linter, JIT compilation, and a PyTorch OpInfo-based test harness. This pipeline is compatible with both real Meta Training and Inference Accelerator (MTIA) silicon and in hardware simulation environments for next-generation devices. In contrast to previous kernel-generation approaches that prioritize performance for a limited set of high-usage kernels, TritorX prioritizes coverage. Our system emphasizes correctness and generality across the entire operator set, including diverse data types, shapes, and argument patterns. In our experiments, TritorX successfully generated kernels and wrappers for 481 unique ATen operators that pass all corresponding PyTorch OpInfo tests (over 20,000 in total). TritorX paves the way for overnight generation of complete PyTorch ATen backends for new accelerator platforms.", "AI": {"tldr": "TritorX\u662f\u4e00\u4e2aAI\u7cfb\u7edf\uff0c\u80fd\u591f\u5927\u89c4\u6a21\u751f\u6210\u529f\u80fd\u6b63\u786e\u7684Triton PyTorch ATen\u5185\u6838\uff0c\u7528\u4e8e\u65b0\u5174\u52a0\u901f\u5668\u5e73\u53f0\uff0c\u91cd\u70b9\u5173\u6ce8\u8986\u76d6\u7387\u548c\u6b63\u786e\u6027\u800c\u975e\u6027\u80fd\u4f18\u5316\u3002", "motivation": "\u4e3a\u65b0\u5174\u52a0\u901f\u5668\u5e73\u53f0\u5feb\u901f\u751f\u6210\u5b8c\u6574\u7684PyTorch ATen\u540e\u7aef\uff0c\u4f20\u7edf\u65b9\u6cd5\u53ea\u5173\u6ce8\u5c11\u6570\u9ad8\u6027\u80fd\u5185\u6838\uff0c\u800cTritorX\u65e8\u5728\u5b9e\u73b0\u6574\u4e2a\u7b97\u5b50\u96c6\u7684\u5e7f\u6cdb\u8986\u76d6\u3002", "method": "\u96c6\u6210\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u3001\u81ea\u5b9a\u4e49linter\u3001JIT\u7f16\u8bd1\u548c\u57fa\u4e8ePyTorch OpInfo\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u517c\u5bb9\u771f\u5b9eMTIA\u82af\u7247\u548c\u786c\u4ef6\u4eff\u771f\u73af\u5883\u3002", "result": "\u6210\u529f\u4e3a481\u4e2a\u72ec\u7279\u7684ATen\u7b97\u5b50\u751f\u6210\u5185\u6838\u548c\u5305\u88c5\u5668\uff0c\u901a\u8fc7\u6240\u6709\u5bf9\u5e94\u7684PyTorch OpInfo\u6d4b\u8bd5\uff08\u603b\u8ba1\u8d85\u8fc720,000\u4e2a\uff09\u3002", "conclusion": "TritorX\u4e3a\u5b9e\u73b0\u65b0\u5174\u52a0\u901f\u5668\u5e73\u53f0\u4e00\u591c\u4e4b\u95f4\u751f\u6210\u5b8c\u6574PyTorch ATen\u540e\u7aef\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2512.10979", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10979", "abs": "https://arxiv.org/abs/2512.10979", "authors": ["Sima Attar-Khorasani", "Lincoln Sherpa", "Matthias Lieber", "Siavash Ghiasvand"], "title": "Seamless Transitions: A Comprehensive Review of Live Migration Technologies", "comment": "35 pages, 0 figures", "summary": "Live migration, a technology enabling seamless transition of operational computational entities between various hosts while preserving continuous functionality and client connectivity, has been the subject of extensive research. However, existing reviews often overlook critical technical aspects and practical challenges integral to the usage of live migration techniques in real-world scenarios. This work bridges this gap by integrating the aspects explored in existing reviews together with a comprehensive analysis of live migration technologies across multiple dimensions, with focus on migration techniques, migration units, and infrastructure characteristics. Despite efforts to make live migration widely accessible, its reliance on multiple system factors can create challenges. In certain cases, the complexities and resource demands outweigh the benefits, making its implementation hard to justify. The focus of this work is mainly on container based and virtual machine-based migration technologies, examining the current state of the art and the disparity in adoption between these two approaches. Furthermore, this work explores the impact of migration objectives and operational constraints on the usability and efficacy of existing technologies. By outlining current technical challenges and providing guidelines for future research and development directions, this work serves a dual purpose: first, to equip enthusiasts with a valuable resource on live migration, and second, to contribute to the advancement of live migration technologies and their practical implementation across diverse computing environments.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u91cd\u70b9\u5173\u6ce8\u5bb9\u5668\u548c\u865a\u62df\u673a\u8fc1\u79fb\uff0c\u5206\u6790\u4e86\u6280\u672f\u73b0\u72b6\u3001\u5b9e\u9645\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7efc\u8ff0\u5f80\u5f80\u5ffd\u7565\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5173\u952e\u6280\u672f\u7ec6\u8282\u548c\u5b9e\u9645\u6311\u6218\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u5168\u9762\u7684\u6280\u672f\u5206\u6790\u3002", "method": "\u6574\u5408\u73b0\u6709\u7efc\u8ff0\u7684\u7814\u7a76\u6210\u679c\uff0c\u4ece\u8fc1\u79fb\u6280\u672f\u3001\u8fc1\u79fb\u5355\u5143\u548c\u57fa\u7840\u8bbe\u65bd\u7279\u5f81\u7b49\u591a\u4e2a\u7ef4\u5ea6\u5bf9\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff0c\u7279\u522b\u5173\u6ce8\u5bb9\u5668\u548c\u865a\u62df\u673a\u4e24\u79cd\u8fc1\u79fb\u65b9\u5f0f\u3002", "result": "\u53d1\u73b0\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u867d\u7136\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5bf9\u591a\u7cfb\u7edf\u56e0\u7d20\u7684\u4f9d\u8d56\u5e26\u6765\u6311\u6218\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u590d\u6742\u6027\u548c\u8d44\u6e90\u9700\u6c42\u53ef\u80fd\u8d85\u8fc7\u6536\u76ca\uff1b\u5bb9\u5668\u548c\u865a\u62df\u673a\u8fc1\u79fb\u5728\u91c7\u7528\u7a0b\u5ea6\u4e0a\u5b58\u5728\u5dee\u5f02\uff1b\u8fc1\u79fb\u76ee\u6807\u548c\u64cd\u4f5c\u7ea6\u675f\u663e\u8457\u5f71\u54cd\u73b0\u6709\u6280\u672f\u7684\u53ef\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6982\u8ff0\u5f53\u524d\u6280\u672f\u6311\u6218\u5e76\u63d0\u4f9b\u672a\u6765\u7814\u53d1\u65b9\u5411\u6307\u5357\uff0c\u65e2\u4e3a\u7231\u597d\u8005\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5b9e\u65f6\u8fc1\u79fb\u8d44\u6e90\uff0c\u53c8\u6709\u52a9\u4e8e\u63a8\u52a8\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u5728\u4e0d\u540c\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2512.10980", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10980", "abs": "https://arxiv.org/abs/2512.10980", "authors": ["Akhmadillo Mamirov"], "title": "Reducing Fragmentation and Starvation in GPU Clusters through Dynamic Multi-Objective Scheduling", "comment": null, "summary": "GPU clusters have become essential for training and deploying modern AI systems, yet real deployments continue to report average utilization near 50%. This inefficiency is largely caused by fragmentation, heterogeneous workloads, and the limitations of static scheduling policies. This work presents a systematic evaluation of these issues and introduces three specialized dynamic schedulers: Hybrid Priority (HPS), Predictive Backfill (PBS), and Smart Batch (SBS). These schedulers are designed to improve utilization, fairness, and overall throughput in multi-tenant GPU clusters. We evaluate all schedulers using a controlled simulation of 1,000 AI jobs on a 64-GPU, 8-node cluster that includes a realistic mix of training, inference, and research workloads. Static baselines (FIFO, SJF, Shortest, Shortest-GPU) achieve 45 to 67% GPU utilization and 12.5 to 18.3 jobs per hour and experience severe starvation, with as many as 156 jobs waiting longer than 30 minutes. The dynamic schedulers significantly outperform these policies. HPS achieves the highest utilization (78.2%), highest throughput (25.8 jobs per hour), and the lowest fairness variance among dynamic methods (457), reducing starvation to 12 jobs. PBS improves fragmentation handling and reaches 76.1% utilization, while SBS increases efficiency for structurally similar jobs and reaches 74.6% utilization. Across all key metrics, including throughput, job wait times, fairness variance, and starvation, dynamic multi-objective schedulers consistently outperform single-objective heuristics. These results show that targeted and transparent scheduling strategies can meaningfully increase GPU efficiency in heterogeneous AI clusters and provide a practical foundation for future production scheduling frameworks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86GPU\u96c6\u7fa4\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u52a8\u6001\u8c03\u5ea6\u5668\uff08HPS\u3001PBS\u3001SBS\uff09\uff0c\u572864-GPU\u96c6\u7fa4\u4e0a\u6d4b\u8bd5\u663e\u793a\u52a8\u6001\u8c03\u5ea6\u5668\u663e\u8457\u4f18\u4e8e\u9759\u6001\u8c03\u5ea6\u7b56\u7565\uff0c\u6700\u9ad8\u8fbe\u523078.2%\u5229\u7528\u7387\u548c25.8\u4f5c\u4e1a/\u5c0f\u65f6\u3002", "motivation": "GPU\u96c6\u7fa4\u5bf9\u73b0\u4ee3AI\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4e2d\u5e73\u5747\u5229\u7528\u7387\u4ec5\u7ea650%\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8d44\u6e90\u788e\u7247\u5316\u3001\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u548c\u9759\u6001\u8c03\u5ea6\u7b56\u7565\u7684\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8c03\u5ea6\u65b9\u6848\u6765\u63d0\u9ad8\u5229\u7528\u7387\u3001\u516c\u5e73\u6027\u548c\u541e\u5410\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u4e13\u95e8\u7684\u52a8\u6001\u8c03\u5ea6\u5668\uff1a\u6df7\u5408\u4f18\u5148\u7ea7\u8c03\u5ea6\u5668\uff08HPS\uff09\u3001\u9884\u6d4b\u6027\u56de\u586b\u8c03\u5ea6\u5668\uff08PBS\uff09\u548c\u667a\u80fd\u6279\u5904\u7406\u8c03\u5ea6\u5668\uff08SBS\uff09\u3002\u5728\u5305\u542b1000\u4e2aAI\u4f5c\u4e1a\u768464-GPU\u30018\u8282\u70b9\u96c6\u7fa4\u4e0a\u8fdb\u884c\u63a7\u5236\u6a21\u62df\u8bc4\u4f30\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u5305\u62ec\u8bad\u7ec3\u3001\u63a8\u7406\u548c\u7814\u7a76\u4efb\u52a1\u3002", "result": "\u9759\u6001\u8c03\u5ea6\u5668\uff08FIFO\u3001SJF\u7b49\uff09GPU\u5229\u7528\u7387\u4e3a45-67%\uff0c\u541e\u5410\u91cf12.5-18.3\u4f5c\u4e1a/\u5c0f\u65f6\uff0c\u5b58\u5728\u4e25\u91cd\u9965\u997f\u95ee\u9898\uff08\u6700\u591a156\u4e2a\u4f5c\u4e1a\u7b49\u5f85\u8d85\u8fc730\u5206\u949f\uff09\u3002\u52a8\u6001\u8c03\u5ea6\u5668\u663e\u8457\u4f18\u4e8e\u9759\u6001\u7b56\u7565\uff1aHPS\u8fbe\u5230\u6700\u9ad8\u5229\u7528\u738778.2%\u548c\u6700\u9ad8\u541e\u5410\u91cf25.8\u4f5c\u4e1a/\u5c0f\u65f6\uff0c\u9965\u997f\u4f5c\u4e1a\u51cf\u5c11\u523012\u4e2a\uff1bPBS\u8fbe\u523076.1%\u5229\u7528\u7387\uff1bSBS\u8fbe\u523074.6%\u5229\u7528\u7387\u3002", "conclusion": "\u52a8\u6001\u591a\u76ee\u6807\u8c03\u5ea6\u5668\u5728\u541e\u5410\u91cf\u3001\u4f5c\u4e1a\u7b49\u5f85\u65f6\u95f4\u3001\u516c\u5e73\u6027\u65b9\u5dee\u548c\u9965\u997f\u95ee\u9898\u7b49\u5173\u952e\u6307\u6807\u4e0a\u4e00\u81f4\u4f18\u4e8e\u5355\u76ee\u6807\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u9488\u5bf9\u6027\u7684\u900f\u660e\u8c03\u5ea6\u7b56\u7565\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5f02\u6784AI\u96c6\u7fa4\u7684GPU\u6548\u7387\uff0c\u4e3a\u672a\u6765\u751f\u4ea7\u8c03\u5ea6\u6846\u67b6\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2512.11169", "categories": ["cs.AI", "cs.LG", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.11169", "abs": "https://arxiv.org/abs/2512.11169", "authors": ["Akhil S Anand", "Elias Aarekol", "Martin Mziray Dalseg", "Magnus Stalhane", "Sebastien Gros"], "title": "CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound", "comment": null, "summary": "Combinatorial sequential decision making problems are typically modeled as mixed integer linear programs (MILPs) and solved via branch and bound (B&B) algorithms. The inherent difficulty of modeling MILPs that accurately represent stochastic real world problems leads to suboptimal performance in the real world. Recently, machine learning methods have been applied to build MILP models for decision quality rather than how accurately they model the real world problem. However, these approaches typically rely on supervised learning, assume access to true optimal decisions, and use surrogates for the MILP gradients. In this work, we introduce a proof of concept CORL framework that end to end fine tunes an MILP scheme using reinforcement learning (RL) on real world data to maximize its operational performance. We enable this by casting an MILP solved by B&B as a differentiable stochastic policy compatible with RL. We validate the CORL method in a simple illustrative combinatorial sequential decision making example.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CORL\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7aef\u5230\u7aef\u5fae\u8c03MILP\u65b9\u6848\uff0c\u4ee5\u6700\u5927\u5316\u5b9e\u9645\u8fd0\u8425\u6027\u80fd\uff0c\u5c06MILP\u6c42\u89e3\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u53ef\u5fae\u5206\u7684\u968f\u673a\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u7684\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u65b9\u6cd5\u5728\u5efa\u6a21\u968f\u673a\u73b0\u5b9e\u95ee\u9898\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u5bfc\u81f4\u5b9e\u9645\u6027\u80fd\u4e0d\u4f73\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u8981\u771f\u5b9e\u6700\u4f18\u51b3\u7b56\uff0c\u5e76\u4f7f\u7528MILP\u68af\u5ea6\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCORL\u6982\u5ff5\u9a8c\u8bc1\u6846\u67b6\uff0c\u5c06\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u6c42\u89e3\u7684MILP\u8f6c\u5316\u4e3a\u53ef\u5fae\u5206\u7684\u968f\u673a\u7b56\u7565\uff0c\u4f7f\u5176\u4e0e\u5f3a\u5316\u5b66\u4e60\u517c\u5bb9\uff0c\u4ece\u800c\u80fd\u591f\u57fa\u4e8e\u5b9e\u9645\u6570\u636e\u7aef\u5230\u7aef\u5fae\u8c03MILP\u65b9\u6848\u3002", "result": "\u5728\u7b80\u5355\u7684\u7ec4\u5408\u5e8f\u5217\u51b3\u7b56\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86CORL\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "CORL\u6846\u67b6\u901a\u8fc7\u5c06MILP\u6c42\u89e3\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u53ef\u5fae\u5206\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u5b9e\u9645\u8fd0\u8425\u6027\u80fd\u7684\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u4e3a\u7ec4\u5408\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.10987", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10987", "abs": "https://arxiv.org/abs/2512.10987", "authors": ["Sumit Chongder"], "title": "Evaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems", "comment": "13 pages, 14 figures, 2 tables", "summary": "In recent years, the landscape of federated learning has witnessed significant advancements, particularly in decentralized methodologies. This research paper presents a comprehensive comparison of Centralized Hierarchical Federated Learning (HFL) with Decentralized Aggregated Federated Learning (AFL) and Decentralized Continual Federated Learning (CFL) architectures. While HFL, in its centralized approach, faces challenges such as communication bottlenecks and privacy concerns due to centralized data aggregation, AFL and CFL provide promising alternatives by distributing computation and aggregation processes across devices. Through evaluation of Fashion MNIST and MNIST datasets, this study demonstrates the advantages of decentralized methodologies, showcasing how AFL and CFL outperform HFL in precision, recall, F1 score, and balanced accuracy. The analysis highlights the importance of decentralized aggregation mechanisms in AFL and CFL, which effectively enables collaborative model training across distributed devices. This comparative study contributes valuable insights into the evolving landscape of federated learning, guiding researchers and practitioners towards decentralized methodologies for enhanced performance in collaborative model training scenarios.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u96c6\u4e2d\u5f0f\u5206\u5c42\u8054\u90a6\u5b66\u4e60\uff08HFL\uff09\u4e0e\u53bb\u4e2d\u5fc3\u5316\u805a\u5408\u8054\u90a6\u5b66\u4e60\uff08AFL\uff09\u548c\u53bb\u4e2d\u5fc3\u5316\u6301\u7eed\u8054\u90a6\u5b66\u4e60\uff08CFL\uff09\u67b6\u6784\uff0c\u901a\u8fc7Fashion MNIST\u548cMNIST\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u53d1\u73b0\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u96c6\u4e2d\u5f0f\u5206\u5c42\u8054\u90a6\u5b66\u4e60\uff08HFL\uff09\u9762\u4e34\u901a\u4fe1\u74f6\u9888\u548c\u9690\u79c1\u95ee\u9898\uff0c\u800c\u53bb\u4e2d\u5fc3\u5316\u7684AFL\u548cCFL\u901a\u8fc7\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u805a\u5408\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5168\u9762\u6bd4\u8f83\u8fd9\u4e9b\u67b6\u6784\u7684\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5bf9\u6bd4\u5206\u6790\u65b9\u6cd5\uff0c\u5728Fashion MNIST\u548cMNIST\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e09\u79cd\u8054\u90a6\u5b66\u4e60\u67b6\u6784\uff1a\u96c6\u4e2d\u5f0fHFL\u3001\u53bb\u4e2d\u5fc3\u5316AFL\u548c\u53bb\u4e2d\u5fc3\u5316CFL\uff0c\u91cd\u70b9\u5173\u6ce8\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548c\u5e73\u8861\u51c6\u786e\u7387\u7b49\u6027\u80fd\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u53bb\u4e2d\u5fc3\u5316\u7684AFL\u548cCFL\u5728\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548c\u5e73\u8861\u51c6\u786e\u7387\u7b49\u591a\u4e2a\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u7684HFL\uff0c\u8bc1\u660e\u4e86\u53bb\u4e2d\u5fc3\u5316\u805a\u5408\u673a\u5236\u5728\u5206\u5e03\u5f0f\u8bbe\u5907\u534f\u540c\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff08AFL\u548cCFL\uff09\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\uff08HFL\uff09\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u6307\u5bfc\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u534f\u540c\u6a21\u578b\u8bad\u7ec3\u6548\u679c\u3002"}}
{"id": "2512.11689", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.11689", "abs": "https://arxiv.org/abs/2512.11689", "authors": ["Manuela Chacon-Chamorro", "Juan Sebasti\u00e1n Pinz\u00f3n", "Rub\u00e9n Manrique", "Luis Felipe Giraldo", "Nicanor Quijano"], "title": "Evaluating Cooperative Resilience in Multiagent Systems: A Comparison Between Humans and LLMs", "comment": "Supplementary material in https://github.com/mavivi95/resilience_humans_vs_LLM/blob/main/Supplementary_File.pdf", "summary": "This paper presents a comparative analysis of cooperative resilience in multi-agent systems, defined as the ability to anticipate, resist, recover from, and transform to disruptive events that affect collective well-being. We focus on mixed-motive social dilemmas instantiated as a \\textit{Tragedy of the Commons} environment from the Melting Pot suite, where we systematically compare human groups and Large Language Model (LLM)-based agents, each evaluated with and without explicit communication. Cooperative resilience is assessed under a continuously disruptive condition induced by a persistent unsustainable consumption bot, together with intermittent environmental shocks implemented as stochastic removal of shared resources across scenarios. This experimental design establishes a benchmark for cooperative resilience across agent architectures and interaction modalities, constituting a key step toward systematically comparing humans and LLM-based agents. Using this framework, we find that human groups with communication achieve the highest cooperative resilience compared to all other groups. Communication also improves the resilience of LLM agents, but their performance remains below human levels. Motivated by the performance of humans, we further examine a long-horizon setting with harsher environmental conditions, where humans sustain the shared resource and maintain high resilience in diverse disruption scenarios. Together, these results suggest that human decision-making under adverse social conditions can inform the design of artificial agents that promote prosocial and resilient behaviors.", "AI": {"tldr": "\u6bd4\u8f83\u4eba\u7c7b\u4e0eLLM\u667a\u80fd\u4f53\u5728\u516c\u5171\u8d44\u6e90\u56f0\u5883\u4e2d\u7684\u5408\u4f5c\u97e7\u6027\u8868\u73b0\uff0c\u53d1\u73b0\u4eba\u7c7b\u901a\u8fc7\u6c9f\u901a\u80fd\u8fbe\u5230\u6700\u9ad8\u97e7\u6027\u6c34\u5e73\uff0cLLM\u667a\u80fd\u4f53\u867d\u53d7\u76ca\u4e8e\u6c9f\u901a\u4f46\u4ecd\u4e0d\u53ca\u4eba\u7c7b\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u5177\u793e\u4f1a\u9002\u5e94\u6027\u7684AI\u667a\u80fd\u4f53\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5efa\u7acb\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5408\u4f5c\u97e7\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5728\u9762\u5bf9\u6301\u7eed\u7834\u574f\u548c\u95f4\u6b47\u6027\u73af\u5883\u51b2\u51fb\u65f6\u7684\u8868\u73b0\uff0c\u63a2\u7d22\u6c9f\u901a\u5bf9\u5408\u4f5c\u97e7\u6027\u7684\u5f71\u54cd\uff0c\u4e3a\u8bbe\u8ba1\u5177\u6709\u793e\u4f1a\u9002\u5e94\u6027\u7684AI\u667a\u80fd\u4f53\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528Melting Pot\u5957\u4ef6\u4e2d\u7684\"\u516c\u5730\u60b2\u5267\"\u73af\u5883\u4f5c\u4e3a\u6df7\u5408\u52a8\u673a\u793e\u4f1a\u56f0\u5883\u573a\u666f\uff0c\u8bbe\u7f6e\u6301\u7eed\u7834\u574f\u6027\u6d88\u8d39\u673a\u5668\u4eba\u548c\u95f4\u6b47\u6027\u73af\u5883\u51b2\u51fb\uff08\u968f\u673a\u79fb\u9664\u5171\u4eab\u8d44\u6e90\uff09\uff0c\u6bd4\u8f83\u4eba\u7c7b\u7ec4\u548cLLM\u667a\u80fd\u4f53\u7ec4\u5728\u6709/\u65e0\u660e\u786e\u6c9f\u901a\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u5728\u66f4\u4e25\u82db\u7684\u957f\u671f\u73af\u5883\u4e2d\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u4eba\u7c7b\u8868\u73b0\u3002", "result": "\u4eba\u7c7b\u7ec4\u901a\u8fc7\u6c9f\u901a\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u5408\u4f5c\u97e7\u6027\uff1b\u6c9f\u901a\u4e5f\u80fd\u63d0\u5347LLM\u667a\u80fd\u4f53\u7684\u97e7\u6027\uff0c\u4f46\u5176\u8868\u73b0\u4ecd\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\uff1b\u5728\u66f4\u4e25\u82db\u7684\u957f\u671f\u73af\u5883\u4e2d\uff0c\u4eba\u7c7b\u80fd\u591f\u7ef4\u6301\u5171\u4eab\u8d44\u6e90\u5e76\u4fdd\u6301\u9ad8\u97e7\u6027\u3002", "conclusion": "\u4eba\u7c7b\u5728\u4e0d\u5229\u793e\u4f1a\u6761\u4ef6\u4e0b\u7684\u51b3\u7b56\u673a\u5236\u53ef\u4ee5\u4e3a\u8bbe\u8ba1\u4fc3\u8fdb\u4eb2\u793e\u4f1a\u884c\u4e3a\u548c\u97e7\u6027\u7684AI\u667a\u80fd\u4f53\u63d0\u4f9b\u91cd\u8981\u53c2\u8003\uff0c\u6c9f\u901a\u662f\u63d0\u5347\u5408\u4f5c\u97e7\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u5f53\u524dLLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u793e\u4f1a\u56f0\u5883\u4e2d\u7684\u8868\u73b0\u4ecd\u4e0e\u4eba\u7c7b\u5b58\u5728\u5dee\u8ddd\u3002"}}
{"id": "2512.11213", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.11213", "abs": "https://arxiv.org/abs/2512.11213", "authors": ["Dongwon Jung", "Peng Shi", "Yi Zhang"], "title": "FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration", "comment": null, "summary": "Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.", "AI": {"tldr": "FutureWeaver\u6846\u67b6\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u53cc\u7ea7\u89c4\u5212\uff0c\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u534f\u4f5c\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u6280\u672f\uff08\u5982\u91cd\u590d\u91c7\u6837\u3001\u81ea\u6211\u9a8c\u8bc1\u7b49\uff09\u5728\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u539f\u5219\u6027\u7684\u8ba1\u7b97\u5206\u914d\u673a\u5236\u6765\u4fc3\u8fdb\u534f\u4f5c\uff0c\u65e0\u6cd5\u5728\u660e\u786e\u9884\u7b97\u7ea6\u675f\u4e0b\u5c06\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u5e94\u7528\u4e8e\u534f\u4f5c\u4ea4\u4e92\u3002", "method": "\u63d0\u51faFutureWeaver\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\uff0c\u5c06\u53ef\u91cd\u7528\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5c01\u88c5\u4e3a\u53ef\u8c03\u7528\u51fd\u6570\uff1b2\uff09\u901a\u8fc7\u81ea\u6211\u6e38\u620f\u53cd\u601d\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u62bd\u8c61\u51fa\u91cd\u590d\u4ea4\u4e92\u6a21\u5f0f\u81ea\u52a8\u751f\u6210\u6a21\u5757\uff1b3\uff09\u91c7\u7528\u53cc\u7ea7\u89c4\u5212\u67b6\u6784\uff0c\u5728\u63a8\u7406\u5f53\u524d\u4efb\u52a1\u72b6\u6001\u7684\u540c\u65f6\u63a8\u6d4b\u672a\u6765\u6b65\u9aa4\uff0c\u4f18\u5316\u8ba1\u7b97\u5206\u914d\u3002", "result": "\u5728\u590d\u6742\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFutureWeaver\u5728\u4e0d\u540c\u9884\u7b97\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63a8\u7406\u65f6\u4f18\u5316\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "FutureWeaver\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u524d\u77bb\u6027\u89c4\u5212\u5b9e\u73b0\u4e86\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u7684\u9ad8\u6548\u534f\u4f5c\u4f18\u5316\u3002"}}
{"id": "2512.11200", "categories": ["cs.DC", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.11200", "abs": "https://arxiv.org/abs/2512.11200", "authors": ["Adilet Metinov", "Gulida M. Kudakeeva", "Gulnara D. Kabaeva"], "title": "Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration", "comment": "9 pages , 2 tables", "summary": "Current AI code generation systems suffer from significant latency bottlenecks due to CPU-GPU data transfers during compilation, execution, and testing phases. We establish theoretical foundations for three complementary approaches to GPU-native compilation that eliminate these transfers: (1) parallel traditional compilation adapted for GPU execution, (2) neural compilation using learned sequence-to-sequence translation with probabilistic verification, and (3) hybrid architectures combining both strategies. We derive latency and energy bounds demonstrating potential speedups of 10-100x for code iteration cycles. Our analysis shows that traditional GPU compilation provides 2-5x improvements through transfer elimination, neural compilation achieves 10-100x speedups via massive parallelism, and hybrid approaches offer practical deployment paths with guaranteed correctness. We formalize the probabilistic verification framework that enables trading compilation accuracy for parallel exploration, and discuss implications for self-improving AI systems and future analog computing substrates.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e09\u79cdGPU\u539f\u751f\u7f16\u8bd1\u65b9\u6cd5\u6d88\u9664CPU-GPU\u6570\u636e\u4f20\u8f93\u74f6\u9888\uff0c\u7406\u8bba\u5206\u6790\u663e\u793a\u53ef\u5b9e\u73b010-100\u500d\u4ee3\u7801\u8fed\u4ee3\u52a0\u901f", "motivation": "\u5f53\u524dAI\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u5728\u7f16\u8bd1\u3001\u6267\u884c\u548c\u6d4b\u8bd5\u9636\u6bb5\u5b58\u5728\u663e\u8457\u7684CPU-GPU\u6570\u636e\u4f20\u8f93\u5ef6\u8fdf\u74f6\u9888\uff0c\u9650\u5236\u4e86\u4ee3\u7801\u8fed\u4ee3\u6548\u7387", "method": "\u63d0\u51fa\u4e09\u79cd\u4e92\u8865\u7684GPU\u539f\u751f\u7f16\u8bd1\u65b9\u6cd5\uff1a1\uff09\u5e76\u884c\u4f20\u7edf\u7f16\u8bd1\u9002\u914dGPU\u6267\u884c\uff1b2\uff09\u795e\u7ecf\u7f16\u8bd1\u4f7f\u7528\u5b66\u4e60\u578b\u5e8f\u5217\u5230\u5e8f\u5217\u7ffb\u8bd1\u4e0e\u6982\u7387\u9a8c\u8bc1\uff1b3\uff09\u7ed3\u5408\u4e24\u8005\u7684\u6df7\u5408\u67b6\u6784", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\uff1a\u4f20\u7edfGPU\u7f16\u8bd1\u901a\u8fc7\u6d88\u9664\u4f20\u8f93\u5b9e\u73b02-5\u500d\u6539\u8fdb\uff0c\u795e\u7ecf\u7f16\u8bd1\u901a\u8fc7\u5927\u89c4\u6a21\u5e76\u884c\u5b9e\u73b010-100\u500d\u52a0\u901f\uff0c\u6df7\u5408\u65b9\u6cd5\u63d0\u4f9b\u5177\u6709\u6b63\u786e\u6027\u4fdd\u8bc1\u7684\u5b9e\u7528\u90e8\u7f72\u8def\u5f84", "conclusion": "GPU\u539f\u751f\u7f16\u8bd1\u80fd\u663e\u8457\u52a0\u901f\u4ee3\u7801\u8fed\u4ee3\u5468\u671f\uff0c\u6982\u7387\u9a8c\u8bc1\u6846\u67b6\u5141\u8bb8\u5728\u7f16\u8bd1\u51c6\u786e\u6027\u548c\u5e76\u884c\u63a2\u7d22\u4e4b\u95f4\u6743\u8861\uff0c\u5bf9\u81ea\u6539\u8fdbAI\u7cfb\u7edf\u548c\u672a\u6765\u6a21\u62df\u8ba1\u7b97\u57fa\u677f\u6709\u91cd\u8981\u5f71\u54cd"}}
{"id": "2512.11306", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.11306", "abs": "https://arxiv.org/abs/2512.11306", "authors": ["Tianyuan Wu", "Lunxi Cao", "Yining Wei", "Wei Gao", "Yuheng Zhao", "Dakai An", "Shaopan Xiong", "Zhiqiang Lv", "Ju Huang", "Siran Yang", "Yinghao Yu", "Jiamang Wang", "Lin Qu", "Wei Wang"], "title": "RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training", "comment": "17 pages, 15 figures", "summary": "Rollout-training disaggregation is emerging as the standard architecture for Reinforcement Learning (RL) post-training, where memory-bound rollout and compute-bound training are physically disaggregated onto purpose-built clusters to maximize hardware efficiency. However, the strict synchronization required by on-policy algorithms introduces severe dependency bubbles, forcing one cluster to idle while the dependent phase is running on the other. We present RollMux, a cluster scheduling framework that reclaims these bubbles through cross-cluster orchestration. RollMux is built on the insight that the structural idleness of one job can be effectively utilized by the active phase of another. To realize this, we introduce the co-execution group abstraction, which partitions the cluster into isolated locality domains. This abstraction enables a two-tier scheduling architecture: an inter-group scheduler that optimizes job placement using conservative stochastic planning, and an intra-group scheduler that orchestrates a provably optimal round-robin schedule. The group abstraction also imposes a residency constraint, ensuring that massive model states remain cached in host memory to enable \"warm-star\" context switching. We evaluate RollMux on a production-scale testbed with 328 H20 and 328 H800 GPUs. RollMux improves cost efficiency by 1.84x over standard disaggregation and 1.38x over state-of-the-art co-located baselines, all while achieving 100% SLO attainment.", "AI": {"tldr": "RollMux\u662f\u4e00\u4e2a\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u4e2drollout-training\u89e3\u8026\u67b6\u6784\u7684\u96c6\u7fa4\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u96c6\u7fa4\u7f16\u6392\u6d88\u9664\u540c\u6b65\u4f9d\u8d56\u5e26\u6765\u7684\u7a7a\u95f2\u65f6\u95f4\uff0c\u5c06\u6210\u672c\u6548\u7387\u63d0\u53471.84\u500d\u3002", "motivation": "\u5728\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u4e2d\uff0crollout\uff08\u5185\u5b58\u5bc6\u96c6\u578b\uff09\u548ctraining\uff08\u8ba1\u7b97\u5bc6\u96c6\u578b\uff09\u901a\u5e38\u89e3\u8026\u5230\u4e13\u7528\u96c6\u7fa4\u4ee5\u63d0\u9ad8\u786c\u4ef6\u6548\u7387\u3002\u4f46\u57fa\u4e8e\u7b56\u7565\u7b97\u6cd5\u6240\u9700\u7684\u4e25\u683c\u540c\u6b65\u5bfc\u81f4\u4e25\u91cd\u4f9d\u8d56\u6c14\u6ce1\uff0c\u4f7f\u5f97\u4e00\u4e2a\u96c6\u7fa4\u8fd0\u884c\u65f6\u53e6\u4e00\u4e2a\u96c6\u7fa4\u5fc5\u987b\u7a7a\u95f2\uff0c\u9020\u6210\u8d44\u6e90\u6d6a\u8d39\u3002", "method": "\u63d0\u51faRollMux\u6846\u67b6\uff0c\u57fa\u4e8e\"\u4e00\u4e2a\u4f5c\u4e1a\u7684\u7ed3\u6784\u6027\u7a7a\u95f2\u53ef\u88ab\u53e6\u4e00\u4e2a\u4f5c\u4e1a\u7684\u6d3b\u52a8\u9636\u6bb5\u5229\u7528\"\u7684\u6d1e\u5bdf\u3002\u5f15\u5165\u534f\u540c\u6267\u884c\u7ec4\u62bd\u8c61\uff0c\u5c06\u96c6\u7fa4\u5212\u5206\u4e3a\u9694\u79bb\u7684\u5c40\u90e8\u6027\u57df\uff0c\u5b9e\u73b0\u4e24\u5c42\u8c03\u5ea6\u67b6\u6784\uff1a\u7ec4\u95f4\u8c03\u5ea6\u5668\u4f7f\u7528\u4fdd\u5b88\u968f\u673a\u89c4\u5212\u4f18\u5316\u4f5c\u4e1a\u653e\u7f6e\uff0c\u7ec4\u5185\u8c03\u5ea6\u5668\u7f16\u6392\u53ef\u8bc1\u660e\u6700\u4f18\u7684\u8f6e\u8be2\u8c03\u5ea6\u3002\u7ec4\u62bd\u8c61\u8fd8\u65bd\u52a0\u9a7b\u7559\u7ea6\u675f\uff0c\u786e\u4fdd\u5927\u6a21\u578b\u72b6\u6001\u7f13\u5b58\u5728\u4e3b\u673a\u5185\u5b58\u4e2d\uff0c\u5b9e\u73b0\"\u70ed\u542f\u52a8\"\u4e0a\u4e0b\u6587\u5207\u6362\u3002", "result": "\u5728\u5305\u542b328\u4e2aH20\u548c328\u4e2aH800 GPU\u7684\u751f\u4ea7\u7ea7\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8bc4\u4f30\uff0cRollMux\u76f8\u6bd4\u6807\u51c6\u89e3\u8026\u67b6\u6784\u5c06\u6210\u672c\u6548\u7387\u63d0\u53471.84\u500d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5171\u7f6e\u57fa\u7ebf\u63d0\u53471.38\u500d\uff0c\u540c\u65f6\u5b9e\u73b0100%\u7684\u670d\u52a1\u6c34\u5e73\u76ee\u6807\u8fbe\u6210\u7387\u3002", "conclusion": "RollMux\u901a\u8fc7\u8de8\u96c6\u7fa4\u7f16\u6392\u6709\u6548\u56de\u6536\u4e86rollout-training\u89e3\u8026\u67b6\u6784\u4e2d\u7684\u4f9d\u8d56\u6c14\u6ce1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u786c\u4ef6\u5229\u7528\u7387\u548c\u6210\u672c\u6548\u7387\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11271", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11271", "abs": "https://arxiv.org/abs/2512.11271", "authors": ["Yuxing Chen", "Basem Suleiman", "Qifan Chen"], "title": "TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning", "comment": "4 pages, 3 figures", "summary": "Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.", "AI": {"tldr": "TriFlow\u662f\u4e00\u4e2a\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u3001\u89c4\u5212\u548c\u6cbb\u7406\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u5c06\u5f00\u653e\u5f0f\u7528\u6237\u8bf7\u6c42\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u884c\u7a0b\uff0c\u5728\u7a7a\u95f4\u3001\u65f6\u95f4\u548c\u9884\u7b97\u7ea6\u675f\u4e0b\u6ee1\u8db3\u7528\u6237\u504f\u597d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u7ea6\u675f\u6ee1\u8db3\u3001\u5de5\u5177\u534f\u8c03\u548c\u6548\u7387\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7ecf\u5e38\u4ea7\u751f\u4e0d\u53ef\u884c\u6216\u6210\u672c\u8fc7\u9ad8\u7684\u8ba1\u5212\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u7684\u9700\u6c42\u3002", "method": "TriFlow\u91c7\u7528\u6e10\u8fdb\u5f0f\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u3001\u89c4\u5212\u548c\u6cbb\u7406\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u63a8\u7406\u548c\u8bed\u8a00\u7075\u6d3b\u6027\uff0c\u4f7f\u7528\u89c4\u5219-LLM\u534f\u4f5c\u7ec4\u88c5\u7ea6\u675f\u4e00\u81f4\u7684\u884c\u7a0b\uff0c\u5e76\u8fdb\u884c\u6709\u754c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728TravelPlanner\u548cTripTailor\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u5206\u522b\u8fbe\u523091.1%\u548c97%\u7684\u6700\u7ec8\u901a\u8fc7\u7387\uff0c\u76f8\u6bd4\u5f53\u524dSOTA\u5b9e\u73b0\u4e86\u8d85\u8fc710\u500d\u7684\u8fd0\u884c\u6548\u7387\u63d0\u5347\u3002", "conclusion": "TriFlow\u901a\u8fc7\u6e10\u8fdb\u5f0f\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u4e2d\u7684\u7ea6\u675f\u6ee1\u8db3\u548c\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u53ef\u6267\u884c\u7684\u884c\u7a0b\u89c4\u5212\u3002"}}
{"id": "2512.11323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11323", "abs": "https://arxiv.org/abs/2512.11323", "authors": ["Jianyi Zhang", "Ziyin Zhou", "Xu Ji", "Shizhao Liu", "Zhangchi Zhao"], "title": "CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving", "comment": null, "summary": "Benefiting from strong and efficient multi-modal alignment strategies, Large Visual Language Models (LVLMs) are able to simulate human visual and reasoning capabilities, such as solving CAPTCHAs. However, existing benchmarks based on visual CAPTCHAs still face limitations. Previous studies, when designing benchmarks and datasets, customized them according to their research objectives. Consequently, these benchmarks cannot comprehensively cover all CAPTCHA types. Notably, there is a dearth of dedicated benchmarks for LVLMs. To address this problem, we introduce a novel CAPTCHA benchmark for the first time, named CAPTURE CAPTCHA for Testing Under Real-world Experiments, specifically for LVLMs. Our benchmark encompasses 4 main CAPTCHA types and 25 sub-types from 31 vendors. The diversity enables a multi-dimensional and thorough evaluation of LVLM performance. CAPTURE features extensive class variety, large-scale data, and unique LVLM-tailored labels, filling the gaps in previous research in terms of data comprehensiveness and labeling pertinence. When evaluated by this benchmark, current LVLMs demonstrate poor performance in solving CAPTCHAs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684CAPTCHA\u57fa\u51c6\u6d4b\u8bd5CAPTURE\uff0c\u8986\u76d64\u5927\u7c7b25\u5c0f\u7c7bCAPTCHA\u7c7b\u578b\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LVLM\u5728\u89e3\u51b3\u9a8c\u8bc1\u7801\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9CAPTCHA\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5168\u9762\u8986\u76d6\u6240\u6709CAPTCHA\u7c7b\u578b\uff0c\u4e14\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4e13\u7528\u57fa\u51c6\u3002\u73b0\u6709\u7814\u7a76\u5728\u8bbe\u8ba1\u57fa\u51c6\u548c\u6570\u636e\u96c6\u65f6\u901a\u5e38\u6839\u636e\u7279\u5b9a\u7814\u7a76\u76ee\u6807\u5b9a\u5236\uff0c\u5bfc\u81f4\u8bc4\u4f30\u4e0d\u591f\u5168\u9762\u3002", "method": "\u63d0\u51fa\u4e86CAPTURE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u6765\u81ea31\u4e2a\u4f9b\u5e94\u5546\u76844\u4e2a\u4e3b\u8981CAPTCHA\u7c7b\u578b\u548c25\u4e2a\u5b50\u7c7b\u578b\u3002\u8be5\u57fa\u51c6\u5177\u6709\u5e7f\u6cdb\u7684\u7c7b\u522b\u591a\u6837\u6027\u3001\u5927\u89c4\u6a21\u6570\u636e\u4ee5\u53ca\u4e13\u95e8\u4e3aLVLM\u5b9a\u5236\u7684\u6807\u7b7e\uff0c\u586b\u8865\u4e86\u5148\u524d\u7814\u7a76\u5728\u6570\u636e\u5168\u9762\u6027\u548c\u6807\u7b7e\u9488\u5bf9\u6027\u65b9\u9762\u7684\u7a7a\u767d\u3002", "result": "\u4f7f\u7528\u8be5\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u5f53\u524d\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u89e3\u51b3CAPTCHA\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "CAPTURE\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u8bc4\u4f30LVLM\u5728CAPTCHA\u89e3\u51b3\u80fd\u529b\u65b9\u9762\u63d0\u4f9b\u4e86\u5168\u9762\u3001\u591a\u7ef4\u5ea6\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u4e13\u7528\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524dLVLM\u5728\u6b64\u7c7b\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.11532", "categories": ["cs.DC", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.11532", "abs": "https://arxiv.org/abs/2512.11532", "authors": ["Chong Tang", "Hao Dai", "Jagmohan Chauhan"], "title": "Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems", "comment": null, "summary": "The growing demand for real-time DNN applications on edge devices necessitates faster inference of increasingly complex models. Although many devices include specialized accelerators (e.g., mobile GPUs), dynamic control-flow operators and unsupported kernels often fall back to CPU execution. Existing frameworks handle these fallbacks poorly, leaving CPU cores idle and causing high latency and memory spikes. We introduce Parallax, a framework that accelerates mobile DNN inference without model refactoring or custom operator implementations. Parallax first partitions the computation DAG to expose parallelism, then employs branch-aware memory management with dedicated arenas and buffer reuse to reduce runtime footprint. An adaptive scheduler executes branches according to device memory constraints, meanwhile, fine-grained subgraph control enables heterogeneous inference of dynamic models. By evaluating on five representative DNNs across three different mobile devices, Parallax achieves up to 46% latency reduction, maintains controlled memory overhead (26.5% on average), and delivers up to 30% energy savings compared with state-of-the-art frameworks, offering improvements aligned with the responsiveness demands of real-time mobile inference.", "AI": {"tldr": "Parallax\u662f\u4e00\u4e2a\u79fb\u52a8\u7aefDNN\u63a8\u7406\u52a0\u901f\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u56fe\u5206\u533a\u3001\u5206\u652f\u611f\u77e5\u5185\u5b58\u7ba1\u7406\u548c\u81ea\u9002\u5e94\u8c03\u5ea6\uff0c\u5728\u4e0d\u4fee\u6539\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u8fbe46%\u7684\u5ef6\u8fdf\u964d\u4f4e\u548c30%\u7684\u80fd\u8017\u8282\u7701\u3002", "motivation": "\u79fb\u52a8\u8bbe\u5907\u4e0a\u5b9e\u65f6DNN\u5e94\u7528\u9700\u6c42\u589e\u957f\uff0c\u4f46\u73b0\u6709\u6846\u67b6\u5728\u5904\u7406\u52a8\u6001\u63a7\u5236\u6d41\u64cd\u4f5c\u7b26\u548c\u4e0d\u652f\u6301\u7684\u6838\u51fd\u6570\u65f6\u6027\u80fd\u4e0d\u4f73\uff0c\u5bfc\u81f4CPU\u6838\u5fc3\u95f2\u7f6e\u3001\u9ad8\u5ef6\u8fdf\u548c\u5185\u5b58\u5cf0\u503c\u95ee\u9898\u3002", "method": "1) \u5bf9\u8ba1\u7b97DAG\u8fdb\u884c\u5206\u533a\u4ee5\u66b4\u9732\u5e76\u884c\u6027\uff1b2) \u91c7\u7528\u5206\u652f\u611f\u77e5\u5185\u5b58\u7ba1\u7406\uff0c\u4f7f\u7528\u4e13\u7528\u5185\u5b58\u6c60\u548c\u7f13\u51b2\u533a\u91cd\u7528\uff1b3) \u81ea\u9002\u5e94\u8c03\u5ea6\u5668\u6839\u636e\u8bbe\u5907\u5185\u5b58\u7ea6\u675f\u6267\u884c\u5206\u652f\uff1b4) \u7ec6\u7c92\u5ea6\u5b50\u56fe\u63a7\u5236\u5b9e\u73b0\u52a8\u6001\u6a21\u578b\u7684\u5f02\u6784\u63a8\u7406\u3002", "result": "\u5728\u4e09\u79cd\u4e0d\u540c\u79fb\u52a8\u8bbe\u5907\u4e0a\u8bc4\u4f30\u4e94\u4e2a\u4ee3\u8868\u6027DNN\u6a21\u578b\uff0cParallax\u5b9e\u73b0\u4e86\u9ad8\u8fbe46%\u7684\u5ef6\u8fdf\u964d\u4f4e\uff0c\u5e73\u574726.5%\u7684\u5185\u5b58\u5f00\u9500\u63a7\u5236\uff0c\u4ee5\u53ca\u9ad8\u8fbe30%\u7684\u80fd\u8017\u8282\u7701\u3002", "conclusion": "Parallax\u6846\u67b6\u5728\u4e0d\u9700\u6a21\u578b\u91cd\u6784\u6216\u81ea\u5b9a\u4e49\u64cd\u4f5c\u7b26\u5b9e\u73b0\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79fb\u52a8DNN\u63a8\u7406\u6027\u80fd\uff0c\u6ee1\u8db3\u4e86\u5b9e\u65f6\u79fb\u52a8\u63a8\u7406\u7684\u54cd\u5e94\u6027\u9700\u6c42\u3002"}}
{"id": "2512.11421", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11421", "abs": "https://arxiv.org/abs/2512.11421", "authors": ["Gonca G\u00fcrsun"], "title": "Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance", "comment": "Accepted to AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.\n  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4efb\u52a1\u5b8c\u6210\u6846\u67b6\uff0c\u4f7f\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u80fd\u5728\u5f3a\u5316\u5b66\u4e60\u5f62\u5f0f\u5316\u7684\u73af\u5883\u4e2d\uff0c\u5728\u660e\u786e\u7684\u884c\u4e3a\u6307\u5bfc\u4e0b\u53ef\u9760\u5730\u884c\u52a8\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u6790\u5668\u3001\u63a8\u7406\u6a21\u5757\u548c\u751f\u6210\u6a21\u5757\u7684\u534f\u540c\u8fdb\u5316\u5b9e\u73b0\u53ef\u4fe1\u884c\u4e3a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5728\u591a\u8f6e\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\u5f80\u5f80\u7f3a\u4e4f\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002\u9700\u8981\u4e00\u79cd\u6846\u67b6\u6765\u786e\u4fddLLM\u667a\u80fd\u4f53\u5728\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u80fd\u591f\u6309\u7167\u660e\u786e\u7684\u884c\u4e3a\u6307\u5bfc\u53ef\u9760\u5730\u884c\u52a8\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1) \u8f7b\u91cf\u7ea7\u4efb\u52a1\u5206\u6790\u5668\uff0c\u9009\u62e9\u63a8\u7406\u548c\u751f\u6210\u7b56\u7565\uff1b2) \u63a8\u7406\u6a21\u5757\uff0c\u5b66\u4e60\u53ef\u9a8c\u8bc1\u7684\u89c2\u5bdf-\u52a8\u4f5c\u6620\u5c04\uff1b3) \u751f\u6210\u6a21\u5757\uff0c\u901a\u8fc7\u9a8c\u8bc1\u6216\u786e\u5b9a\u6027\u5408\u6210\u5f3a\u5236\u6267\u884c\u7ea6\u675f\u517c\u5bb9\u7684\u8f93\u51fa\u3002\u8fd9\u4e9b\u7ec4\u4ef6\u5728\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u534f\u540c\u8fdb\u5316\u3002", "result": "\u8be5\u6846\u67b6\u4f7fLLM\u667a\u80fd\u4f53\u80fd\u591f\u5728\u5f3a\u5316\u5b66\u4e60\u5f62\u5f0f\u5316\u7684\u73af\u5883\u4e2d\uff08\u5177\u6709\u5b9a\u4e49\u7684\u89c2\u5bdf\u3001\u52a8\u4f5c\u548c\u5956\u52b1\u4fe1\u53f7\uff09\u6309\u7167\u660e\u786e\u7684\u884c\u4e3a\u6307\u5bfc\u884c\u52a8\uff0c\u5b9e\u73b0\u53ef\u4fe1\u8d56\u7684\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u4efb\u52a1\u5206\u6790\u5668\u3001\u63a8\u7406\u6a21\u5757\u548c\u751f\u6210\u6a21\u5757\u7684\u534f\u540c\u8fdb\u5316\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LLM\u667a\u80fd\u4f53\u5728\u591a\u8f6e\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u884c\u4e3a\u53ef\u4fe1\u5ea6\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u6309\u7167\u660e\u786e\u6307\u5bfc\u6267\u884c\u4efb\u52a1\u3002"}}
{"id": "2512.11426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11426", "abs": "https://arxiv.org/abs/2512.11426", "authors": ["Shuowei Cai", "Yansong Ning", "Hao Liu"], "title": "AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints", "comment": null, "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance", "AI": {"tldr": "AgentBalance\u662f\u4e00\u4e2a\u5728\u660e\u786etoken\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5148\u9009\u62e9\u9aa8\u5e72\u6a21\u578b\u518d\u8bbe\u8ba1\u62d3\u6251\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u76f8\u540c\u9884\u7b97\u4e0b\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6784\u5efa\u65f6\u5f88\u5c11\u5728\u660e\u786e\u7684token\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u7ea6\u675f\u4e0b\u8fdb\u884c\u5efa\u6a21\u548c\u4f18\u5316\uff0c\u8fd9\u5bfc\u81f4\u5f53\u9884\u7b97\u6210\u4e3a\u7ea6\u675f\u65f6\uff0c\u73b0\u6709\u7684\u62d3\u6251\u4f18\u5148\u8bbe\u8ba1\u65b9\u6cd5\u5f80\u5f80\u6210\u672c\u6548\u76ca\u4e0d\u9ad8\u3002", "method": "\u91c7\u7528\"\u5148\u9aa8\u5e72\u540e\u62d3\u6251\"\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff1a1) \u9aa8\u5e72\u5bfc\u5411\u7684\u667a\u80fd\u4f53\u751f\u6210\uff1a\u901a\u8fc7LLM\u6c60\u6784\u5efa\u3001\u6c60\u9009\u62e9\u548c\u89d2\u8272-\u9aa8\u5e72\u5339\u914d\u6784\u5efa\u5f02\u6784\u9aa8\u5e72\u7684\u667a\u80fd\u4f53\uff1b2) \u81ea\u9002\u5e94MAS\u62d3\u6251\u751f\u6210\uff1a\u901a\u8fc7\u667a\u80fd\u4f53\u8868\u793a\u5b66\u4e60\u3001\u95e8\u63a7\u673a\u5236\u548c\u5ef6\u8fdf\u611f\u77e5\u62d3\u6251\u5408\u6210\u6765\u6307\u5bfc\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u3002", "result": "\u5728\u5305\u542b14\u4e2a\u5019\u9009LLM\u9aa8\u5e72\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentBalance\u5728\u5339\u914d\u7684token\u6210\u672c\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8fbe10%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5ef6\u8fdf\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8fbe22%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728\u6027\u80fd-\u9884\u7b97\u66f2\u7ebf\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684AUC\u3002\u8be5\u6846\u67b6\u8fd8\u80fd\u4f5c\u4e3a\u73b0\u6709MAS\u7684\u63d2\u4ef6\uff0c\u5728\u76f8\u540c\u7ea6\u675f\u4e0b\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "AgentBalance\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5728\u660e\u786e\u9884\u7b97\u7ea6\u675f\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6709\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u5148\u4f18\u5316\u667a\u80fd\u4f53\u9aa8\u5e72\u518d\u8bbe\u8ba1\u901a\u4fe1\u62d3\u6251\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.11433", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.11433", "abs": "https://arxiv.org/abs/2512.11433", "authors": ["Agustin Martin Picard", "Thibaut Boissin", "Varshini Subhash", "R\u00e9mi Cad\u00e8ne", "Thomas Fel"], "title": "Back to the Baseline: Examining Baseline Effects on Explainability Metrics", "comment": null, "summary": "Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5f53\u524dXAI\u4e2d\u5e38\u7528\u7684\u4fdd\u771f\u5ea6\u8bc4\u4f30\u6307\u6807\uff08\u63d2\u5165\u548c\u5220\u9664\uff09\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff1a\u57fa\u7ebf\u9009\u62e9\u4f1a\u504f\u5411\u67d0\u4e9b\u5f52\u56e0\u65b9\u6cd5\uff0c\u751a\u81f3\u5bfc\u81f4\u7ebf\u6027\u6a21\u578b\u5f97\u51fa\u77db\u76fe\u7684\u6700\u4f18\u65b9\u6cd5\u7ed3\u8bba\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u7ebf\u5e94\u6ee1\u8db3\u4e24\u4e2a\u7406\u60f3\u5c5e\u6027\uff1a\u79fb\u9664\u4fe1\u606f\u548c\u4e0d\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\u56fe\u50cf\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u7ebf\u6765\u6539\u8fdb\u8fd9\u4e00\u6743\u8861\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f52\u56e0\u65b9\u6cd5\u8bc4\u4f30\u5b58\u5728\u6839\u672c\u7f3a\u9677\u3002\u63d2\u5165\u548c\u5220\u9664\u7b49\u4fdd\u771f\u5ea6\u6307\u6807\u4f9d\u8d56\u4e8e\u57fa\u7ebf\u51fd\u6570\u6765\u4fee\u6539\u8f93\u5165\u56fe\u50cf\uff0c\u4f46\u57fa\u7ebf\u9009\u62e9\u4f1a\u7cfb\u7edf\u6027\u5730\u504f\u5411\u67d0\u4e9b\u5f52\u56e0\u65b9\u6cd5\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u4e0d\u53ef\u9760\u3002\u66f4\u4e25\u91cd\u7684\u662f\uff0c\u5373\u4f7f\u7b80\u5355\u7684\u7ebf\u6027\u6a21\u578b\u4f7f\u7528\u5e38\u7528\u57fa\u7ebf\u4e5f\u4f1a\u5f97\u51fa\u77db\u76fe\u7684\u6700\u4f18\u65b9\u6cd5\u7ed3\u8bba\uff0c\u8fd9\u66b4\u9732\u4e86\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u7684\u6839\u672c\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u9996\u5148\u5206\u6790\u4e86\u57fa\u7ebf\u5e94\u6ee1\u8db3\u7684\u4e24\u4e2a\u7406\u60f3\u5c5e\u6027\uff1a\u4fe1\u606f\u79fb\u9664\u548c\u4e0d\u8fc7\u5ea6\u4ea7\u751f\u5206\u5e03\u5916\u56fe\u50cf\u3002\u7136\u540e\u5bf9\u73b0\u6709\u57fa\u7ebf\u8fdb\u884c\u7cfb\u7edf\u6027\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5b83\u4eec\u90fd\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e24\u4e2a\u6807\u51c6\uff0c\u5b58\u5728\u6743\u8861\u5173\u7cfb\u3002\u6700\u540e\uff0c\u4f5c\u8005\u5229\u7528\u7279\u5f81\u53ef\u89c6\u5316\u6280\u672f\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u7ebf\uff0c\u8be5\u57fa\u7ebf\u80fd\u591f\u79fb\u9664\u4fe1\u606f\u800c\u4e0d\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\u56fe\u50cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u57fa\u7ebf\u90fd\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u4fe1\u606f\u79fb\u9664\u548c\u5206\u5e03\u5185\u4fdd\u6301\u4e24\u4e2a\u6807\u51c6\uff0c\u5b58\u5728\u660e\u663e\u7684\u6743\u8861\u5173\u7cfb\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u65b0\u57fa\u7ebf\u5728\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u80fd\u591f\u66f4\u597d\u5730\u79fb\u9664\u4fe1\u606f\u800c\u4e0d\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\u56fe\u50cf\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u5f52\u56e0\u65b9\u6cd5\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "\u5f52\u56e0\u65b9\u6cd5\u7684\u8bc4\u4f30\u4e25\u91cd\u4f9d\u8d56\u4e8e\u57fa\u7ebf\u9009\u62e9\uff0c\u800c\u73b0\u6709\u57fa\u7ebf\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u65b0\u57fa\u7ebf\u901a\u8fc7\u6539\u8fdb\u4fe1\u606f\u79fb\u9664\u4e0e\u5206\u5e03\u5185\u4fdd\u6301\u7684\u6743\u8861\uff0c\u4e3a\u66f4\u53ef\u9760\u3001\u65e0\u504f\u7684\u5f52\u56e0\u65b9\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u91cd\u65b0\u5ba1\u89c6XAI\u8bc4\u4f30\u57fa\u51c6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.11727", "categories": ["cs.DC", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11727", "abs": "https://arxiv.org/abs/2512.11727", "authors": ["Yuze He", "Ferdi Kossmann", "Srinivasan Seshan", "Peter Steenkiste"], "title": "ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning", "comment": null, "summary": "Recent advances in video analytics address real-time data drift by continuously retraining specialized, lightweight DNN models for individual cameras. However, the current practice of retraining a separate model for each camera suffers from high compute and communication costs, making it unscalable. We present ECCO, a new video analytics framework designed for resource-efficient continuous learning. The key insight is that the data drift, which necessitates model retraining, often shows temporal and spatial correlations across nearby cameras. By identifying cameras that experience similar drift and retraining a shared model for them, ECCO can substantially reduce the associated compute and communication costs. Specifically, ECCO introduces: (i) a lightweight grouping algorithm that dynamically forms and updates camera groups; (ii) a GPU allocator that dynamically assigns GPU resources across different groups to improve retraining accuracy and ensure fairness; and (iii) a transmission controller at each camera that configures frame sampling and coordinates bandwidth sharing with other cameras based on its assigned GPU resources. We conducted extensive evaluations on three distinctive datasets for two vision tasks. Compared to leading baselines, ECCO improves retraining accuracy by 6.7%-18.1% using the same compute and communication resources, or supports 3.3 times more concurrent cameras at the same accuracy.", "AI": {"tldr": "ECCO\u662f\u4e00\u4e2a\u89c6\u9891\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u7ecf\u5386\u76f8\u4f3c\u6570\u636e\u6f02\u79fb\u7684\u6444\u50cf\u5934\u5e76\u4e3a\u5176\u8bad\u7ec3\u5171\u4eab\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u4e3a\u6bcf\u4e2a\u6444\u50cf\u5934\u5355\u72ec\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5\u5b58\u5728\u9ad8\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\uff0c\u96be\u4ee5\u6269\u5c55\u3002\u6570\u636e\u6f02\u79fb\u5728\u76f8\u90bb\u6444\u50cf\u5934\u95f4\u901a\u5e38\u5177\u6709\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u8fd9\u4e3a\u4f18\u5316\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "ECCO\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u8f7b\u91cf\u7ea7\u5206\u7ec4\u7b97\u6cd5\u52a8\u6001\u5f62\u6210\u548c\u66f4\u65b0\u6444\u50cf\u5934\u7ec4\uff1b2) GPU\u5206\u914d\u5668\u52a8\u6001\u5206\u914dGPU\u8d44\u6e90\u4ee5\u63d0\u9ad8\u91cd\u8bad\u7ec3\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\uff1b3) \u6bcf\u4e2a\u6444\u50cf\u5934\u7684\u4f20\u8f93\u63a7\u5236\u5668\u914d\u7f6e\u5e27\u91c7\u6837\u5e76\u534f\u8c03\u5e26\u5bbd\u5171\u4eab\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cECCO\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u76f8\u540c\u8ba1\u7b97\u548c\u901a\u4fe1\u8d44\u6e90\u4e0b\u5c06\u91cd\u8bad\u7ec3\u51c6\u786e\u6027\u63d0\u9ad8\u4e866.7%-18.1%\uff0c\u6216\u5728\u76f8\u540c\u51c6\u786e\u6027\u4e0b\u652f\u63013.3\u500d\u66f4\u591a\u7684\u5e76\u53d1\u6444\u50cf\u5934\u3002", "conclusion": "ECCO\u901a\u8fc7\u5229\u7528\u6444\u50cf\u5934\u95f4\u6570\u636e\u6f02\u79fb\u7684\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u5b9e\u73b0\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u8fde\u7eed\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u9891\u5206\u6790\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2512.11469", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11469", "abs": "https://arxiv.org/abs/2512.11469", "authors": ["Pranav Ramanathan", "Thomas Prellberg", "Matthew Lewis", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Three methods, one problem: Classical and AI approaches to no-three-in-line", "comment": null, "summary": "The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\u4e0eAI\u65b9\u6cd5\u5728No-Three-In-Line\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0cILP\u572819\u00d719\u7f51\u683c\u5185\u83b7\u5f97\u6700\u4f18\u89e3\uff0cPatternBoost\u572814\u00d714\u7f51\u683c\u5185\u5339\u914d\u6700\u4f18\u6027\u80fd\uff0cPPO\u572810\u00d710\u7f51\u683c\u8868\u73b0\u5b8c\u7f8e\u4f46\u572811\u00d711\u5931\u8d25\u3002", "motivation": "No-Three-In-Line\u95ee\u9898\u662f\u7ec4\u5408\u51e0\u4f55\u4e2d\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u4f20\u7edf\u6574\u6570\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u867d\u7136\u80fd\u4fdd\u8bc1\u6700\u4f18\u89e3\u4f46\u9762\u4e34\u6307\u6570\u7ea7\u89c4\u6a21\u6269\u5c55\u95ee\u9898\uff0c\u800c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4e3a\u6a21\u5f0f\u8fd1\u4f3c\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9700\u8981\u7cfb\u7edf\u6bd4\u8f83\u7ecf\u5178\u4f18\u5316\u4e0eAI\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u5e94\u7528PatternBoost transformer\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\uff08PPO\uff09\u65b9\u6cd5\u9996\u6b21\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u5e76\u4e0e\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u8fdb\u884c\u5bf9\u6bd4\u3002ILP\u4f5c\u4e3a\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\u63d0\u4f9b\u6700\u4f18\u89e3\u57fa\u51c6\uff0cPatternBoost\u91c7\u7528transformer\u67b6\u6784\u5b66\u4e60\u6a21\u5f0f\uff0cPPO\u4f7f\u7528\u7b56\u7565\u4f18\u5316\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u3002", "result": "ILP\u572819\u00d719\u7f51\u683c\u5185\u83b7\u5f97\u53ef\u8bc1\u660e\u7684\u6700\u4f18\u89e3\uff1bPatternBoost\u572814\u00d714\u7f51\u683c\u5185\u5339\u914d\u6700\u4f18\u6027\u80fd\uff0c\u6d4b\u8bd5\u635f\u5931\u51cf\u5c1196%\uff1bPPO\u572810\u00d710\u7f51\u683c\u4e0a\u83b7\u5f97\u5b8c\u7f8e\u89e3\u4f46\u572811\u00d711\u7f51\u683c\u4e0a\u56e0\u7ea6\u675f\u8fdd\u53cd\u800c\u5931\u8d25\u3002", "conclusion": "\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\u5bf9\u4e8e\u7cbe\u786e\u89e3\u4ecd\u7136\u5fc5\u4e0d\u53ef\u5c11\uff0c\u800cAI\u65b9\u6cd5\u5728\u8f83\u5c0f\u5b9e\u4f8b\u4e0a\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u6df7\u5408\u65b9\u6cd5\u4e3a\u6269\u5c55\u5230\u66f4\u5927\u95ee\u9898\u89c4\u6a21\u63d0\u4f9b\u4e86\u6700\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2512.11505", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11505", "abs": "https://arxiv.org/abs/2512.11505", "authors": ["Priyam Basu", "Yunfeng Zhang", "Vipul Raheja"], "title": "BAID: A Benchmark for Bias Assessment of AI Detectors", "comment": "Accepted at the workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks at AAAI 2026", "summary": "AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.", "AI": {"tldr": "BAID\u6846\u67b6\u7cfb\u7edf\u8bc4\u4f30AI\u6587\u672c\u68c0\u6d4b\u5668\u5728\u4eba\u53e3\u7edf\u8ba1\u5b66\u3001\u5e74\u9f84\u3001\u6559\u80b2\u6c34\u5e73\u3001\u65b9\u8a00\u3001\u6b63\u5f0f\u7a0b\u5ea6\u3001\u653f\u6cbb\u503e\u5411\u548c\u4e3b\u9898\u7b497\u4e2a\u7ef4\u5ea6\u7684\u504f\u89c1\uff0c\u53d1\u73b0\u68c0\u6d4b\u5668\u5bf9\u5c11\u6570\u7fa4\u4f53\u6587\u672c\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u7279\u522b\u662f\u53ec\u56de\u7387\u504f\u4f4e\u3002", "motivation": "\u73b0\u6709AI\u6587\u672c\u68c0\u6d4b\u5668\u5728\u6559\u80b2\u548c\u5de5\u4f5c\u573a\u666f\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4e4b\u524d\u7684\u7814\u7a76\u4ec5\u53d1\u73b0\u9488\u5bf9\u82f1\u8bed\u5b66\u4e60\u8005\u7684\u5b64\u7acb\u504f\u89c1\u6848\u4f8b\uff0c\u7f3a\u4e4f\u5bf9\u66f4\u5e7f\u6cdb\u793e\u4f1a\u8bed\u8a00\u56e0\u7d20\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u63d0\u51faBAID\u8bc4\u4f30\u6846\u67b6\uff0c\u6784\u5efa\u8d85\u8fc720\u4e07\u4e2a\u6837\u672c\uff0c\u6db5\u76d67\u4e2a\u4e3b\u8981\u7c7b\u522b\uff1a\u4eba\u53e3\u7edf\u8ba1\u5b66\u3001\u5e74\u9f84\u3001\u6559\u80b2\u6c34\u5e73\u3001\u65b9\u8a00\u3001\u6b63\u5f0f\u7a0b\u5ea6\u3001\u653f\u6cbb\u503e\u5411\u548c\u4e3b\u9898\u3002\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u5408\u6210\u7248\u672c\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u63d0\u793a\u4ee5\u4fdd\u7559\u539f\u59cb\u5185\u5bb9\u540c\u65f6\u53cd\u6620\u7279\u5b9a\u5b50\u7fa4\u4f53\u7684\u5199\u4f5c\u98ce\u683c\uff0c\u7136\u540e\u8bc4\u4f304\u4e2a\u5f00\u6e90\u6700\u5148\u8fdb\u7684AI\u6587\u672c\u68c0\u6d4b\u5668\u3002", "result": "\u53d1\u73b0\u68c0\u6d4b\u5668\u5728\u68c0\u6d4b\u6027\u80fd\u4e0a\u5b58\u5728\u4e00\u81f4\u7684\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5bf9\u6765\u81ea\u4ee3\u8868\u6027\u4e0d\u8db3\u7fa4\u4f53\u7684\u6587\u672c\u53ec\u56de\u7387\u8f83\u4f4e\uff0c\u8868\u660eAI\u6587\u672c\u68c0\u6d4b\u5668\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "conclusion": "BAID\u6846\u67b6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684AI\u68c0\u6d4b\u5668\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5728\u5c06\u8fd9\u4e9b\u5de5\u5177\u90e8\u7f72\u7ed9\u516c\u4f17\u4f7f\u7528\u4e4b\u524d\u9700\u8981\u8fdb\u884c\u504f\u89c1\u611f\u77e5\u7684\u8bc4\u4f30\u3002"}}
{"id": "2512.11544", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11544", "abs": "https://arxiv.org/abs/2512.11544", "authors": ["Yuan Shen", "Xiaojun Wu", "Linghua Yu"], "title": "AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives", "comment": "47 pages, 2 figures", "summary": "This study aims to simulate real-world clinical scenarios to systematically evaluate the ability of Large Language Models (LLMs) to extract core medical information from patient chief complaints laden with noise and redundancy, and to verify whether they exhibit a functional decline analogous to Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD). We employed a cross-sectional analysis design based on standardized medical probes, selecting four mainstream LLMs as research subjects: GPT-4o, Gemini 2.5, DeepSeek 3.1, and Qwen3-Max. An evaluation system comprising twenty medical probes across five core dimensions was used to simulate a genuine clinical communication environment. All probes had gold-standard answers defined by clinical experts and were assessed via a double-blind, inverse rating scale by two independent clinicians. The results show that all tested models exhibited functional defects to varying degrees, with Qwen3-Max demonstrating the best overall performance and Gemini 2.5 the worst. Under conditions of extreme noise, most models experienced a functional collapse. Notably, GPT-4o made a severe misjudgment in the risk assessment for pulmonary embolism (PE) secondary to deep vein thrombosis (DVT). This research is the first to empirically confirm that LLMs exhibit features resembling metabolic dysfunction when processing clinical information, proposing the innovative concept of \"AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)\". These findings offer a crucial safety warning for the application of Artificial Intelligence (AI) in healthcare, emphasizing that current LLMs must be used as auxiliary tools under human expert supervision, as there remains a significant gap between their theoretical knowledge and practical clinical application.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5b9e\u8bc1\u786e\u8ba4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u4e34\u5e8a\u4fe1\u606f\u65f6\u8868\u73b0\u51fa\u7c7b\u4f3c\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u7684\u7279\u5f81\uff0c\u63d0\u51fa\u4e86\"AI-\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u76f8\u5173\u8102\u80aa\u6027\u809d\u75c5(AI-MASLD)\"\u7684\u521b\u65b0\u6982\u5ff5\uff0c\u4e3aAI\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u5b89\u5168\u8b66\u793a\u3002", "motivation": "\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u5145\u6ee1\u566a\u58f0\u548c\u5197\u4f59\u7684\u60a3\u8005\u4e3b\u8bc9\u4e2d\u63d0\u53d6\u6838\u5fc3\u533b\u7597\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u5e76\u9a8c\u8bc1\u5176\u662f\u5426\u8868\u73b0\u51fa\u7c7b\u4f3c\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u76f8\u5173\u8102\u80aa\u6027\u809d\u75c5(MASLD)\u7684\u529f\u80fd\u8870\u9000\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6807\u51c6\u5316\u533b\u7597\u63a2\u9488\u7684\u6a2a\u65ad\u9762\u5206\u6790\u8bbe\u8ba1\uff0c\u9009\u62e9GPT-4o\u3001Gemini 2.5\u3001DeepSeek 3.1\u548cQwen3-Max\u56db\u79cd\u4e3b\u6d41LLMs\u4f5c\u4e3a\u7814\u7a76\u5bf9\u8c61\u3002\u4f7f\u7528\u5305\u542b\u4e94\u4e2a\u6838\u5fc3\u7ef4\u5ea6\u3001\u4e8c\u5341\u4e2a\u533b\u7597\u63a2\u9488\u7684\u8bc4\u4f30\u7cfb\u7edf\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u6c9f\u901a\u73af\u5883\uff0c\u6240\u6709\u63a2\u9488\u5747\u6709\u4e34\u5e8a\u4e13\u5bb6\u5b9a\u4e49\u7684\u91d1\u6807\u51c6\u7b54\u6848\uff0c\u5e76\u7531\u4e24\u540d\u72ec\u7acb\u4e34\u5e8a\u533b\u751f\u901a\u8fc7\u53cc\u76f2\u3001\u9006\u8bc4\u5206\u91cf\u8868\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u5747\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u529f\u80fd\u7f3a\u9677\uff0cQwen3-Max\u6574\u4f53\u8868\u73b0\u6700\u4f73\uff0cGemini 2.5\u6700\u5dee\u3002\u5728\u6781\u7aef\u566a\u58f0\u6761\u4ef6\u4e0b\uff0c\u5927\u591a\u6570\u6a21\u578b\u51fa\u73b0\u529f\u80fd\u5d29\u6e83\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cGPT-4o\u5728\u6df1\u9759\u8109\u8840\u6813(DVT)\u7ee7\u53d1\u80ba\u6813\u585e(PE)\u7684\u98ce\u9669\u8bc4\u4f30\u4e2d\u51fa\u73b0\u4e86\u4e25\u91cd\u8bef\u5224\u3002", "conclusion": "\u9996\u6b21\u5b9e\u8bc1\u786e\u8ba4LLMs\u5728\u5904\u7406\u4e34\u5e8a\u4fe1\u606f\u65f6\u8868\u73b0\u51fa\u7c7b\u4f3c\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u7684\u7279\u5f81\uff0c\u63d0\u51fa\"AI-MASLD\"\u521b\u65b0\u6982\u5ff5\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3aAI\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5173\u952e\u5b89\u5168\u8b66\u544a\uff0c\u5f3a\u8c03\u5f53\u524dLLMs\u5fc5\u987b\u5728\u4eba\u7c7b\u4e13\u5bb6\u76d1\u7763\u4e0b\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u4f7f\u7528\uff0c\u56e0\u4e3a\u5176\u7406\u8bba\u77e5\u8bc6\u4e0e\u5b9e\u9645\u4e34\u5e8a\u5e94\u7528\u4e4b\u95f4\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2512.11588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11588", "abs": "https://arxiv.org/abs/2512.11588", "authors": ["Gregor von Laszewski", "Wesley Brewer", "Jeyan Thiyagalingam", "Juri Papay", "Armstrong Foundjem", "Piotr Luszczek", "Murali Emani", "Shirley V. Moore", "Vijay Janapa Reddi", "Matthew D. Sinclair", "Sebastian Lobentanzer", "Sujata Goswami", "Benjamin Hawks", "Marco Colombo", "Nhan Tran", "Christine R. Kirkpatrick", "Abdulkareem Alsudais", "Gregg Barrett", "Tianhao Li", "Kirsten Morehouse", "Shivaram Venkataraman", "Rutwik Jain", "Kartik Mathur", "Victor Lu", "Tejinder Singh", "Khojasteh Z. Mirza", "Kongtao Chen", "Sasidhar Kunapuli", "Gavin Farrell", "Renato Umeton", "Geoffrey C. Fox"], "title": "AI Benchmark Democratization and Carpentry", "comment": "43 pages, 2 figures, 7 tables", "summary": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance.\n  Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This calls for skills and education in AI Benchmark Carpentry. From our experience with MLCommons, educational initiatives, and programs like the DOE's Trillion Parameter Consortium, key barriers include high resource demands, limited access to specialized hardware, lack of benchmark design expertise, and uncertainty in relating results to application domains. Current benchmarks often emphasize peak performance on top-tier hardware, offering limited guidance for diverse, real-world scenarios.\n  Benchmarking must become dynamic, incorporating evolving models, updated data, and heterogeneous platforms while maintaining transparency, reproducibility, and interpretability. Democratization requires both technical innovation and systematic education across levels, building sustained expertise in benchmark design and use. Benchmarks should support application-relevant comparisons, enabling informed, context-sensitive decisions. Dynamic, inclusive benchmarking will ensure evaluation keeps pace with AI evolution and supports responsible, reproducible, and accessible AI deployment. Community efforts can provide a foundation for AI Benchmark Carpentry.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAI\u57fa\u51c6\u6d4b\u8bd5\u9700\u8981\u4ece\u9759\u6001\u8f6c\u5411\u52a8\u6001\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9AI\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u7684\u8bc4\u4f30\u6311\u6218\uff0c\u5e76\u5f15\u5165\"AI\u57fa\u51c6\u6d4b\u8bd5\u5de5\u827a\u5b66\"\u6982\u5ff5\u6765\u57f9\u517b\u76f8\u5173\u6280\u80fd\u548c\u6559\u80b2\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u9762\u4e34\u591a\u91cd\u6311\u6218\uff1aAI\u6a21\u578b\u67b6\u6784\u3001\u89c4\u6a21\u3001\u6570\u636e\u96c6\u548c\u90e8\u7f72\u73af\u5883\u5feb\u901f\u6f14\u53d8\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u8bb0\u5fc6\u9759\u6001\u57fa\u51c6\u5bfc\u81f4\u7ed3\u679c\u4e0e\u771f\u5b9e\u6027\u80fd\u8131\u8282\uff0c\u73b0\u6709\u57fa\u51c6\u8fc7\u5ea6\u5f3a\u8c03\u9876\u7ea7\u786c\u4ef6\u5cf0\u503c\u6027\u80fd\u800c\u7f3a\u4e4f\u5b9e\u9645\u5e94\u7528\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u81ea\u9002\u5e94\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b\u6301\u7eed\u6f14\u5316\u7684\u6a21\u578b\u3001\u66f4\u65b0\u6570\u636e\u3001\u5f02\u6784\u5e73\u53f0\u652f\u6301\uff0c\u540c\u65f6\u4fdd\u6301\u900f\u660e\u5ea6\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u5f3a\u8c03\u901a\u8fc7\"AI\u57fa\u51c6\u6d4b\u8bd5\u5de5\u827a\u5b66\"\u8fdb\u884c\u7cfb\u7edf\u6027\u6559\u80b2\uff0c\u57f9\u517b\u57fa\u51c6\u8bbe\u8ba1\u548c\u4f7f\u7528\u4e13\u4e1a\u77e5\u8bc6\u3002", "result": "\u8bc6\u522b\u51fa\u5173\u952e\u969c\u788d\u5305\u62ec\u9ad8\u8d44\u6e90\u9700\u6c42\u3001\u4e13\u7528\u786c\u4ef6\u8bbf\u95ee\u9650\u5236\u3001\u57fa\u51c6\u8bbe\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u7f3a\u4e4f\u3001\u7ed3\u679c\u4e0e\u5e94\u7528\u9886\u57df\u5173\u8054\u4e0d\u786e\u5b9a\u6027\u3002\u63d0\u51fa\u793e\u533a\u52aa\u529b\u53ef\u4e3aAI\u57fa\u51c6\u6d4b\u8bd5\u5de5\u827a\u5b66\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "\u52a8\u6001\u5305\u5bb9\u6027\u57fa\u51c6\u6d4b\u8bd5\u80fd\u786e\u4fdd\u8bc4\u4f30\u8ddf\u4e0aAI\u53d1\u5c55\u6b65\u4f10\uff0c\u652f\u6301\u8d1f\u8d23\u4efb\u3001\u53ef\u91cd\u590d\u548c\u53ef\u8bbf\u95ee\u7684AI\u90e8\u7f72\u3002\u57fa\u51c6\u6d4b\u8bd5\u5e94\u652f\u6301\u5e94\u7528\u76f8\u5173\u6bd4\u8f83\uff0c\u5b9e\u73b0\u57fa\u4e8e\u60c5\u5883\u7684\u660e\u667a\u51b3\u7b56\u3002"}}
{"id": "2512.11653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11653", "abs": "https://arxiv.org/abs/2512.11653", "authors": ["Chutian Ma", "Grigorii Pomazkin", "Giacinto Paolo Saggese", "Paul Smith"], "title": "Causal Inference in Energy Demand Prediction", "comment": null, "summary": "Energy demand prediction is critical for grid operators, industrial energy\n  consumers, and service providers. Energy demand is influenced by multiple\n  factors, including weather conditions (e.g. temperature, humidity, wind\n  speed, solar radiation), and calendar information (e.g. hour of day and\n  month of year), which further affect daily work and life schedules. These\n  factors are causally interdependent, making the problem more complex than\n  simple correlation-based learning techniques satisfactorily allow for. We\n  propose a structural causal model that explains the causal relationship\n  between these variables. A full analysis is performed to validate our causal\n  beliefs, also revealing important insights consistent with prior studies.\n  For example, our causal model reveals that energy demand responds to\n  temperature fluctuations with season-dependent sensitivity. Additionally, we\n  find that energy demand exhibits lower variance in winter due to the\n  decoupling effect between temperature changes and daily activity patterns.\n  We then build a Bayesian model, which takes advantage of the causal insights\n  we learned as prior knowledge. The model is trained and tested on unseen\n  data and yields state-of-the-art performance in the form of a 3.84 percent MAPE on\n  the test set. The model also demonstrates strong robustness, as the\n  cross-validation across two years of data yields an average MAPE of 3.88 percent.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528\u5929\u6c14\u548c\u65e5\u5386\u4fe1\u606f\u7684\u56e0\u679c\u5173\u7cfb\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f97\u4e863.84%\u7684\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\u3002", "motivation": "\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u5bf9\u7535\u7f51\u8fd0\u8425\u5546\u3001\u5de5\u4e1a\u80fd\u6e90\u6d88\u8d39\u8005\u548c\u670d\u52a1\u63d0\u4f9b\u5546\u81f3\u5173\u91cd\u8981\u3002\u80fd\u6e90\u9700\u6c42\u53d7\u5929\u6c14\u6761\u4ef6\uff08\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u98ce\u901f\u3001\u592a\u9633\u8f90\u5c04\uff09\u548c\u65e5\u5386\u4fe1\u606f\uff08\u5c0f\u65f6\u3001\u6708\u4efd\uff09\u7b49\u591a\u56e0\u7d20\u5f71\u54cd\uff0c\u8fd9\u4e9b\u56e0\u7d20\u5b58\u5728\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f7f\u5f97\u7b80\u5355\u7684\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u6765\u89e3\u91ca\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u901a\u8fc7\u5168\u9762\u5206\u6790\u9a8c\u8bc1\u56e0\u679c\u4fe1\u5ff5\u3002\u57fa\u4e8e\u5b66\u5230\u7684\u56e0\u679c\u6d1e\u5bdf\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u5728\u672a\u89c1\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f97\u4e863.84%\u7684MAPE\uff08\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\uff09\uff0c\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u8de8\u4e24\u5e74\u6570\u636e\u7684\u4ea4\u53c9\u9a8c\u8bc1\u5e73\u5747MAPE\u4e3a3.88%\uff0c\u663e\u793a\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002\u56e0\u679c\u5206\u6790\u63ed\u793a\u4e86\u80fd\u6e90\u9700\u6c42\u5bf9\u6e29\u5ea6\u6ce2\u52a8\u7684\u54cd\u5e94\u5177\u6709\u5b63\u8282\u4f9d\u8d56\u6027\u654f\u611f\u6027\uff0c\u51ac\u5b63\u80fd\u6e90\u9700\u6c42\u65b9\u5dee\u8f83\u4f4e\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u5efa\u6a21\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u6355\u6349\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u56e0\u679c\u5173\u7cfb\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u548c\u9c81\u68d2\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u80fd\u6e90\u7ba1\u7406\u63d0\u4f9b\u91cd\u8981\u6d1e\u5bdf\u3002"}}
