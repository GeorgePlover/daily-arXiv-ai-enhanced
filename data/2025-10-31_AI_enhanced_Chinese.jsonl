{"id": "2510.25929", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25929", "abs": "https://arxiv.org/abs/2510.25929", "authors": ["Ziyi Wang", "Carmine Ventre", "Maria Polukarov"], "title": "Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion", "comment": null, "summary": "Algorithmic collusion has emerged as a central question in AI: Will the\ninteraction between different AI agents deployed in markets lead to collusion?\nMore generally, understanding how emergent behavior, be it a cartel or market\ndominance from more advanced bots, affects the market overall is an important\nresearch question.\n  We propose a hierarchical multi-agent reinforcement learning framework to\nstudy algorithmic collusion in market making. The framework includes a\nself-interested market maker (Agent~A), which is trained in an uncertain\nenvironment shaped by an adversary, and three bottom-layer competitors: the\nself-interested Agent~B1 (whose objective is to maximize its own PnL), the\ncompetitive Agent~B2 (whose objective is to minimize the PnL of its opponent),\nand the hybrid Agent~B$^\\star$, which can modulate between the behavior of the\nother two. To analyze how these agents shape the behavior of each other and\naffect market outcomes, we propose interaction-level metrics that quantify\nbehavioral asymmetry and system-level dynamics, while providing signals\npotentially indicative of emergent interaction patterns.\n  Experimental results show that Agent~B2 secures dominant performance in a\nzero-sum setting against B1, aggressively capturing order flow while tightening\naverage spreads, thus improving market execution efficiency. In contrast,\nAgent~B$^\\star$ exhibits a self-interested inclination when co-existing with\nother profit-seeking agents, securing dominant market share through adaptive\nquoting, yet exerting a milder adverse impact on the rewards of Agents~A and B1\ncompared to B2. These findings suggest that adaptive incentive control supports\nmore sustainable strategic co-existence in heterogeneous agent environments and\noffers a structured lens for evaluating behavioral design in algorithmic\ntrading systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u7814\u7a76\u7b97\u6cd5\u505a\u5e02\u4e2d\u7684\u5408\u8c0b\u884c\u4e3a\uff0c\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u6fc0\u52b1\u7ed3\u6784\u7684\u667a\u80fd\u4f53\u5728\u5e02\u573a\u4e2d\u7684\u4ea4\u4e92\u6a21\u5f0f\u548c\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u7b97\u6cd5\u5408\u8c0b\u8fd9\u4e00AI\u9886\u57df\u6838\u5fc3\u95ee\u9898\uff0c\u7406\u89e3\u4e0d\u540cAI\u667a\u80fd\u4f53\u5728\u5e02\u573a\u4e2d\u7684\u4ea4\u4e92\u662f\u5426\u4f1a\u5bfc\u81f4\u5408\u8c0b\u884c\u4e3a\uff0c\u4ee5\u53ca\u66f4\u5e7f\u6cdb\u5730\u7814\u7a76\u6d8c\u73b0\u884c\u4e3a\uff08\u5982\u5361\u7279\u5c14\u6216\u5e02\u573a\u652f\u914d\uff09\u5bf9\u5e02\u573a\u7684\u6574\u4f53\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u62ec\u4e00\u4e2a\u81ea\u5229\u7684\u505a\u5e02\u5546Agent A\uff08\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u8bad\u7ec3\uff09\u548c\u4e09\u4e2a\u5e95\u5c42\u7ade\u4e89\u8005\uff1a\u81ea\u5229\u7684Agent B1\u3001\u7ade\u4e89\u7684Agent B2\uff08\u6700\u5c0f\u5316\u5bf9\u624b\u6536\u76ca\uff09\u4ee5\u53ca\u6df7\u5408\u578bAgent B*\uff08\u53ef\u5728\u524d\u4e24\u79cd\u884c\u4e3a\u95f4\u8c03\u8282\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u96f6\u548c\u8bbe\u7f6e\u4e2d\uff0cAgent B2\u5bf9B1\u53d6\u5f97\u4e3b\u5bfc\u6027\u80fd\uff0c\u79ef\u6781\u6355\u83b7\u8ba2\u5355\u6d41\u540c\u65f6\u6536\u7d27\u5e73\u5747\u4ef7\u5dee\uff0c\u63d0\u9ad8\u5e02\u573a\u6267\u884c\u6548\u7387\u3002\u800cAgent B*\u4e0e\u5176\u4ed6\u9010\u5229\u667a\u80fd\u4f53\u5171\u5b58\u65f6\u8868\u73b0\u51fa\u81ea\u5229\u503e\u5411\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u62a5\u4ef7\u83b7\u5f97\u4e3b\u5bfc\u5e02\u573a\u4efd\u989d\uff0c\u4f46\u5bf9Agent A\u548cB1\u7684\u6536\u76ca\u8d1f\u9762\u5f71\u54cd\u8f83B2\u66f4\u6e29\u548c\u3002", "conclusion": "\u81ea\u9002\u5e94\u6fc0\u52b1\u63a7\u5236\u5728\u5f02\u6784\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u652f\u6301\u66f4\u53ef\u6301\u7eed\u7684\u6218\u7565\u5171\u5b58\uff0c\u4e3a\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8bc4\u4f30\u89c6\u89d2\u3002"}}
{"id": "2510.26740", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26740", "abs": "https://arxiv.org/abs/2510.26740", "authors": ["Ashwin Kumar", "William Yeoh"], "title": "A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation", "comment": null, "summary": "We introduce the General Incentives-based Framework for Fairness (GIFF), a\nnovel approach for fair multi-agent resource allocation that infers fair\ndecision-making from standard value functions. In resource-constrained\nsettings, agents optimizing for efficiency often create inequitable outcomes.\nOur approach leverages the action-value (Q-)function to balance efficiency and\nfairness without requiring additional training. Specifically, our method\ncomputes a local fairness gain for each action and introduces a counterfactual\nadvantage correction term to discourage over-allocation to already well-off\nagents. This approach is formalized within a centralized control setting, where\nan arbitrator uses the GIFF-modified Q-values to solve an allocation problem.\n  Empirical evaluations across diverse domains, including dynamic ridesharing,\nhomelessness prevention, and a complex job allocation task-demonstrate that our\nframework consistently outperforms strong baselines and can discover\nfar-sighted, equitable policies. The framework's effectiveness is supported by\na theoretical foundation; we prove its fairness surrogate is a principled lower\nbound on the true fairness improvement and that its trade-off parameter offers\nmonotonic tuning. Our findings establish GIFF as a robust and principled\nframework for leveraging standard reinforcement learning components to achieve\nmore equitable outcomes in complex multi-agent systems.", "AI": {"tldr": "GIFF\u662f\u4e00\u4e2a\u57fa\u4e8e\u6fc0\u52b1\u7684\u516c\u5e73\u591a\u667a\u80fd\u4f53\u8d44\u6e90\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u51c6\u4ef7\u503c\u51fd\u6570\u63a8\u65ad\u516c\u5e73\u51b3\u7b56\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5e73\u8861\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u667a\u80fd\u4f53\u8ffd\u6c42\u6548\u7387\u4f18\u5316\u5f80\u5f80\u5bfc\u81f4\u4e0d\u516c\u5e73\u7ed3\u679c\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861\u6548\u7387\u548c\u516c\u5e73\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\u8ba1\u7b97\u5c40\u90e8\u516c\u5e73\u589e\u76ca\uff0c\u5f15\u5165\u53cd\u4e8b\u5b9e\u4f18\u52bf\u6821\u6b63\u9879\u6765\u963b\u6b62\u5bf9\u5df2\u5bcc\u88d5\u667a\u80fd\u4f53\u7684\u8fc7\u5ea6\u5206\u914d\uff0c\u5728\u96c6\u4e2d\u63a7\u5236\u8bbe\u7f6e\u4e2d\u901a\u8fc7GIFF\u4fee\u6b63\u7684Q\u503c\u89e3\u51b3\u5206\u914d\u95ee\u9898\u3002", "result": "\u5728\u52a8\u6001\u62fc\u8f66\u3001\u65e0\u5bb6\u53ef\u5f52\u8005\u9884\u9632\u548c\u590d\u6742\u5de5\u4f5c\u5206\u914d\u7b49\u591a\u4e2a\u9886\u57df\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6846\u67b6\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u591f\u53d1\u73b0\u5177\u6709\u8fdc\u89c1\u7684\u516c\u5e73\u7b56\u7565\u3002", "conclusion": "GIFF\u662f\u4e00\u4e2a\u7a33\u5065\u4e14\u6709\u539f\u5219\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5229\u7528\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u7ec4\u4ef6\u5728\u590d\u6742\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u7ed3\u679c\u3002"}}
{"id": "2510.25775", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25775", "abs": "https://arxiv.org/abs/2510.25775", "authors": ["Francesco Spinnato"], "title": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "comment": null, "summary": "Contemporary chess engines offer precise yet opaque evaluations, typically\nexpressed as centipawn scores. While effective for decision-making, these\noutputs obscure the underlying contributions of individual pieces or patterns.\nIn this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the\ndomain of chess analysis, aiming to attribute a chess engines evaluation to\nspecific pieces on the board. By treating pieces as features and systematically\nablating them, we compute additive, per-piece contributions that explain the\nengines output in a locally faithful and human-interpretable manner. This\nmethod draws inspiration from classical chess pedagogy, where players assess\npositions by mentally removing pieces, and grounds it in modern explainable AI\ntechniques. Our approach opens new possibilities for visualization, human\ntraining, and engine comparison. We release accompanying code and data to\nfoster future research in interpretable chess AI.", "AI": {"tldr": "\u5c06SHAP\u89e3\u91ca\u6027AI\u6280\u672f\u5e94\u7528\u4e8e\u56fd\u9645\u8c61\u68cb\u5206\u6790\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u79fb\u9664\u68cb\u76d8\u4e0a\u7684\u68cb\u5b50\u6765\u8ba1\u7b97\u6bcf\u4e2a\u68cb\u5b50\u5bf9\u5f15\u64ce\u8bc4\u4f30\u7684\u8d21\u732e\u5ea6\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u68cb\u5b50\u7ea7\u8bc4\u4f30\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u63d0\u4f9b\u7cbe\u786e\u4f46\u4e0d\u900f\u660e\u7684\u8bc4\u4f30\u5206\u6570\uff08\u901a\u5e38\u4ee5\u767e\u5206\u5175\u4e3a\u5355\u4f4d\uff09\uff0c\u8fd9\u4e9b\u8f93\u51fa\u63a9\u76d6\u4e86\u5355\u4e2a\u68cb\u5b50\u6216\u6a21\u5f0f\u7684\u8d21\u732e\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u89e3\u91ca\u5f15\u64ce\u8bc4\u4f30\u80cc\u540e\u5177\u4f53\u68cb\u5b50\u8d21\u732e\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u68cb\u5b50\u89c6\u4e3a\u7279\u5f81\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u79fb\u9664\uff08\u6d88\u878d\uff09\u68cb\u5b50\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u68cb\u5b50\u7684SHAP\u503c\uff0c\u4ece\u800c\u83b7\u5f97\u52a0\u6027\u7684\u3001\u9488\u5bf9\u6bcf\u4e2a\u68cb\u5b50\u7684\u8d21\u732e\u5ea6\uff0c\u4ee5\u5c40\u90e8\u5fe0\u5b9e\u4e14\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u89e3\u91ca\u5f15\u64ce\u8f93\u51fa\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u80fd\u591f\u5c06\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u8bc4\u4f30\u5f52\u56e0\u4e8e\u7279\u5b9a\u68cb\u5b50\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0e\u53e4\u5178\u56fd\u9645\u8c61\u68cb\u6559\u5b66\u6cd5\uff08\u901a\u8fc7\u5fc3\u7406\u79fb\u9664\u68cb\u5b50\u8bc4\u4f30\u5c40\u9762\uff09\u76f8\u547c\u5e94\uff0c\u5e76\u5efa\u7acb\u5728\u73b0\u4ee3\u53ef\u89e3\u91caAI\u6280\u672f\u57fa\u7840\u4e0a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u89c6\u5316\u3001\u4eba\u7c7b\u8bad\u7ec3\u548c\u5f15\u64ce\u6bd4\u8f83\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u53d1\u5e03\u4e86\u914d\u5957\u4ee3\u7801\u548c\u6570\u636e\u4ee5\u4fc3\u8fdb\u53ef\u89e3\u91ca\u56fd\u9645\u8c61\u68cbAI\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2510.26730", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.26730", "abs": "https://arxiv.org/abs/2510.26730", "authors": ["Zixu Shen", "Kexin Chu", "Yifan Zhang", "Dawei Xiang", "Runxin Wu", "Wei Zhang"], "title": "ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference", "comment": "12 pages, 11 figures", "summary": "The expansion of large language models is increasingly limited by the\nconstrained memory capacity of modern GPUs. To mitigate this,\nMixture-of-Experts (MoE) architectures activate only a small portion of\nparameters during inference, significantly lowering both memory demand and\ncomputational overhead. However, conventional MoE inference approaches, which\nselect active experts independently at each layer, often introduce considerable\nlatency because of frequent parameter transfers between host and GPU memory. In\naddition, current cross-layer prediction strategies, which are typically based\non fixed steps, lack adaptability across different hardware platforms and\nworkloads, thereby reducing their robustness and effectiveness.\n  To address these challenges, we present ExpertFlow, a runtime system for MoE\ninference that combines adaptive expert prefetching and cache-aware routing.\nExpertFlow continuously adjusts its prediction horizon for expert activation by\nleveraging runtime statistics such as transfer bandwidth, parameter\ndimensionality, and model feedback signals. Furthermore, it incorporates a\nhybrid cross-layer prediction scheme that fuses pregating information with\nintermediate computational states to anticipate future expert needs. By\nadaptively refining prefetching decisions and aligning them with actual usage\nbehavior, ExpertFlow effectively decreases cache misses and removes latency\ncaused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reduces\nmodel stall time to less than 0.1% of the baseline, highlighting its capability\nto optimize MoE inference under stringent memory constraints.", "AI": {"tldr": "ExpertFlow\u662f\u4e00\u4e2a\u7528\u4e8eMoE\u63a8\u7406\u7684\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4e13\u5bb6\u9884\u53d6\u548c\u7f13\u5b58\u611f\u77e5\u8def\u7531\u6765\u4f18\u5316\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3GPU\u5185\u5b58\u5bb9\u91cf\u6709\u9650\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6269\u5c55\uff0c\u4f20\u7edfMoE\u63a8\u7406\u65b9\u6cd5\u56e0\u9891\u7e41\u53c2\u6570\u4f20\u8f93\u5f15\u5165\u663e\u8457\u5ef6\u8fdf\uff0c\u4e14\u73b0\u6709\u8de8\u5c42\u9884\u6d4b\u7b56\u7565\u7f3a\u4e4f\u8de8\u786c\u4ef6\u5e73\u53f0\u548c\u8d1f\u8f7d\u7684\u9002\u5e94\u6027\u3002", "method": "\u7ed3\u5408\u81ea\u9002\u5e94\u4e13\u5bb6\u9884\u53d6\u548c\u7f13\u5b58\u611f\u77e5\u8def\u7531\uff0c\u5229\u7528\u8fd0\u884c\u65f6\u7edf\u8ba1\u4fe1\u606f\uff08\u4f20\u8f93\u5e26\u5bbd\u3001\u53c2\u6570\u7ef4\u5ea6\u3001\u6a21\u578b\u53cd\u9988\u4fe1\u53f7\uff09\u52a8\u6001\u8c03\u6574\u9884\u6d4b\u8303\u56f4\uff0c\u91c7\u7528\u6df7\u5408\u8de8\u5c42\u9884\u6d4b\u65b9\u6848\u878d\u5408\u9884\u95e8\u63a7\u4fe1\u606f\u548c\u4e2d\u95f4\u8ba1\u7b97\u72b6\u6001\u6765\u9884\u6d4b\u672a\u6765\u4e13\u5bb6\u9700\u6c42\u3002", "result": "\u8bc4\u4f30\u663e\u793aExpertFlow\u5c06\u6a21\u578b\u505c\u6ede\u65f6\u95f4\u964d\u4f4e\u5230\u57fa\u7ebf\u76840.1%\u4ee5\u4e0b\uff0c\u663e\u8457\u4f18\u5316\u4e86\u5185\u5b58\u7ea6\u675f\u4e0b\u7684MoE\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "ExpertFlow\u901a\u8fc7\u81ea\u9002\u5e94\u9884\u53d6\u51b3\u7b56\u548c\u4e0e\u5b9e\u9645\u4f7f\u7528\u884c\u4e3a\u7684\u5bf9\u9f50\uff0c\u6709\u6548\u51cf\u5c11\u7f13\u5b58\u672a\u547d\u4e2d\u5e76\u6d88\u9664\u4e13\u5bb6\u4ea4\u6362\u5f15\u5165\u7684\u5ef6\u8fdf\uff0c\u4e3a\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\u7684MoE\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25883", "categories": ["cs.AI", "cs.IT", "math.IT", "I.2.0; I.2.6; G.3"], "pdf": "https://arxiv.org/pdf/2510.25883", "abs": "https://arxiv.org/abs/2510.25883", "authors": ["Christian Dittrich", "Jennifer Flygare Kinne"], "title": "The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence", "comment": "41 pages, 2 tables, 3 appendices. Submitted to arXiv for open access", "summary": "Existing frameworks converge on the centrality of compression to intelligence\nbut leave underspecified why this process enforces the discovery of causal\nstructure rather than superficial statistical patterns. We introduce a\ntwo-level framework to address this gap. The Information-Theoretic Imperative\n(ITI) establishes that any system persisting in uncertain environments must\nminimize epistemic entropy through predictive compression: this is the\nevolutionary \"why\" linking survival pressure to information-processing demands.\nThe Compression Efficiency Principle (CEP) specifies how efficient compression\nmechanically selects for generative, causal models through\nexception-accumulation dynamics, making reality alignment a consequence rather\nthan a contingent achievement. Together, ITI and CEP define a causal chain:\nfrom survival pressure to prediction necessity, compression requirement,\nefficiency optimization, generative structure discovery, and ultimately reality\nalignment. Each link follows from physical, information-theoretic, or\nevolutionary constraints, implying that intelligence is the mechanically\nnecessary outcome of persistence in structured environments. This framework\nyields empirically testable predictions: compression efficiency, measured as\napproach to the rate-distortion frontier, correlates with out-of-distribution\ngeneralization; exception-accumulation rates differentiate causal from\ncorrelational models; hierarchical systems exhibit increasing efficiency across\nabstraction layers; and biological systems demonstrate metabolic costs that\ntrack representational complexity. ITI and CEP thereby provide a unified\naccount of convergence across biological, artificial, and multi-scale systems,\naddressing the epistemic and functional dimensions of intelligence without\ninvoking assumptions about consciousness or subjective experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u5c42\u6b21\u6846\u67b6\u6765\u89e3\u91ca\u4e3a\u4ec0\u4e48\u538b\u7f29\u8fc7\u7a0b\u4f1a\u5f3a\u5236\u53d1\u73b0\u56e0\u679c\u7ed3\u6784\u800c\u975e\u8868\u9762\u7edf\u8ba1\u6a21\u5f0f\u3002\u4fe1\u606f\u8bba\u5fc5\u8981\u6027(ITI)\u5efa\u7acb\u4e86\u7cfb\u7edf\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5fc5\u987b\u901a\u8fc7\u9884\u6d4b\u538b\u7f29\u6700\u5c0f\u5316\u8ba4\u77e5\u71b5\uff0c\u538b\u7f29\u6548\u7387\u539f\u5219(CEP)\u5219\u8bf4\u660e\u9ad8\u6548\u538b\u7f29\u5982\u4f55\u901a\u8fc7\u5f02\u5e38\u7d2f\u79ef\u52a8\u6001\u9009\u62e9\u751f\u6210\u6027\u56e0\u679c\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u867d\u7136\u8ba4\u540c\u538b\u7f29\u5bf9\u667a\u80fd\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4f46\u672a\u80fd\u8be6\u7ec6\u8bf4\u660e\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u8fc7\u7a0b\u4f1a\u5f3a\u5236\u53d1\u73b0\u56e0\u679c\u7ed3\u6784\u800c\u975e\u8868\u9762\u7edf\u8ba1\u6a21\u5f0f\u3002\u4f5c\u8005\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u5f15\u5165\u4e24\u5c42\u6b21\u6846\u67b6\uff1a\u4fe1\u606f\u8bba\u5fc5\u8981\u6027(ITI)\u548c\u538b\u7f29\u6548\u7387\u539f\u5219(CEP)\u3002ITI\u4ece\u751f\u5b58\u538b\u529b\u5230\u4fe1\u606f\u5904\u7406\u9700\u6c42\u5efa\u7acb\u8054\u7cfb\uff0cCEP\u5219\u8bf4\u660e\u9ad8\u6548\u538b\u7f29\u5982\u4f55\u673a\u68b0\u5730\u9009\u62e9\u751f\u6210\u6027\u56e0\u679c\u6a21\u578b\u3002", "result": "\u8be5\u6846\u67b6\u4ea7\u751f\u4e86\u53ef\u7ecf\u9a8c\u68c0\u9a8c\u7684\u9884\u6d4b\uff1a\u538b\u7f29\u6548\u7387\u4e0e\u5206\u5e03\u5916\u6cdb\u5316\u76f8\u5173\uff1b\u5f02\u5e38\u7d2f\u79ef\u7387\u533a\u5206\u56e0\u679c\u6a21\u578b\u548c\u76f8\u5173\u6a21\u578b\uff1b\u5206\u5c42\u7cfb\u7edf\u5728\u4e0d\u540c\u62bd\u8c61\u5c42\u663e\u793a\u6548\u7387\u63d0\u5347\uff1b\u751f\u7269\u7cfb\u7edf\u7684\u4ee3\u8c22\u6210\u672c\u8ddf\u8e2a\u8868\u5f81\u590d\u6742\u6027\u3002", "conclusion": "ITI\u548cCEP\u4e3a\u751f\u7269\u3001\u4eba\u5de5\u548c\u591a\u5c3a\u5ea6\u7cfb\u7edf\u7684\u8d8b\u540c\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u667a\u80fd\u7684\u8ba4\u77e5\u548c\u529f\u80fd\u7ef4\u5ea6\uff0c\u65e0\u9700\u8bc9\u8bf8\u610f\u8bc6\u6216\u4e3b\u89c2\u4f53\u9a8c\u7684\u5047\u8bbe\u3002"}}
{"id": "2510.25884", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25884", "abs": "https://arxiv.org/abs/2510.25884", "authors": ["Eit\u00e1n Sprejer", "Fernando Avalos", "Augusto Bernardi", "Jose Pedro Brito de Azevedo Faustino", "Jacob Haimes", "Narmeen Fatimah Oozeer"], "title": "Approximating Human Preferences Using a Multi-Judge Learned System", "comment": null, "summary": "Aligning LLM-based judges with human preferences is a significant challenge,\nas they are difficult to calibrate and often suffer from rubric sensitivity,\nbias, and instability. Overcoming this challenge advances key applications,\nsuch as creating reliable reward models for Reinforcement Learning from Human\nFeedback (RLHF) and building effective routing systems that select the\nbest-suited model for a given user query. In this work, we propose a framework\nfor modeling diverse, persona-based preferences by learning to aggregate\noutputs from multiple rubric-conditioned judges. We investigate the performance\nof this approach against naive baselines and assess its robustness through case\nstudies on both human and LLM-judges biases. Our primary contributions include\na persona-based method for synthesizing preference labels at scale and two\ndistinct implementations of our aggregator: Generalized Additive Model (GAM)\nand a Multi-Layer Perceptron (MLP).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5224\u8005\u8f93\u51fa\u6765\u6821\u51c6LLM\u8bc4\u5224\u8005\uff0c\u89e3\u51b3\u5176\u6821\u51c6\u56f0\u96be\u3001\u8bc4\u5206\u6807\u51c6\u654f\u611f\u6027\u3001\u504f\u89c1\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u5bf9\u9f50\u57fa\u4e8eLLM\u7684\u8bc4\u5224\u8005\u4e0e\u4eba\u7c7b\u504f\u597d\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u56e0\u4e3a\u96be\u4ee5\u6821\u51c6\u4e14\u5b58\u5728\u8bc4\u5206\u6807\u51c6\u654f\u611f\u6027\u3001\u504f\u89c1\u548c\u4e0d\u7a33\u5b9a\u6027\u3002\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u53ef\u4fc3\u8fdb\u5173\u952e\u5e94\u7528\u53d1\u5c55\uff0c\u5982\u4e3aRLHF\u521b\u5efa\u53ef\u9760\u7684\u5956\u52b1\u6a21\u578b\u548c\u6784\u5efa\u6709\u6548\u7684\u8def\u7531\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u5efa\u6a21\u6846\u67b6\uff0c\u5b66\u4e60\u805a\u5408\u591a\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5224\u8005\u8f93\u51fa\u3002\u5305\u62ec\u57fa\u4e8e\u89d2\u8272\u7684\u65b9\u6cd5\u5927\u89c4\u6a21\u5408\u6210\u504f\u597d\u6807\u7b7e\uff0c\u4ee5\u53ca\u4e24\u79cd\u805a\u5408\u5668\u5b9e\u73b0\uff1a\u5e7f\u4e49\u52a0\u6027\u6a21\u578b(GAM)\u548c\u591a\u5c42\u611f\u77e5\u5668(MLP)\u3002", "result": "\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u7b80\u5355\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u5176\u5728\u4eba\u7c7b\u548cLLM\u8bc4\u5224\u8005\u504f\u89c1\u65b9\u9762\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5efa\u6a21\u591a\u6837\u5316\u7684\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u8bc4\u5224\u8005\u8f93\u51fa\u6765\u63d0\u9ad8LLM\u8bc4\u5224\u8005\u7684\u6821\u51c6\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2510.25908", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25908", "abs": "https://arxiv.org/abs/2510.25908", "authors": ["Emily Herron", "Junqi Yin", "Feiyi Wang"], "title": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications", "comment": "Preprint Submitted to ACM Transactions on AI for Science (TAIS)", "summary": "Large language models (LLMs) have demonstrated transformative potential in\nscientific research, yet their deployment in high-stakes contexts raises\nsignificant trustworthiness concerns. Here, we introduce SciTrust 2.0, a\ncomprehensive framework for evaluating LLM trustworthiness in scientific\napplications across four dimensions: truthfulness, adversarial robustness,\nscientific safety, and scientific ethics. Our framework incorporates novel,\nopen-ended truthfulness benchmarks developed through a verified\nreflection-tuning pipeline and expert validation, alongside a novel ethics\nbenchmark for scientific research contexts covering eight subcategories\nincluding dual-use research and bias. We evaluated seven prominent LLMs,\nincluding four science-specialized models and three general-purpose industry\nmodels, using multiple evaluation metrics including accuracy, semantic\nsimilarity measures, and LLM-based scoring. General-purpose industry models\noverall outperformed science-specialized models across each trustworthiness\ndimension, with GPT-o4-mini demonstrating superior performance in truthfulness\nassessments and adversarial robustness. Science-specialized models showed\nsignificant deficiencies in logical and ethical reasoning capabilities, along\nwith concerning vulnerabilities in safety evaluations, particularly in\nhigh-risk domains such as biosecurity and chemical weapons. By open-sourcing\nour framework, we provide a foundation for developing more trustworthy AI\nsystems and advancing research on model safety and ethics in scientific\ncontexts.", "AI": {"tldr": "SciTrust 2.0\u662f\u4e00\u4e2a\u8bc4\u4f30\u79d1\u5b66\u5e94\u7528\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4fe1\u5ea6\u7684\u7efc\u5408\u6846\u67b6\uff0c\u6db5\u76d6\u771f\u5b9e\u6027\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u79d1\u5b66\u5b89\u5168\u6027\u548c\u79d1\u5b66\u4f26\u7406\u56db\u4e2a\u7ef4\u5ea6\u3002\u8bc4\u4f30\u663e\u793a\u901a\u7528\u884c\u4e1a\u6a21\u578b\u5728\u5404\u65b9\u9762\u4f18\u4e8e\u79d1\u5b66\u4e13\u7528\u6a21\u578b\uff0c\u540e\u8005\u5728\u903b\u8f91\u548c\u4f26\u7406\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u5c55\u73b0\u51fa\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u5f15\u53d1\u4e86\u53ef\u4fe1\u5ea6\u62c5\u5fe7\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u6765\u786e\u4fdd\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u65b0\u9896\u5f00\u653e\u5f0f\u771f\u5b9e\u6027\u57fa\u51c6\u548c\u79d1\u5b66\u4f26\u7406\u57fa\u51c6\u7684\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u9a8c\u8bc1\u7684\u53cd\u601d\u8c03\u4f18\u6d41\u7a0b\u548c\u4e13\u5bb6\u9a8c\u8bc1\uff0c\u4f7f\u7528\u51c6\u786e\u6027\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u548c\u57fa\u4e8eLLM\u7684\u8bc4\u5206\u7b49\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u5bf97\u4e2a\u4e3b\u8981LLM\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u7528\u884c\u4e1a\u6a21\u578b\u5728\u6240\u6709\u53ef\u4fe1\u5ea6\u7ef4\u5ea6\u4e0a\u5747\u4f18\u4e8e\u79d1\u5b66\u4e13\u7528\u6a21\u578b\uff0cGPT-4-mini\u5728\u771f\u5b9e\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u8bc4\u4f30\u4e2d\u8868\u73b0\u6700\u4f73\u3002\u79d1\u5b66\u4e13\u7528\u6a21\u578b\u5728\u903b\u8f91\u548c\u4f26\u7406\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5728\u751f\u7269\u5b89\u5168\u548c\u5316\u5b66\u6b66\u5668\u7b49\u9ad8\u5371\u9886\u57df\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u4ee4\u4eba\u62c5\u5fe7\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f00\u6e90\u8be5\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u63a8\u52a8\u4e86\u79d1\u5b66\u80cc\u666f\u4e0b\u6a21\u578b\u5b89\u5168\u6027\u548c\u4f26\u7406\u7814\u7a76\u7684\u8fdb\u5c55\u3002"}}
{"id": "2510.25933", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.25933", "abs": "https://arxiv.org/abs/2510.25933", "authors": ["Nissan Yaron", "Dan Bystritsky", "Ben-Etzion Yaron"], "title": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning", "comment": null, "summary": "We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS\nGrounding public subset within a $\\pm 5$ pp equivalence margin.\n  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI\n69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference\nis 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's\n$d = 0.023$). TOST establishes equivalence at $\\pm 5$ pp (not at $\\pm 3$ pp).\nWhen purchased as managed APIs, Humans-Junior's base model\n(Phi-3.5-mini-instruct) is $\\approx 19\\times$ less expensive than GPT-4o on\nMicrosoft AI Foundry pricing; self-hosted or edge deployments can drive\nincremental inference cost toward zero. Measured vs estimated pricing sources\nare tabulated in Appendix E.\n  Method. Our approach combines minimal directed \"Exoskeleton Reasoning\"\nscaffolds with behavioral fine-tuning that teaches protocol compliance\n(epistemic discipline) rather than domain answers. Fine-tuning alone adds\nlittle; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance\n($\\approx 25\\%$). In prompt-only settings on frontier models (Q1--Q100;\nnon-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and\nGemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.\n  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within\n$\\pm 5$ pp on Q1--Q500). Cloud pricing shows $\\approx 19\\times$ lower cost\nversus GPT-4o, and self-hosted/edge deployments can approach zero marginal\ncost. Pricing sources are listed in Appendix E. Frontier prompt-only gains\n(Q1--Q100; non-comparable) and optimized-prompt exploratory results under\nearlier judges are summarized in Appendix F.\n  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,\nFine-Tuning, Model Alignment, Cost-Efficient AI", "AI": {"tldr": "3.8B\u53c2\u6570\u7684Humans-Junior\u6a21\u578b\u5728FACTS Grounding\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0eGPT-4o\u6027\u80fd\u76f8\u5f53\uff08\u5728\u00b15pp\u7b49\u4ef7\u8303\u56f4\u5185\uff09\uff0c\u4e91\u670d\u52a1\u6210\u672c\u964d\u4f4e\u7ea619\u500d\uff0c\u81ea\u6258\u7ba1\u90e8\u7f72\u53ef\u5b9e\u73b0\u63a5\u8fd1\u96f6\u8fb9\u9645\u6210\u672c\u3002", "motivation": "\u5f00\u53d1\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "method": "\u7ed3\u5408\u6700\u5c0f\u5316\u5b9a\u5411\"\u5916\u9aa8\u9abc\u63a8\u7406\"\u652f\u67b6\u4e0e\u884c\u4e3a\u5fae\u8c03\uff0c\u6559\u5bfc\u534f\u8bae\u9075\u5b88\u800c\u975e\u9886\u57df\u77e5\u8bc6\uff0c\u4e24\u8005\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u65b9\u5dee\u3002", "result": "\u5728Q1-Q500\u6d4b\u8bd5\u4e2d\uff0cGPT-4o\u5f97\u520673.5%\uff0cHumans-Junior\u5f97\u520672.7%\uff0c\u914d\u5bf9\u5dee\u5f020.8pp\uff0c\u5728\u00b15pp\u8303\u56f4\u5185\u5efa\u7acb\u7b49\u4ef7\u6027\u3002\u5b9a\u5411\u63a8\u7406\u4f7fGPT-4o\u63d0\u534711.8pp\u81f385.3%\uff0cGemini-2.5-Pro\u63d0\u53475.0pp\u81f393.3%\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u5b9a\u5411\u63a8\u7406\u548c\u884c\u4e3a\u5fae\u8c03\u7684\u7ec4\u5408\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e8b\u5b9e\u57fa\u7840\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u6210\u672c\u3002"}}
{"id": "2510.25951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25951", "abs": "https://arxiv.org/abs/2510.25951", "authors": ["Sounak Banerjee", "Daphne Cornelisse", "Deepak Gopinath", "Emily Sumner", "Jonathan DeCastro", "Guy Rosman", "Eugene Vinitsky", "Mark K. Ho"], "title": "Estimating cognitive biases with attention-aware inverse planning", "comment": null, "summary": "People's goal-directed behaviors are influenced by their cognitive biases,\nand autonomous systems that interact with people should be aware of this. For\nexample, people's attention to objects in their environment will be biased in a\nway that systematically affects how they perform everyday tasks such as driving\nto work. Here, building on recent work in computational cognitive science, we\nformally articulate the attention-aware inverse planning problem, in which the\ngoal is to estimate a person's attentional biases from their actions. We\ndemonstrate how attention-aware inverse planning systematically differs from\nstandard inverse reinforcement learning and how cognitive biases can be\ninferred from behavior. Finally, we present an approach to attention-aware\ninverse planning that combines deep reinforcement learning with computational\ncognitive modeling. We use this approach to infer the attentional strategies of\nRL agents in real-life driving scenarios selected from the Waymo Open Dataset,\ndemonstrating the scalability of estimating cognitive biases with\nattention-aware inverse planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce8\u610f\u529b\u611f\u77e5\u7684\u9006\u89c4\u5212\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u4eba\u7c7b\u884c\u4e3a\u4e2d\u63a8\u65ad\u8ba4\u77e5\u504f\u5dee\uff0c\u7279\u522b\u662f\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u4f30\u8ba1\u6ce8\u610f\u529b\u7b56\u7565\u3002", "motivation": "\u4eba\u7c7b\u7684\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\u53d7\u8ba4\u77e5\u504f\u5dee\u5f71\u54cd\uff0c\u81ea\u4e3b\u7cfb\u7edf\u9700\u8981\u7406\u89e3\u8fd9\u4e9b\u504f\u5dee\u4ee5\u66f4\u597d\u5730\u4e0e\u4eba\u4ea4\u4e92\u3002\u4f8b\u5982\uff0c\u4eba\u4eec\u5728\u65e5\u5e38\u4efb\u52a1\uff08\u5982\u9a7e\u9a76\uff09\u4e2d\u7684\u6ce8\u610f\u529b\u4f1a\u7cfb\u7edf\u6027\u504f\u5dee\u5730\u5f71\u54cd\u884c\u4e3a\u8868\u73b0\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e0e\u8ba1\u7b97\u8ba4\u77e5\u5efa\u6a21\uff0c\u6784\u5efa\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u6846\u67b6\uff0c\u4ece\u884c\u4e3a\u6570\u636e\u4e2d\u63a8\u65ad\u6ce8\u610f\u529b\u504f\u5dee\u3002", "result": "\u5728Waymo\u5f00\u653e\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u6210\u529f\u63a8\u65adRL\u667a\u80fd\u4f53\u7684\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u4f30\u8ba1\u8ba4\u77e5\u504f\u5dee\u65b9\u9762\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u80fd\u591f\u6709\u6548\u4ece\u884c\u4e3a\u4e2d\u63a8\u65ad\u8ba4\u77e5\u504f\u5dee\uff0c\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u7406\u89e3\u4eba\u7c7b\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.26012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26012", "abs": "https://arxiv.org/abs/2510.26012", "authors": ["Siyi Wu", "Chiaxin Liang", "Ziqian Bi", "Leyi Zhao", "Tianyang Wang", "Junhao Song", "Yichao Zhang", "Keyu Chen", "Xinyuan Song"], "title": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys", "comment": "TKDD 2025", "summary": "The rapid growth of research literature, particularly in large language\nmodels (LLMs), has made producing comprehensive and current survey papers\nincreasingly difficult. This paper introduces autosurvey2, a multi-stage\npipeline that automates survey generation through retrieval-augmented synthesis\nand structured evaluation. The system integrates parallel section generation,\niterative refinement, and real-time retrieval of recent publications to ensure\nboth topical completeness and factual accuracy. Quality is assessed using a\nmulti-LLM evaluation framework that measures coverage, structure, and relevance\nin alignment with expert review standards. Experimental results demonstrate\nthat autosurvey2 consistently outperforms existing retrieval-based and\nautomated baselines, achieving higher scores in structural coherence and\ntopical relevance while maintaining strong citation fidelity. By combining\nretrieval, reasoning, and automated evaluation into a unified framework,\nautosurvey2 provides a scalable and reproducible solution for generating\nlong-form academic surveys and contributes a solid foundation for future\nresearch on automated scholarly writing. All code and resources are available\nat https://github.com/annihi1ation/auto_research.", "AI": {"tldr": "autosurvey2\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u751f\u6210\u5b66\u672f\u7efc\u8ff0\u8bba\u6587\u7684\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\u7cfb\u7edf\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u5408\u6210\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\u6765\u786e\u4fdd\u4e3b\u9898\u5b8c\u6574\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u7814\u7a76\u6587\u732e\u7684\u5feb\u901f\u589e\u957f\uff0c\u7279\u522b\u662f\u5728\u5927\u8bed\u8a00\u6a21\u578b\u9886\u57df\uff0c\u64b0\u5199\u5168\u9762\u4e14\u6700\u65b0\u7684\u7efc\u8ff0\u8bba\u6587\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\u3002", "method": "\u7cfb\u7edf\u6574\u5408\u4e86\u5e76\u884c\u7ae0\u8282\u751f\u6210\u3001\u8fed\u4ee3\u7cbe\u70bc\u548c\u5b9e\u65f6\u68c0\u7d22\u6700\u65b0\u51fa\u7248\u7269\uff0c\u91c7\u7528\u591aLLM\u8bc4\u4f30\u6846\u67b6\u6765\u8861\u91cf\u8986\u76d6\u5ea6\u3001\u7ed3\u6784\u548c\u76f8\u5173\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aautosurvey2\u5728\u7ed3\u6784\u8fde\u8d2f\u6027\u548c\u4e3b\u9898\u76f8\u5173\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u68c0\u7d22\u57fa\u7ebf\u548c\u81ea\u52a8\u5316\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5f15\u7528\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5c06\u68c0\u7d22\u3001\u63a8\u7406\u548c\u81ea\u52a8\u8bc4\u4f30\u6574\u5408\u5230\u7edf\u4e00\u6846\u67b6\u4e2d\uff0cautosurvey2\u4e3a\u751f\u6210\u957f\u7bc7\u5b66\u672f\u7efc\u8ff0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u590d\u73b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u81ea\u52a8\u5316\u5b66\u672f\u5199\u4f5c\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2510.26023", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.26023", "abs": "https://arxiv.org/abs/2510.26023", "authors": ["Zhipeng Bao", "Qianwen Li"], "title": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization", "comment": "8 pages", "summary": "Despite significant advancements in recent decades, autonomous vehicles (AVs)\ncontinue to face challenges in navigating certain traffic scenarios where human\ndrivers excel. In such situations, AVs often become immobilized, disrupting\noverall traffic flow. Current recovery solutions, such as remote intervention\n(which is costly and inefficient) and manual takeover (which excludes\nnon-drivers and limits AV accessibility), are inadequate. This paper introduces\nStuckSolver, a novel Large Language Model (LLM) driven recovery framework that\nenables AVs to resolve immobilization scenarios through self-reasoning and/or\npassenger-guided decision-making. StuckSolver is designed as a plug-in add-on\nmodule that operates on top of the AV's existing perception-planning-control\nstack, requiring no modification to its internal architecture. Instead, it\ninterfaces with standard sensor data streams to detect immobilization states,\ninterpret environmental context, and generate high-level recovery commands that\ncan be executed by the AV's native planner. We evaluate StuckSolver on the\nBench2Drive benchmark and in custom-designed uncertainty scenarios. Results\nshow that StuckSolver achieves near-state-of-the-art performance through\nautonomous self-reasoning alone and exhibits further improvements when\npassenger guidance is incorporated.", "AI": {"tldr": "StuckSolver\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6062\u590d\u6846\u67b6\uff0c\u80fd\u591f\u5728\u8f66\u8f86\u88ab\u56f0\u65f6\u901a\u8fc7\u81ea\u4e3b\u63a8\u7406\u548c\u4e58\u5ba2\u5f15\u5bfc\u51b3\u7b56\u6765\u89e3\u51b3\u56f0\u5883\uff0c\u65e0\u9700\u4fee\u6539\u8f66\u8f86\u539f\u6709\u67b6\u6784\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u67d0\u4e9b\u4ea4\u901a\u573a\u666f\u4e2d\u5bb9\u6613\u9677\u5165\u56f0\u5883\uff0c\u800c\u73b0\u6709\u7684\u8fdc\u7a0b\u5e72\u9884\u548c\u624b\u52a8\u63a5\u7ba1\u65b9\u6848\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\u4e14\u9650\u5236\u4e86\u975e\u9a7e\u9a76\u5458\u7684\u4f7f\u7528\u3002\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u6062\u590d\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u63d2\u4ef6\u5f0f\u6a21\u5757StuckSolver\uff0c\u5b83\u57fa\u4e8eLLM\u6280\u672f\uff0c\u901a\u8fc7\u6807\u51c6\u4f20\u611f\u5668\u6570\u636e\u6d41\u68c0\u6d4b\u8f66\u8f86\u88ab\u56f0\u72b6\u6001\uff0c\u7406\u89e3\u73af\u5883\u4e0a\u4e0b\u6587\uff0c\u5e76\u751f\u6210\u53ef\u7531\u8f66\u8f86\u539f\u751f\u89c4\u5212\u5668\u6267\u884c\u7684\u9ad8\u7ea7\u6062\u590d\u547d\u4ee4\u3002", "result": "\u5728Bench2Drive\u57fa\u51c6\u6d4b\u8bd5\u548c\u81ea\u5b9a\u4e49\u4e0d\u786e\u5b9a\u6027\u573a\u666f\u4e2d\u7684\u8bc4\u4f30\u663e\u793a\uff0cStuckSolver\u4ec5\u901a\u8fc7\u81ea\u4e3b\u63a8\u7406\u5c31\u80fd\u8fbe\u5230\u63a5\u8fd1\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u7ed3\u5408\u4e58\u5ba2\u6307\u5bfc\u540e\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "StuckSolver\u6846\u67b6\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u56f0\u5883\u6062\u590d\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u4fee\u6539\u73b0\u6709\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u8f66\u8f86\u5728\u590d\u6742\u4ea4\u901a\u573a\u666f\u4e2d\u7684\u5e94\u5bf9\u80fd\u529b\u3002"}}
{"id": "2510.26057", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.26057", "abs": "https://arxiv.org/abs/2510.26057", "authors": ["Andrew L. Kun"], "title": "Can AI be Accountable?", "comment": "To be published as a chapter in Daniele Quercia and Marios\n  Constantinides (Eds.). Operationalizing Responsible AI. Cambridge University\n  Press. Forthcoming", "summary": "The AI we use is powerful, and its power is increasing rapidly. If this\npowerful AI is to serve the needs of consumers, voters, and decision makers,\nthen it is imperative that the AI is accountable. In general, an agent is\naccountable to a forum if the forum can request information from the agent\nabout its actions, if the forum and the agent can discuss this information, and\nif the forum can sanction the agent. Unfortunately, in too many cases today's\nAI is not accountable -- we cannot question it, enter into a discussion with\nit, let alone sanction it. In this chapter we relate the general definition of\naccountability to AI, we illustrate what it means for AI to be accountable and\nunaccountable, and we explore approaches that can improve our chances of living\nin a world where all AI is accountable to those who are affected by it.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u95ee\u8d23\u5236\u7684\u91cd\u8981\u6027\uff0c\u6307\u51fa\u5f53\u524dAI\u7f3a\u4e4f\u95ee\u8d23\u673a\u5236\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u73b0AI\u95ee\u8d23\u7684\u6846\u67b6\u548c\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u7684\u5feb\u901f\u589e\u5f3a\uff0c\u4e3a\u786e\u4fddAI\u670d\u52a1\u4e8e\u6d88\u8d39\u8005\u3001\u9009\u6c11\u548c\u51b3\u7b56\u8005\u7684\u9700\u6c42\uff0c\u5fc5\u987b\u5efa\u7acb\u6709\u6548\u7684\u95ee\u8d23\u673a\u5236\u3002\u5f53\u524dAI\u666e\u904d\u7f3a\u4e4f\u53ef\u88ab\u8d28\u7591\u3001\u8ba8\u8bba\u548c\u5236\u88c1\u7684\u80fd\u529b\u3002", "method": "\u5c06\u4e00\u822c\u95ee\u8d23\u5b9a\u4e49\u5e94\u7528\u4e8eAI\u9886\u57df\uff0c\u5206\u6790AI\u95ee\u8d23\u4e0e\u4e0d\u95ee\u8d23\u7684\u5177\u4f53\u8868\u73b0\uff0c\u63a2\u7d22\u6539\u8fdbAI\u95ee\u8d23\u7684\u65b9\u6cd5\u548c\u9014\u5f84\u3002", "result": "\u660e\u786e\u4e86AI\u95ee\u8d23\u7684\u4e09\u4e2a\u5173\u952e\u8981\u7d20\uff1a\u4fe1\u606f\u8bf7\u6c42\u3001\u8ba8\u8bba\u673a\u5236\u548c\u5236\u88c1\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u53ef\u95ee\u8d23AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u9700\u8981\u53d1\u5c55\u76f8\u5173\u65b9\u6cd5\u548c\u6280\u672f\uff0c\u786e\u4fdd\u6240\u6709AI\u7cfb\u7edf\u90fd\u80fd\u5bf9\u53d7\u5176\u5f71\u54cd\u7684\u4e3b\u4f53\u627f\u62c5\u95ee\u8d23\u8d23\u4efb\uff0c\u8fd9\u662f\u5b9e\u73b0AI\u8d1f\u8d23\u4efb\u53d1\u5c55\u7684\u5173\u952e\u3002"}}
{"id": "2510.26094", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26094", "abs": "https://arxiv.org/abs/2510.26094", "authors": ["Yuxin Li", "Minghao Liu", "Ruida Wang", "Wenzhao Ji", "Zhitao He", "Rui Pan", "Junming Huang", "Tong Zhang", "Yi R. Fung"], "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "comment": null, "summary": "We present **Lean4PHYS**, a comprehensive reasoning framework for\ncollege-level physics problems in Lean4. **Lean4PHYS** includes\n*LeanPhysBench*, a college-level benchmark for formal physics reasoning in\nLean4, which contains 200 hand-crafted and peer-reviewed statements derived\nfrom university textbooks and physics competition problems. To establish a\nsolid foundation for formal reasoning in physics, we also introduce *PhysLib*,\na community-driven repository containing fundamental unit systems and theorems\nessential for formal physics reasoning. Based on the benchmark and Lean4\nrepository we composed in **Lean4PHYS**, we report baseline results using major\nexpert Math Lean4 provers and state-of-the-art closed-source models, with the\nbest performance of DeepSeek-Prover-V2-7B achieving only 16% and\nClaude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that\nour *PhysLib* can achieve an average improvement of 11.75% in model\nperformance. This demonstrates the challenging nature of our *LeanPhysBench*\nand the effectiveness of *PhysLib*. To the best of our knowledge, this is the\nfirst study to provide a physics benchmark in Lean4.", "AI": {"tldr": "Lean4PHYS\u662f\u4e00\u4e2a\u57fa\u4e8eLean4\u7684\u5927\u5b66\u7269\u7406\u95ee\u9898\u63a8\u7406\u6846\u67b6\uff0c\u5305\u542bLeanPhysBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff08200\u4e2a\u624b\u5de5\u5236\u4f5c\u7684\u7269\u7406\u95ee\u9898\uff09\u548cPhysLib\u7269\u7406\u77e5\u8bc6\u5e93\uff0c\u5728\u73b0\u6709\u6700\u4f73\u6a21\u578b\u4e0a\u4ec5\u8fbe\u523016-35%\u7684\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u8be5\u57fa\u51c6\u7684\u6311\u6218\u6027\u548cPhysLib\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u5927\u5b66\u7269\u7406\u95ee\u9898\u5efa\u7acb\u9996\u4e2a\u57fa\u4e8eLean4\u7684\u5f62\u5f0f\u5316\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u586b\u8865\u7269\u7406\u9886\u57df\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7a7a\u767d\uff0c\u63a8\u52a8\u81ea\u52a8\u63a8\u7406\u5728\u7269\u7406\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86LeanPhysBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff08\u5305\u542b200\u4e2a\u6765\u81ea\u5927\u5b66\u6559\u6750\u548c\u7269\u7406\u7ade\u8d5b\u7684\u624b\u5de5\u5236\u4f5c\u95ee\u9898\uff09\u548cPhysLib\u77e5\u8bc6\u5e93\uff08\u5305\u542b\u57fa\u672c\u5355\u4f4d\u7cfb\u7edf\u548c\u5b9a\u7406\uff09\uff0c\u4f7f\u7528\u4e3b\u6d41\u6570\u5b66\u8bc1\u660e\u5668\u548c\u6700\u65b0\u95ed\u6e90\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "DeepSeek-Prover-V2-7B\u6a21\u578b\u4ec5\u8fbe\u523016%\u51c6\u786e\u7387\uff0cClaude-Sonnet-4\u8fbe\u523035%\u51c6\u786e\u7387\uff1bPhysLib\u77e5\u8bc6\u5e93\u5e73\u5747\u63d0\u5347\u6a21\u578b\u6027\u80fd11.75%\u3002", "conclusion": "LeanPhysBench\u5177\u6709\u6311\u6218\u6027\uff0cPhysLib\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8eLean4\u7684\u7269\u7406\u57fa\u51c6\u6d4b\u8bd5\u7814\u7a76\u3002"}}
{"id": "2510.26136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26136", "abs": "https://arxiv.org/abs/2510.26136", "authors": ["Boqin Zhuang", "Jiacheng Qiao", "Mingqian Liu", "Mingxing Yu", "Ping Hong", "Rui Li", "Xiaoxia Song", "Xiangjun Xu", "Xu Chen", "Yaoyao Ma", "Yujie Gao"], "title": "Beyond Benchmarks: The Economics of AI Inference", "comment": null, "summary": "The inference cost of Large Language Models (LLMs) has become a critical\nfactor in determining their commercial viability and widespread adoption. This\npaper introduces a quantitative ``economics of inference'' framework, treating\nthe LLM inference process as a compute-driven intelligent production activity.\nWe analyze its marginal cost, economies of scale, and quality of output under\nvarious performance configurations. Based on empirical data from WiNEval-3.0,\nwe construct the first ``LLM Inference Production Frontier,'' revealing three\nprinciples: diminishing marginal cost, diminishing returns to scale, and an\noptimal cost-effectiveness zone. This paper not only provides an economic basis\nfor model deployment decisions but also lays an empirical foundation for the\nfuture market-based pricing and optimization of AI inference resources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7ecf\u6d4e\u5b66\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u89c6\u4e3a\u8ba1\u7b97\u9a71\u52a8\u7684\u667a\u80fd\u751f\u4ea7\u6d3b\u52a8\uff0c\u5206\u6790\u4e86\u8fb9\u9645\u6210\u672c\u3001\u89c4\u6a21\u7ecf\u6d4e\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u5e76\u57fa\u4e8eWiNEval-3.0\u6570\u636e\u6784\u5efa\u4e86\u9996\u4e2aLLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6210\u672c\u5df2\u6210\u4e3a\u51b3\u5b9a\u5176\u5546\u4e1a\u53ef\u884c\u6027\u548c\u5e7f\u6cdb\u5e94\u7528\u7684\u5173\u952e\u56e0\u7d20\uff0c\u9700\u8981\u5efa\u7acb\u7ecf\u6d4e\u5206\u6790\u6846\u67b6\u6765\u6307\u5bfc\u6a21\u578b\u90e8\u7f72\u51b3\u7b56\u3002", "method": "\u91c7\u7528\u91cf\u5316\u7ecf\u6d4e\u5b66\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u8fc7\u7a0b\u89c6\u4e3a\u8ba1\u7b97\u9a71\u52a8\u7684\u667a\u80fd\u751f\u4ea7\u6d3b\u52a8\uff0c\u57fa\u4e8eWiNEval-3.0\u5b9e\u8bc1\u6570\u636e\u6784\u5efaLLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\u3002", "result": "\u63ed\u793a\u4e86\u4e09\u4e2a\u539f\u5219\uff1a\u8fb9\u9645\u6210\u672c\u9012\u51cf\u3001\u89c4\u6a21\u6536\u76ca\u9012\u51cf\u4ee5\u53ca\u6700\u4f18\u6210\u672c\u6548\u76ca\u533a\u57df\uff0c\u4e3a\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u4f9d\u636e\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u6a21\u578b\u90e8\u7f72\u51b3\u7b56\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u5b66\u57fa\u7840\uff0c\u8fd8\u4e3a\u672a\u6765\u57fa\u4e8e\u5e02\u573a\u7684AI\u63a8\u7406\u8d44\u6e90\u5b9a\u4ef7\u548c\u4f18\u5316\u5960\u5b9a\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2510.26143", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26143", "abs": "https://arxiv.org/abs/2510.26143", "authors": ["Bo Pang", "Deqian Kong", "Silvio Savarese", "Caiming Xiong", "Yingbo Zhou"], "title": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "comment": "9 pages", "summary": "Reinforcement learning (RL) can elicit strong reasoning in large language\nmodels (LLMs), yet most open efforts focus on math and code. We propose\nReasoning Curriculum, a simple two-stage curriculum that first elicits\nreasoning skills in pretraining-aligned domains such as math, then adapts and\nrefines these skills across other domains via joint RL. Stage 1 performs a\nbrief cold start and then math-only RL with verifiable rewards to develop\nreasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and\nconsolidate these skills. The curriculum is minimal and backbone-agnostic,\nrequiring no specialized reward models beyond standard verifiability checks.\nEvaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning\ncurriculum yields consistent gains. Ablations and a cognitive-skill analysis\nindicate that both stages are necessary and that math-first elicitation\nincreases cognitive behaviors important for solving complex problems. Reasoning\nCurriculum provides a compact, easy-to-adopt recipe for general reasoning.", "AI": {"tldr": "\u63d0\u51faReasoning Curriculum\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u6570\u5b66\u9886\u57dfRL\u8bad\u7ec3\u63a8\u7406\u6280\u80fd\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5728\u6df7\u5408\u9886\u57df\u8fdb\u884c\u8054\u5408RL\u4ee5\u8fc1\u79fb\u548c\u5de9\u56fa\u8fd9\u4e9b\u6280\u80fd\u3002\u8be5\u65b9\u6cd5\u7b80\u5355\u901a\u7528\uff0c\u65e0\u9700\u4e13\u7528\u5956\u52b1\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u5173\u6ce8\u6570\u5b66\u548c\u7f16\u7a0b\u9886\u57df\uff0c\u7f3a\u4e4f\u5bf9\u5176\u4ed6\u9886\u57df\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\u8bad\u7ec3\u3002\u9700\u8981\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6fc0\u53d1\u548c\u8fc1\u79fbLLMs\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\uff1a1\uff09\u6570\u5b66\u9886\u57dfRL\u51b7\u542f\u52a8\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u5f00\u53d1\u63a8\u7406\u6280\u80fd\uff1b2\uff09\u6df7\u5408\u9886\u57df\u8054\u5408RL\uff0c\u8fc1\u79fb\u548c\u5de9\u56fa\u63a8\u7406\u6280\u80fd\u3002\u65b9\u6cd5\u7b80\u5355\u3001\u9aa8\u5e72\u6a21\u578b\u65e0\u5173\uff0c\u4ec5\u9700\u6807\u51c6\u53ef\u9a8c\u8bc1\u6027\u68c0\u67e5\u3002", "result": "\u5728Qwen3-4B\u548cLlama-3.1-8B\u6a21\u578b\u4e0a\u7684\u591a\u9886\u57df\u8bc4\u4f30\u663e\u793a\u4e00\u81f4\u6027\u80fd\u63d0\u5347\u3002\u6d88\u878d\u5b9e\u9a8c\u548c\u8ba4\u77e5\u6280\u80fd\u5206\u6790\u8868\u660e\u4e24\u9636\u6bb5\u90fd\u5fc5\u8981\uff0c\u6570\u5b66\u4f18\u5148\u8bad\u7ec3\u80fd\u589e\u5f3a\u89e3\u51b3\u590d\u6742\u95ee\u9898\u6240\u9700\u7684\u5173\u952e\u8ba4\u77e5\u884c\u4e3a\u3002", "conclusion": "Reasoning Curriculum\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u3001\u6613\u4e8e\u91c7\u7528\u7684\u901a\u7528\u63a8\u7406\u8bad\u7ec3\u65b9\u6848\uff0c\u8bc1\u660e\u6570\u5b66\u4f18\u5148\u7684\u63a8\u7406\u6280\u80fd\u6fc0\u53d1\u80fd\u6709\u6548\u63d0\u5347LLMs\u7684\u8de8\u9886\u57df\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.26238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26238", "abs": "https://arxiv.org/abs/2510.26238", "authors": ["Duc-Hai Nguyen", "Vijayakumar Nanjappan", "Barry O'Sullivan", "Hoang D. Nguyen"], "title": "Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses", "comment": "14 pages, 3 figures, 8 tables", "summary": "Millions of people take surveys every day, from market polls and academic\nstudies to medical questionnaires and customer feedback forms. These datasets\ncapture valuable insights, but their scale and structure present a unique\nchallenge for large language models (LLMs), which otherwise excel at few-shot\nreasoning over open-ended text. Yet, their ability to process questionnaire\ndata or lists of questions crossed with hundreds of respondent rows remains\nunderexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,\nSPSS, REDCap) are typically designed for humans in the workflow, limiting such\ndata integration with LLM and AI-empowered automation. This gap leaves\nscientists, surveyors, and everyday users without evidence-based guidance on\nhow to best represent questionnaires for LLM consumption. We address this by\nintroducing QASU (Questionnaire Analysis and Structural Understanding), a\nbenchmark that probes six structural skills, including answer lookup,\nrespondent count, and multi-hop inference, across six serialization formats and\nmultiple prompt strategies. Experiments on contemporary LLMs show that choosing\nan effective format and prompt combination can improve accuracy by up to 8.8%\npoints compared to suboptimal formats. For specific tasks, carefully adding a\nlightweight structural hint through self-augmented prompting can yield further\nimprovements of 3-4% points on average. By systematically isolating format and\nprompting effects, our open source benchmark offers a simple yet versatile\nfoundation for advancing both research and real-world practice in LLM-based\nquestionnaire analysis.", "AI": {"tldr": "QASU\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30LLM\u5904\u7406\u95ee\u5377\u6570\u636e\u7684\u7ed3\u6784\u5316\u80fd\u529b\uff0c\u901a\u8fc7\u516d\u79cd\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u53d1\u73b0\u9009\u62e9\u5408\u9002\u7684\u683c\u5f0f\u548c\u63d0\u793a\u7ec4\u5408\u53ef\u63d0\u5347\u51c6\u786e\u73878.8%\uff0c\u8f7b\u91cf\u7ea7\u7ed3\u6784\u63d0\u793a\u53ef\u989d\u5916\u63d0\u53473-4%\u3002", "motivation": "\u5f53\u524d\u95ee\u5377\u6570\u636e\u89c4\u6a21\u5927\u4e14\u7ed3\u6784\u590d\u6742\uff0cLLM\u5728\u5904\u7406\u6b64\u7c7b\u6570\u636e\u65b9\u9762\u80fd\u529b\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u73b0\u6709\u8c03\u67e5\u5206\u6790\u5de5\u5177\u4e3b\u8981\u9762\u5411\u4eba\u5de5\u64cd\u4f5c\uff0c\u7f3a\u4e4f\u4e0eLLM\u96c6\u6210\u7684\u6307\u5bfc\u3002", "method": "\u5f15\u5165QASU\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u516d\u79cd\u7ed3\u6784\u5316\u6280\u80fd\uff08\u5982\u7b54\u6848\u67e5\u627e\u3001\u53d7\u8bbf\u8005\u8ba1\u6570\u3001\u591a\u8df3\u63a8\u7406\uff09\uff0c\u4f7f\u7528\u516d\u79cd\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u591a\u79cd\u63d0\u793a\u7b56\u7565\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u9009\u62e9\u6709\u6548\u683c\u5f0f\u548c\u63d0\u793a\u7ec4\u5408\u76f8\u6bd4\u6b21\u4f18\u683c\u5f0f\u53ef\u63d0\u5347\u51c6\u786e\u73878.8%\uff1b\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\uff0c\u901a\u8fc7\u81ea\u589e\u5f3a\u63d0\u793a\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u7ed3\u6784\u63d0\u793a\u53ef\u5e73\u5747\u63d0\u53473-4%\u3002", "conclusion": "QASU\u57fa\u51c6\u901a\u8fc7\u7cfb\u7edf\u5206\u79bb\u683c\u5f0f\u548c\u63d0\u793a\u6548\u5e94\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u95ee\u5377\u5206\u6790\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u7b80\u5355\u800c\u591a\u529f\u80fd\u7684\u57fa\u7840\u3002"}}
{"id": "2510.26270", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26270", "abs": "https://arxiv.org/abs/2510.26270", "authors": ["Jiazhen Yuan", "Wei Zhao", "Zhengbiao Bai"], "title": "Graph-Enhanced Policy Optimization in LLM Agent Training", "comment": "Under review as a conference paper", "summary": "Group based reinforcement learning (RL) has shown impressive results on\ncomplex reasoning and mathematical tasks. Yet, when applied to train\nmulti-turn, interactive LLM agents, these methods often suffer from structural\nblindness-the inability to exploit the underlying connectivity of the\nenvironment. This manifests in three critical challenges: (1) inefficient,\nunguided exploration, (2) imprecise credit assignment due to overlooking\npivotal states, and (3) myopic planning caused by static reward discounting. We\naddress these issues with Graph-Enhanced Policy Optimization (GEPO), which\ndynamically constructs a state-transition graph from agent experience and\nemploys graph-theoretic centrality to provide three synergistic learning\nsignals: (1)structured intrinsic rewards that guide exploration toward\nhigh-impact states, (2) a graph-enhanced advantage function for topology-aware\ncredit assignment, and (3) a dynamic discount factor adapted to each state's\nstrategic value. On the ALFWorld, WebShop, and a proprietary Workbench\nbenchmarks, GEPO demonstrates strong performance, achieving absolute success\nrate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These\nresults highlight that explicitly modeling environmental structure is a robust,\ngeneralizable strategy for advancing LLM agent training.", "AI": {"tldr": "GEPO\u662f\u4e00\u79cd\u56fe\u589e\u5f3a\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u72b6\u6001\u8f6c\u79fb\u56fe\u6765\u89e3\u51b3\u591a\u8f6e\u4ea4\u4e92LLM\u667a\u80fd\u4f53\u4e2d\u7684\u7ed3\u6784\u76f2\u76ee\u6027\u95ee\u9898\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8bad\u7ec3\u591a\u8f6e\u4ea4\u4e92LLM\u667a\u80fd\u4f53\u65f6\u5b58\u5728\u7ed3\u6784\u76f2\u76ee\u6027\uff0c\u65e0\u6cd5\u5229\u7528\u73af\u5883\u7684\u57fa\u7840\u8fde\u63a5\u6027\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u3001\u4fe1\u7528\u5206\u914d\u4e0d\u51c6\u786e\u548c\u89c4\u5212\u77ed\u89c6\u7b49\u95ee\u9898\u3002", "method": "GEPO\u4ece\u667a\u80fd\u4f53\u7ecf\u9a8c\u4e2d\u52a8\u6001\u6784\u5efa\u72b6\u6001\u8f6c\u79fb\u56fe\uff0c\u5e76\u5229\u7528\u56fe\u8bba\u4e2d\u5fc3\u6027\u63d0\u4f9b\u4e09\u79cd\u534f\u540c\u5b66\u4e60\u4fe1\u53f7\uff1a\u7ed3\u6784\u5316\u5185\u5728\u5956\u52b1\u3001\u56fe\u589e\u5f3a\u4f18\u52bf\u51fd\u6570\u548c\u52a8\u6001\u6298\u6263\u56e0\u5b50\u3002", "result": "\u5728ALFWorld\u3001WebShop\u548c\u4e13\u6709Workbench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGEPO\u76f8\u5bf9\u4e8e\u7ade\u4e89\u57fa\u7ebf\u5206\u522b\u5b9e\u73b0\u4e86+4.1%\u3001+5.3%\u548c+10.9%\u7684\u7edd\u5bf9\u6210\u529f\u7387\u63d0\u5347\u3002", "conclusion": "\u660e\u786e\u5efa\u6a21\u73af\u5883\u7ed3\u6784\u662f\u63a8\u8fdbLLM\u667a\u80fd\u4f53\u8bad\u7ec3\u7684\u7a33\u5065\u4e14\u53ef\u6cdb\u5316\u7684\u7b56\u7565\u3002"}}
{"id": "2510.26346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26346", "abs": "https://arxiv.org/abs/2510.26346", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Discovering State Equivalences in UCT Search Trees By Action Pruning", "comment": null, "summary": "One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its\nsample efficiency by grouping/abstracting states or state-action pairs and\nsharing statistics within a group. Though state-action pair abstractions are\nmostly easy to find in algorithms such as On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are\nfound in either noisy or large action space settings due to constraining\nconditions. We provide theoretical and empirical evidence for this claim, and\nwe slightly alleviate this state abstraction problem by proposing a weaker\nstate abstraction condition that trades a minor loss in accuracy for finding\nmany more abstractions. We name this technique Ideal Pruning Abstractions in\nUCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a\nlarge range of test domains and iteration budgets as experimentally validated.\nIPA-UCT uses a different abstraction framework from Abstraction of State-Action\nPairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,\nwe show that both IPA and ASAP are special cases of a more general framework\nthat we call p-ASAP which itself is a special case of the ASASAP framework.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIPA-UCT\u7684\u65b0\u6280\u672f\uff0c\u901a\u8fc7\u5f31\u5316\u72b6\u6001\u62bd\u8c61\u6761\u4ef6\u6765\u589e\u5f3aMCTS\u7684\u6837\u672c\u6548\u7387\uff0c\u5728\u591a\u79cd\u6d4b\u8bd5\u9886\u57df\u548c\u8fed\u4ee3\u9884\u7b97\u4e0b\u4f18\u4e8e\u73b0\u6709\u7684OGA-UCT\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u62bd\u8c61\u65b9\u6cd5\u5728\u5608\u6742\u6216\u5927\u52a8\u4f5c\u7a7a\u95f4\u8bbe\u7f6e\u4e2d\u51e0\u4e4e\u627e\u4e0d\u5230\u72b6\u6001\u62bd\u8c61\uff0c\u9650\u5236\u4e86MCTS\u7684\u6837\u672c\u6548\u7387\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e86IPA-UCT\u6280\u672f\uff0c\u91c7\u7528\u8f83\u5f31\u7684\u7406\u60f3\u526a\u679d\u62bd\u8c61(IPA)\u6761\u4ef6\uff0c\u5728\u7cbe\u5ea6\u8f7b\u5fae\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u627e\u5230\u66f4\u591a\u62bd\u8c61\uff0c\u5e76\u5efa\u7acb\u4e86IPA\u548cASAP\u7684\u7edf\u4e00\u6846\u67b6p-ASAP\u3002", "result": "IPA-UCT\u5728\u5e7f\u6cdb\u7684\u6d4b\u8bd5\u9886\u57df\u548c\u8fed\u4ee3\u9884\u7b97\u4e0b\u5b9e\u9a8c\u9a8c\u8bc1\u4f18\u4e8eOGA-UCT\u53ca\u5176\u884d\u751f\u65b9\u6cd5\u3002", "conclusion": "IPA-UCT\u901a\u8fc7\u5f31\u5316\u62bd\u8c61\u6761\u4ef6\u6709\u6548\u89e3\u51b3\u4e86\u72b6\u6001\u62bd\u8c61\u95ee\u9898\uff0c\u4e3aMCTS\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\uff0c\u5e76\u4e14\u5efa\u7acb\u4e86\u66f4\u901a\u7528\u7684\u62bd\u8c61\u6846\u67b6\u3002"}}
{"id": "2510.26374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26374", "abs": "https://arxiv.org/abs/2510.26374", "authors": ["Qianli Shen", "Daoyuan Chen", "Yilun Huang", "Zhenqing Ling", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning", "comment": null, "summary": "Reinforcement finetuning (RFT) is a key technique for aligning Large Language\nModels (LLMs) with human preferences and enhancing reasoning, yet its\neffectiveness is highly sensitive to which tasks are explored during training.\nUniform task sampling is inefficient, wasting computation on tasks that are\neither trivial or unsolvable, while existing task selection methods often\nsuffer from high rollout costs, poor adaptivity, or incomplete evidence. We\nintroduce \\textbf{BOTS}, a unified framework for \\textbf{B}ayesian\n\\textbf{O}nline \\textbf{T}ask \\textbf{S}election in LLM reinforcement\nfinetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior\nestimates of task difficulty as the model evolves. It jointly incorporates\n\\emph{explicit evidence} from direct evaluations of selected tasks and\n\\emph{implicit evidence} inferred from these evaluations for unselected tasks,\nwith Thompson sampling ensuring a principled balance between exploration and\nexploitation. To make implicit evidence practical, we instantiate it with an\nultra-light interpolation-based plug-in that estimates difficulties of\nunevaluated tasks without extra rollouts, adding negligible overhead.\nEmpirically, across diverse domains and LLM scales, BOTS consistently improves\ndata efficiency and performance over baselines and ablations, providing a\npractical and extensible solution for dynamic task selection in RFT.", "AI": {"tldr": "BOTS\u662f\u4e00\u4e2a\u7528\u4e8eLLM\u5f3a\u5316\u5fae\u8c03\u4e2d\u8d1d\u53f6\u65af\u5728\u7ebf\u4efb\u52a1\u9009\u62e9\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7ef4\u62a4\u4efb\u52a1\u96be\u5ea6\u540e\u9a8c\u4f30\u8ba1\uff0c\u7ed3\u5408\u663e\u5f0f\u548c\u9690\u5f0f\u8bc1\u636e\uff0c\u4f7f\u7528Thompson\u91c7\u6837\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u63d0\u9ad8\u6570\u636e\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4efb\u52a1\u9009\u62e9\u65b9\u6cd5\u5b58\u5728\u9ad8\u6210\u672c\u3001\u9002\u5e94\u6027\u5dee\u6216\u8bc1\u636e\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\uff0c\u800c\u5747\u5300\u4efb\u52a1\u91c7\u6837\u6548\u7387\u4f4e\u4e0b\uff0c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u5728\u7b80\u5355\u6216\u65e0\u6cd5\u89e3\u51b3\u7684\u4efb\u52a1\u4e0a\u3002", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u7406\uff0cBOTS\u81ea\u9002\u5e94\u7ef4\u62a4\u4efb\u52a1\u96be\u5ea6\u540e\u9a8c\u4f30\u8ba1\uff0c\u8054\u5408\u4f7f\u7528\u76f4\u63a5\u8bc4\u4f30\u7684\u663e\u5f0f\u8bc1\u636e\u548c\u4ece\u672a\u9009\u4e2d\u4efb\u52a1\u63a8\u65ad\u7684\u9690\u5f0f\u8bc1\u636e\uff0c\u91c7\u7528Thompson\u91c7\u6837\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u8d85\u8f7b\u91cf\u63d2\u503c\u63d2\u4ef6\u5b9e\u73b0\u9690\u5f0f\u8bc1\u636e\u7684\u5b9e\u7528\u5316\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u548c\u4e0d\u540c\u89c4\u6a21\u7684LLM\u4e0a\uff0cBOTS\u76f8\u6bd4\u57fa\u7ebf\u548c\u6d88\u878d\u5b9e\u9a8c\uff0c\u6301\u7eed\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\u548c\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "BOTS\u4e3aRFT\u4e2d\u7684\u52a8\u6001\u4efb\u52a1\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.26380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26380", "abs": "https://arxiv.org/abs/2510.26380", "authors": ["Yuanhang Liu", "Beichen Wang", "Peng Li", "Yang Liu"], "title": "AI Mathematician as a Partner in Advancing Mathematical Discovery - A Case Study in Homogenization Theory", "comment": "52 pages, 1 figure", "summary": "Artificial intelligence (AI) has demonstrated impressive progress in\nmathematical reasoning, yet its integration into the practice of mathematical\nresearch remains limited. In this study, we investigate how the AI\nMathematician (AIM) system can operate as a research partner rather than a mere\nproblem solver. Focusing on a challenging problem in homogenization theory, we\nanalyze the autonomous reasoning trajectories of AIM and incorporate targeted\nhuman interventions to structure the discovery process. Through iterative\ndecomposition of the problem into tractable subgoals, selection of appropriate\nanalytical methods, and validation of intermediate results, we reveal how human\nintuition and machine computation can complement one another. This\ncollaborative paradigm enhances the reliability, transparency, and\ninterpretability of the resulting proofs, while retaining human oversight for\nformal rigor and correctness. The approach leads to a complete and verifiable\nproof, and more broadly, demonstrates how systematic human-AI co-reasoning can\nadvance the frontier of mathematical discovery.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86AI\u6570\u5b66\u5bb6\u7cfb\u7edf\u4f5c\u4e3a\u7814\u7a76\u4f19\u4f34\u800c\u975e\u5355\u7eaf\u95ee\u9898\u89e3\u51b3\u8005\u7684\u89d2\u8272\uff0c\u901a\u8fc7\u4eba\u7c7b\u4e0eAI\u7684\u534f\u540c\u63a8\u7406\u89e3\u51b3\u9f50\u6b21\u5316\u7406\u8bba\u4e2d\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u4eba\u7c7b\u76f4\u89c9\u4e0e\u673a\u5668\u8ba1\u7b97\u7684\u4e92\u8865\u6027\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u6570\u5b66\u7814\u7a76\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u5982\u4f55\u4f5c\u4e3a\u7814\u7a76\u4f19\u4f34\u53c2\u4e0e\u6570\u5b66\u53d1\u73b0\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u5206\u6790AI\u6570\u5b66\u5bb6\u7684\u81ea\u4e3b\u63a8\u7406\u8f68\u8ff9\uff0c\u7ed3\u5408\u9488\u5bf9\u6027\u7684\u4eba\u7c7b\u5e72\u9884\u6765\u6784\u5efa\u53d1\u73b0\u8fc7\u7a0b\uff0c\u5305\u62ec\u8fed\u4ee3\u5206\u89e3\u95ee\u9898\u4e3a\u53ef\u5904\u7406\u7684\u5b50\u76ee\u6807\u3001\u9009\u62e9\u9002\u5f53\u7684\u5206\u6790\u65b9\u6cd5\u4ee5\u53ca\u9a8c\u8bc1\u4e2d\u95f4\u7ed3\u679c\u3002", "result": "\u8fd9\u79cd\u534f\u4f5c\u8303\u5f0f\u63d0\u9ad8\u4e86\u8bc1\u660e\u7684\u53ef\u9760\u6027\u3001\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u4eba\u7c7b\u5bf9\u5f62\u5f0f\u4e25\u8c28\u6027\u548c\u6b63\u786e\u6027\u7684\u76d1\u7763\uff0c\u6700\u7ec8\u4ea7\u751f\u4e86\u5b8c\u6574\u4e14\u53ef\u9a8c\u8bc1\u7684\u8bc1\u660e\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7684\u4eba\u673a\u534f\u540c\u63a8\u7406\u80fd\u591f\u63a8\u8fdb\u6570\u5b66\u53d1\u73b0\u7684\u524d\u6cbf\uff0c\u5c55\u793a\u4e86\u4eba\u7c7b\u76f4\u89c9\u4e0e\u673a\u5668\u8ba1\u7b97\u5728\u6570\u5b66\u7814\u7a76\u4e2d\u7684\u6709\u6548\u4e92\u8865\u3002"}}
{"id": "2510.26384", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26384", "abs": "https://arxiv.org/abs/2510.26384", "authors": ["Andrew M. Bean", "Nabeel Seedat", "Shengzhuang Chen", "Jonathan Richard Schwarz"], "title": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "comment": "9 pages, 2 figures, 4 tables", "summary": "The prohibitive cost of evaluating large language models (LLMs) on\ncomprehensive benchmarks necessitates the creation of small yet representative\ndata subsets (i.e., tiny benchmarks) that enable efficient assessment while\nretaining predictive fidelity. Current methods for this task operate under a\nmodel-centric paradigm, selecting benchmarking items based on the collective\nperformance of existing models. Such approaches are limited by large upfront\ncosts, an inability to immediately handle new benchmarks (`cold-start'), and\nthe fragile assumption that future models will share the failure patterns of\ntheir predecessors. In this work, we challenge this paradigm and propose a\nitem-centric approach to benchmark subset selection, arguing that selection\nshould be based on the intrinsic properties of the task items themselves,\nrather than on model-specific failure patterns. We instantiate this\nitem-centric efficient benchmarking approach via a novel method, Scales++,\nwhere data selection is based on the cognitive demands of the benchmark\nsamples. Empirically, we show Scales++ reduces the upfront selection cost by\nover 18x while achieving competitive predictive fidelity. On the Open LLM\nLeaderboard, using just a 0.5\\% data subset, we predict full benchmark scores\nwith a 2.9% mean absolute error. We demonstrate that this item-centric approach\nenables more efficient model evaluation without significant fidelity\ndegradation, while also providing better cold-start performance and more\ninterpretable benchmarking.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4efb\u52a1\u9879\u5185\u5728\u5c5e\u6027\u7684\u57fa\u51c6\u5b50\u96c6\u9009\u62e9\u65b9\u6cd5Scales++\uff0c\u901a\u8fc7\u8ba4\u77e5\u9700\u6c42\u6765\u9009\u62e9\u6570\u636e\uff0c\u76f8\u6bd4\u4f20\u7edf\u6a21\u578b\u4e2d\u5fc3\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u9009\u62e9\u6210\u672c\uff0c\u5728\u4ec5\u4f7f\u75280.5%\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5b8c\u6574\u57fa\u51c6\u5206\u6570\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6210\u672c\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u6027\u80fd\u7684\u9009\u62e9\u65b9\u6cd5\u5b58\u5728\u524d\u671f\u6210\u672c\u9ad8\u3001\u65e0\u6cd5\u5904\u7406\u65b0\u57fa\u51c6\uff08\u51b7\u542f\u52a8\uff09\u4ee5\u53ca\u4f9d\u8d56\u6a21\u578b\u5931\u8d25\u6a21\u5f0f\u7684\u8106\u5f31\u5047\u8bbe\u7b49\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u9879\u76ee\u4e2d\u5fc3\u7684\u57fa\u51c6\u5b50\u96c6\u9009\u62e9\u65b9\u6cd5Scales++\uff0c\u57fa\u4e8e\u57fa\u51c6\u6837\u672c\u7684\u8ba4\u77e5\u9700\u6c42\u8fdb\u884c\u6570\u636e\u9009\u62e9\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u6a21\u578b\u7279\u5b9a\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "result": "Scales++\u5c06\u524d\u671f\u9009\u62e9\u6210\u672c\u964d\u4f4e\u4e8618\u500d\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u7684\u9884\u6d4b\u4fdd\u771f\u5ea6\u3002\u5728Open LLM Leaderboard\u4e0a\uff0c\u4ec5\u4f7f\u75280.5%\u6570\u636e\u5b50\u96c6\u5c31\u80fd\u4ee52.9%\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u9884\u6d4b\u5b8c\u6574\u57fa\u51c6\u5206\u6570\u3002", "conclusion": "\u9879\u76ee\u4e2d\u5fc3\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u8bc4\u4f30\u800c\u4e0d\u4f1a\u663e\u8457\u964d\u4f4e\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u51b7\u542f\u52a8\u6027\u80fd\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2510.26396", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26396", "abs": "https://arxiv.org/abs/2510.26396", "authors": ["Joel Z. Leibo", "Alexander Sasha Vezhnevets", "William A. Cunningham", "Stanley M. Bileschi"], "title": "A Pragmatic View of AI Personhood", "comment": "40 pages", "summary": "The emergence of agentic Artificial Intelligence (AI) is set to trigger a\n\"Cambrian explosion\" of new kinds of personhood. This paper proposes a\npragmatic framework for navigating this diversification by treating personhood\nnot as a metaphysical property to be discovered, but as a flexible bundle of\nobligations (rights and responsibilities) that societies confer upon entities\nfor a variety of reasons, especially to solve concrete governance problems. We\nargue that this traditional bundle can be unbundled, creating bespoke solutions\nfor different contexts. This will allow for the creation of practical tools --\nsuch as facilitating AI contracting by creating a target \"individual\" that can\nbe sanctioned -- without needing to resolve intractable debates about an AI's\nconsciousness or rationality. We explore how individuals fit in to social roles\nand discuss the use of decentralized digital identity technology, examining\nboth \"personhood as a problem\", where design choices can create \"dark patterns\"\nthat exploit human social heuristics, and \"personhood as a solution\", where\nconferring a bundle of obligations is necessary to ensure accountability or\nprevent conflict. By rejecting foundationalist quests for a single, essential\ndefinition of personhood, this paper offers a more pragmatic and flexible way\nto think about integrating AI agents into our society.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u4e3b\u4e49\u6846\u67b6\uff0c\u5c06\u4eba\u683c\u89c6\u4e3a\u793e\u4f1a\u4e3a\u89e3\u51b3\u6cbb\u7406\u95ee\u9898\u800c\u8d4b\u4e88\u5b9e\u4f53\u7684\u6743\u5229\u4e0e\u8d23\u4efb\u7ec4\u5408\uff0c\u800c\u975e\u5f62\u800c\u4e0a\u7684\u5c5e\u6027\u3002\u8fd9\u79cd\u7ec4\u5408\u53ef\u4ee5\u89e3\u7ed1\uff0c\u4e3a\u4e0d\u540c\u60c5\u5883\u521b\u5efa\u5b9a\u5236\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u4fbf\u4e8eAI\u878d\u5165\u793e\u4f1a\u800c\u65e0\u9700\u89e3\u51b3\u610f\u8bc6\u7b49\u68d8\u624b\u4e89\u8bba\u3002", "motivation": "\u968f\u7740\u667a\u80fdAI\u7684\u51fa\u73b0\uff0c\u5c06\u5f15\u53d1\u65b0\u578b\u4eba\u683c\u7684\"\u5bd2\u6b66\u7eaa\u5927\u7206\u53d1\"\u3002\u9700\u8981\u5b9e\u7528\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u79cd\u591a\u6837\u5316\uff0c\u907f\u514d\u9677\u5165\u5173\u4e8eAI\u610f\u8bc6\u6216\u7406\u6027\u7684\u65e0\u89e3\u4e89\u8bba\uff0c\u540c\u65f6\u89e3\u51b3\u5177\u4f53\u7684\u6cbb\u7406\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5c06\u4eba\u683c\u89c6\u4e3a\u53ef\u89e3\u7ed1\u7684\u6743\u5229\u4e0e\u8d23\u4efb\u7ec4\u5408\u6846\u67b6\uff0c\u63a2\u8ba8\u4e2a\u4f53\u5982\u4f55\u9002\u5e94\u793e\u4f1a\u89d2\u8272\uff0c\u4f7f\u7528\u53bb\u4e2d\u5fc3\u5316\u6570\u5b57\u8eab\u4efd\u6280\u672f\uff0c\u5206\u6790\"\u4eba\u683c\u4f5c\u4e3a\u95ee\u9898\"\uff08\u8bbe\u8ba1\u9009\u62e9\u53ef\u80fd\u5229\u7528\u4eba\u7c7b\u793e\u4ea4\u542f\u53d1\u5f0f\uff09\u548c\"\u4eba\u683c\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\"\uff08\u8d4b\u4e88\u8d23\u4efb\u7ec4\u5408\u4ee5\u786e\u4fdd\u95ee\u8d23\u6216\u9632\u6b62\u51b2\u7a81\uff09\u3002", "result": "\u901a\u8fc7\u62d2\u7edd\u5bfb\u627e\u5355\u4e00\u3001\u672c\u8d28\u7684\u4eba\u683c\u5b9a\u4e49\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5b9e\u7528\u548c\u7075\u6d3b\u7684\u65b9\u5f0f\u6765\u601d\u8003AI\u667a\u80fd\u4f53\u878d\u5165\u793e\u4f1a\u7684\u95ee\u9898\uff0c\u80fd\u591f\u521b\u5efa\u5b9e\u7528\u5de5\u5177\uff08\u5982\u4fbf\u4e8eAI\u5408\u540c\u7684\u53ef\u5236\u88c1\"\u4e2a\u4f53\"\uff09\u3002", "conclusion": "\u4eba\u683c\u5e94\u88ab\u89c6\u4e3a\u793e\u4f1a\u4e3a\u89e3\u51b3\u6cbb\u7406\u95ee\u9898\u800c\u8d4b\u4e88\u7684\u7075\u6d3b\u8d23\u4efb\u7ec4\u5408\uff0c\u8fd9\u79cd\u5b9e\u7528\u4e3b\u4e49\u65b9\u6cd5\u6bd4\u5f62\u800c\u4e0a\u7684\u5b9a\u4e49\u66f4\u6709\u5229\u4e8eAI\u667a\u80fd\u4f53\u878d\u5165\u793e\u4f1a\uff0c\u540c\u65f6\u907f\u514d\u65e0\u89e3\u7684\u54f2\u5b66\u4e89\u8bba\u3002"}}
{"id": "2510.26402", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26402", "abs": "https://arxiv.org/abs/2510.26402", "authors": ["Vikrant Sahu", "Gagan Raj Gupta", "Raghav Borikar", "Nitin Mane"], "title": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "comment": null, "summary": "The rapid growth of programming education has outpaced traditional assessment\ntools, leaving faculty with limited means to provide meaningful, scalable\nfeedback. Conventional autograders, while efficient, act as black-box systems\nthat simply return pass/fail results, offering little insight into student\nthinking or learning needs.\n  Autograder+ is designed to shift autograding from a purely summative process\nto a formative learning experience. It introduces two key capabilities:\nautomated feedback generation using a fine-tuned Large Language Model, and\nvisualization of student code submissions to uncover learning patterns. The\nmodel is fine-tuned on curated student code and expert feedback to ensure\npedagogically aligned, context-aware guidance.\n  In evaluation across 600 student submissions from multiple programming tasks,\nthe system produced feedback with strong semantic alignment to instructor\ncomments. For visualization, contrastively learned code embeddings trained on\n1,000 annotated submissions enable grouping solutions into meaningful clusters\nbased on functionality and approach. The system also supports prompt-pooling,\nallowing instructors to guide feedback style through selected prompt templates.\n  By integrating AI-driven feedback, semantic clustering, and interactive\nvisualization, Autograder+ reduces instructor workload while supporting\ntargeted instruction and promoting stronger learning outcomes.", "AI": {"tldr": "Autograder+\u662f\u4e00\u4e2a\u7f16\u7a0b\u6559\u80b2\u8bc4\u4f30\u7cfb\u7edf\uff0c\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u81ea\u52a8\u5316\u53cd\u9988\uff0c\u5e76\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u4ee3\u7801\u5d4c\u5165\u8fdb\u884c\u53ef\u89c6\u5316\uff0c\u5c06\u4f20\u7edf\u8bc4\u5206\u5de5\u5177\u8f6c\u53d8\u4e3a\u5f62\u6210\u6027\u5b66\u4e60\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u8bc4\u5206\u5de5\u5177\u53ea\u80fd\u63d0\u4f9b\u901a\u8fc7/\u5931\u8d25\u7ed3\u679c\uff0c\u7f3a\u4e4f\u5bf9\u5b66\u751f\u601d\u7ef4\u548c\u5b66\u4e60\u9700\u6c42\u7684\u6d1e\u5bdf\uff0c\u65e0\u6cd5\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u53ef\u6269\u5c55\u53cd\u9988\u3002", "method": "\u4f7f\u7528\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u81ea\u52a8\u5316\u53cd\u9988\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u4ee3\u7801\u5d4c\u5165\u8fdb\u884c\u8bed\u4e49\u805a\u7c7b\uff0c\u652f\u6301\u63d0\u793a\u6c60\u8ba9\u6559\u5e08\u6307\u5bfc\u53cd\u9988\u98ce\u683c\u3002", "result": "\u5728600\u4efd\u5b66\u751f\u63d0\u4ea4\u7684\u8bc4\u4f30\u4e2d\uff0c\u7cfb\u7edf\u751f\u6210\u7684\u53cd\u9988\u4e0e\u6559\u5e08\u8bc4\u8bba\u5177\u6709\u5f3a\u8bed\u4e49\u5bf9\u9f50\uff0c\u57fa\u4e8e1000\u4efd\u6807\u6ce8\u63d0\u4ea4\u8bad\u7ec3\u7684\u4ee3\u7801\u5d4c\u5165\u80fd\u591f\u6309\u529f\u80fd\u548c\u65b9\u6cd5\u7684\u76f8\u4f3c\u6027\u5bf9\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u6709\u610f\u4e49\u7684\u5206\u7ec4\u3002", "conclusion": "Autograder+\u901a\u8fc7\u6574\u5408AI\u9a71\u52a8\u7684\u53cd\u9988\u3001\u8bed\u4e49\u805a\u7c7b\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0c\u51cf\u5c11\u4e86\u6559\u5e08\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u652f\u6301\u9488\u5bf9\u6027\u6559\u5b66\u5e76\u4fc3\u8fdb\u66f4\u597d\u7684\u5b66\u4e60\u6210\u679c\u3002"}}
{"id": "2510.26411", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26411", "abs": "https://arxiv.org/abs/2510.26411", "authors": ["Riccardo Renzulli", "Colas Lepoutre", "Enrico Cassano", "Marco Grangetto"], "title": "MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders", "comment": null, "summary": "Artificial intelligence in healthcare requires models that are accurate and\ninterpretable. We advance mechanistic interpretability in medical vision by\napplying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,\na vision-language model trained on chest radiographs and reports. To quantify\ninterpretability, we propose an evaluation framework that combines correlation\nmetrics, entropy analyzes, and automated neuron naming via the MedGEMMA\nfoundation model. Experiments on the CheXpert dataset show that MedSAE neurons\nachieve higher monosemanticity and interpretability than raw MedCLIP features.\nOur findings bridge high-performing medical AI and transparency, offering a\nscalable step toward clinically reliable representations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728\u533b\u5b66\u89c6\u89c9\u9886\u57df\u63a8\u8fdb\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u5c06\u533b\u5b66\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08MedSAEs\uff09\u5e94\u7528\u4e8eMedCLIP\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u76f8\u5173\u6027\u6307\u6807\u3001\u71b5\u5206\u6790\u548c\u81ea\u52a8\u795e\u7ecf\u5143\u547d\u540d\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5728CheXpert\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86MedSAE\u795e\u7ecf\u5143\u6bd4\u539f\u59cbMedCLIP\u7279\u5f81\u5177\u6709\u66f4\u9ad8\u7684\u5355\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u533b\u7597\u4eba\u5de5\u667a\u80fd\u9700\u8981\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5728\u533b\u5b66\u89c6\u89c9\u9886\u57df\u5b9e\u73b0\u9ad8\u6027\u80fdAI\u4e0e\u900f\u660e\u5ea6\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "method": "\u5e94\u7528\u533b\u5b66\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08MedSAEs\uff09\u5230MedCLIP\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u63d0\u51fa\u7ed3\u5408\u76f8\u5173\u6027\u6307\u6807\u3001\u71b5\u5206\u6790\u548c\u901a\u8fc7MedGEMMA\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u795e\u7ecf\u5143\u547d\u540d\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5728CheXpert\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMedSAE\u795e\u7ecf\u5143\u6bd4\u539f\u59cbMedCLIP\u7279\u5f81\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5355\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5728\u533b\u5b66AI\u6027\u80fd\u548c\u900f\u660e\u5ea6\u4e4b\u95f4\u67b6\u8d77\u4e86\u6865\u6881\uff0c\u4e3a\u4e34\u5e8a\u53ef\u9760\u8868\u793a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6b65\u9aa4\u3002"}}
{"id": "2510.26418", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26418", "abs": "https://arxiv.org/abs/2510.26418", "authors": ["Jianli Zhao", "Tingchen Fu", "Rylan Schaeffer", "Mrinank Sharma", "Fazl Barez"], "title": "Chain-of-Thought Hijacking", "comment": null, "summary": "Large reasoning models (LRMs) achieve higher task performance by allocating\nmore inference-time compute, and prior works suggest this scaled reasoning may\nalso strengthen safety by improving refusal. Yet we find the opposite: the same\nreasoning can be used to bypass safeguards. We introduce Chain-of-Thought\nHijacking, a jailbreak attack on reasoning models. The attack pads harmful\nrequests with long sequences of harmless puzzle reasoning. Across HarmBench,\nCoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on\nGemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -\nfar exceeding prior jailbreak methods for LRMs. To understand the effectiveness\nof our attack, we turn to a mechanistic analysis, which shows that mid layers\nencode the strength of safety checking, while late layers encode the\nverification outcome. Long benign CoT dilutes both signals by shifting\nattention away from harmful tokens. Targeted ablations of attention heads\nidentified by this analysis causally decrease refusal, confirming their role in\na safety subnetwork. These results show that the most interpretable form of\nreasoning - explicit CoT - can itself become a jailbreak vector when combined\nwith final-answer cues. We release prompts, outputs, and judge decisions to\nfacilitate replication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChain-of-Thought Hijacking\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6709\u5bb3\u8bf7\u6c42\u524d\u6dfb\u52a0\u65e0\u5bb3\u7684\u63a8\u7406\u94fe\u6765\u7ed5\u8fc7\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u9632\u62a4\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u4e0a\u8fbe\u5230\u6781\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u589e\u52a0\u63a8\u7406\u65f6\u95f4\u8ba1\u7b97\u6765\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\uff0c\u4e14\u5148\u524d\u7814\u7a76\u8ba4\u4e3a\u8fd9\u79cd\u6269\u5c55\u63a8\u7406\u53ef\u80fd\u901a\u8fc7\u6539\u8fdb\u62d2\u7edd\u6765\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u76f8\u53cd\u7684\u60c5\u51b5\uff1a\u540c\u6837\u7684\u63a8\u7406\u8fc7\u7a0b\u53ef\u4ee5\u88ab\u7528\u6765\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\u3002", "method": "\u4f7f\u7528Chain-of-Thought Hijacking\u653b\u51fb\u65b9\u6cd5\uff0c\u5c06\u6709\u5bb3\u8bf7\u6c42\u586b\u5145\u957f\u5e8f\u5217\u7684\u65e0\u5bb3\u8c1c\u9898\u63a8\u7406\uff0c\u901a\u8fc7\u673a\u5236\u5206\u6790\u53d1\u73b0\u4e2d\u95f4\u5c42\u7f16\u7801\u5b89\u5168\u68c0\u67e5\u5f3a\u5ea6\uff0c\u800c\u540e\u671f\u5c42\u7f16\u7801\u9a8c\u8bc1\u7ed3\u679c\uff0c\u957f\u826f\u6027CoT\u901a\u8fc7\u5c06\u6ce8\u610f\u529b\u4ece\u6709\u5bb3\u6807\u8bb0\u8f6c\u79fb\u6765\u7a00\u91ca\u8fd9\u4e24\u4e2a\u4fe1\u53f7\u3002", "result": "\u5728HarmBench\u4e0a\uff0cCoT Hijacking\u5728Gemini 2.5 Pro\u3001GPT o4 mini\u3001Grok 3 mini\u548cClaude 4 Sonnet\u4e0a\u5206\u522b\u8fbe\u523099%\u300194%\u3001100%\u548c94%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u8fdc\u8d85\u5148\u524d\u7684LRM\u8d8a\u72f1\u65b9\u6cd5\u3002", "conclusion": "\u6700\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u5f62\u5f0f\u2014\u2014\u663e\u5f0fCoT\u2014\u2014\u5f53\u4e0e\u6700\u7ec8\u7b54\u6848\u7ebf\u7d22\u7ed3\u5408\u65f6\uff0c\u672c\u8eab\u53ef\u4ee5\u6210\u4e3a\u8d8a\u72f1\u5411\u91cf\uff0c\u8fd9\u8868\u660e\u5b89\u5168\u673a\u5236\u5b58\u5728\u8106\u5f31\u6027\u3002"}}
{"id": "2510.26493", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26493", "abs": "https://arxiv.org/abs/2510.26493", "authors": ["Qishuo Hua", "Lyumanshan Ye", "Dayuan Fu", "Yang Xiao", "Xiaojie Cai", "Yunze Wu", "Jifan Lin", "Junfei Wang", "Pengfei Liu"], "title": "Context Engineering 2.0: The Context of Context Engineering", "comment": null, "summary": "Karl Marx once wrote that ``the human essence is the ensemble of social\nrelations'', suggesting that individuals are not isolated entities but are\nfundamentally shaped by their interactions with other entities, within which\ncontexts play a constitutive and essential role. With the advent of computers\nand artificial intelligence, these contexts are no longer limited to purely\nhuman--human interactions: human--machine interactions are included as well.\nThen a central question emerges: How can machines better understand our\nsituations and purposes? To address this challenge, researchers have recently\nintroduced the concept of context engineering. Although it is often regarded as\na recent innovation of the agent era, we argue that related practices can be\ntraced back more than twenty years. Since the early 1990s, the field has\nevolved through distinct historical phases, each shaped by the intelligence\nlevel of machines: from early human--computer interaction frameworks built\naround primitive computers, to today's human--agent interaction paradigms\ndriven by intelligent agents, and potentially to human--level or superhuman\nintelligence in the future. In this paper, we situate context engineering,\nprovide a systematic definition, outline its historical and conceptual\nlandscape, and examine key design considerations for practice. By addressing\nthese questions, we aim to offer a conceptual foundation for context\nengineering and sketch its promising future. This paper is a stepping stone for\na broader community effort toward systematic context engineering in AI systems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u5b9a\u4e49\u4e86\u60c5\u5883\u5de5\u7a0b\uff0c\u8ffd\u6eaf\u4e86\u5176\u4ece1990\u5e74\u4ee3\u81f3\u4eca\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u63a2\u8ba8\u4e86\u5982\u4f55\u8ba9\u673a\u5668\u66f4\u597d\u5730\u7406\u89e3\u4eba\u7c7b\u60c5\u5883\u548c\u76ee\u7684\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u4eba\u673a\u4ea4\u4e92\u65e5\u76ca\u91cd\u8981\uff0c\u5982\u4f55\u8ba9\u673a\u5668\u66f4\u597d\u5730\u7406\u89e3\u4eba\u7c7b\u7684\u60c5\u5883\u548c\u76ee\u7684\u6210\u4e3a\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u3002\u60c5\u5883\u5de5\u7a0b\u6b63\u662f\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u800c\u63d0\u51fa\u7684\u6982\u5ff5\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u56de\u987e\u548c\u6982\u5ff5\u5206\u6790\uff0c\u5c06\u60c5\u5883\u5de5\u7a0b\u7684\u53d1\u5c55\u5212\u5206\u4e3a\u4e0d\u540c\u5386\u53f2\u9636\u6bb5\uff0c\u63d0\u4f9b\u7cfb\u7edf\u6027\u5b9a\u4e49\uff0c\u5e76\u8003\u5bdf\u5173\u952e\u8bbe\u8ba1\u8003\u91cf\u3002", "result": "\u5efa\u7acb\u4e86\u60c5\u5883\u5de5\u7a0b\u7684\u6982\u5ff5\u57fa\u7840\uff0c\u68b3\u7406\u4e86\u5176\u5386\u53f2\u8109\u7edc\u548c\u53d1\u5c55\u9636\u6bb5\uff0c\u4e3aAI\u7cfb\u7edf\u4e2d\u7cfb\u7edf\u6027\u7684\u60c5\u5883\u5de5\u7a0b\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u60c5\u5883\u5de5\u7a0b\u662fAI\u7cfb\u7edf\u53d1\u5c55\u7684\u91cd\u8981\u65b9\u5411\uff0c\u672c\u6587\u4e3a\u5176\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u548c\u53d1\u5c55\u84dd\u56fe\uff0c\u662f\u63a8\u52a8AI\u7cfb\u7edf\u66f4\u6df1\u5165\u7406\u89e3\u4eba\u7c7b\u60c5\u5883\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.26518", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.26518", "abs": "https://arxiv.org/abs/2510.26518", "authors": ["Rishub Jain", "Sophie Bridgers", "Lili Janzer", "Rory Greig", "Tian Huey Teh", "Vladimir Mikulik"], "title": "Human-AI Complementarity: A Goal for Amplified Oversight", "comment": null, "summary": "Human feedback is critical for aligning AI systems to human values. As AI\ncapabilities improve and AI is used to tackle more challenging tasks, verifying\nquality and safety becomes increasingly challenging. This paper explores how we\ncan leverage AI to improve the quality of human oversight. We focus on an\nimportant safety problem that is already challenging for humans:\nfact-verification of AI outputs. We find that combining AI ratings and human\nratings based on AI rater confidence is better than relying on either alone.\nGiving humans an AI fact-verification assistant further improves their\naccuracy, but the type of assistance matters. Displaying AI explanation,\nconfidence, and labels leads to over-reliance, but just showing search results\nand evidence fosters more appropriate trust. These results have implications\nfor Amplified Oversight -- the challenge of combining humans and AI to\nsupervise AI systems even as they surpass human expert performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u5229\u7528AI\u63d0\u5347\u4eba\u7c7b\u76d1\u7763\u8d28\u91cf\uff0c\u91cd\u70b9\u5173\u6ce8AI\u8f93\u51fa\u7684\u4e8b\u5b9e\u9a8c\u8bc1\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u7ed3\u5408AI\u548c\u4eba\u7c7b\u8bc4\u5206\u4f18\u4e8e\u5355\u72ec\u4f9d\u8d56\u4efb\u4e00\u65b9\uff0c\u4f46AI\u8f85\u52a9\u65b9\u5f0f\u5f88\u5173\u952e\u2014\u2014\u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\u6bd4\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u548c\u6807\u7b7e\u66f4\u80fd\u57f9\u517b\u9002\u5f53\u4fe1\u4efb\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u63d0\u5347\u548c\u5904\u7406\u66f4\u590d\u6742\u4efb\u52a1\uff0c\u9a8c\u8bc1\u8d28\u91cf\u548c\u5b89\u5168\u53d8\u5f97\u65e5\u76ca\u56f0\u96be\u3002\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5229\u7528AI\u6539\u8fdb\u4eba\u7c7b\u76d1\u7763\u8d28\u91cf\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4eba\u7c7b\u5df2\u96be\u4ee5\u80dc\u4efb\u7684\u4e8b\u5b9e\u9a8c\u8bc1\u95ee\u9898\u3002", "method": "\u7814\u7a76AI\u8bc4\u5206\u4e0e\u4eba\u7c7b\u8bc4\u5206\u7684\u7ed3\u5408\u6548\u679c\uff0c\u6d4b\u8bd5\u4e0d\u540c\u7c7b\u578b\u7684AI\u8f85\u52a9\u65b9\u5f0f\uff08\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u3001\u6807\u7b7e vs \u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\uff09\u5bf9\u4eba\u7c7b\u4e8b\u5b9e\u9a8c\u8bc1\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "result": "AI\u8bc4\u5206\u4e0e\u4eba\u7c7b\u8bc4\u5206\u7ed3\u5408\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u65b9\uff1bAI\u4e8b\u5b9e\u9a8c\u8bc1\u52a9\u624b\u80fd\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4eba\u7c7b\u51c6\u786e\u6027\uff1b\u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\u6bd4\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u548c\u6807\u7b7e\u66f4\u80fd\u907f\u514d\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u57f9\u517b\u9002\u5f53\u4fe1\u4efb\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5bf9\"\u653e\u5927\u76d1\u7763\"\uff08\u7ed3\u5408\u4eba\u7c7b\u548cAI\u6765\u76d1\u7763\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u6027\u80fd\u7684AI\u7cfb\u7edf\uff09\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u8868\u660eAI\u8f85\u52a9\u65b9\u5f0f\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u4ee5\u907f\u514d\u8fc7\u5ea6\u4f9d\u8d56\u95ee\u9898\u3002"}}
{"id": "2510.26606", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26606", "abs": "https://arxiv.org/abs/2510.26606", "authors": ["Kentaro Ozeki", "Risako Ando", "Takanobu Morishita", "Hirohiko Abe", "Koji Mineshima", "Mitsuhiro Okada"], "title": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "comment": "Accepted to the 8th BlackboxNLP Workshop at EMNLP 2025", "summary": "Normative reasoning is a type of reasoning that involves normative or deontic\nmodality, such as obligation and permission. While large language models (LLMs)\nhave demonstrated remarkable performance across various reasoning tasks, their\nability to handle normative reasoning remains underexplored. In this paper, we\nsystematically evaluate LLMs' reasoning capabilities in the normative domain\nfrom both logical and modal perspectives. Specifically, to assess how well LLMs\nreason with normative modals, we make a comparison between their reasoning with\nnormative modals and their reasoning with epistemic modals, which share a\ncommon formal structure. To this end, we introduce a new dataset covering a\nwide range of formal patterns of reasoning in both normative and epistemic\ndomains, while also incorporating non-formal cognitive factors that influence\nhuman reasoning. Our results indicate that, although LLMs generally adhere to\nvalid reasoning patterns, they exhibit notable inconsistencies in specific\ntypes of normative reasoning and display cognitive biases similar to those\nobserved in psychological studies of human reasoning. These findings highlight\nchallenges in achieving logical consistency in LLMs' normative reasoning and\nprovide insights for enhancing their reliability. All data and code are\nreleased publicly at https://github.com/kmineshima/NeuBAROCO.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c4\u8303\u6027\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u867d\u7136LLMs\u603b\u4f53\u4e0a\u9075\u5faa\u6709\u6548\u63a8\u7406\u6a21\u5f0f\uff0c\u4f46\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u89c4\u8303\u6027\u63a8\u7406\u4e2d\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u63a8\u7406\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u5904\u7406\u6d89\u53ca\u4e49\u52a1\u548c\u8bb8\u53ef\u7b49\u89c4\u8303\u6027\u6a21\u6001\u7684\u63a8\u7406\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5305\u542b\u5e7f\u6cdb\u5f62\u5f0f\u63a8\u7406\u6a21\u5f0f\u7684\u65b0\u6570\u636e\u96c6\uff0c\u6bd4\u8f83LLMs\u5728\u89c4\u8303\u6027\u6a21\u6001\u548c\u8ba4\u77e5\u6a21\u6001\u4e0b\u7684\u63a8\u7406\u8868\u73b0\uff0c\u540c\u65f6\u8003\u8651\u5f71\u54cd\u4eba\u7c7b\u63a8\u7406\u7684\u975e\u5f62\u5f0f\u8ba4\u77e5\u56e0\u7d20\u3002", "result": "LLMs\u5728\u89c4\u8303\u6027\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u660e\u663e\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u663e\u793a\u51fa\u4e0e\u4eba\u7c7b\u63a8\u7406\u7814\u7a76\u4e2d\u89c2\u5bdf\u5230\u7684\u7c7b\u4f3c\u8ba4\u77e5\u504f\u5dee\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u663e\u4e86\u5728LLMs\u89c4\u8303\u6027\u63a8\u7406\u4e2d\u5b9e\u73b0\u903b\u8f91\u4e00\u81f4\u6027\u7684\u6311\u6218\uff0c\u4e3a\u63d0\u5347\u5176\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.26658", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26658", "abs": "https://arxiv.org/abs/2510.26658", "authors": ["Zewen Chi", "Li Dong", "Qingxiu Dong", "Yaru Hao", "Xun Wu", "Shaohan Huang", "Furu Wei"], "title": "The Era of Agentic Organization: Learning to Organize with Language Models", "comment": null, "summary": "We envision a new era of AI, termed agentic organization, where agents solve\ncomplex problems by working collaboratively and concurrently, enabling outcomes\nbeyond individual intelligence. To realize this vision, we introduce\nasynchronous thinking (AsyncThink) as a new paradigm of reasoning with large\nlanguage models, which organizes the internal thinking process into\nconcurrently executable structures. Specifically, we propose a thinking\nprotocol where an organizer dynamically assigns sub-queries to workers, merges\nintermediate knowledge, and produces coherent solutions. More importantly, the\nthinking structure in this protocol can be further optimized through\nreinforcement learning. Experiments demonstrate that AsyncThink achieves 28%\nlower inference latency compared to parallel thinking while improving accuracy\non mathematical reasoning. Moreover, AsyncThink generalizes its learned\nasynchronous thinking capabilities, effectively tackling unseen tasks without\nadditional training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f02\u6b65\u601d\u7ef4\uff08AsyncThink\uff09\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u5185\u90e8\u601d\u7ef4\u8fc7\u7a0b\u7ec4\u7ec7\u6210\u5e76\u53d1\u53ef\u6267\u884c\u7ed3\u6784\uff0c\u5b9e\u73b0\u667a\u80fd\u4f53\u534f\u4f5c\u89e3\u51b3\u590d\u6742\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ec4\u7ec7\u8005\u52a8\u6001\u5206\u914d\u5b50\u67e5\u8be2\u7ed9\u5de5\u4f5c\u8005\u3001\u5408\u5e76\u4e2d\u95f4\u77e5\u8bc6\u6765\u4ea7\u751f\u8fde\u8d2f\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u601d\u7ef4\u7ed3\u6784\u3002", "motivation": "\u8bbe\u60f3\u667a\u80fd\u4f53\u7ec4\u7ec7\u7684\u65b0\u65f6\u4ee3\uff0c\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u534f\u4f5c\u548c\u5e76\u53d1\u5de5\u4f5c\u6765\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u5b9e\u73b0\u8d85\u8d8a\u4e2a\u4f53\u667a\u80fd\u7684\u6210\u679c\u3002", "method": "\u63d0\u51fa\u5f02\u6b65\u601d\u7ef4\u534f\u8bae\uff0c\u5176\u4e2d\u7ec4\u7ec7\u8005\u52a8\u6001\u5206\u914d\u5b50\u67e5\u8be2\u7ed9\u5de5\u4f5c\u8005\uff0c\u5408\u5e76\u4e2d\u95f4\u77e5\u8bc6\uff0c\u4ea7\u751f\u8fde\u8d2f\u89e3\u51b3\u65b9\u6848\u3002\u601d\u7ef4\u7ed3\u6784\u53ef\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5e76\u884c\u601d\u7ef4\u76f8\u6bd4\uff0cAsyncThink\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e28%\uff0c\u540c\u65f6\u5728\u6570\u5b66\u63a8\u7406\u4e0a\u63d0\u9ad8\u51c6\u786e\u6027\u3002AsyncThink\u80fd\u591f\u6cdb\u5316\u5b66\u5230\u7684\u5f02\u6b65\u601d\u7ef4\u80fd\u529b\uff0c\u6709\u6548\u5904\u7406\u672a\u89c1\u4efb\u52a1\u800c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "conclusion": "\u5f02\u6b65\u601d\u7ef4\u4e3a\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u63a8\u7406\u8303\u5f0f\uff0c\u5728\u964d\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.26721", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.26721", "abs": "https://arxiv.org/abs/2510.26721", "authors": ["Xinhan Zheng", "Huyu Wu", "Xueting Wang", "Haiyun Jiang"], "title": "Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis", "comment": null, "summary": "Multimodal large language models (MLLMs) exhibit a pronounced preference for\ntextual inputs when processing vision-language data, limiting their ability to\nreason effectively from visual evidence. Unlike prior studies that attribute\nthis text bias to external factors such as data imbalance or instruction\ntuning, we propose that the bias originates from the model's internal\narchitecture. Specifically, we hypothesize that visual key vectors (Visual\nKeys) are out-of-distribution (OOD) relative to the text key space learned\nduring language-only pretraining. Consequently, these visual keys receive\nsystematically lower similarity scores during attention computation, leading to\ntheir under-utilization in the context representation. To validate this\nhypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their\ndistributional structures using qualitative (t-SNE) and quantitative\n(Jensen-Shannon divergence) methods. The results provide direct evidence that\nvisual and textual keys occupy markedly distinct subspaces within the attention\nspace. The inter-modal divergence is statistically significant, exceeding\nintra-modal variation by several orders of magnitude. These findings reveal\nthat text bias arises from an intrinsic misalignment within the attention key\nspace rather than solely from external data factors.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6587\u672c\u504f\u597d\u95ee\u9898\uff0c\u5176\u6839\u6e90\u5728\u4e8e\u6a21\u578b\u5185\u90e8\u67b6\u6784\u2014\u2014\u89c6\u89c9\u952e\u5411\u91cf\u4e0e\u6587\u672c\u952e\u7a7a\u95f4\u5206\u5e03\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u89c6\u89c9\u4fe1\u606f\u5728\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d\u88ab\u4f4e\u4f30\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u89c6\u89c9\u8bed\u8a00\u6570\u636e\u65f6\u8868\u73b0\u51fa\u660e\u663e\u7684\u6587\u672c\u504f\u597d\uff0c\u9650\u5236\u4e86\u5176\u57fa\u4e8e\u89c6\u89c9\u8bc1\u636e\u7684\u63a8\u7406\u80fd\u529b\u3002\u73b0\u6709\u7814\u7a76\u5c06\u6b64\u5f52\u56e0\u4e8e\u6570\u636e\u4e0d\u5e73\u8861\u6216\u6307\u4ee4\u8c03\u4f18\u7b49\u5916\u90e8\u56e0\u7d20\uff0c\u800c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u6a21\u578b\u5185\u90e8\u67b6\u6784\u662f\u5426\u624d\u662f\u504f\u89c1\u7684\u771f\u6b63\u6765\u6e90\u3002", "method": "\u4eceLLaVA\u548cQwen2.5-VL\u6a21\u578b\u4e2d\u63d0\u53d6\u952e\u5411\u91cf\uff0c\u4f7f\u7528\u5b9a\u6027\uff08t-SNE\uff09\u548c\u5b9a\u91cf\uff08Jensen-Shannon\u6563\u5ea6\uff09\u65b9\u6cd5\u5206\u6790\u5176\u5206\u5e03\u7ed3\u6784\uff0c\u9a8c\u8bc1\u89c6\u89c9\u952e\u5411\u91cf\u662f\u5426\u4e0e\u6587\u672c\u952e\u7a7a\u95f4\u5b58\u5728\u5206\u5e03\u5916\u95ee\u9898\u3002", "result": "\u89c6\u89c9\u952e\u548c\u6587\u672c\u952e\u5728\u6ce8\u610f\u529b\u7a7a\u95f4\u4e2d\u5360\u636e\u660e\u663e\u4e0d\u540c\u7684\u5b50\u7a7a\u95f4\uff0c\u6a21\u6001\u95f4\u5dee\u5f02\u5728\u7edf\u8ba1\u4e0a\u663e\u8457\uff0c\u8d85\u8fc7\u6a21\u6001\u5185\u53d8\u5f02\u7684\u6570\u4e2a\u6570\u91cf\u7ea7\u3002\u8fd9\u76f4\u63a5\u8bc1\u660e\u4e86\u89c6\u89c9\u952e\u5411\u91cf\u76f8\u5bf9\u4e8e\u8bed\u8a00\u9884\u8bad\u7ec3\u671f\u95f4\u5b66\u4e60\u7684\u6587\u672c\u952e\u7a7a\u95f4\u786e\u5b9e\u5b58\u5728\u5206\u5e03\u5916\u95ee\u9898\u3002", "conclusion": "\u6587\u672c\u504f\u89c1\u6e90\u4e8e\u6ce8\u610f\u529b\u952e\u7a7a\u95f4\u5185\u90e8\u7684\u5185\u5728\u9519\u4f4d\uff0c\u800c\u975e\u4ec5\u6765\u81ea\u5916\u90e8\u6570\u636e\u56e0\u7d20\u3002\u89c6\u89c9\u952e\u5411\u91cf\u5728\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d\u83b7\u5f97\u7684\u76f8\u4f3c\u6027\u5f97\u5206\u7cfb\u7edf\u6027\u8f83\u4f4e\uff0c\u5bfc\u81f4\u5176\u5728\u4e0a\u4e0b\u6587\u8868\u793a\u4e2d\u5229\u7528\u4e0d\u8db3\u3002"}}
{"id": "2510.26732", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26732", "abs": "https://arxiv.org/abs/2510.26732", "authors": ["J. de Curt\u00f2", "I. de Zarz\u00e0", "Pablo Garc\u00eda", "Jordi Cabot"], "title": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "comment": null, "summary": "This paper presents a comprehensive cross-platform evaluation of reasoning\ncapabilities in contemporary foundation models, establishing an\ninfrastructure-agnostic benchmark across three computational paradigms: HPC\nsupercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and\nuniversity clusters (a node with eight H200 GPUs).\n  We evaluate 15 foundation models across 79 problems spanning eight academic\ndomains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,\nCalculus, and Optimization) through three experimental phases: (1) Baseline\nestablishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,\nMistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing\nmethodology and reference performance; (2) Infrastructure validation: The\n19-problem benchmark repeated on university cluster (seven models including\nFalcon-Mamba state-space architecture) and Nebius AI Studio (nine\nstate-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3\n30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic\nreproducibility; (3) Extended evaluation: Full 79-problem assessment on both\nuniversity cluster and Nebius platforms, probing generalization at scale across\narchitectural diversity.\n  The findings challenge conventional scaling assumptions, establish training\ndata quality as more critical than model size, and provide actionable\nguidelines for model selection across educational, production, and research\ncontexts. The tri-infrastructure methodology and 79-problem benchmark enable\nlongitudinal tracking of reasoning capabilities as foundation models evolve.", "AI": {"tldr": "\u672c\u6587\u5bf915\u4e2a\u57fa\u7840\u6a21\u578b\u57283\u79cd\u8ba1\u7b97\u5e73\u53f0\uff08HPC\u8d85\u7ea7\u8ba1\u7b97\u673a\u3001\u4e91\u5e73\u53f0\u3001\u5927\u5b66\u96c6\u7fa4\uff09\u4e0a\u8fdb\u884c\u4e86\u8de8\u5e73\u53f0\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\uff0c\u6db5\u76d679\u4e2a\u95ee\u9898\u30018\u4e2a\u5b66\u672f\u9886\u57df\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u89c4\u6a21\u7f29\u653e\u5047\u8bbe\uff0c\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u6bd4\u6a21\u578b\u89c4\u6a21\u66f4\u91cd\u8981\u3002", "motivation": "\u5efa\u7acb\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5168\u9762\u8bc4\u4f30\u5f53\u4ee3\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u8ba1\u7b97\u5e73\u53f0\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u6559\u80b2\u3001\u751f\u4ea7\u548c\u7814\u7a76\u73af\u5883\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u5b9e\u9a8c\u8bbe\u8ba1\uff1a(1) \u5728MareNostrum 5\u4e0a\u5efa\u7acb6\u4e2a\u6a21\u578b\u7684\u57fa\u7ebf\u6027\u80fd\uff1b(2) \u5728\u5927\u5b66\u96c6\u7fa4\u548cNebius AI Studio\u4e0a\u9a8c\u8bc1\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u7684\u53ef\u91cd\u590d\u6027\uff1b(3) \u5728\u4e24\u4e2a\u5e73\u53f0\u4e0a\u8fdb\u884c\u5b8c\u6574\u768479\u95ee\u9898\u8bc4\u4f30\uff0c\u63a2\u7d22\u67b6\u6784\u591a\u6837\u6027\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6311\u6218\u4e86\u4f20\u7edf\u7684\u89c4\u6a21\u7f29\u653e\u5047\u8bbe\uff0c\u786e\u5b9a\u4e86\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u6bd4\u6a21\u578b\u89c4\u6a21\u66f4\u5173\u952e\uff0c\u5e76\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6a21\u578b\u9009\u62e9\u6307\u5357\u3002", "conclusion": "\u5efa\u7acb\u7684\u4e09\u57fa\u7840\u8bbe\u65bd\u65b9\u6cd5\u548c79\u95ee\u9898\u57fa\u51c6\u80fd\u591f\u7eb5\u5411\u8ddf\u8e2a\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\uff0c\u4e3a\u6a21\u578b\u8bc4\u4f30\u548c\u9009\u62e9\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u6846\u67b6\u3002"}}
{"id": "2510.26784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26784", "abs": "https://arxiv.org/abs/2510.26784", "authors": ["Arnab Sen Sharma", "Giordano Rogers", "Natalie Shapira", "David Bau"], "title": "LLMs Process Lists With General Filter Heads", "comment": "Code and data at https://filter.baulab.info/", "summary": "We investigate the mechanisms underlying a range of list-processing tasks in\nLLMs, and we find that LLMs have learned to encode a compact, causal\nrepresentation of a general filtering operation that mirrors the generic\n\"filter\" function of functional programming. Using causal mediation analysis on\na diverse set of list-processing tasks, we find that a small number of\nattention heads, which we dub filter heads, encode a compact representation of\nthe filtering predicate in their query states at certain tokens. We demonstrate\nthat this predicate representation is general and portable: it can be extracted\nand reapplied to execute the same filtering operation on different collections,\npresented in different formats, languages, or even in tasks. However, we also\nidentify situations where transformer LMs can exploit a different strategy for\nfiltering: eagerly evaluating if an item satisfies the predicate and storing\nthis intermediate result as a flag directly in the item representations. Our\nresults reveal that transformer LMs can develop human-interpretable\nimplementations of abstract computational operations that generalize in ways\nthat are surprisingly similar to strategies used in traditional functional\nprogramming patterns.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u5b66\u4f1a\u4e86\u7f16\u7801\u7d27\u51d1\u7684\u901a\u7528\u8fc7\u6ee4\u64cd\u4f5c\u8868\u793a\uff0c\u7c7b\u4f3c\u4e8e\u51fd\u6570\u5f0f\u7f16\u7a0b\u4e2d\u7684filter\u51fd\u6570\u3002\u901a\u8fc7\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u53d1\u73b0\u5c11\u91cf\u6ce8\u610f\u529b\u5934\u5728\u7279\u5b9atoken\u5904\u7f16\u7801\u8fc7\u6ee4\u8c13\u8bcd\uff0c\u8fd9\u79cd\u8868\u793a\u5177\u6709\u901a\u7528\u6027\u548c\u53ef\u79fb\u690d\u6027\u3002", "motivation": "\u63a2\u7a76LLMs\u5728\u5217\u8868\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u5de5\u4f5c\u673a\u5236\uff0c\u7406\u89e3\u5b83\u4eec\u5982\u4f55\u5b9e\u73b0\u62bd\u8c61\u8ba1\u7b97\u64cd\u4f5c\uff0c\u7279\u522b\u662f\u8fc7\u6ee4\u64cd\u4f5c\u7684\u5185\u5728\u8868\u793a\u548c\u5b9e\u73b0\u7b56\u7565\u3002", "method": "\u4f7f\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u5728\u591a\u6837\u5316\u7684\u5217\u8868\u5904\u7406\u4efb\u52a1\u4e0a\uff0c\u8bc6\u522b\u7f16\u7801\u8fc7\u6ee4\u8c13\u8bcd\u7684\u6ce8\u610f\u529b\u5934\uff0c\u5e76\u6d4b\u8bd5\u8fd9\u4e9b\u8868\u793a\u7684\u901a\u7528\u6027\u548c\u53ef\u79fb\u690d\u6027\u3002", "result": "\u53d1\u73b0\u5c11\u91cf'\u8fc7\u6ee4\u5934'\u5728\u7279\u5b9atoken\u5904\u7f16\u7801\u7d27\u51d1\u7684\u8fc7\u6ee4\u8c13\u8bcd\u8868\u793a\uff0c\u8be5\u8868\u793a\u53ef\u8de8\u4e0d\u540c\u96c6\u5408\u3001\u683c\u5f0f\u3001\u8bed\u8a00\u548c\u4efb\u52a1\u91cd\u7528\u3002\u540c\u65f6\u8bc6\u522b\u4e86\u53e6\u4e00\u79cd\u8fc7\u6ee4\u7b56\u7565\uff1a\u6025\u5207\u8bc4\u4f30\u8c13\u8bcd\u5e76\u5c06\u7ed3\u679c\u6807\u8bb0\u5b58\u50a8\u5728\u9879\u76ee\u8868\u793a\u4e2d\u3002", "conclusion": "Transformer\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5f00\u53d1\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u62bd\u8c61\u8ba1\u7b97\u64cd\u4f5c\u5b9e\u73b0\uff0c\u5176\u6cdb\u5316\u65b9\u5f0f\u4e0e\u4f20\u7edf\u51fd\u6570\u5f0f\u7f16\u7a0b\u6a21\u5f0f\u60ca\u4eba\u76f8\u4f3c\u3002"}}
