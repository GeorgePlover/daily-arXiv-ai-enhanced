<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 2]
- [cs.DC](#cs.DC) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [On the Limits of Innate Planning in Large Language Models](https://arxiv.org/abs/2511.21591)
*Charles Schepanowski,Charles Ling*

Main category: cs.AI

TL;DR: LLMs在8拼图任务中表现出规划能力不足，即使有外部验证器提供有效移动，仍无法解决任何谜题，主要问题是内部状态表示脆弱和启发式规划能力弱。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在没有代码执行或其他工具的情况下，进行规划和状态推理的能力，使用8拼图作为测试平台。

Method: 测试四种模型在常见提示条件下（零样本、思维链、算法思维）和分层纠正反馈下的表现，并使用外部移动验证器提供仅有效移动。

Result: 反馈提高了某些模型-提示组合的成功率，但成功运行通常冗长、计算昂贵且间接。即使有外部移动验证器，所有模型都无法解决任何谜题。

Conclusion: 当前LLMs在规划方面存在显著限制，需要维护显式状态和执行结构化搜索的机制才能取得进一步进展。

Abstract: Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.

</details>


### [2] [Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling](https://arxiv.org/abs/2511.21636)
*Peter S. Hovmand,Kari O'Donnell,Callie Ogland-Hand,Brian Biroscak,Douglas D. Gunzler*

Main category: cs.AI

TL;DR: 本文提出了一个将系统动力学和结构方程建模结合到统一数学框架中的方法，用于支持负责任AI/ML的发展。


<details>
  <summary>Details</summary>
Motivation: AI/ML模型在解决复杂问题的同时会放大人类偏见，需要更丰富的因果模型来指导负责任AI/ML的开发。但由于不同方法基于不同假设，难以整合。

Method: 将系统动力学和结构方程建模整合到一个共同的数学框架中，用于从分布生成系统、开发方法并比较结果。

Result: 建立了一个统一的数学框架，能够支持系统动力学的认识论在数据科学和AI/ML应用中的运用。

Conclusion: 该框架有助于弥合不同方法之间的鸿沟，为负责任AI/ML的发展提供更坚实的理论基础。

Abstract: AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's "the unavoidable a priori"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [3] [Diagonal Scaling: A Multi-Dimensional Resource Model and Optimization Framework for Distributed Databases](https://arxiv.org/abs/2511.21612)
*Shahir Abdullah,Syed Rohit Zaman*

Main category: cs.DC

TL;DR: 提出了一种名为Scaling Plane的二维扩展模型，将水平扩展（节点数量）和垂直扩展（节点资源）结合考虑，通过DIAGONALSCALE算法实现对角扩展策略，显著提升云数据库性能和降低成本。


<details>
  <summary>Details</summary>
Motivation: 现代云数据库将扩展视为二元决策（水平扩展或垂直扩展），这种一维视图限制了性能优化，因为数据库性能、成本和协调开销是水平弹性和节点资源共同作用的结果。

Method: 引入Scaling Plane二维模型，每个分布式数据库配置表示为点(H,V)，其中H是节点数量，V是资源向量。提出DIAGONALSCALE离散局部搜索算法，评估水平、垂直和对角移动，选择满足SLA约束的最优配置。

Result: 对角扩展相比仅水平或垂直自动扩展，可将p95延迟降低高达40%，查询成本降低高达37%，重新平衡减少2-5倍。

Conclusion: 研究结果强调了多维扩展模型的必要性，为下一代云数据库系统自动扩展提供了基础。

Abstract: Modern cloud databases present scaling as a binary decision: scale-out by adding nodes or scale-up by increasing per-node resources. This one-dimensional view is limiting because database performance, cost, and coordination overhead emerge from the joint interaction of horizontal elasticity and per-node CPU, memory, network bandwidth, and storage IOPS. As a result, systems often overreact to load spikes, underreact to memory pressure, or oscillate between suboptimal states. We introduce the Scaling Plane, a two-dimensional model in which each distributed database configuration is represented as a point (H, V), with H denoting node count and V a vector of resources. Over this plane, we define smooth approximations of latency, throughput, coordination overhead, and monetary cost, providing a unified view of performance trade-offs. We show analytically and empirically that optimal scaling trajectories frequently lie along diagonal paths: sequences of joint horizontal and vertical adjustments that simultaneously exploit cluster parallelism and per-node improvements. To compute such actions, we propose DIAGONALSCALE, a discrete local-search algorithm that evaluates horizontal, vertical, and diagonal moves in the Scaling Plane and selects the configuration minimizing a multi-objective function subject to SLA constraints. Using synthetic surfaces, microbenchmarks, and experiments on distributed SQL and KV systems, we demonstrate that diagonal scaling reduces p95 latency by up to 40 percent, lowers cost-per-query by up to 37 percent, and reduces rebalancing by 2 to 5 times compared to horizontal-only and vertical-only autoscaling. Our results highlight the need for multi-dimensional scaling models and provide a foundation for next-generation autoscaling in cloud database systems.

</details>


### [4] [AI/ML Model Cards in Edge AI Cyberinfrastructure: towards Agentic AI](https://arxiv.org/abs/2511.21661)
*Beth Plale,Neelesh Karthikeyan,Isuru Gamage,Joe Stubbs,Sachith Withana*

Main category: cs.DC

TL;DR: 本文研究了在ICICLE AI研究所软件生态系统中嵌入的Patra模型卡作为动态对象，评估了采用模型上下文协议（MCP）作为Patra模型卡服务器接口的效益与权衡。


<details>
  <summary>Details</summary>
Motivation: 传统的AI/ML模型卡在模型训练期间进行一次性评估，无法反映模型在其生命周期中的实际使用情况。

Method: 通过Patra模型卡嵌入ICICLE AI研究所软件生态系统，研究模型卡作为动态对象，并评估采用MCP接口与REST接口的对比。

Result: 定量评估显示MCP相比REST接口存在开销，但核心问题是MCP启用的活动会话，这是一个关于动态模型卡适用性和使用的定性问题。

Conclusion: MCP作为模型卡服务器接口在动态模型卡环境中具有特定的适用性，需要在开销和功能之间进行权衡。

Abstract: AI/ML model cards can contain a benchmarked evaluation of an AI/ML model against intended use but a one time assessment during model training does not get at how and where a model is actually used over its lifetime. Through Patra Model Cards embedded in the ICICLE AI Institute software ecosystem we study model cards as dynamic objects. The study reported here assesses the benefits and tradeoffs of adopting the Model Context Protocol (MCP) as an interface to the Patra Model Card server. Quantitative assessment shows the overhead of MCP as compared to a REST interface. The core question however is of active sessions enabled by MCP; this is a qualitative question of fit and use in the context of dynamic model cards that we address as well.

</details>
