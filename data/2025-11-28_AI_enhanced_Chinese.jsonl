{"id": "2511.21612", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.21612", "abs": "https://arxiv.org/abs/2511.21612", "authors": ["Shahir Abdullah", "Syed Rohit Zaman"], "title": "Diagonal Scaling: A Multi-Dimensional Resource Model and Optimization Framework for Distributed Databases", "comment": null, "summary": "Modern cloud databases present scaling as a binary decision: scale-out by adding nodes or scale-up by increasing per-node resources. This one-dimensional view is limiting because database performance, cost, and coordination overhead emerge from the joint interaction of horizontal elasticity and per-node CPU, memory, network bandwidth, and storage IOPS. As a result, systems often overreact to load spikes, underreact to memory pressure, or oscillate between suboptimal states. We introduce the Scaling Plane, a two-dimensional model in which each distributed database configuration is represented as a point (H, V), with H denoting node count and V a vector of resources. Over this plane, we define smooth approximations of latency, throughput, coordination overhead, and monetary cost, providing a unified view of performance trade-offs. We show analytically and empirically that optimal scaling trajectories frequently lie along diagonal paths: sequences of joint horizontal and vertical adjustments that simultaneously exploit cluster parallelism and per-node improvements. To compute such actions, we propose DIAGONALSCALE, a discrete local-search algorithm that evaluates horizontal, vertical, and diagonal moves in the Scaling Plane and selects the configuration minimizing a multi-objective function subject to SLA constraints. Using synthetic surfaces, microbenchmarks, and experiments on distributed SQL and KV systems, we demonstrate that diagonal scaling reduces p95 latency by up to 40 percent, lowers cost-per-query by up to 37 percent, and reduces rebalancing by 2 to 5 times compared to horizontal-only and vertical-only autoscaling. Our results highlight the need for multi-dimensional scaling models and provide a foundation for next-generation autoscaling in cloud database systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aScaling Plane\u7684\u4e8c\u7ef4\u6269\u5c55\u6a21\u578b\uff0c\u5c06\u6c34\u5e73\u6269\u5c55\uff08\u8282\u70b9\u6570\u91cf\uff09\u548c\u5782\u76f4\u6269\u5c55\uff08\u8282\u70b9\u8d44\u6e90\uff09\u7ed3\u5408\u8003\u8651\uff0c\u901a\u8fc7DIAGONALSCALE\u7b97\u6cd5\u5b9e\u73b0\u5bf9\u89d2\u6269\u5c55\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e91\u6570\u636e\u5e93\u6027\u80fd\u548c\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u73b0\u4ee3\u4e91\u6570\u636e\u5e93\u5c06\u6269\u5c55\u89c6\u4e3a\u4e8c\u5143\u51b3\u7b56\uff08\u6c34\u5e73\u6269\u5c55\u6216\u5782\u76f4\u6269\u5c55\uff09\uff0c\u8fd9\u79cd\u4e00\u7ef4\u89c6\u56fe\u9650\u5236\u4e86\u6027\u80fd\u4f18\u5316\uff0c\u56e0\u4e3a\u6570\u636e\u5e93\u6027\u80fd\u3001\u6210\u672c\u548c\u534f\u8c03\u5f00\u9500\u662f\u6c34\u5e73\u5f39\u6027\u548c\u8282\u70b9\u8d44\u6e90\u5171\u540c\u4f5c\u7528\u7684\u7ed3\u679c\u3002", "method": "\u5f15\u5165Scaling Plane\u4e8c\u7ef4\u6a21\u578b\uff0c\u6bcf\u4e2a\u5206\u5e03\u5f0f\u6570\u636e\u5e93\u914d\u7f6e\u8868\u793a\u4e3a\u70b9(H,V)\uff0c\u5176\u4e2dH\u662f\u8282\u70b9\u6570\u91cf\uff0cV\u662f\u8d44\u6e90\u5411\u91cf\u3002\u63d0\u51faDIAGONALSCALE\u79bb\u6563\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\uff0c\u8bc4\u4f30\u6c34\u5e73\u3001\u5782\u76f4\u548c\u5bf9\u89d2\u79fb\u52a8\uff0c\u9009\u62e9\u6ee1\u8db3SLA\u7ea6\u675f\u7684\u6700\u4f18\u914d\u7f6e\u3002", "result": "\u5bf9\u89d2\u6269\u5c55\u76f8\u6bd4\u4ec5\u6c34\u5e73\u6216\u5782\u76f4\u81ea\u52a8\u6269\u5c55\uff0c\u53ef\u5c06p95\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe40%\uff0c\u67e5\u8be2\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe37%\uff0c\u91cd\u65b0\u5e73\u8861\u51cf\u5c112-5\u500d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u591a\u7ef4\u6269\u5c55\u6a21\u578b\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4e91\u6570\u636e\u5e93\u7cfb\u7edf\u81ea\u52a8\u6269\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.21661", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.21661", "abs": "https://arxiv.org/abs/2511.21661", "authors": ["Beth Plale", "Neelesh Karthikeyan", "Isuru Gamage", "Joe Stubbs", "Sachith Withana"], "title": "AI/ML Model Cards in Edge AI Cyberinfrastructure: towards Agentic AI", "comment": null, "summary": "AI/ML model cards can contain a benchmarked evaluation of an AI/ML model against intended use but a one time assessment during model training does not get at how and where a model is actually used over its lifetime. Through Patra Model Cards embedded in the ICICLE AI Institute software ecosystem we study model cards as dynamic objects. The study reported here assesses the benefits and tradeoffs of adopting the Model Context Protocol (MCP) as an interface to the Patra Model Card server. Quantitative assessment shows the overhead of MCP as compared to a REST interface. The core question however is of active sessions enabled by MCP; this is a qualitative question of fit and use in the context of dynamic model cards that we address as well.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728ICICLE AI\u7814\u7a76\u6240\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u4e2d\u5d4c\u5165\u7684Patra\u6a21\u578b\u5361\u4f5c\u4e3a\u52a8\u6001\u5bf9\u8c61\uff0c\u8bc4\u4f30\u4e86\u91c7\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u4f5c\u4e3aPatra\u6a21\u578b\u5361\u670d\u52a1\u5668\u63a5\u53e3\u7684\u6548\u76ca\u4e0e\u6743\u8861\u3002", "motivation": "\u4f20\u7edf\u7684AI/ML\u6a21\u578b\u5361\u5728\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u8fdb\u884c\u4e00\u6b21\u6027\u8bc4\u4f30\uff0c\u65e0\u6cd5\u53cd\u6620\u6a21\u578b\u5728\u5176\u751f\u547d\u5468\u671f\u4e2d\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u3002", "method": "\u901a\u8fc7Patra\u6a21\u578b\u5361\u5d4c\u5165ICICLE AI\u7814\u7a76\u6240\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\uff0c\u7814\u7a76\u6a21\u578b\u5361\u4f5c\u4e3a\u52a8\u6001\u5bf9\u8c61\uff0c\u5e76\u8bc4\u4f30\u91c7\u7528MCP\u63a5\u53e3\u4e0eREST\u63a5\u53e3\u7684\u5bf9\u6bd4\u3002", "result": "\u5b9a\u91cf\u8bc4\u4f30\u663e\u793aMCP\u76f8\u6bd4REST\u63a5\u53e3\u5b58\u5728\u5f00\u9500\uff0c\u4f46\u6838\u5fc3\u95ee\u9898\u662fMCP\u542f\u7528\u7684\u6d3b\u52a8\u4f1a\u8bdd\uff0c\u8fd9\u662f\u4e00\u4e2a\u5173\u4e8e\u52a8\u6001\u6a21\u578b\u5361\u9002\u7528\u6027\u548c\u4f7f\u7528\u7684\u5b9a\u6027\u95ee\u9898\u3002", "conclusion": "MCP\u4f5c\u4e3a\u6a21\u578b\u5361\u670d\u52a1\u5668\u63a5\u53e3\u5728\u52a8\u6001\u6a21\u578b\u5361\u73af\u5883\u4e2d\u5177\u6709\u7279\u5b9a\u7684\u9002\u7528\u6027\uff0c\u9700\u8981\u5728\u5f00\u9500\u548c\u529f\u80fd\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002"}}
{"id": "2511.21591", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21591", "abs": "https://arxiv.org/abs/2511.21591", "authors": ["Charles Schepanowski", "Charles Ling"], "title": "On the Limits of Innate Planning in Large Language Models", "comment": "33 pages, 7 figures", "summary": "Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.", "AI": {"tldr": "LLMs\u57288\u62fc\u56fe\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u89c4\u5212\u80fd\u529b\u4e0d\u8db3\uff0c\u5373\u4f7f\u6709\u5916\u90e8\u9a8c\u8bc1\u5668\u63d0\u4f9b\u6709\u6548\u79fb\u52a8\uff0c\u4ecd\u65e0\u6cd5\u89e3\u51b3\u4efb\u4f55\u8c1c\u9898\uff0c\u4e3b\u8981\u95ee\u9898\u662f\u5185\u90e8\u72b6\u6001\u8868\u793a\u8106\u5f31\u548c\u542f\u53d1\u5f0f\u89c4\u5212\u80fd\u529b\u5f31\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u6ca1\u6709\u4ee3\u7801\u6267\u884c\u6216\u5176\u4ed6\u5de5\u5177\u7684\u60c5\u51b5\u4e0b\uff0c\u8fdb\u884c\u89c4\u5212\u548c\u72b6\u6001\u63a8\u7406\u7684\u80fd\u529b\uff0c\u4f7f\u75288\u62fc\u56fe\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u6d4b\u8bd5\u56db\u79cd\u6a21\u578b\u5728\u5e38\u89c1\u63d0\u793a\u6761\u4ef6\u4e0b\uff08\u96f6\u6837\u672c\u3001\u601d\u7ef4\u94fe\u3001\u7b97\u6cd5\u601d\u7ef4\uff09\u548c\u5206\u5c42\u7ea0\u6b63\u53cd\u9988\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u4f7f\u7528\u5916\u90e8\u79fb\u52a8\u9a8c\u8bc1\u5668\u63d0\u4f9b\u4ec5\u6709\u6548\u79fb\u52a8\u3002", "result": "\u53cd\u9988\u63d0\u9ad8\u4e86\u67d0\u4e9b\u6a21\u578b-\u63d0\u793a\u7ec4\u5408\u7684\u6210\u529f\u7387\uff0c\u4f46\u6210\u529f\u8fd0\u884c\u901a\u5e38\u5197\u957f\u3001\u8ba1\u7b97\u6602\u8d35\u4e14\u95f4\u63a5\u3002\u5373\u4f7f\u6709\u5916\u90e8\u79fb\u52a8\u9a8c\u8bc1\u5668\uff0c\u6240\u6709\u6a21\u578b\u90fd\u65e0\u6cd5\u89e3\u51b3\u4efb\u4f55\u8c1c\u9898\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u89c4\u5212\u65b9\u9762\u5b58\u5728\u663e\u8457\u9650\u5236\uff0c\u9700\u8981\u7ef4\u62a4\u663e\u5f0f\u72b6\u6001\u548c\u6267\u884c\u7ed3\u6784\u5316\u641c\u7d22\u7684\u673a\u5236\u624d\u80fd\u53d6\u5f97\u8fdb\u4e00\u6b65\u8fdb\u5c55\u3002"}}
{"id": "2511.21636", "categories": ["cs.AI", "stat.AP", "stat.CO", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21636", "abs": "https://arxiv.org/abs/2511.21636", "authors": ["Peter S. Hovmand", "Kari O'Donnell", "Callie Ogland-Hand", "Brian Biroscak", "Douglas D. Gunzler"], "title": "Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling", "comment": "Presented at 43rd Conference of the International System Dynamics Society in Boston, United States", "summary": "AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's \"the unavoidable a priori\"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u7ed3\u6784\u65b9\u7a0b\u5efa\u6a21\u7ed3\u5408\u5230\u7edf\u4e00\u6570\u5b66\u6846\u67b6\u4e2d\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u652f\u6301\u8d1f\u8d23\u4efbAI/ML\u7684\u53d1\u5c55\u3002", "motivation": "AI/ML\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u7684\u540c\u65f6\u4f1a\u653e\u5927\u4eba\u7c7b\u504f\u89c1\uff0c\u9700\u8981\u66f4\u4e30\u5bcc\u7684\u56e0\u679c\u6a21\u578b\u6765\u6307\u5bfc\u8d1f\u8d23\u4efbAI/ML\u7684\u5f00\u53d1\u3002\u4f46\u7531\u4e8e\u4e0d\u540c\u65b9\u6cd5\u57fa\u4e8e\u4e0d\u540c\u5047\u8bbe\uff0c\u96be\u4ee5\u6574\u5408\u3002", "method": "\u5c06\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u7ed3\u6784\u65b9\u7a0b\u5efa\u6a21\u6574\u5408\u5230\u4e00\u4e2a\u5171\u540c\u7684\u6570\u5b66\u6846\u67b6\u4e2d\uff0c\u7528\u4e8e\u4ece\u5206\u5e03\u751f\u6210\u7cfb\u7edf\u3001\u5f00\u53d1\u65b9\u6cd5\u5e76\u6bd4\u8f83\u7ed3\u679c\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u80fd\u591f\u652f\u6301\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u8ba4\u8bc6\u8bba\u5728\u6570\u636e\u79d1\u5b66\u548cAI/ML\u5e94\u7528\u4e2d\u7684\u8fd0\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u5f25\u5408\u4e0d\u540c\u65b9\u6cd5\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u8d1f\u8d23\u4efbAI/ML\u7684\u53d1\u5c55\u63d0\u4f9b\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
