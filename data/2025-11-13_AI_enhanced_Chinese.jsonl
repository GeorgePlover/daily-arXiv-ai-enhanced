{"id": "2511.08713", "categories": ["cs.DC", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.08713", "abs": "https://arxiv.org/abs/2511.08713", "authors": ["Gabriel Rodriguez-Canal", "David Katz", "Nick Brown"], "title": "An MLIR pipeline for offloading Fortran to FPGAs via OpenMP", "comment": "Author accepted version of paper published in SC25 LLVM workshop", "summary": "With the slowing of Moore's Law, heterogeneous computing platforms such as Field Programmable Gate Arrays (FPGAs) have gained increasing interest for accelerating HPC workloads. In this work we present, to the best of our knowledge, the first implementation of selective code offloading to FPGAs via the OpenMP target directive within MLIR. Our approach combines the MLIR OpenMP dialect with a High-Level Synthesis (HLS) dialect to provide a portable compilation flow targeting FPGAs. Unlike prior OpenMP FPGA efforts that rely on custom compilers, by contrast we integrate with MLIR and so support any MLIR-compatible front end, demonstrated here with Flang. Building upon a range of existing MLIR building blocks significantly reduces the effort required and demonstrates the composability benefits of the MLIR ecosystem. Our approach supports manual optimisation of offloaded kernels through standard OpenMP directives, and this work establishes a flexible and extensible path for directive-based FPGA acceleration integrated within the MLIR ecosystem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u901a\u8fc7MLIR\u4e2d\u7684OpenMP\u76ee\u6807\u6307\u4ee4\u5b9e\u73b0\u9009\u62e9\u6027\u4ee3\u7801\u5378\u8f7d\u5230FPGA\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408OpenMP\u65b9\u8a00\u548c\u9ad8\u7ea7\u7efc\u5408\u65b9\u8a00\uff0c\u63d0\u4f9b\u9762\u5411FPGA\u7684\u53ef\u79fb\u690d\u7f16\u8bd1\u6d41\u7a0b\u3002", "motivation": "\u968f\u7740\u6469\u5c14\u5b9a\u5f8b\u653e\u7f13\uff0cFPGA\u7b49\u5f02\u6784\u8ba1\u7b97\u5e73\u53f0\u5728\u52a0\u901fHPC\u5de5\u4f5c\u8d1f\u8f7d\u65b9\u9762\u8d8a\u6765\u8d8a\u53d7\u5173\u6ce8\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684FPGA\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u5c06MLIR OpenMP\u65b9\u8a00\u4e0e\u9ad8\u7ea7\u7efc\u5408\u65b9\u8a00\u7ed3\u5408\uff0c\u5229\u7528\u73b0\u6709MLIR\u6784\u5efa\u6a21\u5757\uff0c\u652f\u6301\u4efb\u4f55MLIR\u517c\u5bb9\u7684\u524d\u7aef\uff08\u5982Flang\uff09\uff0c\u901a\u8fc7\u6807\u51c6OpenMP\u6307\u4ee4\u624b\u52a8\u4f18\u5316\u5378\u8f7d\u5185\u6838\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6307\u4ee4\u7684FPGA\u52a0\u901f\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5f00\u53d1\u5de5\u4f5c\u91cf\uff0c\u5c55\u793a\u4e86MLIR\u751f\u6001\u7cfb\u7edf\u7684\u53ef\u7ec4\u5408\u6027\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8e\u6307\u4ee4\u7684FPGA\u52a0\u901f\u5efa\u7acb\u4e86\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u5e76\u96c6\u6210\u5728MLIR\u751f\u6001\u7cfb\u7edf\u4e2d\u3002"}}
{"id": "2511.08936", "categories": ["cs.DC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.08936", "abs": "https://arxiv.org/abs/2511.08936", "authors": ["Liuzixuan Lin", "Andrew A. Chien"], "title": "Distribution and Management of Datacenter Load Decoupling", "comment": null, "summary": "The exploding power consumption of AI and cloud datacenters (DCs) intensifies the long-standing concerns about their carbon footprint, especially because DCs' need for constant power clashes with volatile renewable generation needed for grid decarbonization. DC flexibility (a.k.a. load adaptation) is a key to reducing DC carbon emissions by improving grid renewable absorption.\n  DC flexibility can be created, without disturbing datacenter capacity by decoupling a datacenter's power capacity and grid load with a collection of energy resources. Because decoupling can be costly, we study how to best distribute and manage decoupling to maximize benefits for all. Key considerations include site variation and datacenter-grid cooperation.\n  We first define and compute the power and energy needs of datacenter load decoupling, and then we evaluate designed distribution and management approaches. Evaluation shows that optimized distribution can deliver >98% of the potential grid carbon reduction with 70% of the total decoupling need. For management, DC-grid cooperation (2-way sharing and control vs. 1-way info sharing) enables 1.4x grid carbon reduction. Finally, we show that decoupling may be economically viable, as on average datacenters can get power cost and carbon emissions benefits greater than their local costs of decoupling. However, skew across sites suggests grid intervention may be required.", "AI": {"tldr": "\u6570\u636e\u4e2d\u5fc3\u901a\u8fc7\u80fd\u6e90\u8d44\u6e90\u89e3\u8026\u7535\u529b\u5bb9\u91cf\u548c\u7535\u7f51\u8d1f\u8f7d\uff0c\u521b\u9020\u7075\u6d3b\u6027\u4ee5\u964d\u4f4e\u78b3\u6392\u653e\uff0c\u4f18\u5316\u5206\u5e03\u548c\u7ba1\u7406\u53ef\u5b9e\u73b0\u663e\u8457\u78b3\u51cf\u6392\u548c\u7ecf\u6d4e\u53ef\u884c\u6027\u3002", "motivation": "AI\u548c\u4e91\u6570\u636e\u4e2d\u5fc3\u7684\u9ad8\u80fd\u8017\u52a0\u5267\u4e86\u78b3\u8db3\u8ff9\u95ee\u9898\uff0c\u5176\u6052\u5b9a\u7535\u529b\u9700\u6c42\u4e0e\u6ce2\u52a8\u6027\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u5b58\u5728\u51b2\u7a81\uff0c\u9700\u8981\u901a\u8fc7\u8d1f\u8f7d\u9002\u5e94\u6027\u6765\u6539\u5584\u7535\u7f51\u53ef\u518d\u751f\u80fd\u6e90\u5438\u6536\u3002", "method": "\u5b9a\u4e49\u548c\u8ba1\u7b97\u6570\u636e\u4e2d\u5fc3\u8d1f\u8f7d\u89e3\u8026\u7684\u529f\u7387\u548c\u80fd\u91cf\u9700\u6c42\uff0c\u8bc4\u4f30\u89e3\u8026\u8d44\u6e90\u7684\u5206\u5e03\u548c\u7ba1\u7406\u65b9\u6cd5\uff0c\u5305\u62ec\u7ad9\u70b9\u5dee\u5f02\u548c\u7535\u7f51\u5408\u4f5c\u3002", "result": "\u4f18\u5316\u5206\u5e03\u53ef\u5b9e\u73b098%\u6f5c\u5728\u78b3\u51cf\u6392\uff0c\u4ec5\u970070%\u89e3\u8026\u8d44\u6e90\uff1b\u7535\u7f51\u5408\u4f5c\u7ba1\u7406\u6bd4\u5355\u5411\u4fe1\u606f\u5171\u4eab\u591a\u5b9e\u73b01.4\u500d\u78b3\u51cf\u6392\uff1b\u7ecf\u6d4e\u4e0a\u6536\u76ca\u5927\u4e8e\u672c\u5730\u6210\u672c\u3002", "conclusion": "\u6570\u636e\u4e2d\u5fc3\u8d1f\u8f7d\u89e3\u8026\u662f\u964d\u4f4e\u78b3\u6392\u653e\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u7ad9\u70b9\u95f4\u5dee\u5f02\u53ef\u80fd\u9700\u8981\u7535\u7f51\u5e72\u9884\u4ee5\u786e\u4fdd\u516c\u5e73\u6027\u3002"}}
{"id": "2511.08948", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.08948", "abs": "https://arxiv.org/abs/2511.08948", "authors": ["Jay Tharwani", "Shobhit Aggarwal", "Arnab A Purkayastha"], "title": "Evaluating HPC-Style CPU Performance and Cost in Virtualized Cloud Infrastructures", "comment": "7 pages", "summary": "This paper evaluates HPC-style CPU performance and cost in virtualized cloud infrastructures using a subset of OpenMP workloads in the SPEC ACCEL suite. Four major cloud providers by market share AWS, Azure, Google Cloud Platform (GCP), and Oracle Cloud Infrastructure (OCI) are compared across Intel, AMD, and ARM general purpose instance types under both on-demand and one-year discounted pricing. AWS consistently delivers the shortest runtime in all three instance types, yet charges a premium, especially for on-demand usage. OCI emerges as the most economical option across all CPU families, although it generally runs workloads more slowly than AWS. Azure often exhibits mid-range performance and cost, while GCP presents a mixed profile: it sees a notable boost when moving from Intel to AMD. On the other hand, its ARM instance is more than twice as slow as its own AMD offering and remains significantly more expensive. AWS's internal comparisons reveal that its ARM instance can outperform its Intel and AMD siblings by up to 49 percent in runtime. These findings highlight how instance choices and provider selection can yield substantial variations in both runtime and price, indicating that workload priorities, whether raw speed or cost minimization, should guide decisions on instance types.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u865a\u62df\u5316\u4e91\u57fa\u7840\u8bbe\u65bd\u4e2dHPC\u98ce\u683c\u7684CPU\u6027\u80fd\u548c\u6210\u672c\uff0c\u4f7f\u7528SPEC ACCEL\u5957\u4ef6\u4e2d\u7684OpenMP\u5de5\u4f5c\u8d1f\u8f7d\u5b50\u96c6\u6bd4\u8f83\u4e86AWS\u3001Azure\u3001GCP\u548cOCI\u56db\u5927\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u5728Intel\u3001AMD\u548cARM\u901a\u7528\u5b9e\u4f8b\u7c7b\u578b\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u5728\u4e0d\u540cCPU\u67b6\u6784\uff08Intel\u3001AMD\u3001ARM\uff09\u4e0a\u7684\u6027\u80fd\u548c\u6210\u672c\u5dee\u5f02\uff0c\u4e3aHPC\u5de5\u4f5c\u8d1f\u8f7d\u9009\u62e9\u5408\u9002\u7684\u4e91\u5b9e\u4f8b\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u4f7f\u7528SPEC ACCEL\u5957\u4ef6\u4e2d\u7684OpenMP\u5de5\u4f5c\u8d1f\u8f7d\u5b50\u96c6\uff0c\u5728AWS\u3001Azure\u3001GCP\u548cOCI\u56db\u5927\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u7684Intel\u3001AMD\u548cARM\u901a\u7528\u5b9e\u4f8b\u7c7b\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u6309\u9700\u5b9a\u4ef7\u548c\u4e00\u5e74\u6298\u6263\u5b9a\u4ef7\u4e24\u79cd\u6a21\u5f0f\u3002", "result": "AWS\u5728\u6240\u6709\u4e09\u79cd\u5b9e\u4f8b\u7c7b\u578b\u4e2d\u59cb\u7ec8\u63d0\u4f9b\u6700\u77ed\u8fd0\u884c\u65f6\u95f4\uff0c\u4f46\u6536\u8d39\u8f83\u9ad8\uff1bOCI\u5728\u6240\u6709CPU\u7cfb\u5217\u4e2d\u6700\u4e3a\u7ecf\u6d4e\uff0c\u4f46\u8fd0\u884c\u901f\u5ea6\u8f83\u6162\uff1bAzure\u6027\u80fd\u548c\u6210\u672c\u5904\u4e8e\u4e2d\u7b49\u6c34\u5e73\uff1bGCP\u4eceIntel\u5207\u6362\u5230AMD\u65f6\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5176ARM\u5b9e\u4f8b\u6bd4\u81ea\u8eabAMD\u5b9e\u4f8b\u6162\u4e24\u500d\u4ee5\u4e0a\u4e14\u66f4\u6602\u8d35\uff1bAWS\u7684ARM\u5b9e\u4f8b\u5728\u8fd0\u884c\u65f6\u95f4\u4e0a\u6bd4\u5176Intel\u548cAMD\u5b9e\u4f8b\u5feb\u8fbe49%\u3002", "conclusion": "\u5b9e\u4f8b\u9009\u62e9\u548c\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u9009\u62e9\u4f1a\u5728\u8fd0\u884c\u65f6\u95f4\u548c\u4ef7\u683c\u4e0a\u4ea7\u751f\u663e\u8457\u5dee\u5f02\uff0c\u5e94\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5148\u7ea7\uff08\u539f\u59cb\u901f\u5ea6\u6216\u6210\u672c\u6700\u5c0f\u5316\uff09\u6765\u6307\u5bfc\u5b9e\u4f8b\u7c7b\u578b\u51b3\u7b56\u3002"}}
{"id": "2511.08998", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.08998", "abs": "https://arxiv.org/abs/2511.08998", "authors": ["Zilinghan Li", "Aditya Sinha", "Yijiang Li", "Kyle Chard", "Kibaek Kim", "Ravi Madduri"], "title": "Experiences Building Enterprise-Level Privacy-Preserving Federated Learning to Power AI for Science", "comment": null, "summary": "Federated learning (FL) is a promising approach to enabling collaborative model training without centralized data sharing, a crucial requirement in scientific domains where data privacy, ownership, and compliance constraints are critical. However, building user-friendly enterprise-level FL frameworks that are both scalable and privacy-preserving remains challenging, especially when bridging the gap between local prototyping and distributed deployment across heterogeneous client computing infrastructures. In this paper, based on our experiences building the Advanced Privacy-Preserving Federated Learning (APPFL) framework, we present our vision for an enterprise-grade, privacy-preserving FL framework designed to scale seamlessly across computing environments. We identify several key capabilities that such a framework must provide: (1) Scalable local simulation and prototyping to accelerate experimentation and algorithm design; (2) seamless transition from simulation to deployment; (3) distributed deployment across diverse, real-world infrastructures, from personal devices to cloud clusters and HPC systems; (4) multi-level abstractions that balance ease of use and research flexibility; and (5) comprehensive privacy and security through techniques such as differential privacy, secure aggregation, robust authentication, and confidential computing. We further discuss architectural designs to realize these goals. This framework aims to bridge the gap between research prototypes and enterprise-scale deployment, enabling scalable, reliable, and privacy-preserving AI for science.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4f01\u4e1a\u7ea7\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u6846\u67b6APPFL\uff0c\u65e8\u5728\u89e3\u51b3\u4ece\u672c\u5730\u539f\u578b\u5230\u5206\u5e03\u5f0f\u90e8\u7f72\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u672c\u5730\u6a21\u62df\u3001\u65e0\u7f1d\u90e8\u7f72\u8fc7\u6e21\u3001\u591a\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u3001\u591a\u7ea7\u62bd\u8c61\u548c\u5168\u9762\u9690\u79c1\u4fdd\u62a4\u7b49\u5173\u952e\u80fd\u529b\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u79d1\u5b66\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u6784\u5efa\u65e2\u7528\u6237\u53cb\u597d\u53c8\u5177\u5907\u9690\u79c1\u4fdd\u62a4\u7684\u4f01\u4e1a\u7ea7\u6846\u67b6\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8de8\u8d8a\u5f02\u6784\u5ba2\u6237\u7aef\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u672c\u5730\u539f\u578b\u4e0e\u5206\u5e03\u5f0f\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u57fa\u4e8e\u6784\u5efaAPPFL\u6846\u67b6\u7684\u7ecf\u9a8c\uff0c\u63d0\u51fa\u4f01\u4e1a\u7ea7\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u7684\u613f\u666f\uff0c\u5305\u62ec\u53ef\u6269\u5c55\u672c\u5730\u6a21\u62df\u3001\u65e0\u7f1d\u90e8\u7f72\u8fc7\u6e21\u3001\u5206\u5e03\u5f0f\u90e8\u7f72\u3001\u591a\u7ea7\u62bd\u8c61\u548c\u9690\u79c1\u5b89\u5168\u6280\u672f\uff08\u5dee\u5206\u9690\u79c1\u3001\u5b89\u5168\u805a\u5408\u3001\u8ba4\u8bc1\u548c\u673a\u5bc6\u8ba1\u7b97\uff09\u7b49\u5173\u952e\u80fd\u529b\u3002", "result": "\u63d0\u51fa\u4e86\u5b9e\u73b0\u4f01\u4e1a\u7ea7\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u7684\u67b6\u6784\u8bbe\u8ba1\uff0c\u80fd\u591f\u6865\u63a5\u7814\u7a76\u539f\u578b\u4e0e\u4f01\u4e1a\u7ea7\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u6846\u67b6\u65e8\u5728\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u9760\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u79d1\u5b66AI\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u4ece\u7814\u7a76\u5230\u4f01\u4e1a\u7ea7\u5e94\u7528\u63d0\u4f9b\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08715", "abs": "https://arxiv.org/abs/2511.08715", "authors": ["Connar Hite", "Sean Saud", "Raef Taha", "Nayim Rahman", "Tanvir Atahary", "Scott Douglass", "Tarek Taha"], "title": "Bridging Natural Language and ASP: A Hybrid Approach Using LLMs and AMR Parsing", "comment": null, "summary": "Answer Set Programming (ASP) is a declarative programming paradigm based on logic programming and non-monotonic reasoning. It is a tremendously powerful tool for describing and solving combinatorial problems. Like any other language, ASP requires users to learn how it works and the syntax involved. It is becoming increasingly required for those unfamiliar with programming languages to interact with code. This paper proposes a novel method of translating unconstrained English into ASP programs for logic puzzles using an LLM and Abstract Meaning Representation (AMR) graphs. Everything from ASP rules, facts, and constraints is generated to fully represent and solve the desired problem. Example logic puzzles are used to demonstrate the capabilities of the system. While most current methods rely entirely on an LLM, our system minimizes the role of the LLM only to complete straightforward tasks. The LLM is used to simplify natural language sentences, identify keywords, and generate simple facts. The AMR graphs are then parsed from simplified language and used to generate ASP constraints systematically. The system successfully creates an entire ASP program that solves a combinatorial logic problem. This approach is a significant first step in creating a lighter-weight, explainable system that converts natural language to solve complex logic problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528LLM\u548cAMR\u56fe\u5c06\u65e0\u7ea6\u675f\u82f1\u8bed\u7ffb\u8bd1\u6210ASP\u7a0b\u5e8f\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u903b\u8f91\u8c1c\u9898\uff0c\u751f\u6210\u5b8c\u6574\u7684ASP\u7a0b\u5e8f\u6765\u4ee3\u8868\u548c\u89e3\u51b3\u95ee\u9898\u3002", "motivation": "ASP\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u7ec4\u5408\u95ee\u9898\u89e3\u51b3\u5de5\u5177\uff0c\u4f46\u9700\u8981\u5b66\u4e60\u8bed\u6cd5\u3002\u968f\u7740\u975e\u7f16\u7a0b\u4eba\u5458\u4e0e\u4ee3\u7801\u4ea4\u4e92\u7684\u9700\u6c42\u589e\u52a0\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9\u7528\u6237\u80fd\u591f\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u95ee\u9898\u5e76\u81ea\u52a8\u751f\u6210ASP\u7a0b\u5e8f\u3002", "method": "\u4f7f\u7528LLM\u7b80\u5316\u81ea\u7136\u8bed\u8a00\u53e5\u5b50\u3001\u8bc6\u522b\u5173\u952e\u8bcd\u548c\u751f\u6210\u7b80\u5355\u4e8b\u5b9e\uff0c\u7136\u540e\u4ece\u7b80\u5316\u8bed\u8a00\u89e3\u6790AMR\u56fe\uff0c\u7cfb\u7edf\u6027\u5730\u751f\u6210ASP\u7ea6\u675f\uff0c\u6700\u5c0f\u5316LLM\u7684\u4f5c\u7528\u3002", "result": "\u7cfb\u7edf\u6210\u529f\u521b\u5efa\u4e86\u5b8c\u6574\u7684ASP\u7a0b\u5e8f\u6765\u89e3\u51b3\u7ec4\u5408\u903b\u8f91\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728\u793a\u4f8b\u903b\u8f91\u8c1c\u9898\u4e0a\u7684\u80fd\u529b\u3002", "conclusion": "\u8fd9\u662f\u521b\u5efa\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u5230\u590d\u6742\u903b\u8f91\u95ee\u9898\u89e3\u51b3\u7cfb\u7edf\u7684\u91cd\u8981\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2511.08659", "categories": ["cs.MA", "cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.08659", "abs": "https://arxiv.org/abs/2511.08659", "authors": ["Dave de Jonge"], "title": "Introduction to Automated Negotiation", "comment": null, "summary": "This book is an introductory textbook targeted towards computer science students who are completely new to the topic of automated negotiation. It does not require any prerequisite knowledge, except for elementary mathematics and basic programming skills.\n  This book comes with an simple toy-world negotiation framework implemented in Python that can be used by the readers to implement their own negotiation algorithms and perform experiments with them. This framework is small and simple enough that any reader who does not like to work in Python should be able to re-implement it very quickly in any other programming language of their choice.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u672c\u9762\u5411\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u7684\u81ea\u52a8\u8c08\u5224\u5165\u95e8\u6559\u6750\uff0c\u4e0d\u9700\u8981\u9884\u5907\u77e5\u8bc6\uff0c\u5305\u542b\u57fa\u4e8ePython\u7684\u7b80\u5355\u8c08\u5224\u6846\u67b6\u3002", "motivation": "\u4e3a\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u63d0\u4f9b\u81ea\u52a8\u8c08\u5224\u7684\u5165\u95e8\u6559\u6750\uff0c\u964d\u4f4e\u5b66\u4e60\u95e8\u69db\uff0c\u8ba9\u6ca1\u6709\u9884\u5907\u77e5\u8bc6\u7684\u5b66\u751f\u4e5f\u80fd\u5feb\u901f\u4e0a\u624b\u3002", "method": "\u4f7f\u7528Python\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u73a9\u5177\u4e16\u754c\u8c08\u5224\u6846\u67b6\uff0c\u8bfb\u8005\u53ef\u4ee5\u57fa\u4e8e\u6b64\u5b9e\u73b0\u81ea\u5df1\u7684\u8c08\u5224\u7b97\u6cd5\u5e76\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u6613\u7528\u7684\u8c08\u5224\u6846\u67b6\uff0c\u5b66\u751f\u53ef\u4ee5\u5feb\u901f\u7406\u89e3\u81ea\u52a8\u8c08\u5224\u7684\u57fa\u672c\u6982\u5ff5\u548c\u5b9e\u73b0\u65b9\u6cd5\u3002", "conclusion": "\u672c\u4e66\u6210\u529f\u5730\u4e3a\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u81ea\u52a8\u8c08\u5224\u5b66\u4e60\u8def\u5f84\uff0c\u4ece\u7406\u8bba\u5230\u5b9e\u8df5\uff0c\u6846\u67b6\u8bbe\u8ba1\u7b80\u5355\u6613\u7528\uff0c\u4fbf\u4e8e\u79fb\u690d\u5230\u5176\u4ed6\u7f16\u7a0b\u8bed\u8a00\u3002"}}
{"id": "2511.09143", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09143", "abs": "https://arxiv.org/abs/2511.09143", "authors": ["Myungsu Kim", "Ikjun Yeom", "Younghoon Kim"], "title": "Flex-MIG: Enabling Distributed Execution on MIG", "comment": "13 pages, 11 figures, under review for MLSys 2026", "summary": "GPU clusters in multi-tenant settings often suffer from underutilization, making GPU-sharing technologies essential for efficient resource use. Among them, NVIDIA Multi-Instance GPU (MIG) has gained traction for providing hardware-level isolation that enables concurrent workloads without interference. However, MIG's hardware rigidity and the conventional one-to-one allocation model jointly lead to severe fragmentation and cluster-wide underutilization. We present Flex-MIG, a software-only framework that replaces one-to-one with a one-to-many allocation model and enables host-shared-memory collectives across MIG instances without hardware modification. Flex-MIG eliminates drain-required reconfiguration, reduces fragmentation, and improves makespan by up to 17% across diverse traces, showing that rethinking MIG's operational model as a software-coordinated layer substantially improves cluster efficiency.", "AI": {"tldr": "Flex-MIG\u662f\u4e00\u4e2a\u7eaf\u8f6f\u4ef6\u6846\u67b6\uff0c\u901a\u8fc7\u5c06MIG\u7684\u4e00\u5bf9\u4e00\u5206\u914d\u6a21\u578b\u6539\u4e3a\u4e00\u5bf9\u591a\u5206\u914d\u6a21\u578b\uff0c\u5e76\u652f\u6301\u8de8MIG\u5b9e\u4f8b\u7684\u4e3b\u673a\u5171\u4eab\u5185\u5b58\u96c6\u5408\u901a\u4fe1\uff0c\u663e\u8457\u63d0\u5347\u4e86GPU\u96c6\u7fa4\u7684\u5229\u7528\u7387\u548c\u6548\u7387\u3002", "motivation": "\u591a\u79df\u6237\u73af\u5883\u4e0b\u7684GPU\u96c6\u7fa4\u5b58\u5728\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0cNVIDIA MIG\u867d\u7136\u63d0\u4f9b\u786c\u4ef6\u7ea7\u9694\u79bb\uff0c\u4f46\u5176\u786c\u4ef6\u521a\u6027\u548c\u4f20\u7edf\u4e00\u5bf9\u4e00\u5206\u914d\u6a21\u578b\u5bfc\u81f4\u4e25\u91cd\u7684\u8d44\u6e90\u788e\u7247\u5316\u548c\u96c6\u7fa4\u5229\u7528\u7387\u4f4e\u4e0b\u3002", "method": "Flex-MIG\u91c7\u7528\u7eaf\u8f6f\u4ef6\u65b9\u6cd5\uff0c\u5c06MIG\u7684\u64cd\u4f5c\u6a21\u578b\u91cd\u65b0\u8bbe\u8ba1\u4e3a\u8f6f\u4ef6\u534f\u8c03\u5c42\uff0c\u5b9e\u73b0\u4e00\u5bf9\u591a\u5206\u914d\u6a21\u578b\uff0c\u5e76\u652f\u6301\u8de8MIG\u5b9e\u4f8b\u7684\u4e3b\u673a\u5171\u4eab\u5185\u5b58\u96c6\u5408\u901a\u4fe1\uff0c\u65e0\u9700\u786c\u4ef6\u4fee\u6539\u3002", "result": "Flex-MIG\u6d88\u9664\u4e86\u9700\u8981\u6392\u7a7a\u7684\u91cd\u914d\u7f6e\u9700\u6c42\uff0c\u51cf\u5c11\u4e86\u788e\u7247\u5316\uff0c\u5728\u591a\u6837\u5316\u8ddf\u8e2a\u6d4b\u8bd5\u4e2d\u5c06makespan\u63d0\u9ad8\u4e86\u9ad8\u8fbe17%\u3002", "conclusion": "\u5c06MIG\u7684\u64cd\u4f5c\u6a21\u578b\u91cd\u65b0\u601d\u8003\u4e3a\u8f6f\u4ef6\u534f\u8c03\u5c42\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u96c6\u7fa4\u6548\u7387\uff0cFlex-MIG\u5c55\u793a\u4e86\u5728\u4e0d\u4fee\u6539\u786c\u4ef6\u7684\u60c5\u51b5\u4e0b\u901a\u8fc7\u8f6f\u4ef6\u521b\u65b0\u89e3\u51b3GPU\u8d44\u6e90\u5171\u4eab\u95ee\u9898\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.08747", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08747", "abs": "https://arxiv.org/abs/2511.08747", "authors": ["Isaac Joffe", "Chris Eliasmith"], "title": "Vector Symbolic Algebras for the Abstraction and Reasoning Corpus", "comment": null, "summary": "The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) is a generative, few-shot fluid intelligence benchmark. Although humans effortlessly solve ARC-AGI, it remains extremely difficult for even the most advanced artificial intelligence systems. Inspired by methods for modelling human intelligence spanning neuroscience to psychology, we propose a cognitively plausible ARC-AGI solver. Our solver integrates System 1 intuitions with System 2 reasoning in an efficient and interpretable process using neurosymbolic methods based on Vector Symbolic Algebras (VSAs). Our solver works by object-centric program synthesis, leveraging VSAs to represent abstract objects, guide solution search, and enable sample-efficient neural learning. Preliminary results indicate success, with our solver scoring 10.8% on ARC-AGI-1-Train and 3.0% on ARC-AGI-1-Eval. Additionally, our solver performs well on simpler benchmarks, scoring 94.5% on Sort-of-ARC and 83.1% on 1D-ARC -- the latter outperforming GPT-4 at a tiny fraction of the computational cost. Importantly, our approach is unique; we believe we are the first to apply VSAs to ARC-AGI and have developed the most cognitively plausible ARC-AGI solver yet. Our code is available at: https://github.com/ijoffe/ARC-VSA-2025.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5411\u91cf\u7b26\u53f7\u4ee3\u6570(VSA)\u7684\u8ba4\u77e5\u5408\u7406ARC-AGI\u6c42\u89e3\u5668\uff0c\u7ed3\u5408\u7cfb\u7edf1\u76f4\u89c9\u548c\u7cfb\u7edf2\u63a8\u7406\uff0c\u901a\u8fc7\u9762\u5411\u5bf9\u8c61\u7684\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\u89e3\u51b3ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "ARC-AGI\u662f\u4eba\u7c7b\u8f7b\u677e\u89e3\u51b3\u4f46\u5bf9AI\u7cfb\u7edf\u6781\u5176\u56f0\u96be\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d7\u795e\u7ecf\u79d1\u5b66\u548c\u5fc3\u7406\u5b66\u4e2d\u4eba\u7c7b\u667a\u80fd\u5efa\u6a21\u65b9\u6cd5\u7684\u542f\u53d1\uff0c\u65e8\u5728\u5f00\u53d1\u8ba4\u77e5\u5408\u7406\u7684\u6c42\u89e3\u5668\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5411\u91cf\u7b26\u53f7\u4ee3\u6570(VSA)\u96c6\u6210\u7cfb\u7edf1\u76f4\u89c9\u548c\u7cfb\u7edf2\u63a8\u7406\uff0c\u91c7\u7528\u9762\u5411\u5bf9\u8c61\u7684\u7a0b\u5e8f\u5408\u6210\uff0c\u5229\u7528VSA\u8868\u793a\u62bd\u8c61\u5bf9\u8c61\u3001\u6307\u5bfc\u89e3\u51b3\u65b9\u6848\u641c\u7d22\u5e76\u5b9e\u73b0\u6837\u672c\u9ad8\u6548\u7684\u795e\u7ecf\u5b66\u4e60\u3002", "result": "\u5728ARC-AGI-1-Train\u4e0a\u5f97\u520610.8%\uff0c\u5728ARC-AGI-1-Eval\u4e0a\u5f97\u52063.0%\uff1b\u5728Sort-of-ARC\u4e0a\u5f97\u520694.5%\uff0c\u57281D-ARC\u4e0a\u5f97\u520683.1%\uff08\u4ee5\u6781\u5c0f\u8ba1\u7b97\u6210\u672c\u8d85\u8d8aGPT-4\uff09\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5c06VSA\u5e94\u7528\u4e8eARC-AGI\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u8ba4\u77e5\u5408\u7406\u7684ARC-AGI\u6c42\u89e3\u5668\uff0c\u5176\u72ec\u7279\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.08710", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08710", "abs": "https://arxiv.org/abs/2511.08710", "authors": ["Romain Cosentino", "Sarath Shekkizhar", "Adam Earle"], "title": "Convergence dynamics of Agent-to-Agent Interactions with Misaligned objectives", "comment": null, "summary": "We develop a theoretical framework for agent-to-agent interactions in multi-agent scenarios. We consider the setup in which two language model based agents perform iterative gradient updates toward their respective objectives in-context, using the output of the other agent as input. We characterize the generation dynamics associated with the interaction when the agents have misaligned objectives, and show that this results in a biased equilibrium where neither agent reaches its target - with the residual errors predictable from the objective gap and the geometry induced by the prompt of each agent. We establish the conditions for asymmetric convergence and provide an algorithm that provably achieves an adversarial result, producing one-sided success. Experiments with trained transformer models as well as GPT$5$ for the task of in-context linear regression validate the theory. Our framework presents a setup to study, predict, and defend multi-agent systems; explicitly linking prompt design and interaction setup to stability, bias, and robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u667a\u80fd\u4f53\u95f4\u4ea4\u4e92\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u76ee\u6807\u4e0d\u4e00\u81f4\u65f6\u7684\u8fed\u4ee3\u68af\u5ea6\u66f4\u65b0\u52a8\u6001\uff0c\u63ed\u793a\u4e86\u4f1a\u5bfc\u81f4\u6709\u504f\u5747\u8861\u548c\u53ef\u9884\u6d4b\u7684\u6b8b\u5dee\u8bef\u5dee\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u76ee\u6807\u4e0d\u4e00\u81f4\u65f6\u7684\u4ea4\u4e92\u52a8\u6001\uff0c\u4e3a\u7406\u89e3\u3001\u9884\u6d4b\u548c\u9632\u5fa1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5efa\u7acb\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u4e24\u4e2a\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u4f7f\u7528\u5bf9\u65b9\u8f93\u51fa\u4f5c\u4e3a\u8f93\u5165\u8fdb\u884c\u8fed\u4ee3\u68af\u5ea6\u66f4\u65b0\uff0c\u901a\u8fc7\u5b9e\u9a8c\u4f7f\u7528\u8bad\u7ec3\u597d\u7684transformer\u6a21\u578b\u548cGPT-5\u8fdb\u884c\u4e0a\u4e0b\u6587\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u5f53\u667a\u80fd\u4f53\u76ee\u6807\u4e0d\u4e00\u81f4\u65f6\uff0c\u4f1a\u4ea7\u751f\u6709\u504f\u5747\u8861\uff0c\u53cc\u65b9\u90fd\u65e0\u6cd5\u8fbe\u5230\u76ee\u6807\uff0c\u6b8b\u5dee\u8bef\u5dee\u53ef\u4ece\u76ee\u6807\u5dee\u8ddd\u548c\u63d0\u793a\u51e0\u4f55\u9884\u6d4b\uff1b\u5efa\u7acb\u4e86\u975e\u5bf9\u79f0\u6536\u655b\u6761\u4ef6\u5e76\u63d0\u4f9b\u4e86\u53ef\u8bc1\u660e\u5b9e\u73b0\u5355\u8fb9\u6210\u529f\u7684\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u3001\u9884\u6d4b\u548c\u9632\u5fa1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bbe\u7f6e\uff0c\u660e\u786e\u5c06\u63d0\u793a\u8bbe\u8ba1\u548c\u4ea4\u4e92\u8bbe\u7f6e\u4e0e\u7a33\u5b9a\u6027\u3001\u504f\u5dee\u548c\u9c81\u68d2\u6027\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2511.09194", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09194", "abs": "https://arxiv.org/abs/2511.09194", "authors": ["Simon K\u00f6nig", "Lukas Epple", "Christian Becker"], "title": "Minimize Your Critical Path with Combine-and-Exchange Locks", "comment": "19 pages, 15 figures", "summary": "Coroutines are experiencing a renaissance as many modern programming languages support the use of cooperative multitasking for highly parallel or asynchronous applications. One of the greatest advantages of this is that concurrency and synchronization is manged entirely in the userspace, omitting heavy-weight system calls. However, we find that state-of-the-art userspace synchronization primitives approach synchronization in the userspace from the perspective of kernel-level scheduling. This introduces unnecessary delays on the critical path of the application, limiting throughput. In this paper, we re-think synchronization for tasks that are scheduled entirely in the userspace (e.g., coroutines, fibers, etc.). We develop Combine-and-Exchange Scheduling (CES), a novel scheduling approach that ensures contended critical sections stay on the same thread of execution while parallelizable work is evenly spread across the remaining threads. We show that our approach can be applied to many existing languages and libraries, resulting in 3-fold performance improvements in application benchmarks as well as 8-fold performance improvements in microbenchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7528\u6237\u7a7a\u95f4\u4efb\u52a1\u8c03\u5ea6\u65b9\u6cd5CES\uff0c\u901a\u8fc7\u7ed3\u5408\u4ea4\u6362\u8c03\u5ea6\u6765\u4f18\u5316\u534f\u7a0b\u7b49\u7528\u6237\u7a7a\u95f4\u4efb\u52a1\u7684\u540c\u6b65\u6027\u80fd\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u7528\u6237\u7a7a\u95f4\u540c\u6b65\u539f\u8bed\u5f15\u5165\u7684\u4e0d\u5fc5\u8981\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u4ee3\u7f16\u7a0b\u8bed\u8a00\u5e7f\u6cdb\u652f\u6301\u534f\u7a0b\u7528\u4e8e\u9ad8\u5e76\u884c\u6216\u5f02\u6b65\u5e94\u7528\uff0c\u7528\u6237\u7a7a\u95f4\u540c\u6b65\u907f\u514d\u4e86\u91cd\u91cf\u7ea7\u7cfb\u7edf\u8c03\u7528\uff0c\u4f46\u73b0\u6709\u7528\u6237\u7a7a\u95f4\u540c\u6b65\u539f\u8bed\u4ecd\u4ece\u5185\u6838\u7ea7\u8c03\u5ea6\u89c6\u89d2\u5904\u7406\u540c\u6b65\uff0c\u5bfc\u81f4\u5173\u952e\u8def\u5f84\u4e0a\u51fa\u73b0\u4e0d\u5fc5\u8981\u5ef6\u8fdf\uff0c\u9650\u5236\u541e\u5410\u91cf\u3002", "method": "\u5f00\u53d1\u4e86Combine-and-Exchange Scheduling (CES)\u65b9\u6cd5\uff0c\u786e\u4fdd\u7ade\u4e89\u4e34\u754c\u533a\u4fdd\u6301\u5728\u540c\u4e00\u4e2a\u6267\u884c\u7ebf\u7a0b\u4e0a\uff0c\u540c\u65f6\u5c06\u53ef\u5e76\u884c\u5de5\u4f5c\u5747\u5300\u5206\u5e03\u5230\u5176\u4ed6\u7ebf\u7a0b\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u73b0\u6709\u8bed\u8a00\u548c\u5e93\uff0c\u5728\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b03\u500d\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5fae\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b08\u500d\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "CES\u4e3a\u5b8c\u5168\u5728\u7528\u6237\u7a7a\u95f4\u8c03\u5ea6\u7684\u4efb\u52a1\u91cd\u65b0\u601d\u8003\u4e86\u540c\u6b65\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7528\u6237\u7a7a\u95f4\u4efb\u52a1\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.08926", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08926", "abs": "https://arxiv.org/abs/2511.08926", "authors": ["Zhuhui Li", "Chunbo Luo", "Liming Huang", "Luyu Qi", "Geyong Min"], "title": "Achieving Equilibrium under Utility Heterogeneity: An Agent-Attention Framework for Multi-Agent Multi-Objective Reinforcement Learning", "comment": null, "summary": "Multi-agent multi-objective systems (MAMOS) have emerged as powerful frameworks for modelling complex decision-making problems across various real-world domains, such as robotic exploration, autonomous traffic management, and sensor network optimisation. MAMOS offers enhanced scalability and robustness through decentralised control and more accurately reflects inherent trade-offs between conflicting objectives. In MAMOS, each agent uses utility functions that map return vectors to scalar values. Existing MAMOS optimisation methods face challenges in handling heterogeneous objective and utility function settings, where training non-stationarity is intensified due to private utility functions and the associated policies. In this paper, we first theoretically prove that direct access to, or structured modeling of, global utility functions is necessary for the Bayesian Nash Equilibrium under decentralised execution constraints. To access the global utility functions while preserving the decentralised execution, we propose an Agent-Attention Multi-Agent Multi-Objective Reinforcement Learning (AA-MAMORL) framework. Our approach implicitly learns a joint belief over other agents' utility functions and their associated policies during centralised training, effectively mapping global states and utilities to each agent's policy. In execution, each agent independently selects actions based on local observations and its private utility function to approximate a BNE, without relying on inter-agent communication. We conduct comprehensive experiments in both a custom-designed MAMO Particle environment and the standard MOMALand benchmark. The results demonstrate that access to global preferences and our proposed AA-MAMORL significantly improve performance and consistently outperform state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53\u6ce8\u610f\u529b\u7684\u591a\u667a\u80fd\u4f53\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff08AA-MAMORL\uff09\uff0c\u901a\u8fc7\u9690\u5f0f\u5b66\u4e60\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u6548\u7528\u51fd\u6570\u548c\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u5206\u6563\u6267\u884c\u7684\u540c\u65f6\u8fd1\u4f3c\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u591a\u76ee\u6807\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u591a\u76ee\u6807\u7cfb\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u5904\u7406\u5f02\u6784\u76ee\u6807\u548c\u6548\u7528\u51fd\u6570\u8bbe\u7f6e\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7531\u4e8e\u79c1\u6709\u6548\u7528\u51fd\u6570\u548c\u76f8\u5173\u7b56\u7565\u5bfc\u81f4\u8bad\u7ec3\u975e\u5e73\u7a33\u6027\u52a0\u5267\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5728\u5206\u6563\u6267\u884c\u7ea6\u675f\u4e0b\u5982\u4f55\u83b7\u53d6\u5168\u5c40\u6548\u7528\u51fd\u6570\u4ee5\u5b9e\u73b0\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faAA-MAMORL\u6846\u67b6\uff0c\u5728\u96c6\u4e2d\u8bad\u7ec3\u671f\u95f4\u9690\u5f0f\u5b66\u4e60\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u6548\u7528\u51fd\u6570\u548c\u76f8\u5173\u7b56\u7565\u7684\u8054\u5408\u4fe1\u5ff5\uff0c\u5c06\u5168\u5c40\u72b6\u6001\u548c\u6548\u7528\u6620\u5c04\u5230\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u7b56\u7565\u3002\u5728\u6267\u884c\u9636\u6bb5\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u57fa\u4e8e\u5c40\u90e8\u89c2\u5bdf\u548c\u79c1\u6709\u6548\u7528\u51fd\u6570\u72ec\u7acb\u9009\u62e9\u52a8\u4f5c\uff0c\u65e0\u9700\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u3002", "result": "\u5728\u81ea\u5b9a\u4e49MAMO\u7c92\u5b50\u73af\u5883\u548c\u6807\u51c6MOMALand\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8bbf\u95ee\u5168\u5c40\u504f\u597d\u548c\u63d0\u51fa\u7684AA-MAMORL\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u5e76\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u7406\u8bba\u8bc1\u660e\u5728\u5206\u6563\u6267\u884c\u7ea6\u675f\u4e0b\u9700\u8981\u76f4\u63a5\u8bbf\u95ee\u6216\u7ed3\u6784\u5316\u5efa\u6a21\u5168\u5c40\u6548\u7528\u51fd\u6570\u624d\u80fd\u5b9e\u73b0\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\u3002AA-MAMORL\u6846\u67b6\u901a\u8fc7\u9690\u5f0f\u5b66\u4e60\u8054\u5408\u4fe1\u5ff5\uff0c\u5728\u4fdd\u6301\u5206\u6563\u6267\u884c\u7684\u540c\u65f6\u6709\u6548\u8fd1\u4f3cBNE\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u591a\u76ee\u6807\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09410", "categories": ["cs.DC", "cs.DS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.09410", "abs": "https://arxiv.org/abs/2511.09410", "authors": ["Yusuf Motiwala"], "title": "No Cords Attached: Coordination-Free Concurrent Lock-Free Queues", "comment": "10 pages, 2 figures, 3 tables. Lock-free concurrent queue with coordination-free memory reclamation", "summary": "The queue is conceptually one of the simplest data structures-a basic FIFO container. However, ensuring correctness in the presence of concurrency makes existing lock-free implementations significantly more complex than their original form. Coordination mechanisms introduced to prevent hazards such as ABA, use-after-free, and unsafe reclamation often dominate the design, overshadowing the queue itself. Many schemes compromise strict FIFO ordering, unbounded capacity, or lock-free progress to mask coordination overheads. Yet the true source of complexity lies in the pursuit of infinite protection against reclamation hazards--theoretically sound but impractical and costly. This pursuit not only drives unnecessary complexity but also creates a protection paradox where excessive protection reduces system resilience rather than improving it. While such costs may be tolerable in conventional workloads, the AI era has shifted the paradigm: training and inference pipelines involve hundreds to thousands of concurrent threads per node, and at this scale, protection and coordination overheads dominate, often far heavier than the basic queue operations themselves.\n  This paper introduces Cyclic Memory Protection (CMP), a coordination-free queue that preserves strict FIFO semantics, unbounded capacity, and lock-free progress while restoring simplicity. CMP reclaims the strict FIFO that other approaches sacrificed through bounded protection windows that provide practical reclamation guarantees. We prove strict FIFO and safety via linearizability and bounded reclamation analysis, and show experimentally that CMP outperforms state-of-the-art lock-free queues by up to 1.72-4x under high contention while maintaining scalability to hundreds of threads. Our work demonstrates that highly concurrent queues can return to their fundamental simplicity without weakening queue semantics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5faa\u73af\u5185\u5b58\u4fdd\u62a4(CMP)\u7684\u65e0\u534f\u8c03\u961f\u5217\uff0c\u5728\u4fdd\u6301\u4e25\u683cFIFO\u8bed\u4e49\u3001\u65e0\u754c\u5bb9\u91cf\u548c\u65e0\u9501\u8fdb\u5ea6\u7684\u540c\u65f6\u6062\u590d\u4e86\u7b80\u5355\u6027\u3002CMP\u901a\u8fc7\u6709\u754c\u4fdd\u62a4\u7a97\u53e3\u63d0\u4f9b\u5b9e\u9645\u7684\u91cd\u7528\u4fdd\u8bc1\uff0c\u6027\u80fd\u6bd4\u73b0\u6709\u65e0\u9501\u961f\u5217\u63d0\u53471.72-4\u500d\u3002", "motivation": "\u4f20\u7edf\u65e0\u9501\u961f\u5217\u5b9e\u73b0\u4e3a\u4e86\u9632\u8303ABA\u3001\u91ca\u653e\u540e\u4f7f\u7528\u7b49\u98ce\u9669\u800c\u5f15\u5165\u590d\u6742\u7684\u534f\u8c03\u673a\u5236\uff0c\u8fd9\u4e9b\u4fdd\u62a4\u673a\u5236\u7684\u8bbe\u8ba1\u590d\u6742\u5ea6\u5f80\u5f80\u8d85\u8fc7\u4e86\u961f\u5217\u672c\u8eab\u3002\u5728AI\u65f6\u4ee3\uff0c\u8bad\u7ec3\u548c\u63a8\u7406\u7ba1\u9053\u6d89\u53ca\u6570\u767e\u5230\u6570\u5343\u4e2a\u5e76\u53d1\u7ebf\u7a0b\uff0c\u4fdd\u62a4\u5f00\u9500\u53d8\u5f97\u4e0d\u53ef\u5ffd\u89c6\u3002", "method": "\u91c7\u7528\u5faa\u73af\u5185\u5b58\u4fdd\u62a4(CMP)\u673a\u5236\uff0c\u901a\u8fc7\u6709\u754c\u4fdd\u62a4\u7a97\u53e3\u63d0\u4f9b\u5b9e\u9645\u7684\u91cd\u7528\u4fdd\u8bc1\uff0c\u907f\u514d\u4e86\u65e0\u9650\u4fdd\u62a4\u5e26\u6765\u7684\u590d\u6742\u6027\u548c\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683cFIFO\u8bed\u4e49\u548c\u65e0\u9501\u8fdb\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCMP\u5728\u9ad8\u7ade\u4e89\u6761\u4ef6\u4e0b\u6bd4\u6700\u5148\u8fdb\u7684\u65e0\u9501\u961f\u5217\u6027\u80fd\u63d0\u53471.72-4\u500d\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u6570\u767e\u4e2a\u7ebf\u7a0b\u3002\u901a\u8fc7\u7ebf\u6027\u5316\u6027\u548c\u6709\u754c\u91cd\u7528\u5206\u6790\u8bc1\u660e\u4e86\u4e25\u683cFIFO\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u9ad8\u5ea6\u5e76\u53d1\u7684\u961f\u5217\u53ef\u4ee5\u5728\u4e0d\u524a\u5f31\u961f\u5217\u8bed\u4e49\u7684\u60c5\u51b5\u4e0b\u56de\u5f52\u57fa\u672c\u7b80\u5355\u6027\uff0cCMP\u5c55\u793a\u4e86\u901a\u8fc7\u5b9e\u7528\u4e3b\u4e49\u65b9\u6cd5\u800c\u975e\u7406\u8bba\u5b8c\u7f8e\u4e3b\u4e49\u6765\u5b9e\u73b0\u9ad8\u6027\u80fd\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.09171", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.09171", "abs": "https://arxiv.org/abs/2511.09171", "authors": ["Xinren Zhang", "Jiadong Yu", "Zixin Zhong"], "title": "Learning Efficient Communication Protocols for Multi-Agent Reinforcement Learning", "comment": null, "summary": "Multi-Agent Systems (MAS) have emerged as a powerful paradigm for modeling complex interactions among autonomous entities in distributed environments. In Multi-Agent Reinforcement Learning (MARL), communication enables coordination but can lead to inefficient information exchange, since agents may generate redundant or non-essential messages. While prior work has focused on boosting task performance with information exchange, the existing research lacks a thorough investigation of both the appropriate definition and the optimization of communication protocols (communication topology and message). To fill this gap, we introduce a generalized framework for learning multi-round communication protocols that are both effective and efficient. Within this framework, we propose three novel Communication Efficiency Metrics (CEMs) to guide and evaluate the learning process: the Information Entropy Efficiency Index (IEI) and Specialization Efficiency Index (SEI) for efficiency-augmented optimization, and the Topology Efficiency Index (TEI) for explicit evaluation. We integrate IEI and SEI as the adjusted loss functions to promote informative messaging and role specialization, while using TEI to quantify the trade-off between communication volume and task performance. Through comprehensive experiments, we demonstrate that our learned communication protocol can significantly enhance communication efficiency and achieves better cooperation performance with improved success rates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b66\u4e60\u591a\u8f6e\u901a\u4fe1\u534f\u8bae\u7684\u901a\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u901a\u4fe1\u6548\u7387\u6307\u6807\u6765\u4f18\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u6548\u7387\u548c\u534f\u4f5c\u6027\u80fd\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u901a\u4fe1\u867d\u7136\u80fd\u4fc3\u8fdb\u534f\u8c03\uff0c\u4f46\u53ef\u80fd\u5bfc\u81f4\u5197\u4f59\u6216\u975e\u5fc5\u8981\u7684\u4fe1\u606f\u4ea4\u6362\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u901a\u4fe1\u534f\u8bae\uff08\u901a\u4fe1\u62d3\u6251\u548c\u6d88\u606f\uff09\u7684\u9002\u5f53\u5b9a\u4e49\u548c\u4f18\u5316\u7684\u6df1\u5165\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b66\u4e60\u591a\u8f6e\u901a\u4fe1\u534f\u8bae\u7684\u901a\u7528\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u4e09\u4e2a\u901a\u4fe1\u6548\u7387\u6307\u6807\uff1a\u4fe1\u606f\u71b5\u6548\u7387\u6307\u6570\u548c\u4e13\u4e1a\u5316\u6548\u7387\u6307\u6570\u7528\u4e8e\u6548\u7387\u589e\u5f3a\u4f18\u5316\uff0c\u62d3\u6251\u6548\u7387\u6307\u6570\u7528\u4e8e\u663e\u5f0f\u8bc4\u4f30\u3002\u5c06\u524d\u4e24\u4e2a\u6307\u6807\u6574\u5408\u4e3a\u8c03\u6574\u635f\u5931\u51fd\u6570\uff0c\u4fc3\u8fdb\u4fe1\u606f\u4e30\u5bcc\u7684\u6d88\u606f\u4f20\u9012\u548c\u89d2\u8272\u4e13\u4e1a\u5316\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5b66\u4e60\u5230\u7684\u901a\u4fe1\u534f\u8bae\u80fd\u663e\u8457\u63d0\u9ad8\u901a\u4fe1\u6548\u7387\uff0c\u5e76\u5728\u6539\u8fdb\u6210\u529f\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u597d\u7684\u534f\u4f5c\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u901a\u4fe1\u534f\u8bae\uff0c\u5728\u4fdd\u8bc1\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u901a\u4fe1\u6548\u7387\u3002"}}
{"id": "2511.09447", "categories": ["cs.DC", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.09447", "abs": "https://arxiv.org/abs/2511.09447", "authors": ["Lukas Gianinazzi", "Tal Ben-Nun", "Torsten Hoefler"], "title": "SPADA: A Spatial Dataflow Architecture Programming Language", "comment": null, "summary": "Spatial dataflow architectures like the Cerebras Wafer-Scale Engine achieve exceptional performance in AI and scientific applications by leveraging distributed memory across processing elements (PEs) and localized computation. However, programming these architectures remains challenging due to the need for explicit orchestration of data movement through reconfigurable networks-on-chip and asynchronous computation triggered by data arrival. Existing FPGA and CGRA programming models emphasize loop scheduling but overlook the unique capabilities of spatial dataflow architectures, particularly efficient dataflow over regular grids and intricate routing management.\n  We present SPADA, a programming language that provides precise control over data placement, dataflow patterns, and asynchronous operations while abstracting architecture-specific low-level details. We introduce a rigorous dataflow semantics framework for SPADA that defines routing correctness, data races, and deadlocks. Additionally, we design and implement a compiler targeting Cerebras CSL with multi-level lowering.\n  SPADA serves as both a high-level programming interface and an intermediate representation for domain-specific languages (DSLs), which we demonstrate with the GT4Py stencil DSL. SPADA enables developers to express complex parallel patterns -- including pipelined reductions and multi-dimensional stencils -- in 6--8x less code than CSL with near-ideal weak scaling across three orders of magnitude. By unifying programming for spatial dataflow architectures under a single model, SPADA advances both the theoretical foundations and practical usability of these emerging high-performance computing platforms.", "AI": {"tldr": "SPADA\u662f\u4e00\u79cd\u9488\u5bf9\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u901a\u8fc7\u62bd\u8c61\u5e95\u5c42\u67b6\u6784\u7ec6\u8282\uff0c\u63d0\u4f9b\u5bf9\u6570\u636e\u653e\u7f6e\u3001\u6570\u636e\u6d41\u6a21\u5f0f\u548c\u5f02\u6b65\u64cd\u4f5c\u7684\u7cbe\u786e\u63a7\u5236\uff0c\u663e\u8457\u7b80\u5316\u4e86Cerebras\u7b49\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u7f16\u7a0b\u96be\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684FPGA\u548cCGRA\u7f16\u7a0b\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u5faa\u73af\u8c03\u5ea6\uff0c\u4f46\u5ffd\u7565\u4e86\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u72ec\u7279\u80fd\u529b\uff0c\u7279\u522b\u662f\u9ad8\u6548\u7684\u6570\u636e\u6d41\u7ba1\u7406\u548c\u590d\u6742\u8def\u7531\u63a7\u5236\uff0c\u5bfc\u81f4\u7f16\u7a0b\u8fd9\u4e9b\u67b6\u6784\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faSPADA\u7f16\u7a0b\u8bed\u8a00\uff0c\u5f15\u5165\u4e25\u683c\u7684\u6570\u636e\u6d41\u8bed\u4e49\u6846\u67b6\u6765\u5b9a\u4e49\u8def\u7531\u6b63\u786e\u6027\u3001\u6570\u636e\u7ade\u4e89\u548c\u6b7b\u9501\uff0c\u5e76\u8bbe\u8ba1\u5b9e\u73b0\u9488\u5bf9Cerebras CSL\u7684\u591a\u7ea7\u964d\u4f4e\u7f16\u8bd1\u5668\u3002", "result": "SPADA\u80fd\u591f\u7528\u6bd4CSL\u5c116-8\u500d\u7684\u4ee3\u7801\u8868\u8fbe\u590d\u6742\u7684\u5e76\u884c\u6a21\u5f0f\uff0c\u5305\u62ec\u6d41\u6c34\u7ebf\u5f52\u7ea6\u548c\u591a\u7ef4\u6a21\u677f\uff0c\u5e76\u5728\u4e09\u4e2a\u6570\u91cf\u7ea7\u4e0a\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u6027\u3002", "conclusion": "SPADA\u901a\u8fc7\u7edf\u4e00\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u7f16\u7a0b\u6a21\u578b\uff0c\u63a8\u52a8\u4e86\u8fd9\u4e9b\u65b0\u5174\u9ad8\u6027\u80fd\u8ba1\u7b97\u5e73\u53f0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u53ef\u7528\u6027\u3002"}}
{"id": "2511.08873", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08873", "abs": "https://arxiv.org/abs/2511.08873", "authors": ["Shouang Wei", "Min Zhang", "Xin Lin", "Bo Jiang", "Kun Kuang", "Zhongxiang Dai"], "title": "UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models", "comment": null, "summary": "Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at https://github.com/Mind-Lab-ECNU/UCO.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5355\u5411\u8ba4\u77e5\u4f18\u5316\uff08UCO\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3LLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u65f6\u7684\u52a8\u6001\u9002\u5e94\u95ee\u9898\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u5956\u52b1\u51fd\u6570\u6765\u8bc4\u4f30\u5b66\u751f\u8ba4\u77e5\u8fdb\u6b65\u548c\u8bc6\u522b\u6700\u8fd1\u53d1\u5c55\u533a\u3002", "motivation": "\u5f53\u524dLLM\u5728\u6559\u80b2\u573a\u666f\u4e2d\u4ece\u7b54\u6848\u63d0\u4f9b\u8005\u8f6c\u5411\u667a\u80fd\u5bfc\u5e08\uff0c\u4f46\u73b0\u6709\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u53ea\u80fd\u5b66\u4e60\u8868\u9762\u6559\u5b66\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u52a8\u6001\u9002\u5e94\u80fd\u529b\u3002\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u65e0\u6cd5\u533a\u5206\u5b66\u751f\u662f\u5426\u771f\u6b63\u7406\u89e3\u8fd8\u662f\u91cd\u590d\u6559\u5e08\u7b54\u6848\uff0c\u4ee5\u53ca\u65e0\u6cd5\u5b9e\u65f6\u611f\u77e5\u5b66\u751f\u8ba4\u77e5\u72b6\u6001\u53d8\u5316\u3002", "method": "UCO\u65b9\u6cd5\u91c7\u7528\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u5956\u52b1\u51fd\u6570\uff1a\u8fdb\u6b65\u5956\u52b1\u6355\u6349\u5b66\u751f\u8ba4\u77e5\u8fdb\u6b65\uff0c\u8bc4\u4f30\u5b66\u751f\u662f\u5426\u4ece\u56f0\u60d1\u8f6c\u5411\u7406\u89e3\uff1b\u652f\u67b6\u5956\u52b1\u52a8\u6001\u8bc6\u522b\u5b66\u751f\u7684\u6700\u8fd1\u53d1\u5c55\u533a\uff0c\u9f13\u52b1\u6559\u5e08\u5728\u8be5\u533a\u57df\u5185\u4fdd\u6301\u6709\u6548\u6559\u5b66\u3002", "result": "\u5728BigMath\u548cMathTutorBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUCO\u6a21\u578b\u4f18\u4e8e\u6240\u6709\u540c\u7b49\u89c4\u6a21\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u6027\u80fd\u4e0e\u5148\u8fdb\u7684\u95ed\u6e90\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "UCO\u65b9\u6cd5\u901a\u8fc7\u521b\u65b0\u7684\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u65f6\u7684\u52a8\u6001\u9002\u5e94\u95ee\u9898\uff0c\u5728\u6570\u5b66\u8f85\u5bfc\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.09485", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09485", "abs": "https://arxiv.org/abs/2511.09485", "authors": ["Miroslav Popovic", "Marko Popovic", "Pavle Vasiljevic", "Miodrag Djukic"], "title": "Formal Verification of a Generic Algorithm for TDM Communication Over Inter Satellite Links", "comment": "4 pages, 1 figure, 3 tables", "summary": "The Python Testbed for Federated Learning Algorithms is a simple FL framework targeting edge systems, which provides the three generic algorithms: the centralized federated learning, the decentralized federated learning, and the universal TDM communication in the current time slot. The first two were formally verified in a previous paper using the CSP process algebra, and in this paper, we use the same approach to formally verify the third one, in two phases. In the first phase, we construct the CSP model as a faithful representation of the real Python code. In the second phase, the model checker PAT automatically proves correctness of the third generic algorithm by proving its deadlock freeness (safety property) and successful termination (liveness property).", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528CSP\u8fdb\u7a0b\u4ee3\u6570\u5bf9Python\u8054\u90a6\u5b66\u4e60\u6d4b\u8bd5\u5e8a\u4e2d\u7684\u7b2c\u4e09\u4e2a\u901a\u7528\u7b97\u6cd5\uff08\u901a\u7528TDM\u901a\u4fe1\uff09\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u901a\u8fc7\u6a21\u578b\u68c0\u67e5\u5668PAT\u81ea\u52a8\u8bc1\u660e\u5176\u6b7b\u9501\u81ea\u7531\u6027\u548c\u6210\u529f\u7ec8\u6b62\u6027\u3002", "motivation": "\u5728\u524d\u4e00\u7bc7\u8bba\u6587\u4e2d\u5df2\u7ecf\u5bf9\u524d\u4e24\u4e2a\u901a\u7528\u7b97\u6cd5\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u672c\u6587\u65e8\u5728\u4f7f\u7528\u76f8\u540c\u7684\u65b9\u6cd5\u9a8c\u8bc1\u7b2c\u4e09\u4e2a\u901a\u7528\u7b97\u6cd5\uff0c\u786e\u4fdd\u5176\u6b63\u786e\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u6784\u5efa\u5fe0\u5b9e\u53cd\u6620Python\u4ee3\u7801\u7684CSP\u6a21\u578b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u6a21\u578b\u68c0\u67e5\u5668PAT\u81ea\u52a8\u9a8c\u8bc1\u7b97\u6cd5\u7684\u5b89\u5168\u6027\u548c\u6d3b\u6027\u5c5e\u6027\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u7b2c\u4e09\u4e2a\u901a\u7528\u7b97\u6cd5\u7684\u6b7b\u9501\u81ea\u7531\u6027\uff08\u5b89\u5168\u6027\u5c5e\u6027\uff09\u548c\u6210\u529f\u7ec8\u6b62\u6027\uff08\u6d3b\u6027\u5c5e\u6027\uff09\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u786e\u8ba4\u4e86Python\u8054\u90a6\u5b66\u4e60\u6d4b\u8bd5\u5e8a\u4e2d\u7b2c\u4e09\u4e2a\u901a\u7528\u7b97\u6cd5\u7684\u6b63\u786e\u6027\uff0c\u4e3a\u8fb9\u7f18\u7cfb\u7edf\u4e2d\u7684\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u4e86\u53ef\u9760\u4fdd\u8bc1\u3002"}}
{"id": "2511.08892", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08892", "abs": "https://arxiv.org/abs/2511.08892", "authors": ["Weihao Tan", "Xiangyang Li", "Yunhao Fang", "Heyuan Yao", "Shi Yan", "Hao Luo", "Tenglong Ao", "Huihui Li", "Hongbin Ren", "Bairen Yi", "Yujia Qin", "Bo An", "Libin Liu", "Guang Shi"], "title": "Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds", "comment": null, "summary": "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts a human-like interaction paradigm that unifies perception, reasoning, and action in an end-to-end manner, powered by a vision-language model. It processes raw pixels at 5 Hz to produce precise 30 Hz keyboard-mouse actions and adaptively invokes reasoning only when necessary. Trained in Genshin Impact, Lumine successfully completes the entire five-hour Mondstadt main storyline on par with human-level efficiency and follows natural language instructions to perform a broad spectrum of tasks in both 3D open-world exploration and 2D GUI manipulation across collection, combat, puzzle-solving, and NPC interaction. In addition to its in-domain performance, Lumine demonstrates strong zero-shot cross-game generalization. Without any fine-tuning, it accomplishes 100-minute missions in Wuthering Waves and the full five-hour first chapter of Honkai: Star Rail. These promising results highlight Lumine's effectiveness across distinct worlds and interaction dynamics, marking a concrete step toward generalist agents in open-ended environments.", "AI": {"tldr": "Lumine\u662f\u9996\u4e2a\u80fd\u591f\u57283D\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u5b9e\u65f6\u5b8c\u6210\u6570\u5c0f\u65f6\u590d\u6742\u4efb\u52a1\u7684\u901a\u7528\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7edf\u4e00\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\uff0c\u5728\u300a\u539f\u795e\u300b\u4e2d\u8bad\u7ec3\u540e\u80fd\u591f\u5b8c\u62105\u5c0f\u65f6\u8499\u5fb7\u4e3b\u7ebf\u5267\u60c5\uff0c\u5e76\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u8de8\u6e38\u620f\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5728\u590d\u67423D\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u6267\u884c\u957f\u65f6\u95f4\u4efb\u52a1\u7684\u901a\u7528\u667a\u80fd\u4f53\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5b9e\u65f6\u3001\u957f\u65f6\u7a0b\u4efb\u52a1\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u7aef\u5230\u7aef\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u4ee55Hz\u5904\u7406\u539f\u59cb\u50cf\u7d20\u5e76\u751f\u621030Hz\u7684\u952e\u76d8\u9f20\u6807\u52a8\u4f5c\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u8fdb\u884c\u63a8\u7406\uff0c\u5728\u300a\u539f\u795e\u300b\u6e38\u620f\u4e2d\u8bad\u7ec3\u3002", "result": "\u6210\u529f\u5b8c\u6210\u300a\u539f\u795e\u300b5\u5c0f\u65f6\u8499\u5fb7\u4e3b\u7ebf\u5267\u60c5\uff0c\u8fbe\u5230\u4eba\u7c7b\u6548\u7387\u6c34\u5e73\uff1b\u5728\u300a\u9e23\u6f6e\u300b\u4e2d\u5b8c\u6210100\u5206\u949f\u4efb\u52a1\uff0c\u5728\u300a\u5d29\u574f\uff1a\u661f\u7a79\u94c1\u9053\u300b\u4e2d\u5b8c\u62105\u5c0f\u65f6\u7b2c\u4e00\u7ae0\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u8de8\u6e38\u620f\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Lumine\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u548c\u4e0d\u540c\u4ea4\u4e92\u52a8\u6001\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6807\u5fd7\u7740\u5411\u5f00\u653e\u73af\u5883\u901a\u7528\u667a\u80fd\u4f53\u8fc8\u51fa\u4e86\u5177\u4f53\u4e00\u6b65\u3002"}}
{"id": "2511.09005", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.09005", "abs": "https://arxiv.org/abs/2511.09005", "authors": ["Alvin Chauhan"], "title": "AI Founding Fathers: A Case Study of GIS Search in Multi-Agent Pipelines", "comment": "9 pages, 3 figures. Code and data available at https://github.com/alvco/Founding_Fathers_AI", "summary": "Although Large Language Models (LLMs) show exceptional fluency, efforts persist to extract stronger reasoning capabilities from them. Drawing on search-based interpretations of LLM computation, this paper advances a systematic framework for understanding LLM reasoning and optimization. Namely, that enhancing reasoning is best achieved by structuring a multi-agent pipeline to ensure a traversal of the search space in a gradual, incremental, and sequential (GIS) manner. Stated succinctly, high-quality reasoning is a controlled, incremental search. To test this framework, we investigate the efficacy of recursive refinement (RR)--an iterative process of self-criticism, adversarial stress-testing, and integrating critical feedback--as a practical method for implementing GIS search. We designed an experiment comparing a simple, linear pipeline against a complex, explicitly structured pipeline leveraging a recursive refinement layer. The multi-agent models were constructed to reflect the historical personas of three US Founding Fathers (Hamilton, Jefferson, and Madison) using RAG-powered corpora and were prompted to generate responses to three contemporary political issues. Model performance was evaluated using a two-tiered approach: a quantitative score from an LLM arbiter agent and qualitative human judgment. Our results revealed that the complex model consistently outperformed the simple model across all nine test cases with an average arbiter-outputted score of 88.3 versus 71.7. The complex model's arguments were superior in analytical depth, structural nuance, and strategic framing. We conclude that recursive refinement is a robust architectural feature for enhancing LLM reasoning via GIS search.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u89c6\u4e3a\u53d7\u63a7\u7684\u589e\u91cf\u641c\u7d22\uff0c\u5e76\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u5b9e\u73b0\u6e10\u8fdb\u3001\u589e\u91cf\u548c\u987a\u5e8f\uff08GIS\uff09\u7684\u641c\u7d22\u7a7a\u95f4\u904d\u5386\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528\u9012\u5f52\u7cbe\u70bc\u5c42\u7684\u590d\u6742\u6a21\u578b\u5728\u63a8\u7406\u8d28\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u7b80\u5355\u7ebf\u6027\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6d41\u7545\u6027\uff0c\u4f46\u7814\u7a76\u8005\u4ecd\u5728\u52aa\u529b\u4ece\u4e2d\u63d0\u53d6\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u3002\u672c\u6587\u57fa\u4e8e\u641c\u7d22\u5bfc\u5411\u7684LLM\u8ba1\u7b97\u89e3\u91ca\uff0c\u65e8\u5728\u7cfb\u7edf\u5316\u7406\u89e3LLM\u63a8\u7406\u548c\u4f18\u5316\u3002", "method": "\u91c7\u7528\u9012\u5f52\u7cbe\u70bc\uff08RR\uff09\u4f5c\u4e3a\u5b9e\u73b0GIS\u641c\u7d22\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u5305\u62ec\u81ea\u6211\u6279\u8bc4\u3001\u5bf9\u6297\u6027\u538b\u529b\u6d4b\u8bd5\u548c\u6574\u5408\u5173\u952e\u53cd\u9988\u7684\u8fed\u4ee3\u8fc7\u7a0b\u3002\u8bbe\u8ba1\u4e86\u7b80\u5355\u7ebf\u6027\u7ba1\u9053\u4e0e\u590d\u6742\u7ed3\u6784\u5316\u7ba1\u9053\u7684\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u590d\u6742\u7ba1\u9053\u5305\u542b\u9012\u5f52\u7cbe\u70bc\u5c42\uff0c\u5e76\u4f7f\u7528RAG\u589e\u5f3a\u7684\u8bed\u6599\u5e93\u6784\u5efa\u53cd\u6620\u7f8e\u56fd\u5f00\u56fd\u5143\u52cb\u5386\u53f2\u4eba\u7269\u7684\u591a\u667a\u80fd\u4f53\u6a21\u578b\u3002", "result": "\u590d\u6742\u6a21\u578b\u5728\u6240\u6709\u4e5d\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u7b80\u5355\u6a21\u578b\uff0c\u5e73\u5747\u4ef2\u88c1\u5206\u6570\u4e3a88.3\u5bf971.7\u3002\u590d\u6742\u6a21\u578b\u7684\u8bba\u8bc1\u5728\u5206\u6790\u6df1\u5ea6\u3001\u7ed3\u6784\u7ec6\u5fae\u5dee\u522b\u548c\u6218\u7565\u6846\u67b6\u65b9\u9762\u66f4\u4f18\u8d8a\u3002", "conclusion": "\u9012\u5f52\u7cbe\u70bc\u662f\u901a\u8fc7GIS\u641c\u7d22\u589e\u5f3aLLM\u63a8\u7406\u7684\u5f3a\u5927\u67b6\u6784\u7279\u5f81\uff0c\u7ed3\u6784\u5316\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u80fd\u591f\u5b9e\u73b0\u66f4\u9ad8\u8d28\u91cf\u7684\u63a8\u7406\u8f93\u51fa\u3002"}}
{"id": "2511.08934", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08934", "abs": "https://arxiv.org/abs/2511.08934", "authors": ["Di Liao", "Ruijia Liang", "Ziyi Ye"], "title": "A Research on Business Process Optimisation Model Integrating AI and Big Data Analytics", "comment": null, "summary": "With the deepening of digital transformation, business process optimisation has become the key to improve the competitiveness of enterprises. This study constructs a business process optimisation model integrating artificial intelligence and big data to achieve intelligent management of the whole life cycle of processes. The model adopts a three-layer architecture incorporating data processing, AI algorithms, and business logic to enable real-time process monitoring and optimization. Through distributed computing and deep learning techniques, the system can handle complex business scenarios while maintaining high performance and reliability. Experimental validation across multiple enterprise scenarios shows that the model shortens process processing time by 42%, improves resource utilisation by 28%, and reduces operating costs by 35%. The system maintained 99.9% availability under high concurrent loads. The research results have important theoretical and practical value for promoting the digital transformation of enterprises, and provide new ideas for improving the operational efficiency of enterprises.", "AI": {"tldr": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u878d\u5408\u4eba\u5de5\u667a\u80fd\u4e0e\u5927\u6570\u636e\u7684\u4e1a\u52a1\u6d41\u7a0b\u4f18\u5316\u6a21\u578b\uff0c\u91c7\u7528\u4e09\u5c42\u67b6\u6784\u5b9e\u73b0\u6d41\u7a0b\u5168\u751f\u547d\u5468\u671f\u7684\u667a\u80fd\u7ba1\u7406\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\u8be5\u6a21\u578b\u80fd\u663e\u8457\u7f29\u77ed\u5904\u7406\u65f6\u95f4\u3001\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u5e76\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u5316\u8f6c\u578b\u7684\u6df1\u5165\uff0c\u4e1a\u52a1\u6d41\u7a0b\u4f18\u5316\u6210\u4e3a\u63d0\u5347\u4f01\u4e1a\u7ade\u4e89\u529b\u7684\u5173\u952e\uff0c\u9700\u8981\u6784\u5efa\u667a\u80fd\u5316\u7684\u6d41\u7a0b\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5305\u542b\u6570\u636e\u5904\u7406\u3001AI\u7b97\u6cd5\u548c\u4e1a\u52a1\u903b\u8f91\u7684\u4e09\u5c42\u67b6\u6784\u6a21\u578b\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u5b9e\u73b0\u5b9e\u65f6\u6d41\u7a0b\u76d1\u63a7\u4e0e\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff1a\u6d41\u7a0b\u5904\u7406\u65f6\u95f4\u7f29\u77ed42%\uff0c\u8d44\u6e90\u5229\u7528\u7387\u63d0\u9ad828%\uff0c\u8fd0\u8425\u6210\u672c\u964d\u4f4e35%\uff0c\u7cfb\u7edf\u5728\u9ad8\u5e76\u53d1\u8d1f\u8f7d\u4e0b\u4fdd\u630199.9%\u7684\u53ef\u7528\u6027\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u5bf9\u4f01\u4e1a\u6570\u5b57\u5316\u8f6c\u578b\u5177\u6709\u91cd\u8981\u7406\u8bba\u4ef7\u503c\u548c\u5b9e\u8df5\u610f\u4e49\uff0c\u4e3a\u63d0\u5347\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.08947", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08947", "abs": "https://arxiv.org/abs/2511.08947", "authors": ["Xiaohan Zhang", "Tian Gao", "Mingyue Cheng", "Bokai Pan", "Ze Guo", "Yaguo Liu", "Xiaoyu Tao"], "title": "AlphaCast: A Human Wisdom-LLM Intelligence Co-Reasoning Framework for Interactive Time Series Forecasting", "comment": null, "summary": "Time series forecasting plays a critical role in high-stakes domains such as energy, healthcare, and climate. Although recent advances have improved accuracy, most approaches still treat forecasting as a static one-time mapping task, lacking the interaction, reasoning, and adaptability of human experts. This gap limits their usefulness in complex real-world environments. To address this, we propose AlphaCast, a human wisdom-large language model (LLM) intelligence co-reasoning framework that redefines forecasting as an interactive process. The key idea is to enable step-by-step collaboration between human wisdom and LLM intelligence to jointly prepare, generate, and verify forecasts. The framework consists of two stages: (1) automated prediction preparation, where AlphaCast builds a multi-source cognitive foundation comprising a feature set that captures key statistics and time patterns, a domain knowledge base distilled from corpora and historical series, a contextual repository that stores rich information for each time window, and a case base that retrieves optimal strategies via pattern clustering and matching; and (2) generative reasoning and reflective optimization, where AlphaCast integrates statistical temporal features, prior knowledge, contextual information, and forecasting strategies, triggering a meta-reasoning loop for continuous self-correction and strategy refinement. Extensive experiments on short- and long-term datasets show that AlphaCast consistently outperforms state-of-the-art baselines in predictive accuracy. Code is available at this repository: https://github.com/SkyeGT/AlphaCast_Official .", "AI": {"tldr": "AlphaCast\u662f\u4e00\u4e2a\u7ed3\u5408\u4eba\u7c7b\u667a\u6167\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u7684\u534f\u540c\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4ea4\u4e92\u5f0f\u8fc7\u7a0b\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u9884\u6d4b\u51c6\u5907\u548c\u751f\u6210\u63a8\u7406\u4e0e\u53cd\u601d\u4f18\u5316\u4e24\u4e2a\u9636\u6bb5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5927\u591a\u5c06\u9884\u6d4b\u89c6\u4e3a\u9759\u6001\u7684\u4e00\u6b21\u6027\u6620\u5c04\u4efb\u52a1\uff0c\u7f3a\u4e4f\u4eba\u7c7b\u4e13\u5bb6\u7684\u4ea4\u4e92\u3001\u63a8\u7406\u548c\u9002\u5e94\u6027\uff0c\u9650\u5236\u4e86\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1)\u81ea\u52a8\u5316\u9884\u6d4b\u51c6\u5907\u9636\u6bb5\u6784\u5efa\u591a\u6e90\u8ba4\u77e5\u57fa\u7840\uff0c\u5305\u62ec\u7279\u5f81\u96c6\u3001\u9886\u57df\u77e5\u8bc6\u5e93\u3001\u4e0a\u4e0b\u6587\u5b58\u50a8\u5e93\u548c\u6848\u4f8b\u5e93\uff1b2)\u751f\u6210\u63a8\u7406\u4e0e\u53cd\u601d\u4f18\u5316\u9636\u6bb5\u6574\u5408\u7edf\u8ba1\u7279\u5f81\u3001\u5148\u9a8c\u77e5\u8bc6\u3001\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u9884\u6d4b\u7b56\u7565\uff0c\u89e6\u53d1\u5143\u63a8\u7406\u5faa\u73af\u8fdb\u884c\u6301\u7eed\u81ea\u6211\u6821\u6b63\u548c\u7b56\u7565\u4f18\u5316\u3002", "result": "\u5728\u77ed\u671f\u548c\u957f\u671f\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAlphaCast\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "AlphaCast\u901a\u8fc7\u4eba\u7c7b\u667a\u6167\u4e0eLLM\u667a\u80fd\u7684\u534f\u540c\u63a8\u7406\uff0c\u6210\u529f\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u8f6c\u53d8\u4e3a\u4ea4\u4e92\u5f0f\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u548c\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.09032", "categories": ["cs.AI", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09032", "abs": "https://arxiv.org/abs/2511.09032", "authors": ["Dingji Wang", "You Lu", "Bihuan Chen", "Shuo Hao", "Haowen Jiang", "Yifan Tian", "Xin Peng"], "title": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs", "comment": "The paper has been accepted by the 40th IEEE/ACM International Conference on Automated Software Engineering, ASE 2025", "summary": "End-to-end autonomous driving systems (ADSs), with their strong capabilities in environmental perception and generalizable driving decisions, are attracting growing attention from both academia and industry. However, once deployed on public roads, ADSs are inevitably exposed to diverse driving hazards that may compromise safety and degrade system performance. This raises a strong demand for resilience of ADSs, particularly the capability to continuously monitor driving hazards and adaptively respond to potential safety violations, which is crucial for maintaining robust driving behaviors in complex driving scenarios.\n  To bridge this gap, we propose a runtime resilience-oriented framework, Argus, to mitigate the driving hazards, thus preventing potential safety violations and improving the driving performance of an ADS. Argus continuously monitors the trajectories generated by the ADS for potential hazards and, whenever the EGO vehicle is deemed unsafe, seamlessly takes control through a hazard mitigator. We integrate Argus with three state-of-the-art end-to-end ADSs, i.e., TCP, UniAD and VAD. Our evaluation has demonstrated that Argus effectively and efficiently enhances the resilience of ADSs, improving the driving score of the ADS by up to 150.30% on average, and preventing up to 64.38% of the violations, with little additional time overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aArgus\u7684\u8fd0\u884c\u65f6\u97e7\u6027\u5bfc\u5411\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u6301\u7eed\u76d1\u63a7\u8f68\u8ff9\u548c\u5371\u9669\u7f13\u89e3\u673a\u5236\u6765\u9632\u6b62\u5b89\u5168\u8fdd\u89c4\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u516c\u5171\u9053\u8def\u4e0a\u90e8\u7f72\u65f6\u4f1a\u9762\u4e34\u5404\u79cd\u9a7e\u9a76\u5371\u9669\uff0c\u9700\u8981\u5177\u5907\u6301\u7eed\u76d1\u63a7\u548c\u81ea\u9002\u5e94\u54cd\u5e94\u7684\u97e7\u6027\u80fd\u529b\u6765\u786e\u4fdd\u5b89\u5168\u3002", "method": "Argus\u6846\u67b6\u6301\u7eed\u76d1\u63a7\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u751f\u6210\u7684\u8f68\u8ff9\uff0c\u5f53\u68c0\u6d4b\u5230\u8f66\u8f86\u5904\u4e8e\u4e0d\u5b89\u5168\u72b6\u6001\u65f6\uff0c\u901a\u8fc7\u5371\u9669\u7f13\u89e3\u5668\u65e0\u7f1d\u63a5\u7ba1\u63a7\u5236\u3002", "result": "\u4e0eTCP\u3001UniAD\u548cVAD\u4e09\u4e2a\u5148\u8fdb\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u96c6\u6210\u6d4b\u8bd5\u663e\u793a\uff0cArgus\u80fd\u5c06\u9a7e\u9a76\u8bc4\u5206\u5e73\u5747\u63d0\u5347150.30%\uff0c\u9632\u6b6264.38%\u7684\u8fdd\u89c4\u884c\u4e3a\uff0c\u4e14\u65f6\u95f4\u5f00\u9500\u5f88\u5c0f\u3002", "conclusion": "Argus\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u97e7\u6027\uff0c\u663e\u8457\u6539\u5584\u9a7e\u9a76\u6027\u80fd\u5e76\u9884\u9632\u5b89\u5168\u8fdd\u89c4\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.09044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09044", "abs": "https://arxiv.org/abs/2511.09044", "authors": ["Yousef Emami", "Radha Reddy", "Azadeh Pourkabirian", "Miguel Gutierrez Gaitan"], "title": "Advancing Autonomous Emergency Response Systems: A Generative AI Perspective", "comment": "8 pages, 3 figures, 2 tables", "summary": "Autonomous Vehicles (AVs) are poised to revolutionize emergency services by enabling faster, safer, and more efficient responses. This transformation is driven by advances in Artificial Intelligence (AI), particularly Reinforcement Learning (RL), which allows AVs to navigate complex environments and make critical decisions in real time. However, conventional RL paradigms often suffer from poor sample efficiency and lack adaptability in dynamic emergency scenarios. This paper reviews next-generation AV optimization strategies to address these limitations. We analyze the shift from conventional RL to Diffusion Model (DM)-augmented RL, which enhances policy robustness through synthetic data generation, albeit with increased computational cost. Additionally, we explore the emerging paradigm of Large Language Model (LLM)-assisted In-Context Learning (ICL), which offers a lightweight and interpretable alternative by enabling rapid, on-the-fly adaptation without retraining. By reviewing the state of the art in AV intelligence, DM-augmented RL, and LLM-assisted ICL, this paper provides a critical framework for understanding the next generation of autonomous emergency response systems from a Generative AI perspective.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4e0b\u4e00\u4ee3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u7d27\u6025\u670d\u52a1\u4e2d\u7684\u4f18\u5316\u7b56\u7565\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u4ece\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5411\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u8f6c\u53d8\uff0c\u4e3a\u7406\u89e3\u57fa\u4e8e\u751f\u6210AI\u7684\u81ea\u4e3b\u5e94\u6025\u54cd\u5e94\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6709\u671b\u901a\u8fc7\u66f4\u5feb\u3001\u66f4\u5b89\u5168\u3001\u66f4\u9ad8\u6548\u7684\u54cd\u5e94\u6765\u9769\u65b0\u7d27\u6025\u670d\u52a1\uff0c\u4f46\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u52a8\u6001\u7d27\u6025\u573a\u666f\u4e2d\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u548c\u9002\u5e94\u6027\u5dee\u7684\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u4f18\u5316\u7b56\u7565\u3002", "method": "\u5206\u6790\u4e86\u4ece\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5230\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u7684\u8f6c\u53d8\uff08\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u589e\u5f3a\u7b56\u7565\u9c81\u68d2\u6027\uff09\uff0c\u4ee5\u53ca\u65b0\u5174\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u8303\u5f0f\uff08\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u5373\u65f6\u9002\u5e94\u80fd\u529b\uff09\u3002", "result": "\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8\u4e86\u7b56\u7565\u9c81\u68d2\u6027\u4f46\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u4e86\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u5feb\u901f\u9002\u5e94\u80fd\u529b\uff0c\u4e3a\u81ea\u4e3b\u5e94\u6025\u54cd\u5e94\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e92\u8865\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u7efc\u8ff0\u81ea\u52a8\u9a7e\u9a76\u667a\u80fd\u3001\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6700\u65b0\u6280\u672f\uff0c\u672c\u6587\u4e3a\u7406\u89e3\u4e0b\u4e00\u4ee3\u57fa\u4e8e\u751f\u6210AI\u7684\u81ea\u4e3b\u5e94\u6025\u54cd\u5e94\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u6846\u67b6\u3002"}}
{"id": "2511.09092", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.09092", "abs": "https://arxiv.org/abs/2511.09092", "authors": ["Zezhen Ding", "Zhen Tan", "Jiheng Zhang", "Tianlong Chen"], "title": "OR-R1: Automating Modeling and Solving of Operations Research Optimization Problem via Test-Time Reinforcement Learning", "comment": "9 pages, 5 figures, AAAI 2026", "summary": "Optimization modeling and solving are fundamental to the application of Operations Research (OR) in real-world decision making, yet the process of translating natural language problem descriptions into formal models and solver code remains highly expertise intensive. While recent advances in large language models (LLMs) have opened new opportunities for automation, the generalization ability and data efficiency of existing LLM-based methods are still limited, asmost require vast amounts of annotated or synthetic data, resulting in high costs and scalability barriers. In this work, we present OR-R1, a data-efficient training framework for automated optimization modeling and solving. OR-R1 first employs supervised fine-tuning (SFT) to help the model acquire the essential reasoning patterns for problem formulation and code generation from limited labeled data. In addition, it improves the capability and consistency through Test-Time Group Relative Policy Optimization (TGRPO). This two-stage design enables OR-R1 to leverage both scarce labeled and abundant unlabeled data for effective learning. Experiments show that OR-R1 achieves state-of-the-art performance with an average solving accuracy of $67.7\\%$, using only $1/10$ the synthetic data required by prior methods such as ORLM, exceeding ORLM's solving accuracy by up to $4.2\\%$. Remarkably, OR-R1 outperforms ORLM by over $2.4\\%$ with just $100$ synthetic samples. Furthermore, TGRPO contributes an additional $3.1\\%-6.4\\%$ improvement in accuracy, significantly narrowing the gap between single-attempt (Pass@1) and multi-attempt (Pass@8) performance from $13\\%$ to $7\\%$. Extensive evaluations across diverse real-world benchmarks demonstrate that OR-R1 provides a robust, scalable, and cost-effective solution for automated OR optimization problem modeling and solving, lowering the expertise and data barriers for industrial OR applications.", "AI": {"tldr": "OR-R1\u662f\u4e00\u4e2a\u6570\u636e\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u4f18\u5316\u5efa\u6a21\u548c\u6c42\u89e3\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u6d4b\u8bd5\u65f6\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u4e24\u9636\u6bb5\u8bbe\u8ba1\uff0c\u4ec5\u97001/10\u7684\u5408\u6210\u6570\u636e\u5373\u53ef\u8fbe\u523067.7%\u7684\u5e73\u5747\u6c42\u89e3\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\u5efa\u6a21\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6216\u5408\u6210\u6570\u636e\uff0c\u5bfc\u81f4\u6210\u672c\u9ad8\u4e14\u53ef\u6269\u5c55\u6027\u5dee\uff0c\u9700\u8981\u5f00\u53d1\u6570\u636e\u6548\u7387\u66f4\u9ad8\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u9996\u5148\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u4ece\u6709\u9650\u6807\u6ce8\u6570\u636e\u4e2d\u5b66\u4e60\u95ee\u9898\u5efa\u6a21\u548c\u4ee3\u7801\u751f\u6210\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u7136\u540e\u901a\u8fc7\u6d4b\u8bd5\u65f6\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u63d0\u5347\u80fd\u529b\u548c\u4e00\u81f4\u6027\u3002", "result": "OR-R1\u4ec5\u97001/10\u7684\u5408\u6210\u6570\u636e\u5c31\u8fbe\u523067.7%\u7684\u5e73\u5747\u6c42\u89e3\u51c6\u786e\u7387\uff0c\u6bd4ORLM\u65b9\u6cd5\u9ad8\u51fa4.2%\uff0c\u5728\u4ec5100\u4e2a\u5408\u6210\u6837\u672c\u65f6\u4ecd\u80fd\u8d85\u8d8aORLM 2.4%\u4ee5\u4e0a\uff0cTGRPO\u8d21\u732e\u4e863.1%-6.4%\u7684\u989d\u5916\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "OR-R1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u3001\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u81ea\u52a8\u5316\u8fd0\u7b79\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u548c\u6c42\u89e3\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5de5\u4e1a\u5e94\u7528\u7684\u4e13\u5bb6\u77e5\u8bc6\u548c\u6570\u636e\u58c1\u5792\u3002"}}
{"id": "2511.09158", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09158", "abs": "https://arxiv.org/abs/2511.09158", "authors": ["Yuhao Wang", "Xiaopeng Li", "Cheng Gong", "Ziru Liu", "Suiyun Zhang", "Rui Liu", "Xiangyu Zhao"], "title": "Efficient Reasoning via Reward Model", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has been shown to enhance the reasoning capabilities of large language models (LLMs), enabling the development of large reasoning models (LRMs). However, LRMs such as DeepSeek-R1 and OpenAI o1 often generate verbose responses containing redundant or irrelevant reasoning step-a phenomenon known as overthinking-which substantially increases computational costs. Prior efforts to mitigate this issue commonly incorporate length penalties into the reward function, but we find they frequently suffer from two critical issues: length collapse and training collapse, resulting in sub-optimal performance. To address them, we propose a pipeline for training a Conciseness Reward Model (CRM) that scores the conciseness of reasoning path. Additionally, we introduce a novel reward formulation named Conciseness Reward Function (CRF) with explicit dependency between the outcome reward and conciseness score, thereby fostering both more effective and more efficient reasoning. From a theoretical standpoint, we demonstrate the superiority of the new reward from the perspective of variance reduction and improved convergence properties. Besides, on the practical side, extensive experiments on five mathematical benchmark datasets demonstrate the method's effectiveness and token efficiency, which achieves an 8.1% accuracy improvement and a 19.9% reduction in response token length on Qwen2.5-7B. Furthermore, the method generalizes well to other LLMs including Llama and Mistral. The implementation code and datasets are publicly available for reproduction: https://anonymous.4open.science/r/CRM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u8bad\u7ec3\u7b80\u6d01\u6027\u5956\u52b1\u6a21\u578b\uff08CRM\uff09\u7684\u6d41\u7a0b\u548c\u7b80\u6d01\u6027\u5956\u52b1\u51fd\u6570\uff08CRF\uff09\uff0c\u901a\u8fc7\u51cf\u5c11\u63a8\u7406\u8def\u5f84\u4e2d\u7684\u5197\u4f59\u5185\u5bb9\u6765\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u6570\u5b66\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u51c6\u786e\u7387\u63d0\u5347\u548c\u54cd\u5e94\u957f\u5ea6\u51cf\u5c11\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08\u5982DeepSeek-R1\u548cOpenAI o1\uff09\u7ecf\u5e38\u751f\u6210\u5305\u542b\u5197\u4f59\u6216\u65e0\u5173\u63a8\u7406\u6b65\u9aa4\u7684\u5197\u957f\u54cd\u5e94\uff08\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff09\uff0c\u8fd9\u4f1a\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002\u73b0\u6709\u7684\u957f\u5ea6\u60e9\u7f5a\u65b9\u6cd5\u5b58\u5728\u957f\u5ea6\u5d29\u6e83\u548c\u8bad\u7ec3\u5d29\u6e83\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8bad\u7ec3\u7b80\u6d01\u6027\u5956\u52b1\u6a21\u578b\uff08CRM\uff09\u6765\u5bf9\u63a8\u7406\u8def\u5f84\u7684\u7b80\u6d01\u6027\u8fdb\u884c\u8bc4\u5206\uff0c\u5e76\u5f15\u5165\u65b0\u9896\u7684\u7b80\u6d01\u6027\u5956\u52b1\u51fd\u6570\uff08CRF\uff09\uff0c\u5728\u7ed3\u679c\u5956\u52b1\u548c\u7b80\u6d01\u6027\u8bc4\u5206\u4e4b\u95f4\u5efa\u7acb\u663e\u5f0f\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u5b66\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Qwen2.5-7B\u4e0a\u5b9e\u73b0\u4e868.1%\u7684\u51c6\u786e\u7387\u63d0\u5347\u548c19.9%\u7684\u54cd\u5e94token\u957f\u5ea6\u51cf\u5c11\uff0c\u5e76\u4e14\u5728Llama\u548cMistral\u7b49\u5176\u4ed6LLM\u4e0a\u4e5f\u6709\u826f\u597d\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u65b0\u5956\u52b1\u5728\u65b9\u5dee\u51cf\u5c11\u548c\u6539\u8fdb\u6536\u655b\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\uff0c\u5b9e\u8df5\u4e0a\u6709\u6548\u89e3\u51b3\u4e86\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2511.09178", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09178", "abs": "https://arxiv.org/abs/2511.09178", "authors": ["Niclas Flehmig", "Mary Ann Lundteigen", "Shen Yin"], "title": "Perspectives on a Reliability Monitoring Framework for Agentic AI Systems", "comment": null, "summary": "The implementation of agentic AI systems has the potential of providing more helpful AI systems in a variety of applications. These systems work autonomously towards a defined goal with reduced external control. Despite their potential, one of their flaws is the insufficient reliability which makes them especially unsuitable for high-risk domains such as healthcare or process industry. Unreliable systems pose a risk in terms of unexpected behavior during operation and mitigation techniques are needed. In this work, we derive the main reliability challenges of agentic AI systems during operation based on their characteristics. We draw the connection to traditional AI systems and formulate a fundamental reliability challenge during operation which is inherent to traditional and agentic AI systems. As our main contribution, we propose a two-layered reliability monitoring framework for agentic AI systems which consists of a out-of-distribution detection layer for novel inputs and AI transparency layer to reveal internal operations. This two-layered monitoring approach gives a human operator the decision support which is needed to decide whether an output is potential unreliable or not and intervene. This framework provides a foundation for developing mitigation techniques to reduce risk stemming from uncertain reliability during operation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u5c42\u53ef\u9760\u6027\u76d1\u63a7\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u667a\u80fdAI\u7cfb\u7edf\u5728\u8fd0\u884c\u4e2d\u7684\u53ef\u9760\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u5305\u62ec\u79bb\u7fa4\u68c0\u6d4b\u5c42\u548cAI\u900f\u660e\u5ea6\u5c42\uff0c\u4e3a\u4eba\u7c7b\u64cd\u4f5c\u5458\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u667a\u80fdAI\u7cfb\u7edf\u5728\u533b\u7597\u548c\u6d41\u7a0b\u5de5\u4e1a\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u65f6\uff0c\u7531\u4e8e\u53ef\u9760\u6027\u4e0d\u8db3\u800c\u5b58\u5728\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u7f13\u89e3\u6280\u672f\u6765\u5e94\u5bf9\u8fd0\u884c\u4e2d\u7684\u610f\u5916\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u53cc\u5c42\u53ef\u9760\u6027\u76d1\u63a7\u6846\u67b6\uff1a\u7b2c\u4e00\u5c42\u7528\u4e8e\u68c0\u6d4b\u65b0\u9896\u8f93\u5165\u7684\u79bb\u7fa4\u5206\u5e03\uff0c\u7b2c\u4e8c\u5c42\u901a\u8fc7AI\u900f\u660e\u5ea6\u63ed\u793a\u5185\u90e8\u64cd\u4f5c\uff0c\u4e3a\u4eba\u7c7b\u64cd\u4f5c\u5458\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u7f13\u89e3\u6280\u672f\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u80fd\u591f\u51cf\u5c11\u56e0\u8fd0\u884c\u4e2d\u53ef\u9760\u6027\u4e0d\u786e\u5b9a\u800c\u4ea7\u751f\u7684\u98ce\u9669\u3002", "conclusion": "\u53cc\u5c42\u76d1\u63a7\u6846\u67b6\u80fd\u591f\u6709\u6548\u652f\u6301\u4eba\u7c7b\u64cd\u4f5c\u5458\u5224\u65ad\u8f93\u51fa\u662f\u5426\u53ef\u9760\u5e76\u9002\u65f6\u5e72\u9884\uff0c\u63d0\u5347\u667a\u80fdAI\u7cfb\u7edf\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.09247", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09247", "abs": "https://arxiv.org/abs/2511.09247", "authors": ["Yi-Hsien Hsieh", "Ta-Jung Chien", "Chun-Kai Huang", "Shao-Hua Sun", "Che Lin"], "title": "MedFuse: Multiplicative Embedding Fusion For Irregular Clinical Time Series", "comment": null, "summary": "Clinical time series derived from electronic health records (EHRs) are inherently irregular, with asynchronous sampling, missing values, and heterogeneous feature dynamics. While numerical laboratory measurements are highly informative, existing embedding strategies usually combine feature identity and value embeddings through additive operations, which constrains their ability to capture value-dependent feature interactions. We propose MedFuse, a framework for irregular clinical time series centered on the MuFuse (Multiplicative Embedding Fusion) module. MuFuse fuses value and feature embeddings through multiplicative modulation, preserving feature-specific information while modeling higher-order dependencies across features. Experiments on three real-world datasets covering both intensive and chronic care show that MedFuse consistently outperforms state-of-the-art baselines on key predictive tasks. Analysis of the learned representations further demonstrates that multiplicative fusion enhances expressiveness and supports cross-dataset pretraining. These results establish MedFuse as a generalizable approach for modeling irregular clinical time series.", "AI": {"tldr": "MedFuse\u662f\u4e00\u4e2a\u7528\u4e8e\u4e0d\u89c4\u5219\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e58\u6cd5\u878d\u5408\u6a21\u5757MuFuse\u5c06\u7279\u5f81\u503c\u548c\u7279\u5f81\u8eab\u4efd\u5d4c\u5165\u8fdb\u884c\u4e58\u6cd5\u8c03\u5236\uff0c\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u5b58\u5728\u4e0d\u89c4\u5219\u6027\u3001\u5f02\u6b65\u91c7\u6837\u3001\u7f3a\u5931\u503c\u548c\u5f02\u8d28\u7279\u5f81\u52a8\u6001\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u5d4c\u5165\u7b56\u7565\u901a\u5e38\u901a\u8fc7\u52a0\u6cd5\u64cd\u4f5c\u7ed3\u5408\u7279\u5f81\u8eab\u4efd\u548c\u503c\u5d4c\u5165\uff0c\u9650\u5236\u4e86\u6355\u6349\u503c\u4f9d\u8d56\u7279\u5f81\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faMedFuse\u6846\u67b6\uff0c\u6838\u5fc3\u662fMuFuse\u6a21\u5757\uff0c\u901a\u8fc7\u4e58\u6cd5\u8c03\u5236\u878d\u5408\u503c\u548c\u7279\u5f81\u5d4c\u5165\uff0c\u4fdd\u7559\u7279\u5f81\u7279\u5b9a\u4fe1\u606f\u7684\u540c\u65f6\u5efa\u6a21\u8de8\u7279\u5f81\u7684\u9ad8\u9636\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u6db5\u76d6\u91cd\u75c7\u548c\u6162\u6027\u62a4\u7406\u7684\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cMedFuse\u5728\u5173\u952e\u9884\u6d4b\u4efb\u52a1\u4e0a\u4e00\u81f4\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5b66\u4e60\u8868\u793a\u5206\u6790\u663e\u793a\u4e58\u6cd5\u878d\u5408\u589e\u5f3a\u4e86\u8868\u8fbe\u80fd\u529b\u5e76\u652f\u6301\u8de8\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u3002", "conclusion": "MedFuse\u4e3a\u5efa\u6a21\u4e0d\u89c4\u5219\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6cdb\u5316\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.09275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09275", "abs": "https://arxiv.org/abs/2511.09275", "authors": ["Minlan Shao", "Zijian Zhang", "Yili Wang", "Yiwei Dai", "Xu Shen", "Xin Wang"], "title": "HyperD: Hybrid Periodicity Decoupling Framework for Traffic Forecasting", "comment": null, "summary": "Accurate traffic forecasting plays a vital role in intelligent transportation systems, enabling applications such as congestion control, route planning, and urban mobility optimization.However, traffic forecasting remains challenging due to two key factors: (1) complex spatial dependencies arising from dynamic interactions between road segments and traffic sensors across the network, and (2) the coexistence of multi-scale periodic patterns (e.g., daily and weekly periodic patterns driven by human routines) with irregular fluctuations caused by unpredictable events (e.g., accidents, weather, or construction). To tackle these challenges, we propose HyperD (Hybrid Periodic Decoupling), a novel framework that decouples traffic data into periodic and residual components. The periodic component is handled by the Hybrid Periodic Representation Module, which extracts fine-grained daily and weekly patterns using learnable periodic embeddings and spatial-temporal attention. The residual component, which captures non-periodic, high-frequency fluctuations, is modeled by the Frequency-Aware Residual Representation Module, leveraging complex-valued MLP in frequency domain. To enforce semantic separation between the two components, we further introduce a Dual-View Alignment Loss, which aligns low-frequency information with the periodic branch and high-frequency information with the residual branch. Extensive experiments on four real-world traffic datasets demonstrate that HyperD achieves state-of-the-art prediction accuracy, while offering superior robustness under disturbances and improved computational efficiency compared to existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHyperD\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4ea4\u901a\u6570\u636e\u5206\u89e3\u4e3a\u5468\u671f\u6027\u548c\u6b8b\u5dee\u5206\u91cf\u6765\u89e3\u51b3\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u591a\u5c3a\u5ea6\u5468\u671f\u6027\u6a21\u5f0f\u6311\u6218\uff0c\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u4ea4\u901a\u9884\u6d4b\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u590d\u6742\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u591a\u5c3a\u5ea6\u5468\u671f\u6027\u6a21\u5f0f\u4e0e\u4e0d\u89c4\u5219\u6ce2\u52a8\u7684\u5171\u5b58\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u56e0\u7d20\u3002", "method": "\u63d0\u51faHyperD\u6846\u67b6\uff0c\u5305\u542b\u6df7\u5408\u5468\u671f\u8868\u793a\u6a21\u5757\uff08\u5904\u7406\u5468\u671f\u6027\u5206\u91cf\uff09\u548c\u9891\u7387\u611f\u77e5\u6b8b\u5dee\u8868\u793a\u6a21\u5757\uff08\u5904\u7406\u975e\u5468\u671f\u6027\u6ce2\u52a8\uff09\uff0c\u5e76\u5f15\u5165\u53cc\u89c6\u56fe\u5bf9\u9f50\u635f\u5931\u6765\u5f3a\u5236\u8bed\u4e49\u5206\u79bb\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHyperD\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5728\u5e72\u6270\u4e0b\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "HyperD\u901a\u8fc7\u89e3\u8026\u5468\u671f\u6027\u548c\u6b8b\u5dee\u5206\u91cf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09287", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09287", "abs": "https://arxiv.org/abs/2511.09287", "authors": ["Roland Aydin", "Christian Cyron", "Steve Bachelor", "Ashton Anderson", "Robert West"], "title": "From Model Training to Model Raising - A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development", "comment": "Accepted for publication in Communications of the ACM (CACM), Opinion section", "summary": "Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from \"model training\" to \"model raising\", in which alignment is woven into a model's development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ece\"\u6a21\u578b\u8bad\u7ec3\"\u8f6c\u5411\"\u6a21\u578b\u57f9\u80b2\"\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5c06\u4ef7\u503c\u89c2\u5bf9\u9f50\u878d\u5165\u6a21\u578b\u5f00\u53d1\u5168\u8fc7\u7a0b\uff0c\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u8bad\u7ec3\u8bed\u6599\u5e93\u6765\u5b9e\u73b0\u65e9\u671f\u4ef7\u503c\u89c2\u627f\u8bfa\u3002", "motivation": "\u5f53\u524dAI\u8bad\u7ec3\u65b9\u6cd5\u53ea\u5728\u6a21\u578b\u6838\u5fc3\u80fd\u529b\u5efa\u7acb\u540e\u624d\u8fdb\u884c\u4ef7\u503c\u89c2\u5bf9\u9f50\uff0c\u5bfc\u81f4\u6a21\u578b\u5bb9\u6613\u5931\u51c6\u4e14\u7f3a\u4e4f\u6df1\u5c42\u6b21\u4ef7\u503c\u4f53\u7cfb\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u9010\u6e10\u8d85\u8d8a\u4eba\u7c7b\uff0c\u8fd9\u79cd\u6df1\u5c42\u4ef7\u503c\u89c2\u6574\u5408\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1\u8bad\u7ec3\u8bed\u6599\u5e93\uff1a\u91c7\u7528\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u91cd\u6784\u8bad\u7ec3\u6570\u636e\u3001\u5c06\u4fe1\u606f\u91cd\u65b0\u60c5\u5883\u5316\u4e3a\u751f\u6d3b\u7ecf\u9a8c\u3001\u6a21\u62df\u793e\u4f1a\u4e92\u52a8\u3001\u4ee5\u53ca\u642d\u5efa\u8bad\u7ec3\u6570\u636e\u6392\u5e8f\u7684\u811a\u624b\u67b6\u3002", "result": "\u9884\u671f\u8fd9\u79cd\u8bad\u7ec3\u8bed\u6599\u5e93\u7684\u91cd\u65b0\u8bbe\u8ba1\u5c06\u5b9e\u73b0\u4ece\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u6807\u8bb0\u5f00\u59cb\u7684\u65e9\u671f\u4ef7\u503c\u89c2\u627f\u8bfa\uff0c\u4f7f\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u4ef7\u503c\u89c2\u5185\u5728\u96be\u4ee5\u5206\u79bb\u3002", "conclusion": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u5f00\u59cb\u8d85\u8d8a\u4eba\u7c7b\u80fd\u529b\u7684\u751f\u6001\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u79cd\u4ece\u6a21\u578b\u8bad\u7ec3\u8f6c\u5411\u6a21\u578b\u57f9\u80b2\u7684\u8303\u5f0f\u8f6c\u53d8\u662f\u81f3\u5173\u91cd\u8981\u7684\u9700\u6c42\u3002"}}
{"id": "2511.09325", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09325", "abs": "https://arxiv.org/abs/2511.09325", "authors": ["Stine Beltoft", "Lukas Galke"], "title": "Not Everything That Counts Can Be Counted: A Case for Safe Qualitative AI", "comment": "Accepted at 3rd International Conference on Frontiers of Artificial Intelligence, Ethics, and Multidisciplinary Applications (FAIEMA 2025)", "summary": "Artificial intelligence (AI) and large language models (LLM) are reshaping science, with most recent advances culminating in fully-automated scientific discovery pipelines. But qualitative research has been left behind. Researchers in qualitative methods are hesitant about AI adoption. Yet when they are willing to use AI at all, they have little choice but to rely on general-purpose tools like ChatGPT to assist with interview interpretation, data annotation, and topic modeling - while simultaneously acknowledging these system's well-known limitations of being biased, opaque, irreproducible, and privacy-compromising. This creates a critical gap: while AI has substantially advanced quantitative methods, the qualitative dimensions essential for meaning-making and comprehensive scientific understanding remain poorly integrated. We argue for developing dedicated qualitative AI systems built from the ground up for interpretive research. Such systems must be transparent, reproducible, and privacy-friendly. We review recent literature to show how existing automated discovery pipelines could be enhanced by robust qualitative capabilities, and identify key opportunities where safe qualitative AI could advance multidisciplinary and mixed-methods research.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5f00\u53d1\u4e13\u95e8\u4e3a\u5b9a\u6027\u7814\u7a76\u8bbe\u8ba1\u7684AI\u7cfb\u7edf\uff0c\u4ee5\u5f25\u8865\u5f53\u524dAI\u5728\u5b9a\u6027\u7814\u7a76\u4e2d\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u7cfb\u7edf\u9700\u8981\u5177\u5907\u900f\u660e\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u9690\u79c1\u53cb\u597d\u6027\u3002", "motivation": "\u5f53\u524dAI\u4e3b\u8981\u63a8\u52a8\u4e86\u5b9a\u91cf\u65b9\u6cd5\u7684\u53d1\u5c55\uff0c\u4f46\u5b9a\u6027\u7814\u7a76\u9886\u57df\u88ab\u5ffd\u89c6\u3002\u7814\u7a76\u4eba\u5458\u88ab\u8feb\u4f7f\u7528\u901a\u7528AI\u5de5\u5177\u5982ChatGPT\uff0c\u4f46\u8fd9\u4e9b\u5de5\u5177\u5b58\u5728\u504f\u89c1\u3001\u4e0d\u900f\u660e\u3001\u4e0d\u53ef\u91cd\u590d\u548c\u9690\u79c1\u95ee\u9898\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9a\u6027\u7814\u7a76\u7684\u4e13\u4e1a\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u6587\u732e\u56de\u987e\u5206\u6790\u73b0\u6709\u81ea\u52a8\u5316\u53d1\u73b0\u6d41\u7a0b\u5982\u4f55\u901a\u8fc7\u589e\u5f3a\u5b9a\u6027\u80fd\u529b\u6765\u6539\u8fdb\uff0c\u5e76\u8bc6\u522b\u5b89\u5168\u5b9a\u6027AI\u5728\u591a\u5b66\u79d1\u548c\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u4e2d\u7684\u5173\u952e\u673a\u4f1a\u3002", "result": "\u53d1\u73b0AI\u5728\u5b9a\u6027\u7814\u7a76\u9886\u57df\u5b58\u5728\u4e25\u91cd\u7f3a\u53e3\uff0c\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u6ee1\u8db3\u5b9a\u6027\u7814\u7a76\u7684\u4e13\u4e1a\u8981\u6c42\uff0c\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u7684\u7cfb\u7edf\u3002", "conclusion": "\u9700\u8981\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u4e13\u95e8\u7528\u4e8e\u89e3\u91ca\u6027\u7814\u7a76\u7684\u5b9a\u6027AI\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5fc5\u987b\u900f\u660e\u3001\u53ef\u91cd\u590d\u4e14\u9690\u79c1\u53cb\u597d\uff0c\u4ee5\u63a8\u52a8\u591a\u5b66\u79d1\u548c\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.09378", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09378", "abs": "https://arxiv.org/abs/2511.09378", "authors": ["Augusto B. Corr\u00eaa", "Andr\u00e9 G. Pereira", "Jendrik Seipp"], "title": "The 2025 Planning Performance of Frontier Large Language Models", "comment": null, "summary": "The capacity of Large Language Models (LLMs) for reasoning remains an active area of research, with the capabilities of frontier models continually advancing. We provide an updated evaluation of the end-to-end planning performance of three frontier LLMs as of 2025, where models are prompted to generate a plan from PDDL domain and task descriptions. We evaluate DeepSeek R1, Gemini 2.5 Pro, GPT-5 and as reference the planner LAMA on a subset of domains from the most recent Learning Track of the International Planning Competition. Our results show that on standard PDDL domains, the performance of GPT-5 in terms of solved tasks is competitive with LAMA. When the PDDL domains and tasks are obfuscated to test for pure reasoning, the performance of all LLMs degrades, though less severely than previously reported for other models. These results show substantial improvements over prior generations of LLMs, reducing the performance gap to planners on a challenging benchmark.", "AI": {"tldr": "\u8bc4\u4f30\u4e862025\u5e74\u4e09\u4e2a\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\uff08DeepSeek R1\u3001Gemini 2.5 Pro\u3001GPT-5\uff09\u5728PDDL\u89c4\u5212\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0GPT-5\u5728\u6807\u51c6PDDL\u9886\u57df\u4e0eLAMA\u89c4\u5212\u5668\u7ade\u4e89\uff0c\u4f46\u5728\u6df7\u6dc6\u6d4b\u8bd5\u4e2d\u6240\u6709\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u8bc4\u4f30\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7aef\u5230\u7aef\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e86\u89e3\u5b83\u4eec\u4e0e\u4e13\u4e1a\u89c4\u5212\u5668\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528\u56fd\u9645\u89c4\u5212\u7ade\u8d5b\u5b66\u4e60\u8f68\u9053\u7684PDDL\u9886\u57df\u5b50\u96c6\uff0c\u5bf9\u4e09\u4e2a\u524d\u6cbfLLM\u8fdb\u884c\u6807\u51c6PDDL\u548c\u6df7\u6dc6PDDL\u4efb\u52a1\u7684\u89c4\u5212\u6027\u80fd\u6d4b\u8bd5\uff0c\u5e76\u4e0eLAMA\u89c4\u5212\u5668\u5bf9\u6bd4\u3002", "result": "GPT-5\u5728\u6807\u51c6PDDL\u4efb\u52a1\u4e2d\u4e0eLAMA\u89c4\u5212\u5668\u8868\u73b0\u76f8\u5f53\uff0c\u6240\u6709LLM\u5728\u6df7\u6dc6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4e0b\u964d\u4f46\u7a0b\u5ea6\u6bd4\u4e4b\u524d\u6a21\u578b\u8f7b\uff0c\u663e\u793a\u76f8\u6bd4\u524d\u4ee3LLM\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u524d\u6cbfLLM\u5728\u89c4\u5212\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u5b9e\u8d28\u6027\u8fdb\u6b65\uff0c\u7f29\u5c0f\u4e86\u4e0e\u4e13\u4e1a\u89c4\u5212\u5668\u5728\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2511.09433", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09433", "abs": "https://arxiv.org/abs/2511.09433", "authors": ["Brian Rogers", "Micah Bowles", "Chris J. Lintott", "Steve Croft"], "title": "What We Don't C: Representations for scientific discovery beyond VAEs", "comment": "Accepted to the Machine Learning and the Physical Sciences workshop at NeurIPS 2025", "summary": "Accessing information in learned representations is critical for scientific discovery in high-dimensional domains. We introduce a novel method based on latent flow matching with classifier-free guidance that disentangles latent subspaces by explicitly separating information included in conditioning from information that remains in the residual representation. Across three experiments -- a synthetic 2D Gaussian toy problem, colored MNIST, and the Galaxy10 astronomy dataset -- we show that our method enables access to meaningful features of high dimensional data. Our results highlight a simple yet powerful mechanism for analyzing, controlling, and repurposing latent representations, providing a pathway toward using generative models for scientific exploration of what we don't capture, consider, or catalog.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u6d41\u5339\u914d\u548c\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5206\u79bb\u6761\u4ef6\u4fe1\u606f\u4e0e\u6b8b\u5dee\u8868\u793a\u6765\u89e3\u8026\u6f5c\u5728\u5b50\u7a7a\u95f4\uff0c\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u8bbf\u95ee\u9ad8\u7ef4\u6570\u636e\u7684\u6709\u610f\u4e49\u7279\u5f81\u3002", "motivation": "\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u8bbf\u95ee\u5b66\u4e60\u8868\u793a\u4e2d\u7684\u4fe1\u606f\u5bf9\u4e8e\u9ad8\u7ef4\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u5206\u6790\u3001\u63a7\u5236\u548c\u91cd\u65b0\u5229\u7528\u6f5c\u5728\u8868\u793a\u3002", "method": "\u57fa\u4e8e\u6f5c\u5728\u6d41\u5339\u914d\u4e0e\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u7684\u65b9\u6cd5\uff0c\u663e\u5f0f\u5206\u79bb\u6761\u4ef6\u4fe1\u606f\u4e0e\u6b8b\u5dee\u8868\u793a\uff0c\u5b9e\u73b0\u6f5c\u5728\u5b50\u7a7a\u95f4\u7684\u89e3\u8026\u3002", "result": "\u5728\u5408\u62102D\u9ad8\u65af\u73a9\u5177\u95ee\u9898\u3001\u5f69\u8272MNIST\u548cGalaxy10\u5929\u6587\u6570\u636e\u96c6\u4e09\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u8bbf\u95ee\u4e86\u9ad8\u7ef4\u6570\u636e\u7684\u6709\u610f\u4e49\u7279\u5f81\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f7f\u7528\u751f\u6210\u6a21\u578b\u8fdb\u884c\u79d1\u5b66\u63a2\u7d22\u63d0\u4f9b\u4e86\u4e00\u6761\u7b80\u5355\u800c\u5f3a\u5927\u7684\u9014\u5f84\uff0c\u80fd\u591f\u5206\u6790\u6211\u4eec\u672a\u6355\u83b7\u3001\u8003\u8651\u6216\u7f16\u76ee\u7684\u4fe1\u606f\u3002"}}
{"id": "2511.09483", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09483", "abs": "https://arxiv.org/abs/2511.09483", "authors": ["Peiyu Li", "Xiaobao Huang", "Nitesh V. Chawla"], "title": "CrochetBench: Can Vision-Language Models Move from Describing to Doing in Crochet Domain?", "comment": "code available at https://github.com/Peiyu-Georgia-Li/crochetBench", "summary": "We present CrochetBench, a benchmark for evaluating the ability of multimodal large language models to perform fine-grained, low-level procedural reasoning in the domain of crochet. Unlike prior benchmarks that focus on high-level description or visual question answering, CrochetBench shifts the emphasis from describing to doing: models are required to recognize stitches, select structurally appropriate instructions, and generate compilable crochet procedures. We adopt the CrochetPARADE DSL as our intermediate representation, enabling structural validation and functional evaluation via execution. The benchmark covers tasks including stitch classification, instruction grounding, and both natural language and image-to-DSL translation. Across all tasks, performance sharply declines as the evaluation shifts from surface-level similarity to executable correctness, exposing limitations in long-range symbolic reasoning and 3D-aware procedural synthesis. CrochetBench offers a new lens for assessing procedural competence in multimodal models and highlights the gap between surface-level understanding and executable precision in real-world creative domains. Code is available at https://github.com/Peiyu-Georgia-Li/crochetBench.", "AI": {"tldr": "CrochetBench\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u94a9\u9488\u7f16\u7ec7\u9886\u57df\u8fdb\u884c\u7ec6\u7c92\u5ea6\u3001\u4f4e\u5c42\u6b21\u7a0b\u5e8f\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f3a\u8c03\u4ece\u63cf\u8ff0\u8f6c\u5411\u5b9e\u9645\u64cd\u4f5c\uff0c\u8981\u6c42\u6a21\u578b\u8bc6\u522b\u9488\u6cd5\u3001\u9009\u62e9\u7ed3\u6784\u9002\u5f53\u7684\u6307\u4ee4\u5e76\u751f\u6210\u53ef\u7f16\u8bd1\u7684\u94a9\u9488\u7a0b\u5e8f\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u9ad8\u5c42\u6b21\u63cf\u8ff0\u6216\u89c6\u89c9\u95ee\u7b54\uff0c\u7f3a\u4e4f\u5bf9\u5b9e\u9645\u64cd\u4f5c\u80fd\u529b\u7684\u8bc4\u4f30\u3002CrochetBench\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u8bc4\u4f30\u6a21\u578b\u5728\u771f\u5b9e\u521b\u9020\u6027\u9886\u57df\u4e2d\u7684\u7a0b\u5e8f\u80fd\u529b\uff0c\u63ed\u793a\u8868\u9762\u7406\u89e3\u4e0e\u53ef\u6267\u884c\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u91c7\u7528CrochetPARADE DSL\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u652f\u6301\u7ed3\u6784\u9a8c\u8bc1\u548c\u901a\u8fc7\u6267\u884c\u8fdb\u884c\u529f\u80fd\u8bc4\u4f30\u3002\u57fa\u51c6\u6d4b\u8bd5\u6db5\u76d6\u9488\u6cd5\u5206\u7c7b\u3001\u6307\u4ee4\u63a5\u5730\u4ee5\u53ca\u81ea\u7136\u8bed\u8a00\u548c\u56fe\u50cf\u5230DSL\u7684\u7ffb\u8bd1\u4efb\u52a1\u3002", "result": "\u5728\u6240\u6709\u4efb\u52a1\u4e2d\uff0c\u5f53\u8bc4\u4f30\u4ece\u8868\u9762\u76f8\u4f3c\u6027\u8f6c\u5411\u53ef\u6267\u884c\u6b63\u786e\u6027\u65f6\uff0c\u6a21\u578b\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u66b4\u9732\u51fa\u5728\u957f\u8ddd\u79bb\u7b26\u53f7\u63a8\u7406\u548c3D\u611f\u77e5\u7a0b\u5e8f\u5408\u6210\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "conclusion": "CrochetBench\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u7a0b\u5e8f\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u7a81\u663e\u4e86\u5728\u771f\u5b9e\u521b\u9020\u6027\u9886\u57df\u4e2d\u8868\u9762\u7406\u89e3\u4e0e\u53ef\u6267\u884c\u7cbe\u5ea6\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2511.09493", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09493", "abs": "https://arxiv.org/abs/2511.09493", "authors": ["Adam Tauman Kalai", "Yael Tauman Kalai", "Or Zamir"], "title": "Consensus Sampling for Safer Generative AI", "comment": null, "summary": "Many approaches to AI safety rely on inspecting model outputs or activations, yet certain risks are inherently undetectable by inspection alone. We propose a complementary, architecture-agnostic approach that enhances safety through the aggregation of multiple generative models, with the aggregated model inheriting its safety from the safest subset of a given size among them. Specifically, we present a consensus sampling algorithm that, given $k$ models and a prompt, achieves risk competitive with the average risk of the safest $s$ of the $k$ models, where $s$ is a chosen parameter, while abstaining when there is insufficient agreement between them. The approach leverages the models' ability to compute output probabilities, and we bound the probability of abstention when sufficiently many models are safe and exhibit adequate agreement. The algorithm is inspired by the provable copyright protection algorithm of Vyas et al. (2023). It requires some overlap among safe models, offers no protection when all models are unsafe, and may accumulate risk over repeated use. Nonetheless, our results provide a new, model-agnostic approach for AI safety by amplifying safety guarantees from an unknown subset of models within a collection to that of a single reliable model.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u578b\u805a\u5408\u7684AI\u5b89\u5168\u65b9\u6cd5\uff0c\u901a\u8fc7\u5171\u8bc6\u91c7\u6837\u7b97\u6cd5\u4ecek\u4e2a\u6a21\u578b\u4e2d\u9009\u62e9\u6700\u5b89\u5168\u7684s\u4e2a\u5b50\u96c6\uff0c\u5728\u6a21\u578b\u95f4\u8fbe\u6210\u8db3\u591f\u5171\u8bc6\u65f6\u8f93\u51fa\u7ed3\u679c\uff0c\u5426\u5219\u5f03\u6743\u3002", "motivation": "\u73b0\u6709AI\u5b89\u5168\u65b9\u6cd5\u4f9d\u8d56\u6a21\u578b\u8f93\u51fa\u6216\u6fc0\u6d3b\u68c0\u67e5\uff0c\u4f46\u67d0\u4e9b\u98ce\u9669\u65e0\u6cd5\u901a\u8fc7\u68c0\u67e5\u5355\u72ec\u68c0\u6d4b\uff0c\u9700\u8981\u67b6\u6784\u65e0\u5173\u7684\u8865\u5145\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5171\u8bc6\u91c7\u6837\u7b97\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u8ba1\u7b97\u8f93\u51fa\u6982\u7387\u7684\u80fd\u529b\uff0c\u5f53\u8db3\u591f\u591a\u6a21\u578b\u5b89\u5168\u4e14\u8fbe\u6210\u5171\u8bc6\u65f6\u8f93\u51fa\u7ed3\u679c\uff0c\u5426\u5219\u5f03\u6743\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u4e0ek\u4e2a\u6a21\u578b\u4e2d\u6700\u5b89\u5168\u7684s\u4e2a\u6a21\u578b\u5e73\u5747\u98ce\u9669\u76f8\u5f53\u7684\u5b89\u5168\u6027\uff0c\u5e76\u5728\u6a21\u578b\u95f4\u7f3a\u4e4f\u5171\u8bc6\u65f6\u5f03\u6743\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u65e0\u5173AI\u5b89\u5168\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u5408\u672a\u77e5\u5b89\u5168\u5b50\u96c6\u4e2d\u7684\u6a21\u578b\u6765\u589e\u5f3a\u5355\u4e00\u53ef\u9760\u6a21\u578b\u7684\u5b89\u5168\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2511.09497", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09497", "abs": "https://arxiv.org/abs/2511.09497", "authors": ["Vahid Salehi"], "title": "Fundamentals of Physical AI", "comment": "This paper is already published in Journal of Intelligent System of Systems Lifecycle Management", "summary": "This work will elaborate the fundamental principles of physical artificial intelligence (Physical AI) from a scientific and systemic perspective. The aim is to create a theoretical foundation that describes the physical embodiment, sensory perception, ability to act, learning processes, and context sensitivity of intelligent systems within a coherent framework. While classical AI approaches rely on symbolic processing and data driven models, Physical AI understands intelligence as an emergent phenomenon of real interaction between body, environment, and experience. The six fundamentals presented here are embodiment, sensory perception, motor action, learning, autonomy, and context sensitivity, and form the conceptual basis for designing and evaluating physically intelligent systems. Theoretically, it is shown that these six principles do not represent loose functional modules but rather act as a closed control loop in which energy, information, control, and context are in constant interaction. This circular interaction enables a system to generate meaning not from databases, but from physical experience, a paradigm shift that understands intelligence as an physical embodied process. Physical AI understands learning not as parameter adjustment, but as a change in the structural coupling between agents and the environment. To illustrate this, the theoretical model is explained using a practical scenario: An adaptive assistant robot supports patients in a rehabilitation clinic. This example illustrates that physical intelligence does not arise from abstract calculation, but from immediate, embodied experience. It shows how the six fundamentals interact in a real system: embodiment as a prerequisite, perception as input, movement as expression, learning as adaptation, autonomy as regulation, and context as orientation.", "AI": {"tldr": "\u672c\u6587\u4ece\u79d1\u5b66\u548c\u7cfb\u7edf\u89d2\u5ea6\u9610\u8ff0\u4e86\u7269\u7406\u4eba\u5de5\u667a\u80fd\u7684\u57fa\u672c\u539f\u7406\uff0c\u65e8\u5728\u4e3a\u667a\u80fd\u7cfb\u7edf\u7684\u7269\u7406\u4f53\u73b0\u3001\u611f\u77e5\u3001\u884c\u52a8\u3001\u5b66\u4e60\u548c\u60c5\u5883\u654f\u611f\u6027\u5efa\u7acb\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u89c6\u4e3a\u8eab\u4f53\u3001\u73af\u5883\u548c\u7ecf\u9a8c\u4e4b\u95f4\u771f\u5b9e\u4ea4\u4e92\u7684\u6d8c\u73b0\u73b0\u8c61\u3002", "motivation": "\u4f20\u7edfAI\u4f9d\u8d56\u7b26\u53f7\u5904\u7406\u548c\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u800c\u7269\u7406AI\u5c06\u667a\u80fd\u7406\u89e3\u4e3a\u8eab\u4f53\u3001\u73af\u5883\u548c\u7ecf\u9a8c\u4e4b\u95f4\u771f\u5b9e\u4ea4\u4e92\u7684\u6d8c\u73b0\u73b0\u8c61\uff0c\u9700\u8981\u5efa\u7acb\u63cf\u8ff0\u7269\u7406\u4f53\u73b0\u3001\u611f\u77e5\u3001\u884c\u52a8\u3001\u5b66\u4e60\u548c\u60c5\u5883\u654f\u611f\u6027\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u516d\u4e2a\u57fa\u672c\u539f\u7406\uff1a\u4f53\u73b0\u3001\u611f\u77e5\u3001\u8fd0\u52a8\u884c\u52a8\u3001\u5b66\u4e60\u3001\u81ea\u4e3b\u6027\u548c\u60c5\u5883\u654f\u611f\u6027\uff0c\u8fd9\u4e9b\u539f\u7406\u6784\u6210\u4e00\u4e2a\u5c01\u95ed\u7684\u63a7\u5236\u5faa\u73af\uff0c\u80fd\u91cf\u3001\u4fe1\u606f\u3001\u63a7\u5236\u548c\u60c5\u5883\u5728\u5176\u4e2d\u6301\u7eed\u4ea4\u4e92\u3002", "result": "\u7406\u8bba\u6a21\u578b\u901a\u8fc7\u5eb7\u590d\u8bca\u6240\u4e2d\u7684\u81ea\u9002\u5e94\u8f85\u52a9\u673a\u5668\u4eba\u5b9e\u4f8b\u8bf4\u660e\uff0c\u7269\u7406\u667a\u80fd\u4e0d\u662f\u6765\u81ea\u62bd\u8c61\u8ba1\u7b97\uff0c\u800c\u662f\u6765\u81ea\u76f4\u63a5\u7684\u3001\u5177\u8eab\u5316\u7684\u4f53\u9a8c\uff0c\u516d\u4e2a\u57fa\u672c\u539f\u7406\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u7269\u7406AI\u5c06\u5b66\u4e60\u7406\u89e3\u4e3a\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4e4b\u95f4\u7ed3\u6784\u8026\u5408\u7684\u53d8\u5316\uff0c\u800c\u975e\u53c2\u6570\u8c03\u6574\uff0c\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u5c06\u667a\u80fd\u7406\u89e3\u4e3a\u7269\u7406\u5177\u8eab\u5316\u8fc7\u7a0b\uff0c\u610f\u4e49\u751f\u6210\u6765\u81ea\u7269\u7406\u4f53\u9a8c\u800c\u975e\u6570\u636e\u5e93\u3002"}}
