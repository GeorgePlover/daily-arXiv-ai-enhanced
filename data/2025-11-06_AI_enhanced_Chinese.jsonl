{"id": "2511.03094", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03094", "abs": "https://arxiv.org/abs/2511.03094", "authors": ["Longling Geng", "Edward Y. Chang"], "title": "ALAS: Transactional and Dynamic Multi-Agent LLM Planning", "comment": null, "summary": "Large language models enable flexible multi-agent planning but remain fragile\nin practice: verification is often circular, state changes are not tracked for\nrepair, and small faults trigger costly global recomputation. We present ALAS,\na stateful, disruption-aware framework that separates planning from\nnon-circular validation, records a versioned execution log for grounded checks\nand restore points, and performs localized repair that preserves work in\nprogress. The validator operates independently of the planning LLM with fresh,\nbounded context, avoiding self-check loops and mid-context attrition. The\nrepair protocol edits only the minimal affected region under explicit policies\n(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)\ndefined in a canonical workflow IR that maps to Amazon States Language and Argo\nWorkflows. On job-shop scheduling suites (DMU, TA) across five classical\nbenchmarks, ALAS matches or exceeds strong single-LLM and multi-agent\nbaselines, achieving 83.7% success, reducing token usage by 60%, and running\n1.82times faster under comparable settings. A minimal reliability study shows\nthat the validator detects injected structural faults with low overhead, and\nthat localized repair contains runtime perturbations with a bounded edit radius\nand less makespan degradation than global recompute. Results indicate that the\ncombination of validator isolation, versioned execution logs, and localized\nrepair provides measurable efficiency, feasibility, and scalability for\nmulti-agent LLM planning. Code and seeds will be released.", "AI": {"tldr": "ALAS\u662f\u4e00\u4e2a\u72b6\u6001\u611f\u77e5\u3001\u6297\u5e72\u6270\u7684\u591a\u667a\u80fd\u4f53\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u89c4\u5212\u4e0e\u9a8c\u8bc1\u3001\u8bb0\u5f55\u7248\u672c\u5316\u6267\u884c\u65e5\u5fd7\u3001\u6267\u884c\u5c40\u90e8\u4fee\u590d\u6765\u89e3\u51b3LLM\u89c4\u5212\u4e2d\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u89c4\u5212\u4e2d\u8868\u73b0\u7075\u6d3b\u4f46\u5b9e\u9645\u5e94\u7528\u8106\u5f31\uff1a\u9a8c\u8bc1\u7ecf\u5e38\u5faa\u73af\u3001\u72b6\u6001\u53d8\u5316\u672a\u8ddf\u8e2a\u4fee\u590d\u3001\u5c0f\u6545\u969c\u89e6\u53d1\u6602\u8d35\u7684\u5168\u5c40\u91cd\u8ba1\u7b97\u3002", "method": "ALAS\u6846\u67b6\u5c06\u89c4\u5212\u4e0e\u975e\u5faa\u73af\u9a8c\u8bc1\u5206\u79bb\uff0c\u8bb0\u5f55\u7248\u672c\u5316\u6267\u884c\u65e5\u5fd7\u7528\u4e8e\u57fa\u7840\u68c0\u67e5\u548c\u6062\u590d\u70b9\uff0c\u6267\u884c\u5c40\u90e8\u4fee\u590d\u4ee5\u4fdd\u7559\u8fdb\u884c\u4e2d\u7684\u5de5\u4f5c\u3002\u9a8c\u8bc1\u5668\u72ec\u7acb\u4e8e\u89c4\u5212LLM\u8fd0\u884c\uff0c\u4fee\u590d\u534f\u8bae\u4ec5\u7f16\u8f91\u6700\u5c0f\u53d7\u5f71\u54cd\u533a\u57df\u3002", "result": "\u5728\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u6d4b\u8bd5\u4e2d\uff0cALAS\u8fbe\u523083.7%\u6210\u529f\u7387\uff0c\u51cf\u5c1160%token\u4f7f\u7528\uff0c\u8fd0\u884c\u901f\u5ea6\u5feb1.82\u500d\u3002\u9a8c\u8bc1\u5668\u80fd\u68c0\u6d4b\u6ce8\u5165\u7684\u7ed3\u6784\u6545\u969c\uff0c\u5c40\u90e8\u4fee\u590d\u80fd\u9650\u5236\u8fd0\u884c\u65f6\u6270\u52a8\u3002", "conclusion": "\u9a8c\u8bc1\u5668\u9694\u79bb\u3001\u7248\u672c\u5316\u6267\u884c\u65e5\u5fd7\u548c\u5c40\u90e8\u4fee\u590d\u7684\u7ed3\u5408\u4e3a\u591a\u667a\u80fd\u4f53LLM\u89c4\u5212\u63d0\u4f9b\u4e86\u53ef\u8861\u91cf\u7684\u6548\u7387\u3001\u53ef\u884c\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.03179", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03179", "abs": "https://arxiv.org/abs/2511.03179", "authors": ["Varun Kumar", "George Em Karniadakis"], "title": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework", "comment": null, "summary": "The engineering design process often demands expertise from multiple domains,\nleading to complex collaborations and iterative refinements. Traditional\nmethods can be resource-intensive and prone to inefficiencies. To address this,\nwe formalize the engineering design process through a multi-agent AI framework\nthat integrates structured design and review loops. The framework introduces\nspecialized knowledge-driven agents that collaborate to generate and refine\ndesign candidates. As an exemplar, we demonstrate its application to the\naerodynamic optimization of 4-digit NACA airfoils. The framework consists of\nthree key AI agents: a Graph Ontologist, a Design Engineer, and a Systems\nEngineer. The Graph Ontologist employs a Large Language Model (LLM) to\nconstruct two domain-specific knowledge graphs from airfoil design literature.\nThe Systems Engineer, informed by a human manager, formulates technical\nrequirements that guide design generation and evaluation. The Design Engineer\nleverages the design knowledge graph and computational tools to propose\ncandidate airfoils meeting these requirements. The Systems Engineer reviews and\nprovides feedback both qualitative and quantitative using its own knowledge\ngraph, forming an iterative feedback loop until a design is validated by the\nmanager. The final design is then optimized to maximize performance metrics\nsuch as the lift-to-drag ratio. Overall, this work demonstrates how\ncollaborative AI agents equipped with structured knowledge representations can\nenhance efficiency, consistency, and quality in the engineering design process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bbe\u8ba1\u548c\u8bc4\u5ba1\u5faa\u73af\u6765\u4f18\u5316\u5de5\u7a0b\u8bbe\u8bb4\u8fc7\u7a0b\uff0c\u5e76\u4ee5NACA\u7ffc\u578b\u6c14\u52a8\u4f18\u5316\u4e3a\u4f8b\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u5de5\u7a0b\u8bbe\u8bb4\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u591a\u9886\u57df\u4e13\u5bb6\u534f\u4f5c\uff0c\u5bfc\u81f4\u590d\u6742\u7684\u5408\u4f5c\u548c\u8fed\u4ee3\u4f18\u5316\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e09\u4e2aAI\u667a\u80fd\u4f53\u7684\u6846\u67b6\uff1a\u56fe\u672c\u4f53\u5b66\u5bb6\u4f7f\u7528LLM\u6784\u5efa\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\uff0c\u7cfb\u7edf\u5de5\u7a0b\u5e08\u5236\u5b9a\u6280\u672f\u9700\u6c42\uff0c\u8bbe\u8ba1\u5de5\u7a0b\u5e08\u751f\u6210\u5019\u9009\u8bbe\u8ba1\u5e76\u5f62\u6210\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\u3002", "result": "\u8be5\u6846\u67b6\u6210\u529f\u5e94\u7528\u4e8e4\u4f4d\u6570NACA\u7ffc\u578b\u7684\u6c14\u52a8\u4f18\u5316\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u534f\u4f5c\u751f\u6210\u5e76\u4f18\u5316\u8bbe\u8ba1\uff0c\u6700\u7ec8\u63d0\u5347\u4e86\u5347\u963b\u6bd4\u7b49\u6027\u80fd\u6307\u6807\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u914d\u5907\u7ed3\u6784\u5316\u77e5\u8bc6\u8868\u793a\u7684\u534f\u4f5cAI\u667a\u80fd\u4f53\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5de5\u7a0b\u8bbe\u8bb4\u8fc7\u7a0b\u7684\u6548\u7387\u3001\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002"}}
{"id": "2511.02997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02997", "abs": "https://arxiv.org/abs/2511.02997", "authors": ["Jon Kutasov", "Chloe Loughridge", "Yuqi Sun", "Henry Sleight", "Buck Shlegeris", "Tyler Tracy", "Joe Benton"], "title": "Evaluating Control Protocols for Untrusted AI Agents", "comment": null, "summary": "As AI systems become more capable and widely deployed as agents, ensuring\ntheir safe operation becomes critical. AI control offers one approach to\nmitigating the risk from untrusted AI agents by monitoring their actions and\nintervening or auditing when necessary. Evaluating the safety of these\nprotocols requires understanding both their effectiveness against current\nattacks and their robustness to adaptive adversaries. In this work, we\nsystematically evaluate a range of control protocols in SHADE-Arena, a dataset\nof diverse agentic environments. First, we evaluate blue team protocols,\nincluding deferral to trusted models, resampling, and deferring on critical\nactions, against a default attack policy. We find that resampling for\nincrimination and deferring on critical actions perform best, increasing safety\nfrom 50% to 96%. We then iterate on red team strategies against these protocols\nand find that attack policies with additional affordances, such as knowledge of\nwhen resampling occurs or the ability to simulate monitors, can substantially\nimprove attack success rates against our resampling strategy, decreasing safety\nto 17%. However, deferring on critical actions is highly robust to even our\nstrongest red team strategies, demonstrating the importance of denying attack\npolicies access to protocol internals.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86AI\u63a7\u5236\u534f\u8bae\u5728SHADE-Arena\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u534f\u8bae\u5bf9\u7ea2\u961f\u653b\u51fb\u5177\u6709\u9ad8\u5ea6\u9c81\u68d2\u6027\uff0c\u800c\u91cd\u91c7\u6837\u7b56\u7565\u5728\u7ea2\u961f\u83b7\u5f97\u534f\u8bae\u5185\u90e8\u4fe1\u606f\u65f6\u5b89\u5168\u6027\u5927\u5e45\u4e0b\u964d\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u4f5c\u4e3a\u667a\u80fd\u4f53\u5e7f\u6cdb\u90e8\u7f72\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u8fd0\u884c\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002AI\u63a7\u5236\u901a\u8fc7\u76d1\u63a7\u667a\u80fd\u4f53\u884c\u4e3a\u5e76\u5728\u5fc5\u8981\u65f6\u5e72\u9884\u6216\u5ba1\u8ba1\u6765\u964d\u4f4e\u4e0d\u53ef\u4fe1AI\u7684\u98ce\u9669\u3002", "method": "\u5728SHADE-Arena\u591a\u6837\u5316\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7cfb\u7edf\u8bc4\u4f30\u63a7\u5236\u534f\u8bae\uff0c\u5305\u62ec\u53ef\u4fe1\u6a21\u578b\u5ef6\u8fdf\u3001\u91cd\u91c7\u6837\u548c\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u7b49\u84dd\u961f\u534f\u8bae\uff0c\u5e76\u8fed\u4ee3\u5f00\u53d1\u7ea2\u961f\u653b\u51fb\u7b56\u7565\u3002", "result": "\u91cd\u91c7\u6837\u548c\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u534f\u8bae\u5c06\u5b89\u5168\u6027\u4ece50%\u63d0\u5347\u81f396%\uff1b\u4f46\u5f53\u7ea2\u961f\u83b7\u5f97\u91cd\u91c7\u6837\u53d1\u751f\u65f6\u673a\u6216\u6a21\u62df\u76d1\u63a7\u5668\u80fd\u529b\u65f6\uff0c\u653b\u51fb\u6210\u529f\u7387\u663e\u8457\u63d0\u9ad8\uff0c\u5b89\u5168\u6027\u964d\u81f317%\uff1b\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u534f\u8bae\u5bf9\u6700\u5f3a\u7ea2\u961f\u7b56\u7565\u4ecd\u4fdd\u6301\u9ad8\u5ea6\u9c81\u68d2\u6027\u3002", "conclusion": "\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u534f\u8bae\u5bf9\u81ea\u9002\u5e94\u653b\u51fb\u5177\u6709\u9ad8\u5ea6\u9c81\u68d2\u6027\uff0c\u8868\u660e\u62d2\u7edd\u653b\u51fb\u7b56\u7565\u8bbf\u95ee\u534f\u8bae\u5185\u90e8\u4fe1\u606f\u5bf9\u4e8eAI\u63a7\u5236\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.03029", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03029", "abs": "https://arxiv.org/abs/2511.03029", "authors": ["Kajol Kulkarni", "Samuel Kemmler", "Anna Schwarz", "Gulcin Gedik", "Yanxiang Chen", "Dimitrios Papageorgiou", "Ioannis Kavroulakis", "Roman Iakymchuk"], "title": "Harvesting energy consumption on European HPC systems: Sharing Experience from the CEEC project", "comment": "10 pages, 11 figures, conference", "summary": "Energy efficiency has emerged as a central challenge for modern\nhigh-performance computing (HPC) systems, where escalating computational\ndemands and architectural complexity have led to significant energy footprints.\nThis paper presents the collective experience of the EuroHPC JU Center of\nExcellence in Exascale CFD (CEEC) in measuring, analyzing, and optimizing\nenergy consumption across major European HPC systems. We briefly review key\nmethodologies and tools for energy measurement as well as define metrics for\nreporting results. Through case studies using representative CFD applications\n(waLBerla, FLEXI/GAL{\\AE}XI, Neko, and NekRS), we evaluate energy-to-solution\nand time-to-solution metrics on diverse architectures, including CPU- and\nGPU-based partitions of LUMI, MareNostrum5, MeluXina, and JUWELS Booster. Our\nresults highlight the advantages of accelerators and mixed-precision techniques\nfor reducing energy consumption while maintaining computational accuracy.\nFinally, we advocate the need to facilitate energy measurements on HPC systems\nin order to raise awareness, teach the community, and take actions toward more\nsustainable exascale computing.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86EuroHPC JU CEEC\u9879\u76ee\u5728\u6b27\u6d32\u4e3b\u8981HPC\u7cfb\u7edf\u4e0a\u6d4b\u91cf\u3001\u5206\u6790\u548c\u4f18\u5316\u80fd\u8017\u7684\u96c6\u4f53\u7ecf\u9a8c\uff0c\u901a\u8fc7CFD\u5e94\u7528\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u4e0d\u540c\u67b6\u6784\u7684\u80fd\u6548\u8868\u73b0\u3002", "motivation": "\u73b0\u4ee3\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u9762\u4e34\u80fd\u6548\u6311\u6218\uff0c\u8ba1\u7b97\u9700\u6c42\u589e\u957f\u548c\u67b6\u6784\u590d\u6742\u6027\u5bfc\u81f4\u663e\u8457\u7684\u80fd\u6e90\u8db3\u8ff9\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u6d4b\u91cf\u548c\u4f18\u5316\u80fd\u8017\u3002", "method": "\u4f7f\u7528\u4ee3\u8868\u6027CFD\u5e94\u7528\uff08waLBerla\u3001FLEXI/GAL\u00c6XI\u3001Neko\u3001NekRS\uff09\u5728\u591a\u79cd\u67b6\u6784\u4e0a\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u80fd\u8017\u4e0e\u65f6\u95f4\u6307\u6807\uff0c\u5305\u62ecCPU\u548cGPU\u5206\u533a\u3002", "result": "\u7ed3\u679c\u8868\u660e\u52a0\u901f\u5668\u548c\u6df7\u5408\u7cbe\u5ea6\u6280\u672f\u5728\u4fdd\u6301\u8ba1\u7b97\u7cbe\u5ea6\u7684\u540c\u65f6\u80fd\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u51f8\u663e\u4e86\u8fd9\u4e9b\u6280\u672f\u7684\u80fd\u6548\u4f18\u52bf\u3002", "conclusion": "\u9700\u8981\u5728HPC\u7cfb\u7edf\u4e0a\u4fc3\u8fdb\u80fd\u8017\u6d4b\u91cf\uff0c\u4ee5\u63d0\u9ad8\u610f\u8bc6\u3001\u6559\u80b2\u793e\u533a\u5e76\u91c7\u53d6\u884c\u52a8\u5b9e\u73b0\u66f4\u53ef\u6301\u7eed\u7684\u767e\u4ebf\u4ebf\u6b21\u8ba1\u7b97\u3002"}}
{"id": "2511.03724", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03724", "abs": "https://arxiv.org/abs/2511.03724", "authors": ["Richard Dewey", "Janos Botyanszki", "Ciamac C. Moallemi", "Andrew T. Zheng"], "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning", "comment": null, "summary": "AI researchers have long focused on poker-like games as a testbed for\nenvironments characterized by multi-player dynamics, imperfect information, and\nreasoning under uncertainty. While recent breakthroughs have matched elite\nhuman play at no-limit Texas hold'em, the multi-player dynamics are subdued:\nmost hands converge quickly with only two players engaged through multiple\nrounds of bidding. In this paper, we present Solly, the first AI agent to\nachieve elite human play in reduced-format Liar's Poker, a game characterized\nby extensive multi-player engagement. We trained Solly using self-play with a\nmodel-free, actor-critic, deep reinforcement learning algorithm. Solly played\nat an elite human level as measured by win rate (won over 50% of hands) and\nequity (money won) in heads-up and multi-player Liar's Poker. Solly also\noutperformed large language models (LLMs), including those with reasoning\nabilities, on the same metrics. Solly developed novel bidding strategies,\nrandomized play effectively, and was not easily exploitable by world-class\nhuman players.", "AI": {"tldr": "Solly\u662f\u9996\u4e2a\u5728\u7b80\u5316\u7248Liar's Poker\u4e2d\u8fbe\u5230\u7cbe\u82f1\u4eba\u7c7b\u6c34\u5e73\u7684AI\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u81ea\u5bf9\u5f08\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5728\u5355\u6311\u548c\u591a\u73a9\u5bb6\u6e38\u620f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80dc\u7387\u8d85\u8fc750%\uff0c\u5e76\u8d85\u8d8a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u867d\u7136AI\u5728\u5fb7\u5dde\u6251\u514b\u7b49\u6e38\u620f\u4e2d\u5df2\u53d6\u5f97\u7a81\u7834\uff0c\u4f46\u591a\u4eba\u52a8\u6001\u8f83\u5f31\u3002Liar's Poker\u5177\u6709\u5e7f\u6cdb\u7684\u591a\u4eba\u53c2\u4e0e\u7279\u6027\uff0c\u662f\u6d4b\u8bd5\u591a\u73a9\u5bb6\u52a8\u6001\u3001\u4e0d\u5b8c\u5168\u4fe1\u606f\u548c\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u7684\u7406\u60f3\u73af\u5883\u3002", "method": "\u4f7f\u7528\u6a21\u578b\u65e0\u5173\u7684\u6f14\u5458-\u8bc4\u8bba\u5bb6\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u5bf9\u5f08\u8bad\u7ec3Solly\u667a\u80fd\u4f53\u3002", "result": "Solly\u5728\u5355\u6311\u548c\u591a\u73a9\u5bb6Liar's Poker\u4e2d\u8fbe\u5230\u7cbe\u82f1\u4eba\u7c7b\u6c34\u5e73\uff0c\u80dc\u7387\u8d85\u8fc750%\uff0c\u5728\u8d44\u91d1\u6536\u76ca\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u5177\u6709\u63a8\u7406\u80fd\u529b\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5f00\u53d1\u4e86\u65b0\u9896\u7684\u7ade\u4ef7\u7b56\u7565\u5e76\u6709\u6548\u968f\u673a\u5316\u6e38\u620f\u3002", "conclusion": "Solly\u8bc1\u660e\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u591a\u4eba\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u8fbe\u5230\u7cbe\u82f1\u4eba\u7c7b\u6c34\u5e73\u5e76\u8d85\u8d8a\u73b0\u6709AI\u65b9\u6cd5\u3002"}}
{"id": "2511.03023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03023", "abs": "https://arxiv.org/abs/2511.03023", "authors": ["Sina Montazeri", "Yunhe Feng", "Kewei Sha"], "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework", "comment": null, "summary": "Open data repositories hold potential for evidence-based decision-making, yet\nare inaccessible to non-experts lacking expertise in dataset discovery, schema\nmapping, and statistical analysis. Large language models show promise for\nindividual tasks, but end-to-end analytical workflows expose fundamental\nlimitations: attention dilutes across growing contexts, specialized reasoning\npatterns interfere, and errors propagate undetected. We present PublicAgent, a\nmulti-agent framework that addresses these limitations through decomposition\ninto specialized agents for intent clarification, dataset discovery, analysis,\nand reporting. This architecture maintains focused attention within agent\ncontexts and enables validation at each stage. Evaluation across five models\nand 50 queries derives five design principles for multi-agent LLM systems.\nFirst, specialization provides value independent of model strength--even the\nstrongest model shows 97.5% agent win rates, with benefits orthogonal to model\nscale. Second, agents divide into universal (discovery, analysis) and\nconditional (report, intent) categories. Universal agents show consistent\neffectiveness (std dev 12.4%) while conditional agents vary by model (std dev\n20.5%). Third, agents mitigate distinct failure modes--removing discovery or\nanalysis causes catastrophic failures (243-280 instances), while removing\nreport or intent causes quality degradation. Fourth, architectural benefits\npersist across task complexity with stable win rates (86-92% analysis, 84-94%\ndiscovery), indicating workflow management value rather than reasoning\nenhancement. Fifth, wide variance in agent effectiveness across models (42-96%\nfor analysis) requires model-aware architecture design. These principles guide\nwhen and why specialization is necessary for complex analytical workflows while\nenabling broader access to public data through natural language interfaces.", "AI": {"tldr": "PublicAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7aef\u5230\u7aef\u6570\u636e\u5206\u6790\u5de5\u4f5c\u6d41\u5206\u89e3\u4e3a\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff08\u610f\u56fe\u6f84\u6e05\u3001\u6570\u636e\u96c6\u53d1\u73b0\u3001\u5206\u6790\u548c\u62a5\u544a\uff09\uff0c\u89e3\u51b3\u4e86LLM\u5728\u590d\u6742\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u6ce8\u610f\u529b\u7a00\u91ca\u3001\u4e13\u4e1a\u63a8\u7406\u6a21\u5f0f\u51b2\u7a81\u548c\u9519\u8bef\u4f20\u64ad\u95ee\u9898\u3002", "motivation": "\u5f00\u653e\u6570\u636e\u4ed3\u5e93\u5177\u6709\u57fa\u4e8e\u8bc1\u636e\u51b3\u7b56\u7684\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u6570\u636e\u96c6\u53d1\u73b0\u3001\u6a21\u5f0f\u6620\u5c04\u548c\u7edf\u8ba1\u5206\u6790\u4e13\u4e1a\u77e5\u8bc6\u7684\u975e\u4e13\u5bb6\u96be\u4ee5\u8bbf\u95ee\u3002\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5355\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u7aef\u5230\u7aef\u5206\u6790\u5de5\u4f5c\u6d41\u4e2d\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\u3002", "method": "\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u5206\u6790\u5de5\u4f5c\u6d41\u5206\u89e3\u4e3a\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff1a\u610f\u56fe\u6f84\u6e05\u3001\u6570\u636e\u96c6\u53d1\u73b0\u3001\u5206\u6790\u548c\u62a5\u544a\u3002\u8fd9\u79cd\u67b6\u6784\u5728\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u4e2d\u4fdd\u6301\u4e13\u6ce8\u6ce8\u610f\u529b\uff0c\u5e76\u5728\u6bcf\u4e2a\u9636\u6bb5\u5b9e\u73b0\u9a8c\u8bc1\u3002", "result": "\u8bc4\u4f30\u4e865\u4e2a\u6a21\u578b\u548c50\u4e2a\u67e5\u8be2\uff0c\u5f97\u51fa\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7684\u4e94\u4e2a\u8bbe\u8ba1\u539f\u5219\uff1a\u4e13\u4e1a\u5316\u72ec\u7acb\u4e8e\u6a21\u578b\u5f3a\u5ea6\u63d0\u4f9b\u4ef7\u503c\uff1b\u667a\u80fd\u4f53\u5206\u4e3a\u901a\u7528\u578b\u548c\u6761\u4ef6\u578b\uff1b\u667a\u80fd\u4f53\u7f13\u89e3\u4e0d\u540c\u7684\u5931\u8d25\u6a21\u5f0f\uff1b\u67b6\u6784\u4f18\u52bf\u5728\u4e0d\u540c\u4efb\u52a1\u590d\u6742\u5ea6\u4e0b\u6301\u7eed\u5b58\u5728\uff1b\u667a\u80fd\u4f53\u6709\u6548\u6027\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u8fd9\u4e9b\u539f\u5219\u6307\u5bfc\u4e86\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u5728\u590d\u6742\u5206\u6790\u5de5\u4f5c\u6d41\u4e2d\u9700\u8981\u4e13\u4e1a\u5316\uff0c\u540c\u65f6\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u516c\u5171\u6570\u636e\u8bbf\u95ee\u3002"}}
{"id": "2511.03051", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.03051", "abs": "https://arxiv.org/abs/2511.03051", "authors": ["Tao Zhang", "Kehui Yao", "Luyi Ma", "Jiao Chen", "Reza Yousefi Maragheh", "Kai Zhao", "Jianpeng Xu", "Evren Korpeoglu", "Sushant Kumar", "Kannan Achan"], "title": "No-Human in the Loop: Agentic Evaluation at Scale for Recommendation", "comment": "4 page, NeurIPS 2025 Workshop: Evaluating the Evolving LLM Lifecycle", "summary": "Evaluating large language models (LLMs) as judges is increasingly critical\nfor building scalable and trustworthy evaluation pipelines. We present\nScalingEval, a large-scale benchmarking study that systematically compares 36\nLLMs, including GPT, Gemini, Claude, and Llama, across multiple product\ncategories using a consensus-driven evaluation protocol. Our multi-agent\nframework aggregates pattern audits and issue codes into ground-truth labels\nvia scalable majority voting, enabling reproducible comparison of LLM\nevaluators without human annotation. Applied to large-scale complementary-item\nrecommendation, the benchmark reports four key findings: (i) Anthropic Claude\n3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers\nthe best overall performance across categories; (iii) GPT-4o provides the most\nfavorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among\nopen-source models. Category-level analysis shows strong consensus in\nstructured domains (Electronics, Sports) but persistent disagreement in\nlifestyle categories (Clothing, Food). These results establish ScalingEval as a\nreproducible benchmark and evaluation protocol for LLMs as judges, with\nactionable guidance on scaling, reliability, and model family tradeoffs.", "AI": {"tldr": "ScalingEval\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u7814\u7a76\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e8636\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u4f30\u8005\u7684\u6027\u80fd\uff0c\u53d1\u73b0Claude 3.5 Sonnet\u51b3\u7b56\u7f6e\u4fe1\u5ea6\u6700\u9ad8\uff0cGemini 1.5 Pro\u6574\u4f53\u8868\u73b0\u6700\u4f73\uff0cGPT-4o\u5728\u5ef6\u8fdf-\u51c6\u786e\u6027-\u6210\u672c\u65b9\u9762\u6700\u4f18\uff0cGPT-OSS 20B\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u9886\u5148\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u4f30\u8005\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u6269\u5c55\u4e14\u53ef\u4fe1\u8d56\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u53ef\u590d\u73b0\u6bd4\u8f83\u6846\u67b6\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u591a\u6570\u6295\u7968\u5c06\u6a21\u5f0f\u5ba1\u8ba1\u548c\u95ee\u9898\u4ee3\u7801\u805a\u5408\u4e3a\u771f\u5b9e\u6807\u7b7e\uff0c\u4f7f\u7528\u5171\u8bc6\u9a71\u52a8\u7684\u8bc4\u4f30\u534f\u8bae\u5728\u591a\u4e2a\u4ea7\u54c1\u7c7b\u522b\u4e2d\u7cfb\u7edf\u6bd4\u8f8336\u4e2aLLM\u3002", "result": "\u5728\u4e92\u8865\u5546\u54c1\u63a8\u8350\u7684\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\uff0c\u53d1\u73b0\u7ed3\u6784\u5316\u9886\u57df\uff08\u7535\u5b50\u3001\u4f53\u80b2\uff09\u8fbe\u6210\u5f3a\u5171\u8bc6\uff0c\u800c\u751f\u6d3b\u65b9\u5f0f\u7c7b\u522b\uff08\u670d\u88c5\u3001\u98df\u54c1\uff09\u5b58\u5728\u6301\u7eed\u5206\u6b67\u3002", "conclusion": "ScalingEval\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u4e3aLLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\u63d0\u4f9b\u4e86\u5173\u4e8e\u6269\u5c55\u6027\u3001\u53ef\u9760\u6027\u548c\u6a21\u578b\u5bb6\u65cf\u6743\u8861\u7684\u53ef\u64cd\u4f5c\u6307\u5bfc\u3002"}}
{"id": "2511.03293", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03293", "abs": "https://arxiv.org/abs/2511.03293", "authors": ["Hai Huang", "Xuhong Qiang", "Weisheng Zhao", "Chenchen Liu"], "title": "UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM", "comment": "5 pages, 5 figures, under review for IEEE ISCAS", "summary": "Large Language Models (LLMs) are increasingly deployed on edge devices with\nNeural Processing Units (NPUs), yet the decode phase remains memory-intensive,\nlimiting performance. Processing-in-Memory (PIM) offers a promising solution,\nbut co-executing NPU-PIM systems face challenges such as data layout\nmismatches, bandwidth loss, and redundant storage. To address these issues, we\npropose UMDAM, a unified memory-affinity data layout and DRAM address mapping\nscheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,\ntile-based layout and a configurable DRAM mapping strategy to ensure\ncompatibility with NPU computation while maximizing PIM efficiency -- without\nintroducing extra memory overhead or bandwidth loss. Comprehensive evaluations\non OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up\nto 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving\nend-to-end LLM inference efficiency on edge devices.", "AI": {"tldr": "UMDAM\u662f\u4e00\u79cd\u9488\u5bf9NPU-PIM\u534f\u540c\u6267\u884c\u4f18\u5316\u7684\u7edf\u4e00\u5185\u5b58\u4eb2\u548c\u6027\u6570\u636e\u5e03\u5c40\u548cDRAM\u5730\u5740\u6620\u5c04\u65b9\u6848\uff0c\u901a\u8fc7\u5217\u4e3b\u5e8f\u3001\u57fa\u4e8e\u74e6\u7247\u7684\u5e03\u5c40\u548c\u53ef\u914d\u7f6e\u7684DRAM\u6620\u5c04\u7b56\u7565\uff0c\u5728\u4e0d\u589e\u52a0\u5185\u5b58\u5f00\u9500\u6216\u5e26\u5bbd\u635f\u5931\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u8fb9\u7f18\u8bbe\u5907\u4e0aLLM\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u914d\u5907NPU\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\uff0c\u89e3\u7801\u9636\u6bb5\u4ecd\u7136\u5b58\u5728\u5185\u5b58\u5bc6\u96c6\u578b\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002NPU-PIM\u534f\u540c\u6267\u884c\u9762\u4e34\u6570\u636e\u5e03\u5c40\u4e0d\u5339\u914d\u3001\u5e26\u5bbd\u635f\u5931\u548c\u5197\u4f59\u5b58\u50a8\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faUMDAM\u65b9\u6848\uff0c\u91c7\u7528\u5217\u4e3b\u5e8f\u3001\u57fa\u4e8e\u74e6\u7247\u7684\u5e03\u5c40\u548c\u53ef\u914d\u7f6e\u7684DRAM\u6620\u5c04\u7b56\u7565\uff0c\u786e\u4fdd\u4e0eNPU\u8ba1\u7b97\u7684\u517c\u5bb9\u6027\uff0c\u540c\u65f6\u6700\u5927\u5316PIM\u6548\u7387\u3002", "result": "\u5728OPT\u6a21\u578b\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0cUMDAM\u5c06\u9996\u4ee4\u724c\u65f6\u95f4(TTFT)\u51cf\u5c11\u9ad8\u8fbe3.0\u500d\uff0c\u672b\u4ee4\u724c\u65f6\u95f4(TTLT)\u51cf\u5c112.18\u500d\u3002", "conclusion": "UMDAM\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7aef\u5230\u7aefLLM\u63a8\u7406\u6548\u7387\uff0c\u89e3\u51b3\u4e86NPU-PIM\u534f\u540c\u6267\u884c\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2511.03070", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.03070", "abs": "https://arxiv.org/abs/2511.03070", "authors": ["Drago Plecko", "Patrik Okanovic", "Torsten Hoefler", "Elias Bareinboim"], "title": "Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge", "comment": null, "summary": "Artificial intelligence (AI) systems hold great promise for advancing various\nscientific disciplines, and are increasingly used in real-world applications.\nDespite their remarkable progress, further capabilities are expected in order\nto achieve more general types of intelligence. A critical distinction in this\ncontext is between factual knowledge, which can be evaluated against true or\nfalse answers (e.g., \"what is the capital of England?\"), and probabilistic\nknowledge, reflecting probabilistic properties of the real world (e.g., \"what\nis the sex of a computer science graduate in the US?\"). In this paper, our goal\nis to build a benchmark for understanding the capabilities of LLMs in terms of\nknowledge of probability distributions describing the real world. Given that\nLLMs are trained on vast amounts of text, it may be plausible that they\ninternalize aspects of these distributions. Indeed, LLMs are touted as powerful\nuniversal approximators of real-world distributions. At the same time,\nclassical results in statistics, known as curse of dimensionality, highlight\nfundamental challenges in learning distributions in high dimensions,\nchallenging the notion of universal distributional learning. In this work, we\ndevelop the first benchmark to directly test this hypothesis, evaluating\nwhether LLMs have access to empirical distributions describing real-world\npopulations across domains such as economics, health, education, and social\nbehavior. Our results demonstrate that LLMs perform poorly overall, and do not\nseem to internalize real-world statistics naturally. When interpreted in the\ncontext of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that\nlanguage models do not contain knowledge on observational distributions (Layer\n1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional\n(Layer 2) and counterfactual (Layer 3) knowledge of these models is also\nlimited.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30LLMs\u5bf9\u73b0\u5b9e\u4e16\u754c\u6982\u7387\u5206\u5e03\u77e5\u8bc6\u7684\u638c\u63e1\u7a0b\u5ea6\uff0c\u53d1\u73b0LLMs\u5728\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u7edf\u8ba1\u5206\u5e03\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u672a\u80fd\u81ea\u7136\u5185\u5316\u771f\u5b9e\u4e16\u754c\u7edf\u8ba1\u6570\u636e\u3002", "motivation": "AI\u7cfb\u7edf\u5728\u79d1\u5b66\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u66f4\u5f3a\u7684\u80fd\u529b\u6765\u5b9e\u73b0\u66f4\u901a\u7528\u7684\u667a\u80fd\u3002\u5173\u952e\u533a\u522b\u5728\u4e8e\u4e8b\u5b9e\u6027\u77e5\u8bc6\u548c\u6982\u7387\u6027\u77e5\u8bc6\uff0c\u800cLLMs\u662f\u5426\u80fd\u591f\u5185\u5316\u73b0\u5b9e\u4e16\u754c\u5206\u5e03\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u9996\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u76f4\u63a5\u6d4b\u8bd5LLMs\u662f\u5426\u80fd\u591f\u83b7\u53d6\u63cf\u8ff0\u73b0\u5b9e\u4e16\u754c\u4eba\u53e3\u7684\u7ecf\u9a8c\u5206\u5e03\uff0c\u6db5\u76d6\u7ecf\u6d4e\u3001\u5065\u5eb7\u3001\u6559\u80b2\u548c\u793e\u4f1a\u884c\u4e3a\u7b49\u9886\u57df\u3002", "result": "LLMs\u6574\u4f53\u8868\u73b0\u4e0d\u4f73\uff0c\u4f3c\u4e4e\u65e0\u6cd5\u81ea\u7136\u5185\u5316\u73b0\u5b9e\u4e16\u754c\u7edf\u8ba1\u6570\u636e\u3002\u5728Pearl\u56e0\u679c\u5c42\u6b21\u6846\u67b6\u4e0b\uff0c\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u5bf9\u89c2\u6d4b\u5206\u5e03\u7684\u77e5\u8bc6\u3002", "conclusion": "LLMs\u5728\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u6982\u7387\u5206\u5e03\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u6839\u636e\u56e0\u679c\u5c42\u6b21\u5b9a\u7406\uff0c\u8fd9\u610f\u5473\u7740\u5b83\u4eec\u5728\u5e72\u9884\u6027\u548c\u53cd\u4e8b\u5b9e\u6027\u77e5\u8bc6\u65b9\u9762\u4e5f\u53d7\u5230\u9650\u5236\u3002"}}
{"id": "2511.03533", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03533", "abs": "https://arxiv.org/abs/2511.03533", "authors": ["Nils Japke", "Furat Hamdan", "Diana Baumann", "David Bermbach"], "title": "Investigating the Impact of Isolation on Synchronized Benchmarks", "comment": "Accepted for publication in 2025 IEEE/ACM 18th International\n  Conference on Utility and Cloud Computing", "summary": "Benchmarking in cloud environments suffers from performance variability from\nmulti-tenant resource contention. Duet benchmarking mitigates this by running\ntwo workload versions concurrently on the same VM, exposing them to identical\nexternal interference. However, intra-VM contention between synchronized\nworkloads necessitates additional isolation mechanisms.\n  This work evaluates three such strategies: cgroups and CPU pinning, Docker\ncontainers, and Firecracker MicroVMs. We compare all strategies with an\nunisolated baseline experiment, by running benchmarks with a duet setup\nalongside a noise generator. This noise generator \"steals\" compute resources to\ndegrade performance measurements.\n  All experiments showed different latency distributions while under the\neffects of noise generation, but results show that process isolation generally\nlowered false positives, except for our experiments with Docker containers.\nEven though Docker containers rely internally on cgroups and CPU pinning, they\nwere more susceptible to performance degradation due to noise influence.\nTherefore, we recommend to use process isolation for synchronized workloads,\nwith the exception of Docker containers.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e09\u79cd\u9694\u79bb\u7b56\u7565\uff08cgroups\u548cCPU\u56fa\u5b9a\u3001Docker\u5bb9\u5668\u3001Firecracker\u5fae\u865a\u62df\u673a\uff09\u5728\u4e91\u73af\u5883\u53cc\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u9664\u4e86Docker\u5bb9\u5668\u5916\uff0c\u8fdb\u7a0b\u9694\u79bb\u80fd\u964d\u4f4e\u5047\u9633\u6027\u7387\u3002", "motivation": "\u4e91\u73af\u5883\u4e2d\u591a\u79df\u6237\u8d44\u6e90\u7ade\u4e89\u5bfc\u81f4\u6027\u80fd\u53d8\u5f02\u6027\uff0c\u53cc\u57fa\u51c6\u6d4b\u8bd5\u901a\u8fc7\u5728\u540c\u4e00VM\u4e0a\u5e76\u53d1\u8fd0\u884c\u4e24\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u7248\u672c\u6765\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u9700\u8981\u989d\u5916\u7684\u9694\u79bb\u673a\u5236\u6765\u5904\u7406\u540c\u6b65\u5de5\u4f5c\u8d1f\u8f7d\u95f4\u7684\u5185\u90e8VM\u7ade\u4e89\u3002", "method": "\u901a\u8fc7\u8fd0\u884c\u53cc\u57fa\u51c6\u6d4b\u8bd5\u8bbe\u7f6e\u4e0e\u566a\u58f0\u751f\u6210\u5668\uff0c\u6bd4\u8f83\u4e09\u79cd\u9694\u79bb\u7b56\u7565\uff08cgroups\u548cCPU\u56fa\u5b9a\u3001Docker\u5bb9\u5668\u3001Firecracker\u5fae\u865a\u62df\u673a\uff09\u4e0e\u65e0\u9694\u79bb\u57fa\u7ebf\u5b9e\u9a8c\u7684\u6548\u679c\u3002", "result": "\u6240\u6709\u5b9e\u9a8c\u5728\u566a\u58f0\u5f71\u54cd\u4e0b\u90fd\u663e\u793a\u51fa\u4e0d\u540c\u7684\u5ef6\u8fdf\u5206\u5e03\uff0c\u4f46\u8fdb\u7a0b\u9694\u79bb\u901a\u5e38\u80fd\u964d\u4f4e\u5047\u9633\u6027\u7387\uff0c\u9664\u4e86Docker\u5bb9\u5668\u5b9e\u9a8c\u3002Docker\u5bb9\u5668\u5c3d\u7ba1\u5185\u90e8\u4f9d\u8d56cgroups\u548cCPU\u56fa\u5b9a\uff0c\u4f46\u5bf9\u566a\u58f0\u5bfc\u81f4\u7684\u6027\u80fd\u9000\u5316\u66f4\u654f\u611f\u3002", "conclusion": "\u5efa\u8bae\u5728\u540c\u6b65\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u4f7f\u7528\u8fdb\u7a0b\u9694\u79bb\uff0c\u4f46\u5e94\u907f\u514d\u4f7f\u7528Docker\u5bb9\u5668\u3002"}}
{"id": "2511.03092", "categories": ["cs.AI", "cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03092", "abs": "https://arxiv.org/abs/2511.03092", "authors": ["Jonathan Li", "Nasim Farahini", "Evgenii Iuliugin", "Magnus Vesterlund", "Christian Haggstrom", "Guangtao Wang", "Shubhangi Upasani", "Ayush Sachdeva", "Rui Li", "Faline Fu", "Chen Wu", "Ayesha Siddiqua", "John Long", "Tuowen Zhao", "Matheen Musaddiq", "Hakan Zeffer", "Yun Du", "Mingran Wang", "Qinghua Li", "Bo Li", "Urmish Thakker", "Raghu Prabhakar"], "title": "SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators", "comment": null, "summary": "The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+\ncontext length support have resulted in increasing demands for on-chip memory\nto support large KV caches. Techniques such as StreamingLLM and SnapKV\ndemonstrate how to control KV cache size while maintaining model accuracy. Yet,\nthese techniques are not commonly used within industrial deployments using\nframeworks like vLLM or SGLang. The reason is twofold: on one hand, the static\ngraphs and continuous batching methodology employed by these frameworks make it\ndifficult to admit modifications to the standard multi-head attention\nalgorithm, while on the other hand, the accuracy implications of such\ntechniques on modern instruction-following and reasoning models are not well\nunderstood, obfuscating the need for implementing these techniques. In this\npaper, we explore these accuracy implications on Llama-3.1-8B-Instruct and\nDeepSeek-R1, and develop SnapStream, a KV cache compression method that can be\ndeployed at scale. We demonstrate the efficacy of SnapStream in a 16-way\ntensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators\nrunning at 128k context length and up to 1832 tokens per second in a real\nproduction setting. SnapStream enables $4\\times$ improved on-chip memory usage\nand introduces minimal accuracy degradation on LongBench-v2, AIME24 and\nLiveCodeBench. To the best of our knowledge, this is the first implementation\nof sparse KV attention techniques deployed in a production inference system\nwith static graphs and continuous batching.", "AI": {"tldr": "SnapStream\u662f\u4e00\u79cdKV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u53ef\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b04\u500d\u7247\u4e0a\u5185\u5b58\u4f7f\u7528\u6539\u8fdb\uff0c\u9996\u6b21\u5728\u5177\u6709\u9759\u6001\u56fe\u548c\u8fde\u7eed\u6279\u5904\u7406\u7684\u751f\u4ea7\u63a8\u7406\u7cfb\u7edf\u4e2d\u90e8\u7f72\u7a00\u758fKV\u6ce8\u610f\u529b\u6280\u672f\u3002", "motivation": "\u968f\u7740100B+\u53c2\u6570\u5927\u8bed\u8a00\u6a21\u578b\u548c100k+\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u666e\u53ca\uff0c\u5bf9\u7247\u4e0a\u5185\u5b58\u652f\u6301\u5927KV\u7f13\u5b58\u7684\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u73b0\u6709\u6280\u672f\u5982StreamingLLM\u548cSnapKV\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u5e94\u7528\u6709\u9650\uff0c\u56e0\u4e3a\u9759\u6001\u56fe\u548c\u8fde\u7eed\u6279\u5904\u7406\u6846\u67b6\u96be\u4ee5\u4fee\u6539\u6807\u51c6\u591a\u5934\u6ce8\u610f\u529b\u7b97\u6cd5\uff0c\u4e14\u8fd9\u4e9b\u6280\u672f\u5bf9\u73b0\u4ee3\u6307\u4ee4\u8ddf\u968f\u548c\u63a8\u7406\u6a21\u578b\u7684\u7cbe\u5ea6\u5f71\u54cd\u4e0d\u660e\u786e\u3002", "method": "\u5f00\u53d1SnapStream KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u572816\u8def\u5f20\u91cf\u5e76\u884c\u90e8\u7f72\u7684DeepSeek-671B\u6a21\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u4f7f\u7528SambaNova SN40L\u52a0\u901f\u5668\uff0c\u652f\u6301128k\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u9ad8\u8fbe1832 tokens/\u79d2\u7684\u63a8\u7406\u901f\u5ea6\u3002", "result": "SnapStream\u5b9e\u73b0\u4e864\u500d\u7247\u4e0a\u5185\u5b58\u4f7f\u7528\u6539\u8fdb\uff0c\u5728LongBench-v2\u3001AIME24\u548cLiveCodeBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f15\u5165\u6700\u5c0f\u7cbe\u5ea6\u4e0b\u964d\uff0c\u5728\u771f\u5b9e\u751f\u4ea7\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "SnapStream\u662f\u9996\u4e2a\u5728\u5177\u6709\u9759\u6001\u56fe\u548c\u8fde\u7eed\u6279\u5904\u7406\u7684\u751f\u4ea7\u63a8\u7406\u7cfb\u7edf\u4e2d\u6210\u529f\u90e8\u7f72\u7684\u7a00\u758fKV\u6ce8\u610f\u529b\u6280\u672f\uff0c\u4e3a\u5927\u89c4\u6a21LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5185\u5b58\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03609", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03609", "abs": "https://arxiv.org/abs/2511.03609", "authors": ["Cameron Calk", "Emmanuel Godard"], "title": "Stone Duality Proofs for Colorless Distributed Computability Theorems", "comment": null, "summary": "We introduce a new topological encoding by spectral spaces of executions of\n  round-based full-information adversaries, a model of distributed computations\nthat is functorially presented and that\n  contains many message adversaries. We give a characterization of the\nsolvability of colorless tasks against compact adversaries.\n  Message adversaries are distributed\n  models that are known to be very expressive despite being\n  round-based and crash-free. Colorless tasks are\n  an important class of distributed tasks. For a colorless task, the\n  specification does not depend upon the multiplicity of input or\n  output values, like the ubiquitous agreement tasks.\n  Therefore, our result is a significant\n  step toward unifying topological methods in distributed computing.\n  The main insight is to consider global states obtained after finite\nexecutions of a distributed protocol\n  not as abstract\n  simplicial complexes as previously done, but as spectral\n  spaces, considering the Alexandrov topology on the faces poset. Given\n  an adversary $\\mathcal M$ with a set of inputs $\\mathcal I$,\n  we define a limit object $\\Pi^\\infty_\\mathcal M(\\mathcal I)$\n  by projective limit in the category of spectral spaces. We derive a new\ngeneral distributed computability\n  theorem using Stone duality: there exists an algorithm solving a colorless\ntask $(\\mathcal I,\\mathcal O,\\Delta)$\n  against the compact adversary $\\mathcal M$ if and only if there exists a\nspectral\n  map $f:\\Pi^\\infty_\\mathcal M(\\mathcal I)\\longrightarrow\\mathcal O$ compatible\nwith $\\Delta$.\n  From this general characterization are derived many known colorless\ncomputability\n  theorems.\n  Quite surprisingly, colored and uncolored models have the same\n  computability power (they solve the same tasks). Our new proofs give\n  topological reasons for this equivalence, previously known through\n  algorithmic reductions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u62d3\u6251\u7f16\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c31\u7a7a\u95f4\u6765\u5efa\u6a21\u57fa\u4e8e\u8f6e\u6b21\u7684\u5168\u4fe1\u606f\u5bf9\u624b\u7684\u6267\u884c\u8fc7\u7a0b\uff0c\u4e3a\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u63d0\u4f9b\u4e86\u901a\u7528\u7279\u5f81\u5316\u3002", "motivation": "\u7edf\u4e00\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u62d3\u6251\u65b9\u6cd5\uff0c\u4e3a\u6d88\u606f\u5bf9\u624b\u6a21\u578b\u4e0b\u7684\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u63d0\u4f9b\u901a\u7528\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u8c31\u7a7a\u95f4\u548cAlexandrov\u62d3\u6251\u6765\u5efa\u6a21\u5206\u5e03\u5f0f\u534f\u8bae\u6267\u884c\u540e\u7684\u5168\u5c40\u72b6\u6001\uff0c\u901a\u8fc7\u5c04\u5f71\u6781\u9650\u6784\u9020\u6781\u9650\u5bf9\u8c61\uff0c\u5e76\u5e94\u7528Stone\u5bf9\u5076\u6027\u3002", "result": "\u5f97\u5230\u4e86\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u7684\u901a\u7528\u7279\u5f81\u5316\u5b9a\u7406\uff1a\u5b58\u5728\u7b97\u6cd5\u89e3\u51b3\u65e0\u8272\u4efb\u52a1\u5f53\u4e14\u4ec5\u5f53\u5b58\u5728\u4e0e\u0394\u517c\u5bb9\u7684\u8c31\u6620\u5c04f\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5206\u5e03\u5f0f\u8ba1\u7b97\u62d3\u6251\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f69\u8272\u548c\u975e\u5f69\u8272\u6a21\u578b\u5177\u6709\u76f8\u540c\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u5e76\u4e3a\u8fd9\u79cd\u7b49\u4ef7\u6027\u63d0\u4f9b\u4e86\u62d3\u6251\u89e3\u91ca\u3002"}}
{"id": "2511.03106", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03106", "abs": "https://arxiv.org/abs/2511.03106", "authors": ["Katherine C. Kellogg", "Bingyang Ye", "Yifan Hu", "Guergana K. Savova", "Byron Wallace", "Danielle S. Bitterman"], "title": "Large language models require a new form of oversight: capability-based monitoring", "comment": "Under review", "summary": "The rapid adoption of large language models (LLMs) in healthcare has been\naccompanied by scrutiny of their oversight. Existing monitoring approaches,\ninherited from traditional machine learning (ML), are task-based and founded on\nassumed performance degradation arising from dataset drift. In contrast, with\nLLMs, inevitable model degradation due to changes in populations compared to\nthe training dataset cannot be assumed, because LLMs were not trained for any\nspecific task in any given population. We therefore propose a new organizing\nprinciple guiding generalist LLM monitoring that is scalable and grounded in\nhow these models are developed and used in practice: capability-based\nmonitoring. Capability-based monitoring is motivated by the fact that LLMs are\ngeneralist systems whose overlapping internal capabilities are reused across\nnumerous downstream tasks. Instead of evaluating each downstream task\nindependently, this approach organizes monitoring around shared model\ncapabilities, such as summarization, reasoning, translation, or safety\nguardrails, in order to enable cross-task detection of systemic weaknesses,\nlong-tail errors, and emergent behaviors that task-based monitoring may miss.\nWe describe considerations for developers, organizational leaders, and\nprofessional societies for implementing a capability-based monitoring approach.\nUltimately, capability-based monitoring will provide a scalable foundation for\nsafe, adaptive, and collaborative monitoring of LLMs and future generalist\nartificial intelligence models in healthcare.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u80fd\u529b\u7684\u76d1\u63a7\u65b9\u6cd5\uff0c\u4f5c\u4e3a\u4f20\u7edf\u4efb\u52a1\u578b\u76d1\u63a7\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7528\u4e8e\u533b\u7597\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89c4\u6a21\u5316\u76d1\u63a7\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u76d1\u63a7\u65b9\u6cd5\u57fa\u4e8e\u4efb\u52a1\u6027\u80fd\u9000\u5316\u548c\u6570\u636e\u96c6\u6f02\u79fb\u5047\u8bbe\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5e76\u975e\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u8bad\u7ec3\uff0c\u8fd9\u79cd\u5047\u8bbe\u4e0d\u6210\u7acb\u3002\u9700\u8981\u65b0\u7684\u76d1\u63a7\u539f\u5219\u6765\u9002\u5e94\u901a\u7528\u578bAI\u6a21\u578b\u7684\u7279\u70b9\u3002", "method": "\u57fa\u4e8e\u80fd\u529b\u7684\u76d1\u63a7\u65b9\u6cd5\uff0c\u56f4\u7ed5\u5171\u4eab\u6a21\u578b\u80fd\u529b\uff08\u5982\u6458\u8981\u3001\u63a8\u7406\u3001\u7ffb\u8bd1\u3001\u5b89\u5168\u9632\u62a4\uff09\u7ec4\u7ec7\u76d1\u63a7\uff0c\u800c\u975e\u72ec\u7acb\u8bc4\u4f30\u6bcf\u4e2a\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u8de8\u4efb\u52a1\u68c0\u6d4b\u7cfb\u7edf\u6027\u5f31\u70b9\u3001\u957f\u5c3e\u9519\u8bef\u548c\u6d8c\u73b0\u884c\u4e3a\uff0c\u8fd9\u4e9b\u662f\u4efb\u52a1\u578b\u76d1\u63a7\u53ef\u80fd\u9057\u6f0f\u7684\u3002", "conclusion": "\u57fa\u4e8e\u80fd\u529b\u7684\u76d1\u63a7\u4e3a\u533b\u7597\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u548c\u672a\u6765\u901a\u7528AI\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5b89\u5168\u3001\u81ea\u9002\u5e94\u548c\u534f\u4f5c\u76d1\u63a7\u57fa\u7840\u3002"}}
{"id": "2511.03662", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03662", "abs": "https://arxiv.org/abs/2511.03662", "authors": ["Yannis Coutouly", "Emmanuel Godard"], "title": "A General Input-Dependent Colorless Computability Theorem and Applications to Core-Dependent Adversaries", "comment": "OPODIS-25 version", "summary": "Distributed computing tasks can be presented with a triple $(\\I,\\Ou,\\Delta)$.\nThe solvability of a colorless task on the Iterated Immediate Snapshot model\n(IIS) has been characterized by the Colorless Computability Theorem\n\\cite[Th.4.3.1]{HKRbook}. A recent paper~\\cite{CG-24} generalizes this theorem\nfor any message adversaries $\\ma \\subseteq IIS$ by geometric methods. In 2001,\nMost\\'efaoui, Rajsbaum, Raynal, and Roy \\cite{condbased} introduced\n\\emph{condition-based adversaries}. This setting considers a particular\nadversary that will be applied only to a subset of input configurations. In\nthis setting, they studied the $k$-set agreement task with condition-based\n$t$-resilient adversaries and obtained a sufficient condition on the conditions\nthat make $k$-Set Agreement solvable. In this paper we have three\ncontributions:\n  -We generalize the characterization of~\\cite{CG-24} to \\emph{input-dependent}\nadversaries, which means that the adversaries can change depending on the input\nconfiguration.\n  - We show that core-resilient adversaries of $IIS_n$ have the same\ncomputability power as the core-resilient adversaries of $IIS_n$ where crashes\nonly happen at the start.\n  - Using the two previous contributions, we provide a necessary and sufficient\ncharacterization of the condition-based, core-dependent adversaries that can\nsolve $k$-Set Agreement. We also distinguish four settings that may appear when\npresenting a distributed task as $(\\I,\\Ou,\\Delta)$. Finally, in a later\nsection, we present structural properties on the carrier map $\\Delta$. Such\nproperties allow simpler proof, without changing the computability power of the\ntask. Most of the proofs in this article leverage the topological framework\nused in distributed computing by using simple geometric constructions.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u65e0\u8272\u4efb\u52a1\u7684\u53ef\u8ba1\u7b97\u6027\u7406\u8bba\uff0c\u5c06\u6d88\u606f\u5bf9\u624b\u6a21\u578b\u63a8\u5e7f\u5230\u8f93\u5165\u4f9d\u8d56\u578b\uff0c\u5e76\u7814\u7a76\u4e86\u6761\u4ef6\u57fa\u5bf9\u624b\u4e0b\u7684k-\u96c6\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u53ef\u89e3\u6027\u7279\u5f81\u63cf\u8ff0\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u56fa\u5b9a\u6d88\u606f\u5bf9\u624b\u6a21\u578b\uff0c\u4f46\u5728\u5b9e\u9645\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u5bf9\u624b\u884c\u4e3a\u53ef\u80fd\u4f9d\u8d56\u4e8e\u8f93\u5165\u914d\u7f6e\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u53ef\u8ba1\u7b97\u6027\u7406\u8bba\uff0c\u5904\u7406\u8f93\u5165\u4f9d\u8d56\u578b\u5bf9\u624b\u548c\u6761\u4ef6\u57fa\u5bf9\u624b\u573a\u666f\u3002", "method": "\u4f7f\u7528\u62d3\u6251\u6846\u67b6\u548c\u51e0\u4f55\u6784\u9020\u65b9\u6cd5\uff0c\u5c06CG-24\u7684\u7279\u5f81\u63cf\u8ff0\u63a8\u5e7f\u5230\u8f93\u5165\u4f9d\u8d56\u578b\u5bf9\u624b\uff0c\u5206\u6790\u6838\u5fc3\u5f39\u6027\u5bf9\u624b\u7684\u8ba1\u7b97\u80fd\u529b\u7b49\u4ef7\u6027\uff0c\u5e76\u5efa\u7acb\u6761\u4ef6\u57fa\u6838\u5fc3\u4f9d\u8d56\u5bf9\u624b\u4e0bk-\u96c6\u4e00\u81f4\u95ee\u9898\u7684\u5145\u8981\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86IIS_n\u7684\u6838\u5fc3\u5f39\u6027\u5bf9\u624b\u4e0e\u4ec5\u5728\u5f00\u59cb\u65f6\u53d1\u751f\u5d29\u6e83\u7684\u6838\u5fc3\u5f39\u6027\u5bf9\u624b\u5177\u6709\u76f8\u540c\u7684\u8ba1\u7b97\u80fd\u529b\uff1b\u4e3a\u6761\u4ef6\u57fa\u6838\u5fc3\u4f9d\u8d56\u5bf9\u624b\u4e0b\u7684k-\u96c6\u4e00\u81f4\u95ee\u9898\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u53ef\u89e3\u6027\u7279\u5f81\u63cf\u8ff0\u3002", "conclusion": "\u901a\u8fc7\u62d3\u6251\u65b9\u6cd5\u6210\u529f\u6269\u5c55\u4e86\u5206\u5e03\u5f0f\u4efb\u52a1\u7684\u53ef\u8ba1\u7b97\u6027\u7406\u8bba\uff0c\u4e3a\u8f93\u5165\u4f9d\u8d56\u578b\u548c\u6761\u4ef6\u57fa\u5bf9\u624b\u573a\u666f\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7b80\u5316\u4e86\u8bc1\u660e\u8fc7\u7a0b\u800c\u4e0d\u6539\u53d8\u4efb\u52a1\u7684\u8ba1\u7b97\u80fd\u529b\u3002"}}
{"id": "2511.03108", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03108", "abs": "https://arxiv.org/abs/2511.03108", "authors": ["Azim Ospanov", "Farzan Farnia", "Roozbeh Yousefzadeh"], "title": "miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward", "comment": null, "summary": "We perform a thorough analysis of the formal and informal statements in the\nminiF2F benchmark from the perspective of an AI system that is tasked to\nparticipate in a math Olympiad consisting of the problems in miniF2F. In such\nsetting, the model has to read and comprehend the problems in natural language,\nformalize them in Lean language, then proceed with proving the problems, and it\nwill get credit for each problem if the formal proof corresponds to the\noriginal informal statement presented to the model. Our evaluation results\nreveal that the best accuracy of such pipeline can be about 36% using the SoTA\nmodels in the literature, considerably lower than the individual SoTA\naccuracies, 97% and 69% reported in the autoformalization and theorem proving\nliterature. Analyzing the failure modes, we trace back a considerable portion\nof this drop to discrepancies between the formal and informal statements for\nmore than half of the problems in miniF2F. We proceed with correcting all the\nerrors, discrepancies and simplifications in formal and informal statements,\nand present the miniF2F-v2 with fully verified formal and informal statements\nand proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to\nthe best accuracy of 70%, a significant improvement from the 40% on the\noriginal miniF2F, yet indicating considerable misalignment between the\nautoformalization models and theorem provers. Our deep analysis suggests that a\nhigher quality benchmark can help the community better evaluate progress in the\nfield of formal reasoning and also better diagnose the failure and success\nmodes of autoformalization and theorem proving models. Our dataset is available\nat https://github.com/roozbeh-yz/miniF2F_v2.", "AI": {"tldr": "\u672c\u6587\u5bf9miniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5f62\u5f0f\u5316\u548c\u975e\u5f62\u5f0f\u5316\u9648\u8ff0\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\uff0c\u53d1\u73b0\u539f\u59cb\u57fa\u51c6\u5b58\u5728\u5927\u91cf\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5bfc\u81f4AI\u7cfb\u7edf\u5728\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u7387\u4ec5\u4e3a36%\u3002\u901a\u8fc7\u4fee\u6b63\u6240\u6709\u9519\u8bef\uff0c\u521b\u5efa\u4e86miniF2F-v2\uff0c\u5c06\u51c6\u786e\u7387\u63d0\u5347\u81f370%\u3002", "motivation": "\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u5f62\u5f0f\u5316\u8868\u8fbe\u548c\u5b9a\u7406\u8bc1\u660e\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u53d1\u73b0\u539f\u59cb\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e25\u91cd\u7684\u6570\u636e\u8d28\u91cf\u95ee\u9898\u3002", "method": "\u5bf9miniF2F\u57fa\u51c6\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u8bc6\u522b\u5f62\u5f0f\u5316\u548c\u975e\u9648\u8ff0\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4fee\u6b63\u6240\u6709\u9519\u8bef\u548c\u7b80\u5316\uff0c\u521b\u5efa\u7ecf\u8fc7\u9a8c\u8bc1\u7684miniF2F-v2\u6570\u636e\u96c6\uff0c\u5e76\u91cd\u65b0\u8bc4\u4f30\u5b8c\u6574\u7684\u5b9a\u7406\u8bc1\u660e\u6d41\u7a0b\u3002", "result": "\u539f\u59cbminiF2F\u4e2d\u8d85\u8fc7\u4e00\u534a\u95ee\u9898\u5b58\u5728\u5f62\u5f0f\u5316\u548c\u975e\u5f62\u5f0f\u5316\u9648\u8ff0\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6700\u4f73\u51c6\u786e\u7387\u4ec5\u4e3a36%\u3002\u4fee\u6b63\u540e\u7684miniF2F-v2\u5c06\u51c6\u786e\u7387\u63d0\u5347\u81f370%\uff0c\u4f46\u4ecd\u663e\u793a\u81ea\u52a8\u5f62\u5f0f\u5316\u6a21\u578b\u4e0e\u5b9a\u7406\u8bc1\u660e\u5668\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u4e0d\u5bf9\u9f50\u3002", "conclusion": "\u9ad8\u8d28\u91cf\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u4e8e\u8bc4\u4f30\u5f62\u5f0f\u63a8\u7406\u9886\u57df\u8fdb\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bca\u65ad\u81ea\u52a8\u5f62\u5f0f\u5316\u548c\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\u7684\u5931\u8d25\u548c\u6210\u529f\u6a21\u5f0f\u3002"}}
{"id": "2511.03137", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03137", "abs": "https://arxiv.org/abs/2511.03137", "authors": ["Shipeng Cen", "Ying Tan"], "title": "Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks", "comment": null, "summary": "As optimization problems grow increasingly complex and diverse, advancements\nin optimization techniques and paradigm innovations hold significant\nimportance. The challenges posed by optimization problems are primarily\nmanifested in their non-convexity, high-dimensionality, black-box nature, and\nother unfavorable characteristics. Traditional zero-order or first-order\nmethods, which are often characterized by low efficiency, inaccurate gradient\ninformation, and insufficient utilization of optimization information, are\nill-equipped to address these challenges effectively. In recent years, the\nrapid development of large language models (LLM) has led to substantial\nimprovements in their language understanding and code generation capabilities.\nConsequently, the design of optimization algorithms leveraging large language\nmodels has garnered increasing attention from researchers. In this study, we\nchoose the fireworks algorithm(FWA) as the basic optimizer and propose a novel\napproach to assist the design of the FWA by incorporating multi-modal large\nlanguage model(MLLM). To put it simply, we propose the concept of Critical\nPart(CP), which extends FWA to complex high-dimensional tasks, and further\nutilizes the information in the optimization process with the help of the\nmulti-modal characteristics of large language models. We focus on two specific\ntasks: the \\textit{traveling salesman problem }(TSP) and \\textit{electronic\ndesign automation problem} (EDA). The experimental results show that FWAs\ngenerated under our new framework have achieved or surpassed SOTA results on\nmany problem instances.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u8bbe\u8ba1\u70df\u82b1\u7b97\u6cd5\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5173\u952e\u90e8\u5206\u6982\u5ff5\u6269\u5c55FWA\u5904\u7406\u590d\u6742\u9ad8\u7ef4\u4efb\u52a1\uff0c\u5728\u65c5\u884c\u5546\u95ee\u9898\u548c\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7ed3\u679c\u3002", "motivation": "\u968f\u7740\u4f18\u5316\u95ee\u9898\u65e5\u76ca\u590d\u6742\u591a\u6837\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u5904\u7406\u975e\u51f8\u6027\u3001\u9ad8\u7ef4\u6027\u3001\u9ed1\u76d2\u7279\u6027\u7b49\u95ee\u9898\u65f6\u6548\u7387\u4f4e\u4e0b\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u7406\u89e3\u548c\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u8fdb\u6b65\u4e3a\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u4ee5\u70df\u82b1\u7b97\u6cd5\u4e3a\u57fa\u7840\u4f18\u5316\u5668\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u51fa\u5173\u952e\u90e8\u5206\u6982\u5ff5\u6765\u6269\u5c55FWA\u5904\u7406\u590d\u6742\u9ad8\u7ef4\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u7279\u6027\u5145\u5206\u6316\u6398\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u65b0\u6846\u67b6\u4e0b\u751f\u6210\u7684\u70df\u82b1\u7b97\u6cd5\u5728\u591a\u4e2a\u95ee\u9898\u5b9e\u4f8b\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u4f18\u7ed3\u679c\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u9ad8\u7ef4\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.03138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03138", "abs": "https://arxiv.org/abs/2511.03138", "authors": ["Qi Li", "Jianjun Xu", "Pingtao Wei", "Jiu Li", "Peiqiang Zhao", "Jiwei Shi", "Xuan Zhang", "Yanhui Yang", "Xiaodong Hui", "Peng Xu", "Wenqin Shao"], "title": "A Proprietary Model-Based Safety Response Framework for AI Agents", "comment": null, "summary": "With the widespread application of Large Language Models (LLMs), their\nassociated security issues have become increasingly prominent, severely\nconstraining their trustworthy deployment in critical domains. This paper\nproposes a novel safety response framework designed to systematically safeguard\nLLMs at both the input and output levels. At the input level, the framework\nemploys a supervised fine-tuning-based safety classification model. Through a\nfine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused\nAttention), it performs precise risk identification and differentiated handling\nof user queries, significantly enhancing risk coverage and business scenario\nadaptability, and achieving a risk recall rate of 99.3%. At the output level,\nthe framework integrates Retrieval-Augmented Generation (RAG) with a\nspecifically fine-tuned interpretation model, ensuring all responses are\ngrounded in a real-time, trustworthy knowledge base. This approach eliminates\ninformation fabrication and enables result traceability. Experimental results\ndemonstrate that our proposed safety control model achieves a significantly\nhigher safety score on public safety evaluation benchmarks compared to the\nbaseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk\ntest set, the framework's components attained a perfect 100% safety score,\nvalidating their exceptional protective capabilities in complex risk scenarios.\nThis research provides an effective engineering pathway for building\nhigh-security, high-trust LLM applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5b89\u5168\u54cd\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u8f93\u5165\u7ea7\u5b89\u5168\u5206\u7c7b\u6a21\u578b\u548c\u8f93\u51fa\u7ea7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u7cfb\u7edf\u4fdd\u62a4\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u90e8\u7f72\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5b89\u5168\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u4e25\u91cd\u5236\u7ea6\u4e86\u5728\u5173\u952e\u9886\u57df\u7684\u53ef\u4fe1\u90e8\u7f72\u3002", "method": "\u5728\u8f93\u5165\u7ea7\u91c7\u7528\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u7684\u5b89\u5168\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u8fc7\u56db\u5c42\u7ea7\u5206\u7c7b\u6cd5\u8fdb\u884c\u7cbe\u786e\u98ce\u9669\u8bc6\u522b\uff1b\u5728\u8f93\u51fa\u7ea7\u96c6\u6210\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u4e13\u95e8\u5fae\u8c03\u7684\u89e3\u91ca\u6a21\u578b\uff0c\u786e\u4fdd\u54cd\u5e94\u57fa\u4e8e\u53ef\u4fe1\u77e5\u8bc6\u5e93\u3002", "result": "\u98ce\u9669\u53ec\u56de\u7387\u8fbe\u523099.3%\uff0c\u5728\u516c\u5171\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u4e13\u6709\u9ad8\u98ce\u9669\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97100%\u5b89\u5168\u5206\u6570\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6784\u5efa\u9ad8\u5b89\u5168\u6027\u3001\u9ad8\u53ef\u4fe1\u5ea6\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u7a0b\u8def\u5f84\u3002"}}
{"id": "2511.03169", "categories": ["cs.AI", "D.2.4; I.2.6; I.2.4; K.4.1; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.03169", "abs": "https://arxiv.org/abs/2511.03169", "authors": ["Xuanxiang Huang", "Yacine Izza", "Alexey Ignatiev", "Joao Marques-Silva"], "title": "Uncovering Bugs in Formal Explainers: A Case Study with PyXAI", "comment": null, "summary": "Formal explainable artificial intelligence (XAI) offers unique theoretical\nguarantees of rigor when compared to other non-formal methods of\nexplainability. However, little attention has been given to the validation of\npractical implementations of formal explainers. This paper develops a novel\nmethodology for validating formal explainers and reports on the assessment of\nthe publicly available formal explainer PyXAI. The paper documents the\nexistence of incorrect explanations computed by PyXAI on most of the datasets\nanalyzed in the experiments, thereby confirming the importance of the proposed\nnovel methodology for the validation of formal explainers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9a8c\u8bc1\u5f62\u5f0f\u5316\u89e3\u91ca\u5668\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u516c\u5f00\u53ef\u7528\u7684PyXAI\u89e3\u91ca\u5668\uff0c\u53d1\u73b0\u5176\u5728\u5927\u591a\u6570\u6570\u636e\u96c6\u4e0a\u4ea7\u751f\u4e86\u9519\u8bef\u7684\u89e3\u91ca\u3002", "motivation": "\u5f62\u5f0f\u5316\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u76f8\u6bd4\u975e\u5f62\u5f0f\u5316\u65b9\u6cd5\u5177\u6709\u7406\u8bba\u4e25\u8c28\u6027\u4fdd\u8bc1\uff0c\u4f46\u5bf9\u5f62\u5f0f\u5316\u89e3\u91ca\u5668\u5b9e\u9645\u5b9e\u73b0\u7684\u9a8c\u8bc1\u5173\u6ce8\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9a8c\u8bc1\u5f62\u5f0f\u5316\u89e3\u91ca\u5668\u7684\u65b9\u6cd5\u8bba\uff0c\u5e76\u5bf9PyXAI\u89e3\u91ca\u5668\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0PyXAI\u5728\u5927\u591a\u6570\u5206\u6790\u7684\u6570\u636e\u96c6\u4e0a\u8ba1\u7b97\u51fa\u4e86\u9519\u8bef\u7684\u89e3\u91ca\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u9a8c\u8bc1\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u5f62\u5f0f\u5316\u89e3\u91ca\u5668\u7684\u5b9e\u9645\u5b9e\u73b0\u9700\u8981\u4e25\u683c\u7684\u9a8c\u8bc1\uff0c\u672c\u6587\u63d0\u51fa\u7684\u9a8c\u8bc1\u65b9\u6cd5\u5bf9\u4e8e\u786e\u4fdd\u89e3\u91ca\u7684\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.03186", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03186", "abs": "https://arxiv.org/abs/2511.03186", "authors": ["Yiru Chen", "Sally Fang", "Sai Sree Harsha", "Dan Luo", "Vaishnavi Muppala", "Fei Wu", "Shun Jiang", "Kun Qian", "Yunyao Li"], "title": "Adobe Summit Concierge Evaluation with Human in the Loop", "comment": "Accepted by 6th Workshop on Data Science with Human in the Loop @\n  VLDB 2025", "summary": "Generative AI assistants offer significant potential to enhance productivity,\nstreamline information access, and improve user experience in enterprise\ncontexts. In this work, we present Summit Concierge, a domain-specific AI\nassistant developed for Adobe Summit. The assistant handles a wide range of\nevent-related queries and operates under real-world constraints such as data\nsparsity, quality assurance, and rapid deployment. To address these challenges,\nwe adopt a human-in-the-loop development workflow that combines prompt\nengineering, retrieval grounding, and lightweight human validation. We describe\nthe system architecture, development process, and real-world deployment\noutcomes. Our experience shows that agile, feedback-driven development enables\nscalable and reliable AI assistants, even in cold-start scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e3aAdobe Summit\u5f00\u53d1\u7684\u9886\u57df\u7279\u5b9aAI\u52a9\u624bSummit Concierge\uff0c\u8be5\u52a9\u624b\u80fd\u591f\u5904\u7406\u5404\u79cd\u6d3b\u52a8\u76f8\u5173\u67e5\u8be2\uff0c\u5e76\u5728\u6570\u636e\u7a00\u758f\u3001\u8d28\u91cf\u4fdd\u8bc1\u548c\u5feb\u901f\u90e8\u7f72\u7b49\u73b0\u5b9e\u7ea6\u675f\u4e0b\u8fd0\u884c\u3002", "motivation": "\u751f\u6210\u5f0fAI\u52a9\u624b\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u5177\u6709\u63d0\u5347\u751f\u4ea7\u529b\u3001\u7b80\u5316\u4fe1\u606f\u8bbf\u95ee\u548c\u6539\u5584\u7528\u6237\u4f53\u9a8c\u7684\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u6570\u636e\u7a00\u758f\u3001\u8d28\u91cf\u4fdd\u8bc1\u548c\u5feb\u901f\u90e8\u7f72\u7b49\u73b0\u5b9e\u6311\u6218\u3002", "method": "\u91c7\u7528\u4eba\u5728\u56de\u8def\u5f00\u53d1\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u68c0\u7d22\u57fa\u7840\u548c\u8f7b\u91cf\u7ea7\u4eba\u5de5\u9a8c\u8bc1\uff0c\u6784\u5efa\u4e86\u7cfb\u7edf\u67b6\u6784\u5e76\u5b9e\u65bd\u4e86\u654f\u6377\u7684\u53cd\u9988\u9a71\u52a8\u5f00\u53d1\u6d41\u7a0b\u3002", "result": "\u6210\u529f\u5f00\u53d1\u5e76\u90e8\u7f72\u4e86Summit Concierge\u52a9\u624b\uff0c\u80fd\u591f\u5904\u7406\u5e7f\u6cdb\u7684\u6d3b\u52a8\u76f8\u5173\u67e5\u8be2\uff0c\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u548c\u53ef\u9760\u7684AI\u52a9\u624b\u3002", "conclusion": "\u5373\u4f7f\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\uff0c\u654f\u6377\u7684\u53cd\u9988\u9a71\u52a8\u5f00\u53d1\u65b9\u6cd5\u4e5f\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684AI\u52a9\u624b\uff0c\u4e3a\u7c7b\u4f3c\u4f01\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5f00\u53d1\u8def\u5f84\u3002"}}
{"id": "2511.03235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03235", "abs": "https://arxiv.org/abs/2511.03235", "authors": ["Yi-Fei Liu", "Yi-Long Lu", "Di He", "Hang Zhang"], "title": "From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers", "comment": null, "summary": "Psychological constructs within individuals are widely believed to be\ninterconnected. We investigated whether and how Large Language Models (LLMs)\ncan model the correlational structure of human psychological traits from\nminimal quantitative inputs. We prompted various LLMs with Big Five Personality\nScale responses from 816 human individuals to role-play their responses on nine\nother psychological scales. LLMs demonstrated remarkable accuracy in capturing\nhuman psychological structure, with the inter-scale correlation patterns from\nLLM-generated responses strongly aligning with those from human data $(R^2 >\n0.89)$. This zero-shot performance substantially exceeded predictions based on\nsemantic similarity and approached the accuracy of machine learning algorithms\ntrained directly on the dataset. Analysis of reasoning traces revealed that\nLLMs use a systematic two-stage process: First, they transform raw Big Five\nresponses into natural language personality summaries through information\nselection and compression, analogous to generating sufficient statistics.\nSecond, they generate target scale responses based on reasoning from these\nsummaries. For information selection, LLMs identify the same key personality\nfactors as trained algorithms, though they fail to differentiate item\nimportance within factors. The resulting compressed summaries are not merely\nredundant representations but capture synergistic information--adding them to\noriginal scores enhances prediction alignment, suggesting they encode emergent,\nsecond-order patterns of trait interplay. Our findings demonstrate that LLMs\ncan precisely predict individual participants' psychological traits from\nminimal data through a process of abstraction and reasoning, offering both a\npowerful tool for psychological simulation and valuable insights into their\nemergent reasoning capabilities.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u4ec5\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u91cf\u8868\u6570\u636e\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u63a8\u7406\u8fc7\u7a0b\u51c6\u786e\u9884\u6d4b\u4eba\u7c7b\u5fc3\u7406\u7279\u8d28\u7684\u76f8\u5173\u7ed3\u6784\uff0c\u5176\u8868\u73b0\u63a5\u8fd1\u76f4\u63a5\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76LLMs\u662f\u5426\u80fd\u591f\u4ece\u6700\u5c0f\u5316\u7684\u5b9a\u91cf\u8f93\u5165\u4e2d\u5efa\u6a21\u4eba\u7c7b\u5fc3\u7406\u7279\u8d28\u7684\u76f8\u5173\u7ed3\u6784\uff0c\u63a2\u7d22\u5176\u63a8\u7406\u80fd\u529b\u548c\u5fc3\u7406\u6a21\u62df\u6f5c\u529b\u3002", "method": "\u4f7f\u7528816\u540d\u4eba\u7c7b\u7684\u5927\u4e94\u4eba\u683c\u91cf\u8868\u6570\u636e\u63d0\u793a\u5404\u79cdLLMs\uff0c\u8ba9\u5b83\u4eec\u6a21\u62df\u5728\u5176\u4ed69\u4e2a\u5fc3\u7406\u91cf\u8868\u4e0a\u7684\u56de\u7b54\uff0c\u5e76\u5206\u6790\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "LLMs\u5728\u6355\u6349\u4eba\u7c7b\u5fc3\u7406\u7ed3\u6784\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u91cf\u8868\u95f4\u76f8\u5173\u6a21\u5f0f\u4e0e\u4eba\u7c7b\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4\uff08R\u00b2 > 0.89\uff09\uff0c\u96f6\u6837\u672c\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u9884\u6d4b\u3002", "conclusion": "LLMs\u901a\u8fc7\u62bd\u8c61\u548c\u63a8\u7406\u8fc7\u7a0b\u80fd\u591f\u7cbe\u786e\u9884\u6d4b\u4e2a\u4f53\u5fc3\u7406\u7279\u8d28\uff0c\u8fd9\u65e2\u4e3a\u5fc3\u7406\u6a21\u62df\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\uff0c\u4e5f\u63ed\u793a\u4e86\u5176\u65b0\u5174\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2511.03471", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03471", "abs": "https://arxiv.org/abs/2511.03471", "authors": ["Ming Gu", "Ziwei Wang", "Sicen Lai", "Zirui Gao", "Sheng Zhou", "Jiajun Bu"], "title": "Towards Scalable Web Accessibility Audit with MLLMs as Copilots", "comment": "15 pages. Accepted by AAAI 2026 AISI", "summary": "Ensuring web accessibility is crucial for advancing social welfare, justice,\nand equality in digital spaces, yet the vast majority of website user\ninterfaces remain non-compliant, due in part to the resource-intensive and\nunscalable nature of current auditing practices. While WCAG-EM offers a\nstructured methodology for site-wise conformance evaluation, it involves great\nhuman efforts and lacks practical support for execution at scale. In this work,\nwe present an auditing framework, AAA, which operationalizes WCAG-EM through a\nhuman-AI partnership model. AAA is anchored by two key innovations: GRASP, a\ngraph-based multimodal sampling method that ensures representative page\ncoverage via learned embeddings of visual, textual, and relational cues; and\nMaC, a multimodal large language model-based copilot that supports auditors\nthrough cross-modal reasoning and intelligent assistance in high-effort tasks.\nTogether, these components enable scalable, end-to-end web accessibility\nauditing, empowering human auditors with AI-enhanced assistance for real-world\nimpact. We further contribute four novel datasets designed for benchmarking\ncore stages of the audit pipeline. Extensive experiments demonstrate the\neffectiveness of our methods, providing insights that small-scale language\nmodels can serve as capable experts when fine-tuned.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAAA\u7684\u81ea\u52a8\u5316Web\u53ef\u8bbf\u95ee\u6027\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\u5b9e\u73b0WCAG-EM\u6807\u51c6\u7684\u89c4\u6a21\u5316\u6267\u884c\uff0c\u5305\u542bGRASP\u56fe\u91c7\u6837\u65b9\u6cd5\u548cMaC\u591a\u6a21\u6001\u52a9\u624b\u4e24\u4e2a\u6838\u5fc3\u521b\u65b0\u3002", "motivation": "\u5f53\u524d\u7f51\u7ad9\u53ef\u8bbf\u95ee\u6027\u5ba1\u8ba1\u8d44\u6e90\u5bc6\u96c6\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\uff0c\u5927\u591a\u6570\u7f51\u7ad9\u754c\u9762\u4e0d\u7b26\u5408\u6807\u51c6\uff0c\u963b\u788d\u4e86\u6570\u5b57\u7a7a\u95f4\u7684\u793e\u4f1a\u798f\u5229\u3001\u6b63\u4e49\u548c\u5e73\u7b49\u53d1\u5c55\u3002", "method": "AAA\u6846\u67b6\u5305\u542bGRASP\uff08\u57fa\u4e8e\u56fe\u7684\u591a\u6a21\u6001\u91c7\u6837\u65b9\u6cd5\uff0c\u5229\u7528\u89c6\u89c9\u3001\u6587\u672c\u548c\u5173\u7cfb\u7ebf\u7d22\u7684\u5d4c\u5165\u786e\u4fdd\u9875\u9762\u8986\u76d6\u4ee3\u8868\u6027\uff09\u548cMaC\uff08\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u52a9\u624b\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u63a8\u7406\u652f\u6301\u5ba1\u8ba1\u5458\u5b8c\u6210\u9ad8\u96be\u5ea6\u4efb\u52a1\uff09\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u7ecf\u8fc7\u5fae\u8c03\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u80fd\u529b\u5f3a\u7684\u4e13\u5bb6\u4f7f\u7528\uff0c\u5e76\u8d21\u732e\u4e86\u56db\u4e2a\u7528\u4e8e\u5ba1\u8ba1\u6d41\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u7684\u65b0\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u7aef\u5230\u7aefWeb\u53ef\u8bbf\u95ee\u6027\u5ba1\u8ba1\uff0c\u901a\u8fc7AI\u589e\u5f3a\u8f85\u52a9\u4e3a\u73b0\u5b9e\u4e16\u754c\u5f71\u54cd\u8d4b\u80fd\u4eba\u7c7b\u5ba1\u8ba1\u5458\u3002"}}
{"id": "2511.03545", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03545", "abs": "https://arxiv.org/abs/2511.03545", "authors": ["Sebastian Ordyniak", "Giacomo Paesani", "Mateusz Rychlicki", "Stefan Szeider"], "title": "Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)", "comment": "Part I of a greatly enhanced version of\n  https://doi.org/10.24963/kr.2024/53, whose full version is available on arXiv\n  under https://doi.org/10.48550/arXiv.2407.15780", "summary": "This paper presents a comprehensive theoretical investigation into the\nparameterized complexity of explanation problems in various machine learning\n(ML) models. Contrary to the prevalent black-box perception, our study focuses\non models with transparent internal mechanisms. We address two principal types\nof explanation problems: abductive and contrastive, both in their local and\nglobal variants. Our analysis encompasses diverse ML models, including Decision\nTrees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,\neach offering unique explanatory challenges. This research fills a significant\ngap in explainable AI (XAI) by providing a foundational understanding of the\ncomplexities of generating explanations for these models. This work provides\ninsights vital for further research in the domain of XAI, contributing to the\nbroader discourse on the necessity of transparency and accountability in AI\nsystems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u89e3\u91ca\u95ee\u9898\u7684\u53c2\u6570\u5316\u590d\u6742\u5ea6\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u5177\u6709\u900f\u660e\u5185\u90e8\u673a\u5236\u7684\u6a21\u578b\uff0c\u5305\u62ec\u51b3\u7b56\u6811\u3001\u51b3\u7b56\u96c6\u3001\u51b3\u7b56\u5217\u8868\u3001\u5e03\u5c14\u7535\u8def\u53ca\u5176\u96c6\u6210\u6a21\u578b\u3002", "motivation": "\u586b\u8865\u53ef\u89e3\u91caAI\u9886\u57df\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u4e3a\u7406\u89e3\u751f\u6210\u673a\u5668\u5b66\u4e60\u6a21\u578b\u89e3\u91ca\u7684\u590d\u6742\u6027\u63d0\u4f9b\u57fa\u7840\uff0c\u4fc3\u8fdbAI\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u5236\u3002", "method": "\u5bf9\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u6eaf\u56e0\u548c\u5bf9\u6bd4\u89e3\u91ca\u95ee\u9898\u8fdb\u884c\u53c2\u6570\u5316\u590d\u6742\u5ea6\u5206\u6790\uff0c\u6db5\u76d6\u5c40\u90e8\u548c\u5168\u5c40\u53d8\u4f53\u3002", "result": "\u4e3a\u4e0d\u540cML\u6a21\u578b\u63d0\u4f9b\u4e86\u89e3\u91ca\u95ee\u9898\u590d\u6742\u5ea6\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5404\u79cd\u6a21\u578b\u5728\u89e3\u91ca\u751f\u6210\u65b9\u9762\u7684\u8ba1\u7b97\u7279\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u53ef\u89e3\u91caAI\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86AI\u7cfb\u7edf\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u5236\u7684\u5fc5\u8981\u6027\u3002"}}
