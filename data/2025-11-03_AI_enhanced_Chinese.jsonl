{"id": "2510.26852", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26852", "abs": "https://arxiv.org/abs/2510.26852", "authors": ["Lingyue Fu", "Xin Ding", "Yaoming Zhu", "Shao Zhang", "Lin Qiu", "Weiwen Liu", "Weinan Zhang", "Xuezhi Cao", "Xunliang Cai", "Jiaxin Ding", "Yong Yu"], "title": "CATArena: Evaluation of LLM Agents through Iterative Tournament Competitions", "comment": null, "summary": "Large Language Model (LLM) agents have evolved from basic text generation to\nautonomously completing complex tasks through interaction with external tools.\nHowever, current benchmarks mainly assess end-to-end performance in fixed\nscenarios, restricting evaluation to specific skills and suffering from score\nsaturation and growing dependence on expert annotation as agent capabilities\nimprove. In this work, we emphasize the importance of learning ability,\nincluding both self-improvement and peer-learning, as a core driver for agent\nevolution toward human-level intelligence. We propose an iterative, competitive\npeer-learning framework, which allows agents to refine and optimize their\nstrategies through repeated interactions and feedback, thereby systematically\nevaluating their learning capabilities. To address the score saturation issue\nin current benchmarks, we introduce CATArena, a tournament-style evaluation\nplatform featuring four diverse board and card games with open-ended scoring.\nBy providing tasks without explicit upper score limits, CATArena enables\ncontinuous and dynamic evaluation of rapidly advancing agent capabilities.\nExperimental results and analyses involving both minimal and commercial code\nagents demonstrate that CATArena provides reliable, stable, and scalable\nbenchmarking for core agent abilities, particularly learning ability and\nstrategy coding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CATArena\u8bc4\u4f30\u5e73\u53f0\uff0c\u901a\u8fc7\u56db\u6b3e\u68cb\u724c\u6e38\u620f\u7684\u65e0\u4e0a\u9650\u8bc4\u5206\u7cfb\u7edf\uff0c\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5206\u6570\u9971\u548c\u95ee\u9898\uff0c\u7cfb\u7edf\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u80fd\u529b\u548c\u7b56\u7565\u7f16\u7801\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30\u56fa\u5b9a\u573a\u666f\u4e0b\u7684\u7aef\u5230\u7aef\u6027\u80fd\uff0c\u5b58\u5728\u5206\u6570\u9971\u548c\u3001\u4f9d\u8d56\u4e13\u5bb6\u6807\u6ce8\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u8fed\u4ee3\u5f0f\u7ade\u4e89\u6027\u540c\u4f34\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u91cd\u590d\u4ea4\u4e92\u548c\u53cd\u9988\u4f18\u5316\u7b56\u7565\uff1b\u6784\u5efaCATArena\u5e73\u53f0\uff0c\u5305\u542b\u56db\u6b3e\u5f00\u653e\u5f0f\u68cb\u724c\u6e38\u620f\uff0c\u91c7\u7528\u65e0\u4e0a\u9650\u8bc4\u5206\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eCATArena\u4e3a\u667a\u80fd\u4f53\u6838\u5fc3\u80fd\u529b\uff08\u7279\u522b\u662f\u5b66\u4e60\u80fd\u529b\u548c\u7b56\u7565\u7f16\u7801\uff09\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u7a33\u5b9a\u548c\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "CATArena\u80fd\u591f\u6301\u7eed\u52a8\u6001\u5730\u8bc4\u4f30\u5feb\u901f\u53d1\u5c55\u7684\u667a\u80fd\u4f53\u80fd\u529b\uff0c\u7279\u522b\u662f\u5b66\u4e60\u80fd\u529b\u8fd9\u4e00\u63a8\u52a8\u667a\u80fd\u4f53\u5411\u4eba\u7c7b\u6c34\u5e73\u667a\u80fd\u8fdb\u5316\u7684\u6838\u5fc3\u9a71\u52a8\u529b\u3002"}}
{"id": "2510.26913", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.26913", "abs": "https://arxiv.org/abs/2510.26913", "authors": ["Junyi Shen", "Noppanat Wadlom", "Lingfeng Zhou", "Dequan Wang", "Xu Miao", "Lei Fang", "Yao Lu"], "title": "FlowMesh: A Service Fabric for Composable LLM Workflows", "comment": null, "summary": "AI deployment increasingly resembles a pipeline of data transformation,\nfine-tuning, and agent interactions rather than a monolithic LLM job; recent\nexamples include RLHF/RLAIF training and agentic workflows. To cope with this\nshift, we propose FlowMesh, a multi-tenant service fabric that executes and\noptimizes these workloads as one shared service instead of isolated pipelines.\nIt decomposes workflows into fine-grained operators with recorded lineage,\nenabling de-duplication of work across users and batching requests on the same\nhardware while preserving per-workflow provenance. A global control plane\nmaintains a cluster-wide pool of ready operators and uses a single utility\nfunction to pick both the batch and the worker, balancing throughput, cost, and\ndata locality on heterogeneous GPUs. The data plane is an elastic fleet of\nstateless workers backed by a content-addressable store, enabling rapid,\nautomatic scale-out, safe retry after preemption, and portability across\nmanaged clusters such as Kubernetes and geo-distributed GPU marketplaces such\nas Vast.ai. Compared with baseline solutions, FlowMesh achieves up to 3.8x cost\nreduction and 2.0x lower energy usage, provides a similar or better latency\nprofile, and remains efficient under dynamic and failure-prone conditions.", "AI": {"tldr": "FlowMesh\u662f\u4e00\u4e2a\u591a\u79df\u6237\u670d\u52a1\u67b6\u6784\uff0c\u5c06AI\u5de5\u4f5c\u6d41\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u7b97\u5b50\uff0c\u901a\u8fc7\u5168\u5c40\u63a7\u5236\u5e73\u9762\u548c\u6570\u636e\u5e73\u9762\u5b9e\u73b0\u8de8\u7528\u6237\u5de5\u4f5c\u53bb\u91cd\u3001\u8bf7\u6c42\u6279\u5904\u7406\uff0c\u5728\u5f02\u6784GPU\u4e0a\u5e73\u8861\u541e\u5410\u91cf\u3001\u6210\u672c\u548c\u6570\u636e\u5c40\u90e8\u6027\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\u53ef\u964d\u4f4e3.8\u500d\u6210\u672c\u548c2.0\u500d\u80fd\u8017\u3002", "motivation": "AI\u90e8\u7f72\u6b63\u4ece\u5355\u4e00LLM\u4efb\u52a1\u8f6c\u5411\u6570\u636e\u8f6c\u6362\u3001\u5fae\u8c03\u548c\u667a\u80fd\u4f53\u4ea4\u4e92\u7684\u6d41\u6c34\u7ebf\u6a21\u5f0f\uff0c\u5982RLHF/RLAIF\u8bad\u7ec3\u548c\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002\u4e3a\u5e94\u5bf9\u8fd9\u4e00\u8f6c\u53d8\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6267\u884c\u548c\u4f18\u5316\u8fd9\u4e9b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5171\u4eab\u670d\u52a1\uff0c\u800c\u4e0d\u662f\u5b64\u7acb\u7684\u6d41\u6c34\u7ebf\u3002", "method": "\u5c06\u5de5\u4f5c\u6d41\u5206\u89e3\u4e3a\u5177\u6709\u8bb0\u5f55\u8c31\u7cfb\u7684\u7ec6\u7c92\u5ea6\u7b97\u5b50\uff0c\u5b9e\u73b0\u8de8\u7528\u6237\u5de5\u4f5c\u53bb\u91cd\u548c\u5728\u76f8\u540c\u786c\u4ef6\u4e0a\u6279\u91cf\u5904\u7406\u8bf7\u6c42\uff1b\u5168\u5c40\u63a7\u5236\u5e73\u9762\u7ef4\u62a4\u96c6\u7fa4\u8303\u56f4\u7684\u7b97\u5b50\u6c60\uff0c\u4f7f\u7528\u5355\u4e00\u6548\u7528\u51fd\u6570\u9009\u62e9\u6279\u6b21\u548c\u5de5\u4f5c\u8005\uff1b\u6570\u636e\u5e73\u9762\u662f\u65e0\u72b6\u6001\u5de5\u4f5c\u8005\u5f39\u6027\u8230\u961f\uff0c\u652f\u6301\u5185\u5bb9\u5bfb\u5740\u5b58\u50a8\uff0c\u5b9e\u73b0\u5feb\u901f\u81ea\u52a8\u6269\u5c55\u3001\u5b89\u5168\u91cd\u8bd5\u548c\u8de8\u96c6\u7fa4\u53ef\u79fb\u690d\u6027\u3002", "result": "\u76f8\u6bd4\u57fa\u51c6\u89e3\u51b3\u65b9\u6848\uff0cFlowMesh\u5b9e\u73b0\u9ad8\u8fbe3.8\u500d\u6210\u672c\u964d\u4f4e\u548c2.0\u500d\u80fd\u8017\u964d\u4f4e\uff0c\u63d0\u4f9b\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u5ef6\u8fdf\u7279\u6027\uff0c\u5728\u52a8\u6001\u548c\u6613\u6545\u969c\u6761\u4ef6\u4e0b\u4fdd\u6301\u9ad8\u6548\u3002", "conclusion": "FlowMesh\u901a\u8fc7\u591a\u79df\u6237\u670d\u52a1\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86AI\u5de5\u4f5c\u6d41\u4ece\u5355\u4e00\u4efb\u52a1\u5411\u590d\u6742\u6d41\u6c34\u7ebf\u8f6c\u53d8\u7684\u6311\u6218\uff0c\u5728\u6210\u672c\u3001\u80fd\u8017\u548c\u6027\u80fd\u65b9\u9762\u5747\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u9002\u5408\u52a8\u6001\u548c\u6545\u969c\u6613\u53d1\u7684\u90e8\u7f72\u73af\u5883\u3002"}}
{"id": "2510.27257", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.27257", "abs": "https://arxiv.org/abs/2510.27257", "authors": ["Mengshi Qi", "Jiaxuan Peng", "Jie Zhang", "Juan Zhu", "Yong Li", "Huadong Ma"], "title": "Synergistic Tensor and Pipeline Parallelism", "comment": null, "summary": "In the machine learning system, the hybrid model parallelism combining tensor\nparallelism (TP) and pipeline parallelism (PP) has become the dominant solution\nfor distributed training of Large Language Models~(LLMs) and Multimodal LLMs\n(MLLMs). However, TP introduces significant collective communication overheads,\nwhile PP suffers from synchronization inefficiencies such as pipeline bubbles.\nExisting works primarily address these challenges from isolated perspectives,\nfocusing either on overlapping TP communication or on flexible PP scheduling to\nmitigate pipeline bubbles. In this paper, we propose a new synergistic tensor\nand pipeline parallelism schedule that simultaneously reduces both types of\nbubbles. Our proposed schedule decouples the forward and backward passes in PP\ninto fine-grained computation units, which are then braided to form a composite\ncomputation sequence. This compositional structure enables near-complete\nelimination of TP-related bubbles. Building upon this structure, we further\ndesign the PP schedule to minimize PP bubbles. Experimental results demonstrate\nthat our approach improves training throughput by up to 12% for LLMs and 16%\nfor MLLMs compared to existing scheduling methods. Our source code is avaiable\nat https://github.com/MICLAB-BUPT/STP.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u540c\u5f20\u91cf\u5e76\u884c\u548c\u6d41\u6c34\u7ebf\u5e76\u884c\u8c03\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u524d\u5411\u548c\u540e\u5411\u4f20\u64ad\u4e3a\u7ec6\u7c92\u5ea6\u8ba1\u7b97\u5355\u5143\u5e76\u7f16\u7ec7\u6210\u590d\u5408\u8ba1\u7b97\u5e8f\u5217\uff0c\u540c\u65f6\u51cf\u5c11\u4e24\u79cd\u5e76\u884c\u6a21\u5f0f\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u548c\u6d41\u6c34\u7ebf\u6c14\u6ce1\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u5e76\u884c\u8bad\u7ec3\u65b9\u6cd5\u4e2d\uff0c\u5f20\u91cf\u5e76\u884c\u5e26\u6765\u663e\u8457\u7684\u96c6\u4f53\u901a\u4fe1\u5f00\u9500\uff0c\u800c\u6d41\u6c34\u7ebf\u5e76\u884c\u5b58\u5728\u540c\u6b65\u6548\u7387\u4f4e\u4e0b\u7684\u6d41\u6c34\u7ebf\u6c14\u6ce1\u95ee\u9898\u3002\u73b0\u6709\u5de5\u4f5c\u591a\u4ece\u5b64\u7acb\u89d2\u5ea6\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7f3a\u4e4f\u534f\u540c\u4f18\u5316\u3002", "method": "\u5c06\u6d41\u6c34\u7ebf\u5e76\u884c\u7684\u524d\u5411\u548c\u540e\u5411\u4f20\u64ad\u89e3\u8026\u4e3a\u7ec6\u7c92\u5ea6\u8ba1\u7b97\u5355\u5143\uff0c\u7f16\u7ec7\u6210\u590d\u5408\u8ba1\u7b97\u5e8f\u5217\u4ee5\u6d88\u9664\u5f20\u91cf\u5e76\u884c\u76f8\u5173\u6c14\u6ce1\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bbe\u8ba1\u6d41\u6c34\u7ebf\u5e76\u884c\u8c03\u5ea6\u4ee5\u6700\u5c0f\u5316\u6d41\u6c34\u7ebf\u6c14\u6ce1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u8c03\u5ea6\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728LLM\u8bad\u7ec3\u4e2d\u63d0\u5347\u541e\u5410\u91cf\u8fbe12%\uff0c\u5728MLLM\u8bad\u7ec3\u4e2d\u63d0\u5347\u8fbe16%\u3002", "conclusion": "\u63d0\u51fa\u7684\u534f\u540c\u5f20\u91cf\u548c\u6d41\u6c34\u7ebf\u5e76\u884c\u8c03\u5ea6\u65b9\u6cd5\u80fd\u6709\u6548\u540c\u65f6\u51cf\u5c11\u4e24\u79cd\u5e76\u884c\u6a21\u5f0f\u4e2d\u7684\u6c14\u6ce1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2510.26905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26905", "abs": "https://arxiv.org/abs/2510.26905", "authors": ["Pedro Antonio Alarc\u00f3n Granadeno", "Arturo Miguel Bernal Russell", "Sofia Nelson", "Demetrius Hernandez", "Maureen Petterson", "Michael Murphy", "Walter J. Scheirer", "Jane Cleland-Huang"], "title": "Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations", "comment": "10.5 pages, 9 figures", "summary": "Cyber-physical systems increasingly rely on Foundational Models such as Large\nLanguage Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy\nthrough enhanced perception, inference, and planning. However, these models\nalso introduce new types of errors, such as hallucinations,\novergeneralizations, and context misalignments, resulting in incorrect and\nflawed decisions. To address this, we introduce the concept of Cognition\nEnvelopes, designed to establish reasoning boundaries that constrain\nAI-generated decisions while complementing the use of meta-cognition and\ntraditional safety envelopes. As with safety envelopes, Cognition Envelopes\nrequire practical guidelines and systematic processes for their definition,\nvalidation, and assurance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u8ba4\u77e5\u5305\u7edc\u7684\u6982\u5ff5\uff0c\u65e8\u5728\u4e3aAI\u751f\u6210\u7684\u51b3\u7b56\u5efa\u7acb\u63a8\u7406\u8fb9\u754c\uff0c\u4ee5\u89e3\u51b3\u57fa\u7840\u6a21\u578b\u5728\u7269\u7406\u4fe1\u606f\u7cfb\u7edf\u4e2d\u4ea7\u751f\u7684\u5e7b\u89c9\u3001\u8fc7\u5ea6\u6cdb\u5316\u548c\u4e0a\u4e0b\u6587\u9519\u4f4d\u7b49\u9519\u8bef\u3002", "motivation": "\u968f\u7740\u7269\u7406\u4fe1\u606f\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u57fa\u7840\u6a21\u578b\u6765\u589e\u5f3a\u81ea\u4e3b\u6027\uff0c\u8fd9\u4e9b\u6a21\u578b\u5f15\u5165\u4e86\u65b0\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u5bfc\u81f4\u4e0d\u6b63\u786e\u7684\u51b3\u7b56\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u63a8\u7406\u8fb9\u754c\u6765\u7ea6\u675fAI\u51b3\u7b56\u3002", "method": "\u5f15\u5165\u8ba4\u77e5\u5305\u7edc\u6982\u5ff5\uff0c\u5efa\u7acb\u63a8\u7406\u8fb9\u754c\u6765\u7ea6\u675fAI\u751f\u6210\u7684\u51b3\u7b56\uff0c\u540c\u65f6\u8865\u5145\u5143\u8ba4\u77e5\u548c\u4f20\u7edf\u5b89\u5168\u5305\u7edc\u7684\u4f7f\u7528\uff0c\u9700\u8981\u5b9a\u4e49\u3001\u9a8c\u8bc1\u548c\u4fdd\u8bc1\u7684\u7cfb\u7edf\u5316\u6d41\u7a0b\u3002", "result": "\u63d0\u51fa\u4e86\u8ba4\u77e5\u5305\u7edc\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u4e3a\u7ea6\u675f\u57fa\u7840\u6a21\u578b\u5728\u7269\u7406\u4fe1\u606f\u7cfb\u7edf\u4e2d\u7684\u51b3\u7b56\u9519\u8bef\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8ba4\u77e5\u5305\u7edc\u9700\u8981\u5b9e\u7528\u7684\u6307\u5bfc\u65b9\u9488\u548c\u7cfb\u7edf\u5316\u6d41\u7a0b\u6765\u8fdb\u884c\u5b9a\u4e49\u3001\u9a8c\u8bc1\u548c\u4fdd\u8bc1\uff0c\u7c7b\u4f3c\u4e8e\u5b89\u5168\u5305\u7edc\u7684\u8981\u6c42\uff0c\u4ee5\u6709\u6548\u5e94\u5bf9\u57fa\u7840\u6a21\u578b\u5e26\u6765\u7684\u65b0\u6311\u6218\u3002"}}
{"id": "2510.26989", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.26989", "abs": "https://arxiv.org/abs/2510.26989", "authors": ["Agorakis Bompotas", "Konstantinos Koutras", "Nikitas Rigas Kalogeropoulos", "Panagiotis Kechagias", "Dimitra Gariza", "Athanasios P. Kalogeras", "Christos Alexakos"], "title": "SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation", "comment": "Accepted for presentation to 11th IEEE International Smart Cities\n  Conference (ISC2 2025)", "summary": "The global agricultural sector is undergoing a transformative shift, driven\nby increasing food demands, climate variability and the need for sustainable\npractices. SUSTAINABLE is a smart farming platform designed to integrate IoT,\nAI, satellite imaging, and role-based task orchestration to enable efficient,\ntraceable, and sustainable agriculture with a pilot usecase in viticulture.\nThis paper explores current smart agriculture solutions, presents a comparative\nevaluation, and introduces SUSTAINABLE's key features, including satellite\nindex integration, real-time environmental data, and role-aware task management\ntailored to Mediterranean vineyards.", "AI": {"tldr": "SUSTAINABLE\u662f\u4e00\u4e2a\u667a\u80fd\u519c\u4e1a\u5e73\u53f0\uff0c\u6574\u5408\u7269\u8054\u7f51\u3001\u4eba\u5de5\u667a\u80fd\u3001\u536b\u661f\u6210\u50cf\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u4efb\u52a1\u7f16\u6392\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u8ffd\u6eaf\u548c\u53ef\u6301\u7eed\u7684\u519c\u4e1a\uff0c\u5e76\u4ee5\u8461\u8404\u683d\u57f9\u4e3a\u8bd5\u70b9\u5e94\u7528\u6848\u4f8b\u3002", "motivation": "\u5168\u7403\u519c\u4e1a\u90e8\u95e8\u9762\u4e34\u7cae\u98df\u9700\u6c42\u589e\u957f\u3001\u6c14\u5019\u591a\u53d8\u6027\u548c\u53ef\u6301\u7eed\u5b9e\u8df5\u9700\u6c42\uff0c\u9700\u8981\u8f6c\u578b\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u5e73\u53f0\u6574\u5408\u7269\u8054\u7f51\u3001AI\u3001\u536b\u661f\u6210\u50cf\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u4efb\u52a1\u7f16\u6392\uff0c\u7279\u522b\u9488\u5bf9\u5730\u4e2d\u6d77\u8461\u8404\u56ed\u63d0\u4f9b\u536b\u661f\u6307\u6570\u96c6\u6210\u3001\u5b9e\u65f6\u73af\u5883\u6570\u636e\u548c\u89d2\u8272\u611f\u77e5\u4efb\u52a1\u7ba1\u7406\u3002", "result": "\u8bba\u6587\u5bf9\u73b0\u6709\u667a\u80fd\u519c\u4e1a\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u4e86\u6bd4\u8f83\u8bc4\u4f30\uff0c\u5e76\u4ecb\u7ecd\u4e86SUSTAINABLE\u5e73\u53f0\u7684\u5173\u952e\u7279\u6027\u3002", "conclusion": "SUSTAINABLE\u5e73\u53f0\u901a\u8fc7\u6280\u672f\u521b\u65b0\u4e3a\u519c\u4e1a\u53ef\u6301\u7eed\u53d1\u5c55\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u8461\u8404\u683d\u57f9\u9886\u57df\u5c55\u793a\u4e86\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.27317", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.27317", "abs": "https://arxiv.org/abs/2510.27317", "authors": ["Shuyi Chen", "Panagiotis Oikonomou", "Zhengchang Hua", "Nikos Tziritas", "Karim Djemame", "Nan Zhang", "Georgios Theodoropoulos"], "title": "Dynamic Service Scheduling and Resource Management in Energy-Harvesting Multi-access Edge Computing", "comment": "Accepted by the 21st IEEE International Conference on Green Computing\n  and Communications (GreenCom 2025)", "summary": "Multi-access Edge Computing (MEC) delivers low-latency services by hosting\napplications near end-users. To promote sustainability, these systems are\nincreasingly integrated with renewable Energy Harvesting (EH) technologies,\nenabling operation where grid electricity is unavailable. However, balancing\nthe intermittent nature of harvested energy with dynamic user demand presents a\nsignificant resource allocation challenge. This work proposes an online\nstrategy for an MEC system powered exclusively by EH to address this trade-off.\nOur strategy dynamically schedules computational tasks with dependencies and\ngoverns energy consumption through real-time decisions on server frequency\nscaling and service module migration. Experiments using real-world datasets\ndemonstrate our algorithm's effectiveness in efficiently utilizing harvested\nenergy while maintaining low service latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u7b56\u7565\uff0c\u7528\u4e8e\u5b8c\u5168\u7531\u80fd\u91cf\u6536\u96c6\u4f9b\u7535\u7684\u591a\u63a5\u5165\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u5ea6\u8ba1\u7b97\u4efb\u52a1\u548c\u63a7\u5236\u80fd\u8017\u6765\u5e73\u8861\u95f4\u6b47\u6027\u80fd\u91cf\u4e0e\u52a8\u6001\u7528\u6237\u9700\u6c42\u3002", "motivation": "\u591a\u63a5\u5165\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e0e\u53ef\u518d\u751f\u80fd\u6e90\u6536\u96c6\u6280\u672f\u7ed3\u5408\u4ee5\u63d0\u5347\u53ef\u6301\u7eed\u6027\uff0c\u4f46\u5728\u65e0\u7535\u7f51\u4f9b\u7535\u60c5\u51b5\u4e0b\uff0c\u5e73\u8861\u95f4\u6b47\u6027\u80fd\u91cf\u4e0e\u52a8\u6001\u7528\u6237\u9700\u6c42\u5b58\u5728\u8d44\u6e90\u5206\u914d\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5728\u7ebf\u7b56\u7565\uff0c\u52a8\u6001\u8c03\u5ea6\u5177\u6709\u4f9d\u8d56\u5173\u7cfb\u7684\u8ba1\u7b97\u4efb\u52a1\uff0c\u901a\u8fc7\u670d\u52a1\u5668\u9891\u7387\u8c03\u6574\u548c\u670d\u52a1\u6a21\u5757\u8fc1\u79fb\u5b9e\u65f6\u63a7\u5236\u80fd\u8017\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u6709\u6548\u5229\u7528\u6536\u96c6\u80fd\u91cf\u7684\u540c\u65f6\u4fdd\u6301\u4f4e\u670d\u52a1\u5ef6\u8fdf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5728\u7ebf\u7b56\u7565\u80fd\u591f\u6709\u6548\u89e3\u51b3\u80fd\u91cf\u6536\u96c6\u4f9b\u7535\u7684\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u4f4e\u5ef6\u8fdf\u670d\u52a1\u3002"}}
{"id": "2510.27009", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.27009", "abs": "https://arxiv.org/abs/2510.27009", "authors": ["Jared Junkin", "Samuel Nathanson"], "title": "Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models", "comment": "8 pages, NeurIPS 2025", "summary": "Language models are traditionally designed around causal masking. In domains\nwith spatial or relational structure, causal masking is often viewed as\ninappropriate, and sequential linearizations are instead used. Yet the question\nof whether it is viable to accept the information loss introduced by causal\nmasking on nonsequential data has received little direct study, in part because\nfew domains offer both spatial and sequential representations of the same\ndataset. In this work, we investigate this issue in the domain of chess, which\nnaturally supports both representations. We train language models with\nbidirectional and causal self-attention mechanisms on both spatial\n(board-based) and sequential (move-based) data. Our results show that models\ntrained on spatial board states - \\textit{even with causal masking} -\nconsistently achieve stronger playing strength than models trained on\nsequential data. While our experiments are conducted on chess, our results are\nmethodological and may have broader implications: applying causal masking to\nspatial data is a viable procedure for training unimodal LLMs on spatial data,\nand in some domains is even preferable to sequentialization.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u975e\u987a\u5e8f\u6570\u636e\u4e0a\u5e94\u7528\u56e0\u679c\u63a9\u7801\u662f\u53ef\u884c\u7684\uff0c\u5728\u68cb\u7c7b\u7b49\u7a7a\u95f4\u7ed3\u6784\u6570\u636e\u4e0a\uff0c\u57fa\u4e8e\u7a7a\u95f4\u8868\u793a\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8e\u987a\u5e8f\u8868\u793a\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "motivation": "\u63a2\u8ba8\u5728\u5177\u6709\u7a7a\u95f4\u6216\u5173\u7cfb\u7ed3\u6784\u7684\u9886\u57df\u4e2d\uff0c\u63a5\u53d7\u56e0\u679c\u63a9\u7801\u5e26\u6765\u7684\u4fe1\u606f\u635f\u5931\u662f\u5426\u53ef\u884c\uff0c\u4ee5\u53ca\u7a7a\u95f4\u8868\u793a\u4e0e\u987a\u5e8f\u8868\u793a\u5728\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6548\u679c\u5dee\u5f02\u3002", "method": "\u5728\u68cb\u7c7b\u9886\u57df\u8bad\u7ec3\u5177\u6709\u53cc\u5411\u548c\u56e0\u679c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u522b\u4f7f\u7528\u7a7a\u95f4\uff08\u68cb\u76d8\u72b6\u6001\uff09\u548c\u987a\u5e8f\uff08\u8d70\u68cb\u5e8f\u5217\uff09\u4e24\u79cd\u6570\u636e\u8868\u793a\u65b9\u5f0f\u3002", "result": "\u57fa\u4e8e\u7a7a\u95f4\u68cb\u76d8\u72b6\u6001\u8bad\u7ec3\u7684\u6a21\u578b\uff08\u5373\u4f7f\u4f7f\u7528\u56e0\u679c\u63a9\u7801\uff09\u5728\u68cb\u529b\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u987a\u5e8f\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "conclusion": "\u5728\u7a7a\u95f4\u6570\u636e\u4e0a\u5e94\u7528\u56e0\u679c\u63a9\u7801\u662f\u8bad\u7ec3\u5355\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5728\u67d0\u4e9b\u9886\u57df\u751a\u81f3\u4f18\u4e8e\u987a\u5e8f\u5316\u5904\u7406\u3002"}}
{"id": "2510.27351", "categories": ["cs.DC", "65Y05, 65Y10, 90C59, 68T20"], "pdf": "https://arxiv.org/pdf/2510.27351", "abs": "https://arxiv.org/abs/2510.27351", "authors": ["Milena Veneva"], "title": "ML-Based Optimum Sub-system Size Heuristic for the GPU Implementation of the Tridiagonal Partition Method", "comment": "10 pages, 6 figures, 4 tables, DLCP conference 2025, Moscow, Russia", "summary": "This paper presents a machine learning (ML)-based heuristic for finding the\noptimum sub-system size for the CUDA implementation of the parallel partition\nalgorithm. Computational experiments for different system of linear algebraic\nequation (SLAE) sizes are conducted, and the optimum sub-system size for each\nof them is found empirically. To estimate a model for the sub-system size, we\nperform the k-nearest neighbors (kNN) classification method. Statistical\nanalysis of the results is done. By comparing the predicted values with the\nactual data, the algorithm is deemed to be acceptably good. Next, the heuristic\nis expanded to work for the recursive parallel partition algorithm as well. An\nalgorithm for determining the optimum sub-system size for each recursive step\nis formulated. A kNN model for predicting the optimum number of recursive steps\nfor a particular SLAE size is built.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bfb\u627e\u5e76\u884c\u5206\u533a\u7b97\u6cd5CUDA\u5b9e\u73b0\u7684\u6700\u4f73\u5b50\u7cfb\u7edf\u5927\u5c0f\u3002\u901a\u8fc7k\u8fd1\u90bb\u5206\u7c7b\u65b9\u6cd5\u5efa\u7acb\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u6269\u5c55\u5230\u9012\u5f52\u5e76\u884c\u5206\u533a\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u5e76\u884c\u5206\u533a\u7b97\u6cd5\u7684CUDA\u5b9e\u73b0\u5bfb\u627e\u6700\u4f18\u5b50\u7cfb\u7edf\u5927\u5c0f\uff0c\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5efa\u7acb\u9884\u6d4b\u6a21\u578b\u6765\u907f\u514d\u8017\u65f6\u7684\u7ecf\u9a8c\u6027\u6d4b\u8bd5\u3002", "method": "\u5bf9\u4e0d\u540c\u89c4\u6a21\u7684\u7ebf\u6027\u4ee3\u6570\u65b9\u7a0b\u7ec4\u8fdb\u884c\u8ba1\u7b97\u5b9e\u9a8c\uff0c\u7ecf\u9a8c\u6027\u5730\u627e\u5230\u6700\u4f18\u5b50\u7cfb\u7edf\u5927\u5c0f\uff1b\u4f7f\u7528k\u8fd1\u90bb\u5206\u7c7b\u65b9\u6cd5\u5efa\u7acb\u5b50\u7cfb\u7edf\u5927\u5c0f\u7684\u9884\u6d4b\u6a21\u578b\uff1b\u5c06\u542f\u53d1\u5f0f\u65b9\u6cd5\u6269\u5c55\u5230\u9012\u5f52\u5e76\u884c\u5206\u533a\u7b97\u6cd5\uff0c\u6784\u5efa\u9884\u6d4b\u6700\u4f18\u9012\u5f52\u6b65\u6570\u7684kNN\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u9884\u6d4b\u503c\u4e0e\u5b9e\u9645\u6570\u636e\uff0c\u7b97\u6cd5\u8868\u73b0\u826f\u597d\uff1b\u6210\u529f\u6784\u5efa\u4e86\u9884\u6d4b\u6700\u4f18\u5b50\u7cfb\u7edf\u5927\u5c0f\u548c\u9012\u5f52\u6b65\u6570\u7684\u6a21\u578b\u3002", "conclusion": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5e76\u884c\u5206\u533a\u7b97\u6cd5\u7684\u6700\u4f18\u5b50\u7cfb\u7edf\u5927\u5c0f\u548c\u9012\u5f52\u6b65\u6570\uff0c\u4e3aCUDA\u5b9e\u73b0\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4f18\u5316\u5de5\u5177\u3002"}}
{"id": "2510.27042", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.27042", "abs": "https://arxiv.org/abs/2510.27042", "authors": ["Michael Kleinman", "Matthew Trager", "Alessandro Achille", "Wei Xia", "Stefano Soatto"], "title": "e1: Learning Adaptive Control of Reasoning Effort", "comment": null, "summary": "Increasing the thinking budget of AI models can significantly improve\naccuracy, but not all questions warrant the same amount of reasoning. Users may\nprefer to allocate different amounts of reasoning effort depending on how they\nvalue output quality versus latency and cost. To leverage this tradeoff\neffectively, users need fine-grained control over the amount of thinking used\nfor a particular query, but few approaches enable such control. Existing\nmethods require users to specify the absolute number of desired tokens, but\nthis requires knowing the difficulty of the problem beforehand to appropriately\nset the token budget for a query. To address these issues, we propose Adaptive\nEffort Control, a self-adaptive reinforcement learning method that trains\nmodels to use a user-specified fraction of tokens relative to the current\naverage chain-of-thought length for each query. This approach eliminates\ndataset- and phase-specific tuning while producing better cost-accuracy\ntradeoff curves compared to standard methods. Users can dynamically adjust the\ncost-accuracy trade-off through a continuous effort parameter specified at\ninference time. We observe that the model automatically learns to allocate\nresources proportionally to the task difficulty and, across model scales\nranging from 1.5B to 32B parameters, our approach enables approximately 3x\nreduction in chain-of-thought length while maintaining or improving performance\nrelative to the base model used for RL training.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u52aa\u529b\u63a7\u5236\u65b9\u6cd5\uff0c\u8ba9AI\u6a21\u578b\u6839\u636e\u7528\u6237\u6307\u5b9a\u7684\u52aa\u529b\u53c2\u6570\u52a8\u6001\u8c03\u6574\u63a8\u7406\u957f\u5ea6\uff0c\u5b9e\u73b0\u6210\u672c-\u51c6\u786e\u6027\u7684\u7075\u6d3b\u6743\u8861\uff0c\u76f8\u6bd4\u6807\u51c6\u65b9\u6cd5\u51cf\u5c11\u7ea63\u500d\u63a8\u7406\u957f\u5ea6\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u7528\u6237\u9884\u5148\u6307\u5b9a\u7edd\u5bf9token\u6570\u91cf\uff0c\u4f46\u7528\u6237\u96be\u4ee5\u4e8b\u5148\u77e5\u9053\u95ee\u9898\u96be\u5ea6\u6765\u8bbe\u7f6e\u5408\u9002\u7684token\u9884\u7b97\u3002\u9700\u8981\u8ba9\u7528\u6237\u80fd\u591f\u6839\u636e\u8f93\u51fa\u8d28\u91cf\u4e0e\u5ef6\u8fdf\u6210\u672c\u7684\u6743\u8861\uff0c\u5bf9\u7279\u5b9a\u67e5\u8be2\u7cbe\u7ec6\u63a7\u5236\u63a8\u7406\u52aa\u529b\u7a0b\u5ea6\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u52aa\u529b\u63a7\u5236\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\uff0c\u8ba9\u6a21\u578b\u6839\u636e\u7528\u6237\u6307\u5b9a\u7684\u76f8\u5bf9\u5f53\u524d\u5e73\u5747\u601d\u7ef4\u94fe\u957f\u5ea6\u7684token\u6bd4\u4f8b\u6765\u8c03\u6574\u63a8\u7406\u52aa\u529b\u3002\u7528\u6237\u53ef\u4ee5\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u8fde\u7eed\u52aa\u529b\u53c2\u6570\u52a8\u6001\u8c03\u6574\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\u3002", "result": "\u6a21\u578b\u81ea\u52a8\u5b66\u4e60\u6309\u4efb\u52a1\u96be\u5ea6\u6bd4\u4f8b\u5206\u914d\u8d44\u6e90\uff0c\u57281.5B\u523032B\u53c2\u6570\u89c4\u6a21\u8303\u56f4\u5185\uff0c\u76f8\u6bd4\u7528\u4e8eRL\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u51cf\u5c11\u7ea63\u500d\u7684\u601d\u7ef4\u94fe\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u81ea\u9002\u5e94\u52aa\u529b\u63a7\u5236\u65b9\u6cd5\u6d88\u9664\u4e86\u6570\u636e\u96c6\u548c\u9636\u6bb5\u7279\u5b9a\u7684\u8c03\u4f18\u9700\u6c42\uff0c\u76f8\u6bd4\u6807\u51c6\u65b9\u6cd5\u4ea7\u751f\u66f4\u597d\u7684\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\u66f2\u7ebf\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u52a8\u6001\u8c03\u6574\u63a8\u7406\u52aa\u529b\u7684\u7075\u6d3b\u63a7\u5236\u80fd\u529b\u3002"}}
{"id": "2510.27094", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27094", "abs": "https://arxiv.org/abs/2510.27094", "authors": ["Hamed Mahdavi", "Pouria Mahdavinia", "Alireza Farhadi", "Pegah Mohammadipour", "Samira Malek", "Majid Daliri", "Pedram Mohammadipour", "Alireza Hashemi", "Amir Khasahmadi", "Vasant Honavar"], "title": "CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning", "comment": "Code/data: https://github.com/ref-grader/ref-grader,\n  https://huggingface.co/datasets/combviz/inoi", "summary": "State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based\nOlympiad problems to solving most of the IMO 2025 problems, with leading\nsystems reportedly handling 5 of 6 problems. Given this progress, we assess how\nwell these models can grade proofs: detecting errors, judging their severity,\nand assigning fair scores beyond binary correctness. We study proof-analysis\ncapabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we\ngrade on a 1-4 scale with detailed error annotations, and on MathArena solution\nsets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models\ncan reliably flag incorrect (including subtly incorrect) solutions but exhibit\ncalibration gaps in how partial credit is assigned. To address this, we\nintroduce agentic workflows that extract and analyze reference solutions and\nautomatically derive problem-specific rubrics for a multi-step grading process.\nWe instantiate and compare different design choices for the grading workflows,\nand evaluate their trade-offs. Across our annotated corpus and MathArena, our\nproposed workflows achieve higher agreement with human grades and more\nconsistent handling of partial credit across metrics. We release all code,\ndata, and prompts/logs to facilitate future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u5148\u8fdbLLMs\u5728\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5305\u62ec\u9519\u8bef\u68c0\u6d4b\u3001\u4e25\u91cd\u6027\u5224\u65ad\u548c\u5206\u6570\u5206\u914d\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u7684\u8bc4\u5206\u65b9\u6cd5\u6765\u89e3\u51b3\u90e8\u5206\u5206\u6570\u5206\u914d\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740SOTA LLMs\u4ece\u96be\u4ee5\u89e3\u51b3\u57fa\u4e8e\u8bc1\u660e\u7684\u5965\u8d5b\u95ee\u9898\u53d1\u5c55\u5230\u80fd\u591f\u89e3\u51b3\u5927\u90e8\u5206IMO 2025\u95ee\u9898\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5728\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u68c0\u6d4b\u9519\u8bef\u3001\u5224\u65ad\u4e25\u91cd\u6027\u548c\u5206\u914d\u516c\u5e73\u5206\u6570\u3002", "method": "\u4f7f\u7528\u5305\u542b90\u4e2aGemini 2.5 Pro\u751f\u6210\u89e3\u51b3\u65b9\u6848\u7684\u8bed\u6599\u5e93\uff0c\u91c7\u75281-4\u5206\u5236\u8fdb\u884c\u8bc4\u5206\u548c\u8be6\u7ec6\u9519\u8bef\u6807\u6ce8\uff1b\u540c\u65f6\u4f7f\u7528MathArena\u7684IMO/USAMO 2025\u89e3\u51b3\u65b9\u6848\u96c6\u8fdb\u884c0-7\u5206\u5236\u8bc4\u5206\u3002\u5f15\u5165\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\uff0c\u63d0\u53d6\u548c\u5206\u6790\u53c2\u8003\u89e3\u51b3\u65b9\u6848\uff0c\u81ea\u52a8\u63a8\u5bfc\u95ee\u9898\u7279\u5b9a\u7684\u8bc4\u5206\u6807\u51c6\uff0c\u5b9e\u73b0\u591a\u6b65\u9aa4\u8bc4\u5206\u8fc7\u7a0b\u3002", "result": "\u6a21\u578b\u80fd\u591f\u53ef\u9760\u5730\u6807\u8bb0\u9519\u8bef\u89e3\u51b3\u65b9\u6848\uff08\u5305\u62ec\u7ec6\u5fae\u9519\u8bef\uff09\uff0c\u4f46\u5728\u90e8\u5206\u5206\u6570\u5206\u914d\u65b9\u9762\u5b58\u5728\u6821\u51c6\u5dee\u8ddd\u3002\u63d0\u51fa\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u5728\u4eba\u5de5\u8bc4\u5206\u4e00\u81f4\u6027\u548c\u90e8\u5206\u5206\u6570\u5904\u7406\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u80fd\u591f\u63d0\u9ad8\u4e0e\u4eba\u5de5\u8bc4\u5206\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u90e8\u5206\u5206\u6570\u5904\u7406\u65b9\u9762\u66f4\u52a0\u4e00\u81f4\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4ee3\u7801\u3001\u6570\u636e\u548c\u63d0\u793a/\u65e5\u5fd7\u8d44\u6e90\u3002"}}
{"id": "2510.27343", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27343", "abs": "https://arxiv.org/abs/2510.27343", "authors": ["Ali Norouzifar", "Wil van der Aalst"], "title": "Discriminative Rule Learning for Outcome-Guided Process Model Discovery", "comment": "The paper will be published as part of the CoopIS 2025 conference\n  proceedings", "summary": "Event logs extracted from information systems offer a rich foundation for\nunderstanding and improving business processes. In many real-world\napplications, it is possible to distinguish between desirable and undesirable\nprocess executions, where desirable traces reflect efficient or compliant\nbehavior, and undesirable ones may involve inefficiencies, rule violations,\ndelays, or resource waste. This distinction presents an opportunity to guide\nprocess discovery in a more outcome-aware manner. Discovering a single process\nmodel without considering outcomes can yield representations poorly suited for\nconformance checking and performance analysis, as they fail to capture critical\nbehavioral differences. Moreover, prioritizing one behavior over the other may\nobscure structural distinctions vital for understanding process outcomes. By\nlearning interpretable discriminative rules over control-flow features, we\ngroup traces with similar desirability profiles and apply process discovery\nseparately within each group. This results in focused and interpretable models\nthat reveal the drivers of both desirable and undesirable executions. The\napproach is implemented as a publicly available tool and it is evaluated on\nmultiple real-life event logs, demonstrating its effectiveness in isolating and\nvisualizing critical process patterns.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u679c\u611f\u77e5\u7684\u8fc7\u7a0b\u53d1\u73b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u533a\u5206\u7406\u60f3\u548c\u4e0d\u7406\u60f3\u7684\u8fc7\u7a0b\u6267\u884c\u8f68\u8ff9\uff0c\u5206\u522b\u5b66\u4e60\u8fc7\u7a0b\u6a21\u578b\uff0c\u4ece\u800c\u63ed\u793a\u5173\u952e\u884c\u4e3a\u5dee\u5f02\u3002", "motivation": "\u4f20\u7edf\u8fc7\u7a0b\u53d1\u73b0\u65b9\u6cd5\u4e0d\u8003\u8651\u6267\u884c\u7ed3\u679c\u5dee\u5f02\uff0c\u5bfc\u81f4\u6a21\u578b\u96be\u4ee5\u6709\u6548\u652f\u6301\u5408\u89c4\u68c0\u67e5\u548c\u6027\u80fd\u5206\u6790\uff0c\u65e0\u6cd5\u6355\u6349\u7406\u60f3\u4e0e\u4e0d\u7406\u60f3\u6267\u884c\u4e4b\u95f4\u7684\u5173\u952e\u884c\u4e3a\u533a\u522b\u3002", "method": "\u901a\u8fc7\u5b66\u4e60\u63a7\u5236\u6d41\u7279\u5f81\u4e0a\u7684\u53ef\u89e3\u91ca\u5224\u522b\u89c4\u5219\uff0c\u5c06\u5177\u6709\u76f8\u4f3c\u7406\u60f3\u6027\u7279\u5f81\u7684\u8f68\u8ff9\u5206\u7ec4\uff0c\u5e76\u5728\u6bcf\u4e2a\u7ec4\u5185\u5206\u522b\u5e94\u7528\u8fc7\u7a0b\u53d1\u73b0\u6280\u672f\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u771f\u5b9e\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u5f97\u5230\u9a8c\u8bc1\uff0c\u80fd\u591f\u6709\u6548\u5206\u79bb\u548c\u53ef\u89c6\u5316\u5173\u952e\u8fc7\u7a0b\u6a21\u5f0f\uff0c\u751f\u6210\u805a\u7126\u4e14\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u3002", "conclusion": "\u7ed3\u679c\u611f\u77e5\u7684\u8fc7\u7a0b\u53d1\u73b0\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u63ed\u793a\u7406\u60f3\u548c\u4e0d\u7406\u60f3\u8fc7\u7a0b\u6267\u884c\u7684\u9a71\u52a8\u56e0\u7d20\uff0c\u4e3a\u8fc7\u7a0b\u6539\u8fdb\u63d0\u4f9b\u66f4\u6709\u9488\u5bf9\u6027\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.27353", "categories": ["cs.AI", "I.2.8; F.2.2"], "pdf": "https://arxiv.org/pdf/2510.27353", "abs": "https://arxiv.org/abs/2510.27353", "authors": ["Julien Herrmann", "Guillaume Pallez"], "title": "An In-depth Study of LLM Contributions to the Bin Packing Problem", "comment": "15 pages, 13 figures", "summary": "Recent studies have suggested that Large Language Models (LLMs) could provide\ninteresting ideas contributing to mathematical discovery. This claim was\nmotivated by reports that LLM-based genetic algorithms produced heuristics\noffering new insights into the online bin packing problem under uniform and\nWeibull distributions. In this work, we reassess this claim through a detailed\nanalysis of the heuristics produced by LLMs, examining both their behavior and\ninterpretability. Despite being human-readable, these heuristics remain largely\nopaque even to domain experts. Building on this analysis, we propose a new\nclass of algorithms tailored to these specific bin packing instances. The\nderived algorithms are significantly simpler, more efficient, more\ninterpretable, and more generalizable, suggesting that the considered instances\nare themselves relatively simple. We then discuss the limitations of the claim\nregarding LLMs' contribution to this problem, which appears to rest on the\nmistaken assumption that the instances had previously been studied. Our\nfindings instead emphasize the need for rigorous validation and\ncontextualization when assessing the scientific value of LLM-generated outputs.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u8bc4\u4f30\u4e86LLMs\u5728\u6570\u5b66\u53d1\u73b0\u4e2d\u7684\u8d21\u732e\uff0c\u901a\u8fc7\u5bf9LLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\uff0c\u53d1\u73b0\u8fd9\u4e9b\u7b97\u6cd5\u867d\u7136\u4eba\u7c7b\u53ef\u8bfb\u4f46\u96be\u4ee5\u89e3\u91ca\uff0c\u5e76\u63d0\u51fa\u4e86\u66f4\u7b80\u5355\u3001\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u65b0\u7b97\u6cd5\uff0c\u5f3a\u8c03\u4e86\u5bf9LLM\u751f\u6210\u8f93\u51fa\u8fdb\u884c\u4e25\u683c\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u91cd\u65b0\u8bc4\u4f30LLMs\u5728\u6570\u5b66\u53d1\u73b0\u4e2d\u7684\u8d21\u732e\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u4e2dLLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u89e3\u91ca\u6027\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "method": "\u8be6\u7ec6\u5206\u6790LLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u884c\u4e3a\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u51fa\u9488\u5bf9\u7279\u5b9a\u88c5\u7bb1\u95ee\u9898\u5b9e\u4f8b\u7684\u65b0\u7b97\u6cd5\u7c7b\u522b\uff0c\u5e76\u4e0eLLM\u751f\u6210\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u53d1\u73b0LLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u867d\u7136\u4eba\u7c7b\u53ef\u8bfb\u4f46\u5bf9\u9886\u57df\u4e13\u5bb6\u4ecd\u4e0d\u900f\u660e\uff0c\u63d0\u51fa\u7684\u65b0\u7b97\u6cd5\u66f4\u7b80\u5355\u3001\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u66f4\u5177\u6cdb\u5316\u6027\uff0c\u8868\u660e\u6240\u8003\u8651\u7684\u95ee\u9898\u5b9e\u4f8b\u672c\u8eab\u76f8\u5bf9\u7b80\u5355\u3002", "conclusion": "LLMs\u5bf9\u8be5\u95ee\u9898\u7684\u8d21\u732e\u5b58\u5728\u5c40\u9650\u6027\uff0c\u57fa\u4e8e\u9519\u8bef\u5047\u8bbe\uff08\u8ba4\u4e3a\u8fd9\u4e9b\u5b9e\u4f8b\u5df2\u88ab\u7814\u7a76\u8fc7\uff09\uff0c\u5f3a\u8c03\u9700\u8981\u5bf9LLM\u751f\u6210\u8f93\u51fa\u8fdb\u884c\u4e25\u683c\u9a8c\u8bc1\u548c\u60c5\u5883\u5316\u8bc4\u4f30\u3002"}}
{"id": "2510.27383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27383", "abs": "https://arxiv.org/abs/2510.27383", "authors": ["Yueyang Wang", "Mehmet Dogar", "Gustav Markkula"], "title": "Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints", "comment": null, "summary": "Modelling pedestrian-driver interactions is critical for understanding human\nroad user behaviour and developing safe autonomous vehicle systems. Existing\napproaches often rely on rule-based logic, game-theoretic models, or\n'black-box' machine learning methods. However, these models typically lack\nflexibility or overlook the underlying mechanisms, such as sensory and motor\nconstraints, which shape how pedestrians and drivers perceive and act in\ninteractive scenarios. In this study, we propose a multi-agent reinforcement\nlearning (RL) framework that integrates both visual and motor constraints of\npedestrian and driver agents. Using a real-world dataset from an unsignalised\npedestrian crossing, we evaluate four model variants, one without constraints,\ntwo with either motor or visual constraints, and one with both, across\nbehavioural metrics of interaction realism. Results show that the combined\nmodel with both visual and motor constraints performs best. Motor constraints\nlead to smoother movements that resemble human speed adjustments during\ncrossing interactions. The addition of visual constraints introduces perceptual\nuncertainty and field-of-view limitations, leading the agents to exhibit more\ncautious and variable behaviour, such as less abrupt deceleration. In this\ndata-limited setting, our model outperforms a supervised behavioural cloning\nmodel, demonstrating that our approach can be effective without large training\ndatasets. Finally, our framework accounts for individual differences by\nmodelling parameters controlling the human constraints as population-level\ndistributions, a perspective that has not been explored in previous work on\npedestrian-vehicle interaction modelling. Overall, our work demonstrates that\nmulti-agent RL with human constraints is a promising modelling approach for\nsimulating realistic road user interactions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u89c6\u89c9\u548c\u8fd0\u52a8\u7ea6\u675f\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u884c\u4eba-\u9a7e\u9a76\u5458\u4ea4\u4e92\u884c\u4e3a\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u65e0\u4fe1\u53f7\u4eba\u884c\u6a2a\u9053\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u89c4\u5219\u903b\u8f91\u3001\u535a\u5f08\u8bba\u6216\u9ed1\u76d2\u673a\u5668\u5b66\u4e60\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u4e14\u5ffd\u89c6\u611f\u77e5\u548c\u8fd0\u52a8\u7ea6\u675f\u7b49\u5e95\u5c42\u673a\u5236\uff0c\u8fd9\u4e9b\u673a\u5236\u5851\u9020\u4e86\u884c\u4eba\u548c\u9a7e\u9a76\u5458\u5728\u4ea4\u4e92\u573a\u666f\u4e2d\u7684\u611f\u77e5\u548c\u884c\u4e3a\u65b9\u5f0f\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6574\u5408\u884c\u4eba\u548c\u9a7e\u9a76\u5458\u667a\u80fd\u4f53\u7684\u89c6\u89c9\u548c\u8fd0\u52a8\u7ea6\u675f\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u6a21\u578b\u53d8\u4f53\uff1a\u65e0\u7ea6\u675f\u3001\u4ec5\u8fd0\u52a8\u7ea6\u675f\u3001\u4ec5\u89c6\u89c9\u7ea6\u675f\u3001\u4e24\u8005\u517c\u5907\u3002", "result": "\u7ed3\u5408\u89c6\u89c9\u548c\u8fd0\u52a8\u7ea6\u675f\u7684\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002\u8fd0\u52a8\u7ea6\u675f\u4ea7\u751f\u66f4\u5e73\u6ed1\u7684\u8fd0\u52a8\uff0c\u7c7b\u4f3c\u4eba\u7c7b\u5728\u7a7f\u8d8a\u4ea4\u4e92\u4e2d\u7684\u901f\u5ea6\u8c03\u6574\uff1b\u89c6\u89c9\u7ea6\u675f\u5f15\u5165\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u89c6\u91ce\u9650\u5236\uff0c\u4f7f\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u66f4\u8c28\u614e\u548c\u53ef\u53d8\u7684\u884c\u4e3a\u3002\u5728\u6570\u636e\u6709\u9650\u60c5\u51b5\u4e0b\uff0c\u8be5\u6a21\u578b\u4f18\u4e8e\u76d1\u7763\u884c\u4e3a\u514b\u9686\u6a21\u578b\u3002", "conclusion": "\u7ed3\u5408\u4eba\u7c7b\u7ea6\u675f\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u662f\u6a21\u62df\u771f\u5b9e\u9053\u8def\u7528\u6237\u4ea4\u4e92\u7684\u6709\u524d\u666f\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u63a7\u5236\u4eba\u7c7b\u7ea6\u675f\u7684\u53c2\u6570\u5efa\u6a21\u4e3a\u7fa4\u4f53\u7ea7\u5206\u5e03\u6765\u8003\u8651\u4e2a\u4f53\u5dee\u5f02\uff0c\u8fd9\u662f\u5148\u524d\u884c\u4eba-\u8f66\u8f86\u4ea4\u4e92\u5efa\u6a21\u5de5\u4f5c\u4e2d\u672a\u63a2\u7d22\u7684\u89c6\u89d2\u3002"}}
{"id": "2510.27419", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.27419", "abs": "https://arxiv.org/abs/2510.27419", "authors": ["Tian Liang", "Wenxiang Jiao", "Zhiwei He", "Jiahao Xu", "Haitao Mi", "Dong Yu"], "title": "DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains", "comment": "Work in progress", "summary": "Large Reasoning Models (LRMs) have demonstrated impressive capabilities but\nsuffer from cognitive inefficiencies like ``overthinking'' simple problems and\n``underthinking'' complex ones. While existing methods that use supervised\nfine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can\nimprove efficiency, they often do so at the cost of accuracy. This paper\nintroduces \\textbf{DeepCompress}, a novel framework that simultaneously\nenhances both the accuracy and efficiency of LRMs. We challenge the prevailing\napproach of consistently favoring shorter reasoning paths, showing that longer\nresponses can contain a broader range of correct solutions for difficult\nproblems. DeepCompress employs an adaptive length reward mechanism that\ndynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on\nthe model's evolving capability. It encourages shorter, more efficient\nreasoning for ``Simple'' problems while promoting longer, more exploratory\nthought chains for ``Hard'' problems. This dual-reward strategy enables the\nmodel to autonomously adjust its Chain-of-Thought (CoT) length, compressing\nreasoning for well-mastered problems and extending it for those it finds\nchallenging. Experimental results on challenging mathematical benchmarks show\nthat DeepCompress consistently outperforms baseline methods, achieving superior\naccuracy while significantly improving token efficiency.", "AI": {"tldr": "DeepCompress\u662f\u4e00\u4e2a\u65b0\u9896\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u957f\u5ea6\u5956\u52b1\u673a\u5236\u540c\u65f6\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u6839\u636e\u95ee\u9898\u96be\u5ea6\u52a8\u6001\u8c03\u6574\u63a8\u7406\u94fe\u957f\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u6216\u5e26token\u957f\u5ea6\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u6765\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u5f80\u5f80\u4ee5\u727a\u7272\u51c6\u786e\u6027\u4e3a\u4ee3\u4ef7\u3002\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8ba4\u77e5\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u5982\u5bf9\u7b80\u5355\u95ee\u9898\"\u8fc7\u5ea6\u601d\u8003\"\u548c\u5bf9\u590d\u6742\u95ee\u9898\"\u601d\u8003\u4e0d\u8db3\"\u3002", "method": "DeepCompress\u91c7\u7528\u81ea\u9002\u5e94\u957f\u5ea6\u5956\u52b1\u673a\u5236\uff0c\u5b9e\u65f6\u6839\u636e\u6a21\u578b\u80fd\u529b\u5c06\u95ee\u9898\u52a8\u6001\u5206\u7c7b\u4e3a\"\u7b80\u5355\"\u6216\"\u56f0\u96be\"\u3002\u5bf9\u4e8e\u7b80\u5355\u95ee\u9898\u9f13\u52b1\u66f4\u77ed\u3001\u66f4\u9ad8\u6548\u7684\u63a8\u7406\uff0c\u5bf9\u4e8e\u56f0\u96be\u95ee\u9898\u5219\u4fc3\u8fdb\u66f4\u957f\u3001\u66f4\u5177\u63a2\u7d22\u6027\u7684\u601d\u7ef4\u94fe\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepCompress\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u663e\u8457\u63d0\u9ad8token\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u6a21\u578b\u80fd\u591f\u81ea\u4e3b\u8c03\u6574\u5176\u601d\u7ef4\u94fe\u957f\u5ea6\uff0c\u538b\u7f29\u5df2\u638c\u63e1\u95ee\u9898\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5e76\u6269\u5c55\u5176\u8ba4\u4e3a\u5177\u6709\u6311\u6218\u6027\u95ee\u9898\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ece\u800c\u540c\u65f6\u63d0\u5347\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.27448", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27448", "abs": "https://arxiv.org/abs/2510.27448", "authors": ["Yuhao Zhang", "Dingxin Hu", "Tinghao Yu", "Hao Liu", "Yiting Liu"], "title": "GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language", "comment": null, "summary": "Multi-modal Large Language Models (MLLMs) have gained significant attention\nin both academia and industry for their capabilities in handling multi-modal\ntasks. However, these models face challenges in mathematical geometric\nreasoning due to the scarcity of high-quality geometric data. To address this\nissue, synthetic geometric data has become an essential strategy. Current\nmethods for generating synthetic geometric data involve rephrasing or expanding\nexisting problems and utilizing predefined rules and templates to create\ngeometric images and problems. However, these approaches often produce data\nthat lacks diversity or is prone to noise. Additionally, the geometric images\nsynthesized by existing methods tend to exhibit limited variation and deviate\nsignificantly from authentic geometric diagrams. To overcome these limitations,\nwe propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses\nformal languages to explore combinations of conditions within metric space,\ngenerating high-fidelity geometric problems that differ from the originals\nwhile ensuring correctness through a symbolic engine. Experimental results show\nthat our synthetic data significantly outperforms existing methods. The model\ntrained with our data surpass the proprietary GPT-4o model by 18.7\\% on\ngeometry problem-solving tasks in MathVista and by 16.5\\% on GeoQA.\nAdditionally, it exceeds the performance of a leading open-source model by\n5.7\\% on MathVista and by 2.7\\% on GeoQA.", "AI": {"tldr": "GeoFM\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5f62\u5f0f\u8bed\u8a00\u5728\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u63a2\u7d22\u6761\u4ef6\u7ec4\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b26\u53f7\u5f15\u64ce\u751f\u6210\u9ad8\u4fdd\u771f\u51e0\u4f55\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51e0\u4f55\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u51e0\u4f55\u63a8\u7406\u65b9\u9762\u9762\u4e34\u9ad8\u8d28\u91cf\u51e0\u4f55\u6570\u636e\u7a00\u7f3a\u7684\u6311\u6218\uff0c\u73b0\u6709\u5408\u6210\u51e0\u4f55\u6570\u636e\u65b9\u6cd5\u5b58\u5728\u591a\u6837\u6027\u4e0d\u8db3\u3001\u566a\u58f0\u591a\u3001\u56fe\u50cf\u53d8\u5316\u6709\u9650\u4e14\u4e0e\u771f\u5b9e\u51e0\u4f55\u56fe\u504f\u79bb\u8f83\u5927\u7684\u95ee\u9898\u3002", "method": "GeoFM\u4f7f\u7528\u5f62\u5f0f\u8bed\u8a00\u5728\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u63a2\u7d22\u6761\u4ef6\u7ec4\u5408\uff0c\u901a\u8fc7\u7b26\u53f7\u5f15\u64ce\u751f\u6210\u4e0e\u539f\u59cb\u95ee\u9898\u4e0d\u540c\u4f46\u786e\u4fdd\u6b63\u786e\u6027\u7684\u9ad8\u4fdd\u771f\u51e0\u4f55\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528GeoFM\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728MathVista\u51e0\u4f55\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u4e0a\u8d85\u8fc7GPT-4o\u6a21\u578b18.7%\uff0c\u5728GeoQA\u4e0a\u8d85\u8fc716.5%\uff1b\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\uff0c\u5728MathVista\u4e0a\u8d85\u8fc75.7%\uff0c\u5728GeoQA\u4e0a\u8d85\u8fc72.7%\u3002", "conclusion": "GeoFM\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u51e0\u4f55\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51e0\u4f55\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.27568", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.27568", "abs": "https://arxiv.org/abs/2510.27568", "authors": ["Ali Asgarov", "Umid Suleymanov", "Aadyant Khatri"], "title": "SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning", "comment": "Short Paper - Under Review", "summary": "Solving mathematical reasoning problems requires not only accurate access to\nrelevant knowledge but also careful, multi-step thinking. However, current\nretrieval-augmented models often rely on a single perspective, follow\ninflexible search strategies, and struggle to effectively combine information\nfrom multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge\nIntegration for AGentic Mathematical reAsoning), a unified framework that\norchestrates specialized agents to independently reason, perform targeted\nsearches, and synthesize findings through a moderator mechanism. Each agent\ngenerates hypothetical passages to optimize retrieval for its analytic\nperspective, ensuring knowledge integration is both context-sensitive and\ncomputation-efficient. When evaluated on challenging benchmarks such as\nMATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms\nboth open- and closed-source systems, achieving an absolute performance\nimprovement of 7.4%. Our results demonstrate that multi-agent, on-demand\nknowledge integration significantly enhances both reasoning accuracy and\nefficiency, offering a scalable approach for complex, knowledge-intensive\nproblem-solving. We will release the code upon publication.", "AI": {"tldr": "SIGMA\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u4e13\u95e8\u667a\u80fd\u4f53\u8fdb\u884c\u72ec\u7acb\u63a8\u7406\u3001\u76ee\u6807\u641c\u7d22\u548c\u7ed3\u679c\u5408\u6210\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u68c0\u7d22\u589e\u5f3a\u6a21\u578b\u5b58\u5728\u5355\u89c6\u89d2\u4f9d\u8d56\u3001\u641c\u7d22\u7b56\u7565\u50f5\u5316\u3001\u591a\u6e90\u4fe1\u606f\u6574\u5408\u56f0\u96be\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u590d\u6742\u7684\u6570\u5b66\u63a8\u7406\u95ee\u9898\u3002", "method": "\u5f15\u5165SIGMA\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u95e8\u667a\u80fd\u4f53\u72ec\u7acb\u63a8\u7406\u5e76\u751f\u6210\u5047\u8bbe\u6027\u6bb5\u843d\u4f18\u5316\u68c0\u7d22\uff0c\u4f7f\u7528\u8c03\u8282\u673a\u5236\u5408\u6210\u53d1\u73b0\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u654f\u611f\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u77e5\u8bc6\u6574\u5408\u3002", "result": "\u5728MATH500\u3001AIME\u548cGPQA\u7b49\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSIGMA\u6301\u7eed\u4f18\u4e8e\u5f00\u6e90\u548c\u95ed\u6e90\u7cfb\u7edf\uff0c\u7edd\u5bf9\u6027\u80fd\u63d0\u53477.4%\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u6309\u9700\u77e5\u8bc6\u6574\u5408\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3a\u590d\u6742\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u9898\u89e3\u51b3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u65b9\u6cd5\u3002"}}
{"id": "2510.27617", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27617", "abs": "https://arxiv.org/abs/2510.27617", "authors": ["Heng Ping", "Arijit Bhattacharjee", "Peiyu Zhang", "Shixuan Li", "Wei Yang", "Anzhe Cheng", "Xiaole Zhang", "Jesse Thomason", "Ali Jannesari", "Nesreen Ahmed", "Paul Bogdan"], "title": "VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation", "comment": null, "summary": "Automation of Register Transfer Level (RTL) design can help developers meet\nincreasing computational demands. Large Language Models (LLMs) show promise for\nHardware Description Language (HDL) generation, but face challenges due to\nlimited parametric knowledge and domain-specific constraints. While prompt\nengineering and fine-tuning have limitations in knowledge coverage and training\ncosts, multi-agent architectures offer a training-free paradigm to enhance\nreasoning through collaborative generation. However, current multi-agent\napproaches suffer from two critical deficiencies: susceptibility to noise\npropagation and constrained reasoning space exploration. We propose VeriMoA, a\ntraining-free mixture-of-agents (MoA) framework with two synergistic\ninnovations. First, a quality-guided caching mechanism to maintain all\nintermediate HDL outputs and enables quality-based ranking and selection across\nthe entire generation process, encouraging knowledge accumulation over layers\nof reasoning. Second, a multi-path generation strategy that leverages C++ and\nPython as intermediate representations, decomposing specification-to-HDL\ntranslation into two-stage processes that exploit LLM fluency in high-resource\nlanguages while promoting solution diversity. Comprehensive experiments on\nVerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves\n15--30% improvements in Pass@1 across diverse LLM backbones, especially\nenabling smaller models to match larger models and fine-tuned alternatives\nwithout requiring costly training.", "AI": {"tldr": "VeriMoA\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u8d28\u91cf\u5f15\u5bfc\u7f13\u5b58\u548c\u591a\u8def\u5f84\u751f\u6210\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00(HDL)\u751f\u6210\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e8615-30%\u7684Pass@1\u6539\u8fdb\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\u751f\u6210\u65b9\u9762\u9762\u4e34\u53c2\u6570\u77e5\u8bc6\u6709\u9650\u548c\u9886\u57df\u7279\u5b9a\u7ea6\u675f\u7684\u6311\u6218\uff0c\u800c\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u5b58\u5728\u566a\u58f0\u4f20\u64ad\u548c\u63a8\u7406\u7a7a\u95f4\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u534f\u540c\u521b\u65b0\uff1a1) \u8d28\u91cf\u5f15\u5bfc\u7f13\u5b58\u673a\u5236\uff0c\u7ef4\u62a4\u6240\u6709\u4e2d\u95f4HDL\u8f93\u51fa\u5e76\u8fdb\u884c\u8d28\u91cf\u6392\u5e8f\u9009\u62e9\uff1b2) \u591a\u8def\u5f84\u751f\u6210\u7b56\u7565\uff0c\u5229\u7528C++\u548cPython\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u5c06\u89c4\u8303\u5230HDL\u7684\u7ffb\u8bd1\u5206\u89e3\u4e3a\u4e24\u9636\u6bb5\u8fc7\u7a0b\u3002", "result": "\u5728VerilogEval 2.0\u548cRTLLM 2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVeriMoA\u5b9e\u73b0\u4e8615-30%\u7684Pass@1\u6539\u8fdb\uff0c\u7279\u522b\u662f\u4f7f\u8f83\u5c0f\u6a21\u578b\u80fd\u591f\u5339\u914d\u8f83\u5927\u6a21\u578b\u548c\u5fae\u8c03\u66ff\u4ee3\u65b9\u6848\uff0c\u65e0\u9700\u6602\u8d35\u8bad\u7ec3\u3002", "conclusion": "VeriMoA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u9ad8\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u663e\u8457\u63d0\u5347\u4e86HDL\u751f\u6210\u80fd\u529b\uff0c\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.27628", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27628", "abs": "https://arxiv.org/abs/2510.27628", "authors": ["Sebastian Benthall", "Andrew Clark"], "title": "Validity Is What You Need", "comment": null, "summary": "While AI agents have long been discussed and studied in computer science,\ntoday's Agentic AI systems are something new. We consider other definitions of\nAgentic AI and propose a new realist definition. Agentic AI is a software\ndelivery mechanism, comparable to software as a service (SaaS), which puts an\napplication to work autonomously in a complex enterprise setting. Recent\nadvances in large language models (LLMs) as foundation models have driven\nexcitement in Agentic AI. We note, however, that Agentic AI systems are\nprimarily applications, not foundations, and so their success depends on\nvalidation by end users and principal stakeholders. The tools and techniques\nneeded by the principal users to validate their applications are quite\ndifferent from the tools and techniques used to evaluate foundation models.\nIronically, with good validation measures in place, in many cases the\nfoundation models can be replaced with much simpler, faster, and more\ninterpretable models that handle core logic. When it comes to Agentic AI,\nvalidity is what you need. LLMs are one option that might achieve it.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Agentic AI\u7684\u65b0\u5b9a\u4e49\uff0c\u5c06\u5176\u89c6\u4e3a\u5728\u590d\u6742\u4f01\u4e1a\u73af\u5883\u4e2d\u81ea\u4e3b\u5de5\u4f5c\u7684\u8f6f\u4ef6\u4ea4\u4ed8\u673a\u5236\uff0c\u5f3a\u8c03\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u800c\u975e\u4ec5\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5bf9Agentic AI\u7684\u5b9a\u4e49\u4e0d\u591f\u6e05\u6670\uff0c\u9700\u8981\u4ece\u73b0\u5b9e\u5e94\u7528\u89d2\u5ea6\u91cd\u65b0\u5b9a\u4e49\uff0c\u5e76\u5f3a\u8c03\u9a8c\u8bc1\u5728Agentic AI\u7cfb\u7edf\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83Agentic AI\u4e0eSaaS\u7684\u76f8\u4f3c\u6027\uff0c\u63d0\u51fa\u65b0\u7684\u73b0\u5b9e\u4e3b\u4e49\u5b9a\u4e49\uff0c\u5e76\u5206\u6790\u9a8c\u8bc1\u5de5\u5177\u4e0e\u57fa\u7840\u6a21\u578b\u8bc4\u4f30\u5de5\u5177\u7684\u533a\u522b\u3002", "result": "\u53d1\u73b0Agentic AI\u4e3b\u8981\u662f\u5e94\u7528\u800c\u975e\u57fa\u7840\uff0c\u5176\u6210\u529f\u4f9d\u8d56\u4e8e\u7ec8\u7aef\u7528\u6237\u548c\u4e3b\u8981\u5229\u76ca\u76f8\u5173\u8005\u7684\u9a8c\u8bc1\uff0c\u5728\u826f\u597d\u9a8c\u8bc1\u673a\u5236\u4e0b\uff0c\u57fa\u7840\u6a21\u578b\u53ef\u88ab\u66f4\u7b80\u5355\u3001\u5feb\u901f\u3001\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u66ff\u4ee3\u3002", "conclusion": "Agentic AI\u7684\u5173\u952e\u5728\u4e8e\u6709\u6548\u6027\u9a8c\u8bc1\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u53ea\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u53ef\u80fd\u9009\u9879\u4e4b\u4e00\uff0c\u800c\u975e\u5fc5\u8981\u6761\u4ef6\u3002"}}
