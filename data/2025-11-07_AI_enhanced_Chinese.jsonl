{"id": "2511.03761", "categories": ["cs.MA", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.03761", "abs": "https://arxiv.org/abs/2511.03761", "authors": ["Umut \u00c7al\u0131ky\u0131lmaz", "Nitin Nayak", "Jinghua Groppe", "Sven Groppe"], "title": "OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems", "comment": null, "summary": "In recent years, the research of multi-agent systems has taken a direction to\nexplore larger and more complex models to fulfill sophisticated tasks. We point\nout two possible pitfalls that might be caused by increasing complexity;\nsusceptibilities to faults, and performance bottlenecks. To prevent the former\nthreat, we propose a transaction-based framework to design very complex\nmulti-agent systems (VCMAS). To address the second threat, we offer to\nintegrate transaction scheduling into the proposed framework. We implemented\nboth of these ideas to develop the OptiMA framework and show that it is able to\nfacilitate the execution of VCMAS with more than a hundred agents. We also\ndemonstrate the effect of transaction scheduling on such a system by showing\nimprovements up to more than 16\\%. Furthermore, we also performed a theoretical\nanalysis on the transaction scheduling problem and provided practical tools\nthat can be used for future research on it.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86OptiMA\u6846\u67b6\uff0c\u901a\u8fc7\u4e8b\u52a1\u673a\u5236\u548c\u4e8b\u52a1\u8c03\u5ea6\u6765\u89e3\u51b3\u590d\u6742\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u6613\u53d1\u6027\u548c\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u652f\u6301\u8d85\u8fc7100\u4e2a\u667a\u80fd\u4f53\u7684\u7cfb\u7edf\u8fd0\u884c\uff0c\u6027\u80fd\u63d0\u5347\u8d85\u8fc716%\u3002", "motivation": "\u968f\u7740\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u5411\u66f4\u5927\u66f4\u590d\u6742\u6a21\u578b\u53d1\u5c55\uff0c\u4f5c\u8005\u6307\u51fa\u4e24\u4e2a\u6f5c\u5728\u95ee\u9898\uff1a\u6545\u969c\u6613\u53d1\u6027\u548c\u6027\u80fd\u74f6\u9888\u3002\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u9884\u9632\u8fd9\u4e9b\u5a01\u80c1\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e8b\u52a1\u7684\u6846\u67b6\u6765\u8bbe\u8ba1\u590d\u6742\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u96c6\u6210\u4e8b\u52a1\u8c03\u5ea6\u673a\u5236\u3002\u5f00\u53d1\u4e86OptiMA\u6846\u67b6\u5b9e\u73b0\u8fd9\u4e9b\u60f3\u6cd5\u3002", "result": "OptiMA\u6846\u67b6\u80fd\u591f\u652f\u6301\u8d85\u8fc7100\u4e2a\u667a\u80fd\u4f53\u7684\u590d\u6742\u7cfb\u7edf\u8fd0\u884c\uff0c\u4e8b\u52a1\u8c03\u5ea6\u5e26\u6765\u8d85\u8fc716%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5bf9\u4e8b\u52a1\u8c03\u5ea6\u95ee\u9898\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u3002", "conclusion": "\u4e8b\u52a1\u673a\u5236\u548c\u4e8b\u52a1\u8c03\u5ea6\u662f\u89e3\u51b3\u590d\u6742\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u6027\u80fd\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0cOptiMA\u6846\u67b6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.03844", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03844", "abs": "https://arxiv.org/abs/2511.03844", "authors": ["Yuran Ding", "Xinwei Chen", "Xiaofan Zhang", "Zongwei Zhou"], "title": "ASAP: an Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training", "comment": "This work has been accepted to Workshop on ML for Systems at NeurIPS\n  2025", "summary": "Optimizing large-language model (LLM) training on distributed domain-specific\naccelerator systems presents significant challenges due to its complex\noptimization space. Existing optimization methods, however, rely on\ntime-consuming manual tuning or resource-intensive black-box searches, which\nstruggle to keep pace with the rapidly evolving LLM domain, leading to slow\ndevelopment and underutilized resources. To address this, we introduce ASAP, an\nAgentic Solution to Auto-optimize Performance of Large-Scale LLM Training. It\nis a multi-agent system, featuring Coordinator, Analyzer, and Proposal agents,\nwhich integrates LLM reasoning with insights from performance profiling tools,\nroofline analysis, and a knowledge base of best practices and successful past\noptimizations from human experts. Our proposed design can automate the\ndiagnosis of performance bottlenecks and recommend optimized sharding\nconfigurations with reasoning, thus effectively improving the efficiency of\ndistributed LLM training. Experiments have shown that the ASAP-generated\nsharding configurations can contribute up to 28% training step time reduction\nand 1.43 times throughput improvement. When combined with additional\noptimization from human experts, throughput can be further increased to 2.58\ntimes. The proposed ASAP promises to provide a scalable and explainable\nmethodology for AI-assisted performance engineering in large-scale LLM\ntraining.", "AI": {"tldr": "ASAP\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u4f18\u5316\u5927\u89c4\u6a21LLM\u8bad\u7ec3\u6027\u80fd\uff0c\u901a\u8fc7\u96c6\u6210LLM\u63a8\u7406\u4e0e\u6027\u80fd\u5206\u6790\u5de5\u5177\uff0c\u81ea\u52a8\u8bca\u65ad\u6027\u80fd\u74f6\u9888\u5e76\u63a8\u8350\u4f18\u5316\u7684\u5206\u7247\u914d\u7f6e\uff0c\u53ef\u5b9e\u73b0\u6700\u9ad828%\u7684\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u548c1.43\u500d\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u8017\u65f6\u7684\u624b\u52a8\u8c03\u4f18\u6216\u8d44\u6e90\u5bc6\u96c6\u7684\u9ed1\u76d2\u641c\u7d22\uff0c\u96be\u4ee5\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684LLM\u9886\u57df\uff0c\u5bfc\u81f4\u5f00\u53d1\u7f13\u6162\u548c\u8d44\u6e90\u5229\u7528\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u5305\u542b\u534f\u8c03\u5668\u3001\u5206\u6790\u5668\u548c\u63d0\u8bae\u5668\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u96c6\u6210LLM\u63a8\u7406\u3001\u6027\u80fd\u5206\u6790\u5de5\u5177\u3001\u5c4b\u9876\u7ebf\u5206\u6790\u548c\u5305\u542b\u4e13\u5bb6\u6700\u4f73\u5b9e\u8df5\u7684\u77e5\u8bc6\u5e93\u3002", "result": "ASAP\u751f\u6210\u7684\u5206\u7247\u914d\u7f6e\u53ef\u51cf\u5c1128%\u8bad\u7ec3\u65f6\u95f4\uff0c\u63d0\u53471.43\u500d\u541e\u5410\u91cf\uff1b\u7ed3\u5408\u4e13\u5bb6\u4f18\u5316\u540e\u541e\u5410\u91cf\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u81f32.58\u500d\u3002", "conclusion": "ASAP\u4e3a\u5927\u89c4\u6a21LLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684AI\u8f85\u52a9\u6027\u80fd\u5de5\u7a0b\u65b9\u6cd5\u3002"}}
{"id": "2511.03958", "categories": ["cs.MA", "cs.CL", "cs.HC", "I.2.11; I.2.6; K.3.1"], "pdf": "https://arxiv.org/pdf/2511.03958", "abs": "https://arxiv.org/abs/2511.03958", "authors": ["Kia Karbasi", "Kevin Hong", "Mohammad Amin Samadi", "Gregory Pottie"], "title": "Multi-Agent Collaborative Framework For Math Problem Generation", "comment": "Published in the Proceedings of the 18th International Conference on\n  Educational Data Mining, 6 pages, 5 figures", "summary": "Automatic question generation (AQG) for mathematics education remains an\nelusive goal for Intelligent Tutoring Systems and educators. While pre-trained\ntransformer-based language models have significantly advanced natural language\ngeneration, they often struggle to precisely control problem complexity and\ncognitive demands. In this paper, we introduce a collaborative multi-agent\nframework as a novel method of incorporating inference-time computation into\nAQG. This approach leverages multiple agents that iteratively refine generated\nquestion-answer pairs to better balance complexity and cognitive demand. We\nevaluate the generated questions on five meta-evaluation criteria: relevance,\nimportance, clarity, difficulty matching, answerability, to assess the system's\nability to control the required complexity and quality of the questions.\nPreliminary evaluations show that this collaborative multi-agent framework\nelevates the quality of generated educational content by fostering a more\nnuanced balance between cognitive challenge and clarity. These promising\noutcomes suggest that integrating collaborative multi-agent workflows can yield\nmore controlled, pedagogically valuable content that can help advance automated\neducational content generation and adaptive learning environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u6570\u5b66\u6559\u80b2\u4e2d\u7684\u81ea\u52a8\u95ee\u9898\u751f\u6210\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u8ba1\u7b97\u6765\u66f4\u597d\u5730\u63a7\u5236\u95ee\u9898\u590d\u6742\u5ea6\u548c\u8ba4\u77e5\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u6559\u80b2\u81ea\u52a8\u95ee\u9898\u751f\u6210\u4e2d\u96be\u4ee5\u7cbe\u786e\u63a7\u5236\u95ee\u9898\u590d\u6742\u5ea6\u548c\u8ba4\u77e5\u9700\u6c42\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6559\u80b2\u5185\u5bb9\u3002", "method": "\u91c7\u7528\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u591a\u4e2a\u667a\u80fd\u4f53\u8fed\u4ee3\u4f18\u5316\u751f\u6210\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u4ee5\u5e73\u8861\u590d\u6742\u5ea6\u548c\u8ba4\u77e5\u9700\u6c42\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u663e\u793a\u8be5\u6846\u67b6\u5728\u76f8\u5173\u6027\u3001\u91cd\u8981\u6027\u3001\u6e05\u6670\u5ea6\u3001\u96be\u5ea6\u5339\u914d\u548c\u53ef\u56de\u7b54\u6027\u4e94\u4e2a\u5143\u8bc4\u4f30\u6807\u51c6\u4e0a\u63d0\u5347\u4e86\u751f\u6210\u6559\u80b2\u5185\u5bb9\u7684\u8d28\u91cf\u3002", "conclusion": "\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u80fd\u591f\u4ea7\u751f\u66f4\u53d7\u63a7\u3001\u66f4\u5177\u6559\u5b66\u4ef7\u503c\u7684\u5185\u5bb9\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u81ea\u52a8\u5316\u6559\u80b2\u5185\u5bb9\u751f\u6210\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u73af\u5883\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.03866", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.03866", "abs": "https://arxiv.org/abs/2511.03866", "authors": ["Arijit Bhattacharjee", "Ali TehraniJamsaz", "Le Chen", "Niranjan Hasabnis", "Mihai Capota", "Nesreen Ahmed", "Ali Jannesari"], "title": "OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms", "comment": null, "summary": "Recent advances in large language models (LLMs) have significantly\naccelerated progress in code translation, enabling more accurate and efficient\ntransformation across programming languages. While originally developed for\nnatural language processing, LLMs have shown strong capabilities in modeling\nprogramming language syntax and semantics, outperforming traditional rule-based\nsystems in both accuracy and flexibility. These models have streamlined\ncross-language conversion, reduced development overhead, and accelerated legacy\ncode migration. In this paper, we introduce OMPILOT, a novel domain-specific\nencoder-decoder transformer tailored for translating C++ code into OpenMP,\nenabling effective shared-memory parallelization. OMPILOT leverages custom\npre-training objectives that incorporate the semantics of parallel constructs\nand combines both unsupervised and supervised learning strategies to improve\ncode translation robustness. Unlike previous work that focused primarily on\nloop-level transformations, OMPILOT operates at the function level to capture a\nwider semantic context. To evaluate our approach, we propose OMPBLEU, a novel\ncomposite metric specifically crafted to assess the correctness and quality of\nOpenMP parallel constructs, addressing limitations in conventional translation\nmetrics.", "AI": {"tldr": "OMPILOT\u662f\u4e00\u4e2a\u4e13\u4e3a\u5c06C++\u4ee3\u7801\u7ffb\u8bd1\u6210OpenMP\u5e76\u884c\u4ee3\u7801\u800c\u8bbe\u8ba1\u7684\u9886\u57df\u7279\u5b9a\u7f16\u7801\u5668-\u89e3\u7801\u5668\u8f6c\u6362\u5668\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u65e0\u76d1\u7763\u548c\u6709\u76d1\u7763\u5b66\u4e60\u7b56\u7565\u63d0\u9ad8\u4ee3\u7801\u7ffb\u8bd1\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u51fd\u6570\u7ea7\u522b\u8fdb\u884c\u64cd\u4f5c\u4ee5\u6355\u83b7\u66f4\u5e7f\u6cdb\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u65b9\u9762\u663e\u793a\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u5faa\u73af\u7ea7\u8f6c\u6362\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u66f4\u5e7f\u6cdb\u8bed\u4e49\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u4ee3\u7801\u7ffb\u8bd1\u7684\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u5171\u4eab\u5185\u5b58\u5e76\u884c\u5316\u3002", "method": "OMPILOT\u91c7\u7528\u81ea\u5b9a\u4e49\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u7ed3\u5408\u5e76\u884c\u6784\u9020\u7684\u8bed\u4e49\uff0c\u4f7f\u7528\u65e0\u76d1\u7763\u548c\u6709\u76d1\u7763\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u51fd\u6570\u7ea7\u522b\u8fdb\u884c\u4ee3\u7801\u7ffb\u8bd1\u3002\u540c\u65f6\u63d0\u51fa\u4e86OMPBLEU\u8bc4\u4f30\u6307\u6807\u6765\u8bc4\u4f30OpenMP\u5e76\u884c\u6784\u9020\u7684\u6b63\u786e\u6027\u548c\u8d28\u91cf\u3002", "result": "OMPILOT\u80fd\u591f\u6709\u6548\u5730\u5c06C++\u4ee3\u7801\u8f6c\u6362\u4e3aOpenMP\u5e76\u884c\u4ee3\u7801\uff0c\u5b9e\u73b0\u4e86\u5171\u4eab\u5185\u5b58\u5e76\u884c\u5316\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\u5728\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "OMPILOT\u4e3a\u4ee3\u7801\u7ffb\u8bd1\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5e76\u884c\u7f16\u7a0b\u65b9\u9762\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u7684\u8f6c\u6362\u5668\u6a21\u578b\u548c\u4e13\u95e8\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u7ffb\u8bd1\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2511.03825", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03825", "abs": "https://arxiv.org/abs/2511.03825", "authors": ["Ahmed Mostafa", "Raisul Arefin Nahid", "Samuel Mulder"], "title": "How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis", "comment": "Publication Notice. This paper was published in the BAR 2025 Workshop\n  (with NDSS 2025) and is for research and educational use. Copyright\n  \\c{opyright} 2025 Internet Society. All rights reserved. Personal/classroom\n  reproduction is permitted with this notice and full paper citation. All other\n  uses, including commercial, require prior written permission from the\n  Internet Society", "summary": "Tokenization is fundamental in assembly code analysis, impacting intrinsic\ncharacteristics like vocabulary size, semantic coverage, and extrinsic\nperformance in downstream tasks. Despite its significance, tokenization in the\ncontext of assembly code remains an underexplored area. This study aims to\naddress this gap by evaluating the intrinsic properties of Natural Language\nProcessing (NLP) tokenization models and parameter choices, such as vocabulary\nsize. We explore preprocessing customization options and pre-tokenization rules\ntailored to the unique characteristics of assembly code. Additionally, we\nassess their impact on downstream tasks like function signature prediction -- a\ncritical problem in binary code analysis.\n  To this end, we conduct a thorough study on various tokenization models,\nsystematically analyzing their efficiency in encoding assembly instructions and\ncapturing semantic nuances. Through intrinsic evaluations, we compare\ntokenizers based on tokenization efficiency, vocabulary compression, and\nrepresentational fidelity for assembly code. Using state-of-the-art pre-trained\nmodels such as the decoder-only Large Language Model (LLM) Llama 3.2, the\nencoder-only transformer BERT, and the encoder-decoder model BART, we evaluate\nthe effectiveness of these tokenizers across multiple performance metrics.\nPreliminary findings indicate that tokenizer choice significantly influences\ndownstream performance, with intrinsic metrics providing partial but incomplete\npredictability of extrinsic evaluation outcomes. These results reveal complex\ntrade-offs between intrinsic tokenizer properties and their utility in\npractical assembly code tasks. Ultimately, this study provides valuable\ninsights into optimizing tokenization models for low-level code analysis,\ncontributing to the robustness and scalability of Natural Language Model\n(NLM)-based binary analysis workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86NLP\u5206\u8bcd\u6a21\u578b\u5728\u6c47\u7f16\u4ee3\u7801\u5206\u6790\u4e2d\u7684\u5185\u5728\u7279\u6027\uff0c\u5305\u62ec\u8bcd\u6c47\u91cf\u5927\u5c0f\u3001\u8bed\u4e49\u8986\u76d6\u7b49\uff0c\u5e76\u63a2\u8ba8\u4e86\u9884\u5904\u7406\u5b9a\u5236\u9009\u9879\u548c\u9884\u5206\u8bcd\u89c4\u5219\u5bf9\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u51fd\u6570\u7b7e\u540d\u9884\u6d4b\uff09\u7684\u5f71\u54cd\u3002", "motivation": "\u6c47\u7f16\u4ee3\u7801\u5206\u6790\u4e2d\u7684\u5206\u8bcd\u65b9\u6cd5\u662f\u4e00\u4e2a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\uff0c\u4f46\u5176\u5bf9\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8bc4\u4f30\u4e0d\u540c\u5206\u8bcd\u6a21\u578b\u7684\u5185\u5728\u7279\u6027\u53ca\u5176\u5bf9\u6c47\u7f16\u4ee3\u7801\u5206\u6790\u7684\u9002\u7528\u6027\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u5404\u79cd\u5206\u8bcd\u6a21\u578b\uff0c\u5206\u6790\u5176\u5728\u7f16\u7801\u6c47\u7f16\u6307\u4ee4\u548c\u6355\u6349\u8bed\u4e49\u7ec6\u5fae\u5dee\u522b\u65b9\u9762\u7684\u6548\u7387\u3002\u4f7f\u7528Llama 3.2\u3001BERT\u548cBART\u7b49\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u901a\u8fc7\u5185\u5728\u8bc4\u4f30\u6bd4\u8f83\u5206\u8bcd\u5668\u7684\u6548\u7387\u3001\u8bcd\u6c47\u538b\u7f29\u548c\u8868\u793a\u4fdd\u771f\u5ea6\u3002", "result": "\u521d\u6b65\u53d1\u73b0\u8868\u660e\u5206\u8bcd\u5668\u9009\u62e9\u663e\u8457\u5f71\u54cd\u4e0b\u6e38\u6027\u80fd\uff0c\u5185\u5728\u6307\u6807\u53ea\u80fd\u90e8\u5206\u9884\u6d4b\u5916\u5728\u8bc4\u4f30\u7ed3\u679c\u3002\u7814\u7a76\u63ed\u793a\u4e86\u5185\u5728\u5206\u8bcd\u5668\u7279\u6027\u4e0e\u5b9e\u9645\u6c47\u7f16\u4ee3\u7801\u4efb\u52a1\u6548\u7528\u4e4b\u95f4\u7684\u590d\u6742\u6743\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4f18\u5316\u4f4e\u5c42\u4ee3\u7801\u5206\u6790\u7684\u5206\u8bcd\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u7684\u4e8c\u8fdb\u5236\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.03941", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03941", "abs": "https://arxiv.org/abs/2511.03941", "authors": ["Fabio Diniz Rossi"], "title": "Stochastic Modeling for Energy-Efficient Edge Infrastructure", "comment": "8 pages, 4 figures, 3 tables", "summary": "Edge Computing enables low-latency processing for real-time applications but\nintroduces challenges in power management due to the distributed nature of edge\ndevices and their limited energy resources. This paper proposes a stochastic\nmodeling approach using Markov Chains to analyze power state transitions in\nEdge Computing. By deriving steady-state probabilities and evaluating energy\nconsumption, we demonstrate the benefits of AI-driven predictive power scaling\nover conventional reactive methods. Monte Carlo simulations validate the model,\nshowing strong alignment between theoretical and empirical results. Sensitivity\nanalysis highlights how varying transition probabilities affect power\nefficiency, confirming that predictive scaling minimizes unnecessary\ntransitions and improves overall system responsiveness. Our findings suggest\nthat AI-based power management strategies significantly enhance energy\nefficiency by anticipating workload demands and optimizing state transitions.\nExperimental results indicate that AI-based power management optimizes workload\ndistribution across heterogeneous edge nodes, reducing energy consumption\ndisparities between devices, improving overall efficiency, and enhancing\nadaptive power coordination in multi-node environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u968f\u673a\u5efa\u6a21\u65b9\u6cd5\u6765\u5206\u6790\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u529f\u7387\u72b6\u6001\u8f6c\u6362\uff0c\u901a\u8fc7AI\u9a71\u52a8\u7684\u9884\u6d4b\u6027\u529f\u7387\u7f29\u653e\u76f8\u6bd4\u4f20\u7edf\u53cd\u5e94\u5f0f\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u80fd\u6e90\u6548\u7387\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u867d\u7136\u80fd\u591f\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u5904\u7406\uff0c\u4f46\u7531\u4e8e\u8fb9\u7f18\u8bbe\u5907\u7684\u5206\u5e03\u5f0f\u7279\u6027\u548c\u6709\u9650\u7684\u80fd\u6e90\u8d44\u6e90\uff0c\u7ed9\u529f\u7387\u7ba1\u7406\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u8fdb\u884c\u968f\u673a\u5efa\u6a21\uff0c\u63a8\u5bfc\u7a33\u6001\u6982\u7387\u5e76\u8bc4\u4f30\u80fd\u8017\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAI\u9a71\u52a8\u7684\u9884\u6d4b\u6027\u529f\u7387\u7f29\u653e\u80fd\u591f\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u72b6\u6001\u8f6c\u6362\uff0c\u63d0\u9ad8\u7cfb\u7edf\u54cd\u5e94\u6027\uff0c\u5728\u5f02\u6784\u8fb9\u7f18\u8282\u70b9\u95f4\u4f18\u5316\u5de5\u4f5c\u8d1f\u8f7d\u5206\u5e03\uff0c\u964d\u4f4e\u8bbe\u5907\u95f4\u7684\u80fd\u8017\u5dee\u5f02\u3002", "conclusion": "\u57fa\u4e8eAI\u7684\u529f\u7387\u7ba1\u7406\u7b56\u7565\u901a\u8fc7\u9884\u6d4b\u5de5\u4f5c\u8d1f\u8f7d\u9700\u6c42\u5e76\u4f18\u5316\u72b6\u6001\u8f6c\u6362\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u7684\u80fd\u6e90\u6548\u7387\u3002"}}
{"id": "2511.04500", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04500", "abs": "https://arxiv.org/abs/2511.04500", "authors": ["Andrea Cera Palatsi", "Samuel Martin-Gutierrez", "Ana S. Cardenal", "Max Pellert"], "title": "Large language models replicate and predict human cooperation across experiments in game theory", "comment": null, "summary": "Large language models (LLMs) are increasingly used both to make decisions in\ndomains such as health, education and law, and to simulate human behavior. Yet\nhow closely LLMs mirror actual human decision-making remains poorly understood.\nThis gap is critical: misalignment could produce harmful outcomes in practical\napplications, while failure to replicate human behavior renders LLMs\nineffective for social simulations. Here, we address this gap by developing a\ndigital twin of game-theoretic experiments and introducing a systematic\nprompting and probing framework for machine-behavioral evaluation. Testing\nthree open-source models (Llama, Mistral and Qwen), we find that Llama\nreproduces human cooperation patterns with high fidelity, capturing human\ndeviations from rational choice theory, while Qwen aligns closely with Nash\nequilibrium predictions. Notably, we achieved population-level behavioral\nreplication without persona-based prompting, simplifying the simulation\nprocess. Extending beyond the original human-tested games, we generate and\npreregister testable hypotheses for novel game configurations outside the\noriginal parameter grid. Our findings demonstrate that appropriately calibrated\nLLMs can replicate aggregate human behavioral patterns and enable systematic\nexploration of unexplored experimental spaces, offering a complementary\napproach to traditional research in the social and behavioral sciences that\ngenerates new empirical predictions about human social decision-making.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u535a\u5f08\u8bba\u5b9e\u9a8c\u7684\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u63d0\u793a\u548c\u63a2\u6d4b\u6846\u67b6\u8bc4\u4f30LLMs\u7684\u884c\u4e3a\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0Llama\u80fd\u9ad8\u4fdd\u771f\u590d\u73b0\u4eba\u7c7b\u5408\u4f5c\u6a21\u5f0f\uff0c\u800cQwen\u66f4\u63a5\u8fd1\u7eb3\u4ec0\u5747\u8861\u9884\u6d4b\uff0c\u65e0\u9700\u89d2\u8272\u63d0\u793a\u5373\u53ef\u5b9e\u73b0\u7fa4\u4f53\u884c\u4e3a\u590d\u5236\u3002", "motivation": "\u7406\u89e3LLMs\u4e0e\u4eba\u7c7b\u51b3\u7b56\u7684\u76f8\u4f3c\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u4e0d\u5339\u914d\u53ef\u80fd\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u5bb3\u7ed3\u679c\uff0c\u800c\u65e0\u6cd5\u590d\u73b0\u4eba\u7c7b\u884c\u4e3a\u4f1a\u4f7fLLMs\u5728\u793e\u4f1a\u6a21\u62df\u4e2d\u65e0\u6548\u3002", "method": "\u5f00\u53d1\u535a\u5f08\u8bba\u5b9e\u9a8c\u7684\u6570\u5b57\u5b6a\u751f\uff0c\u5f15\u5165\u7cfb\u7edf\u5316\u63d0\u793a\u548c\u63a2\u6d4b\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\uff08Llama\u3001Mistral\u548cQwen\uff09\uff0c\u5e76\u5728\u539f\u59cb\u53c2\u6570\u7f51\u683c\u4e4b\u5916\u751f\u6210\u53ef\u6d4b\u8bd5\u5047\u8bbe\u3002", "result": "Llama\u80fd\u9ad8\u4fdd\u771f\u590d\u73b0\u4eba\u7c7b\u5408\u4f5c\u6a21\u5f0f\u5e76\u6355\u6349\u4eba\u7c7b\u504f\u79bb\u7406\u6027\u9009\u62e9\u7406\u8bba\u7684\u884c\u4e3a\uff0cQwen\u4e0e\u7eb3\u4ec0\u5747\u8861\u9884\u6d4b\u9ad8\u5ea6\u4e00\u81f4\uff0c\u65e0\u9700\u89d2\u8272\u63d0\u793a\u5373\u53ef\u5b9e\u73b0\u7fa4\u4f53\u884c\u4e3a\u590d\u5236\u3002", "conclusion": "\u9002\u5f53\u6821\u51c6\u7684LLMs\u53ef\u4ee5\u590d\u73b0\u7fa4\u4f53\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\uff0c\u5e76\u80fd\u7cfb\u7edf\u63a2\u7d22\u672a\u5f00\u53d1\u7684\u5b9e\u9a8c\u7a7a\u95f4\uff0c\u4e3a\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u8865\u5145\u65b9\u6cd5\uff0c\u751f\u6210\u5173\u4e8e\u4eba\u7c7b\u793e\u4ea4\u51b3\u7b56\u7684\u65b0\u7ecf\u9a8c\u9884\u6d4b\u3002"}}
{"id": "2511.03845", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03845", "abs": "https://arxiv.org/abs/2511.03845", "authors": ["Tianning Dong", "Luyi Ma", "Varun Vasudevan", "Jason Cho", "Sushant Kumar", "Kannan Achan"], "title": "To See or To Read: User Behavior Reasoning in Multimodal LLMs", "comment": "Accepted by the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025) Workshop: Efficient Reasoning", "summary": "Multimodal Large Language Models (MLLMs) are reshaping how modern agentic\nsystems reason over sequential user-behavior data. However, whether textual or\nimage representations of user behavior data are more effective for maximizing\nMLLM performance remains underexplored. We present \\texttt{BehaviorLens}, a\nsystematic benchmarking framework for assessing modality trade-offs in\nuser-behavior reasoning across six MLLMs by representing transaction data as\n(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a\nreal-world purchase-sequence dataset, we find that when data is represented as\nimages, MLLMs next-purchase prediction accuracy is improved by 87.5% compared\nwith an equivalent textual representation without any additional computational\ncost.", "AI": {"tldr": "BehaviorLens\u6846\u67b6\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7528\u6237\u884c\u4e3a\u63a8\u7406\u4e2d\u7684\u6a21\u6001\u6743\u8861\uff0c\u53d1\u73b0\u56fe\u50cf\u8868\u793a\u76f8\u6bd4\u6587\u672c\u8868\u793a\u80fd\u63d0\u534787.5%\u7684\u4e0b\u4e00\u8d2d\u4e70\u9884\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22\u6587\u672c\u548c\u56fe\u50cf\u4e24\u79cd\u7528\u6237\u884c\u4e3a\u6570\u636e\u8868\u793a\u65b9\u5f0f\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4ee5\u786e\u5b9a\u54ea\u79cd\u8868\u793a\u65b9\u5f0f\u66f4\u6709\u6548\u3002", "method": "\u5f00\u53d1BehaviorLens\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5728\u516d\u4e2aMLLMs\u4e0a\u6d4b\u8bd5\u4e09\u79cd\u6570\u636e\u8868\u793a\u65b9\u5f0f\uff1a\u6587\u672c\u6bb5\u843d\u3001\u6563\u70b9\u56fe\u548c\u6d41\u7a0b\u56fe\uff0c\u4f7f\u7528\u771f\u5b9e\u8d2d\u4e70\u5e8f\u5217\u6570\u636e\u96c6\u3002", "result": "\u5f53\u6570\u636e\u8868\u793a\u4e3a\u56fe\u50cf\u65f6\uff0cMLLMs\u7684\u4e0b\u4e00\u8d2d\u4e70\u9884\u6d4b\u51c6\u786e\u7387\u76f8\u6bd4\u7b49\u6548\u6587\u672c\u8868\u793a\u63d0\u9ad8\u4e8687.5%\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u56fe\u50cf\u8868\u793a\u5728\u7528\u6237\u884c\u4e3a\u63a8\u7406\u4efb\u52a1\u4e2d\u6bd4\u6587\u672c\u8868\u793a\u66f4\u6709\u6548\uff0c\u80fd\u663e\u8457\u63d0\u5347MLLMs\u6027\u80fd\u3002"}}
{"id": "2511.04268", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04268", "abs": "https://arxiv.org/abs/2511.04268", "authors": ["Iker Mart\u00edn-\u00c1lvarez", "Jos\u00e9 I. Aliaga", "Maribel Castillo", "Sergio Iserte"], "title": "Parallel Spawning Strategies for Dynamic-Aware MPI Applications", "comment": "10 pages, 1 Table, 6 Figures, 8 Equations, 2 Listings", "summary": "Dynamic resource management is an increasingly important capability of High\nPerformance Computing systems, as it enables jobs to adjust their resource\nallocation at runtime. This capability has been shown to reduce workload\nmakespan, substantially decrease job waiting times and improve overall system\nutilization. In this context, malleability refers to the ability of\napplications to adapt to new resource allocations during execution. Although\nbeneficial, malleability incurs significant reconfiguration costs, making the\nreduction of these costs an important research topic.\n  Some existing methods for MPI applications respawn the entire application,\nwhich is an expensive solution that avoids the reuse of original processes.\nOther MPI methods reuse them, but fail to fully release unneeded processes when\nshrinking, since some ranks within the same communicator remain active across\nnodes, preventing the application from returning those nodes to the system.\nThis work overcomes both limitations by proposing a novel parallel spawning\nstrategy, in which all processes cooperate in spawning before redistribution,\nthereby reducing execution time. Additionally, it removes shrinkage\nlimitations, allowing better adaptation of parallel systems to workload and\nreducing their makespan. As a result, it preserves competitive expansion times\nwith at most a $1.25\\times$ overhead, while enabling fast shrink operations\nthat reduce their cost by at least $20\\times$. This strategy has been validated\non both homogeneous and heterogeneous systems and can also be applied in\nshared-resource environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5e76\u884c\u751f\u6210\u7b56\u7565\uff0c\u7528\u4e8eMPI\u5e94\u7528\u7a0b\u5e8f\u7684\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u8fdb\u7a0b\u534f\u4f5c\u751f\u6210\u548c\u91cd\u65b0\u5206\u914d\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6269\u5c55\u548c\u6536\u7f29\u64cd\u4f5c\u7684\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684MPI\u5e94\u7528\u7a0b\u5e8f\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u8981\u4e48\u91cd\u65b0\u751f\u6210\u6574\u4e2a\u5e94\u7528\u7a0b\u5e8f\u6210\u672c\u9ad8\u6602\uff0c\u8981\u4e48\u5728\u6536\u7f29\u65f6\u65e0\u6cd5\u5b8c\u5168\u91ca\u653e\u4e0d\u9700\u8981\u7684\u8fdb\u7a0b\uff0c\u5bfc\u81f4\u8282\u70b9\u65e0\u6cd5\u5f52\u8fd8\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u5e76\u884c\u751f\u6210\u7b56\u7565\uff0c\u6240\u6709\u8fdb\u7a0b\u5728\u91cd\u65b0\u5206\u914d\u524d\u534f\u4f5c\u751f\u6210\u65b0\u8fdb\u7a0b\uff0c\u540c\u65f6\u6d88\u9664\u4e86\u6536\u7f29\u9650\u5236\uff0c\u4f7f\u5e76\u884c\u7cfb\u7edf\u80fd\u66f4\u597d\u5730\u9002\u5e94\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u6269\u5c55\u65f6\u95f4\uff08\u6700\u591a1.25\u500d\u5f00\u9500\uff09\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u6536\u7f29\u64cd\u4f5c\uff0c\u6210\u672c\u964d\u4f4e\u81f3\u5c1120\u500d\u3002\u8be5\u65b9\u6cd5\u5df2\u5728\u540c\u6784\u548c\u5f02\u6784\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\uff0c\u5e76\u9002\u7528\u4e8e\u5171\u4eab\u8d44\u6e90\u73af\u5883\u3002", "conclusion": "\u8be5\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86MPI\u5e94\u7528\u7a0b\u5e8f\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u91cd\u65b0\u914d\u7f6e\u6210\u672c\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u9002\u5e94\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2511.04646", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04646", "abs": "https://arxiv.org/abs/2511.04646", "authors": ["Narjes Nourzad", "Hanqing Yang", "Shiyu Chen", "Carlee Joe-Wong"], "title": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration", "comment": null, "summary": "Cooperative multi-agent planning requires agents to make joint decisions with\npartial information and limited communication. Coordination at the trajectory\nlevel often fails, as small deviations in timing or movement cascade into\nconflicts. Symbolic planning mitigates this challenge by raising the level of\nabstraction and providing a minimal vocabulary of actions that enable\nsynchronization and collective progress. We present DR. WELL, a decentralized\nneurosymbolic framework for cooperative multi-agent planning. Cooperation\nunfolds through a two-phase negotiation protocol: agents first propose\ncandidate roles with reasoning and then commit to a joint allocation under\nconsensus and environment constraints. After commitment, each agent\nindependently generates and executes a symbolic plan for its role without\nrevealing detailed trajectories. Plans are grounded in execution outcomes via a\nshared world model that encodes the current state and is updated as agents act.\nBy reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids\nbrittle step-level alignment and enables higher-level operations that are\nreusable, synchronizable, and interpretable. Experiments on cooperative\nblock-push tasks show that agents adapt across episodes, with the dynamic world\nmodel capturing reusable patterns and improving task completion rates and\nefficiency. Experiments on cooperative block-push tasks show that our dynamic\nworld model improves task completion and efficiency through negotiation and\nself-refinement, trading a time overhead for evolving, more efficient\ncollaboration strategies.", "AI": {"tldr": "DR.WELL\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u89c4\u5212\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u534f\u5546\u534f\u8bae\u548c\u7b26\u53f7\u89c4\u5212\u907f\u514d\u8f68\u8ff9\u7ea7\u534f\u8c03\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5728\u90e8\u5206\u4fe1\u606f\u548c\u6709\u9650\u901a\u4fe1\u4e0b\u8fdb\u884c\u8054\u5408\u51b3\u7b56\u65f6\uff0c\u8f68\u8ff9\u7ea7\u534f\u8c03\u56e0\u5fae\u5c0f\u504f\u5dee\u5bfc\u81f4\u51b2\u7a81\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u534f\u5546\u534f\u8bae\uff1a\u667a\u80fd\u4f53\u5148\u63d0\u51fa\u5019\u9009\u89d2\u8272\u53ca\u7406\u7531\uff0c\u7136\u540e\u5728\u5171\u8bc6\u548c\u73af\u5883\u7ea6\u675f\u4e0b\u627f\u8bfa\u8054\u5408\u5206\u914d\uff1b\u627f\u8bfa\u540e\u5404\u81ea\u72ec\u7acb\u751f\u6210\u548c\u6267\u884c\u7b26\u53f7\u8ba1\u5212\uff0c\u901a\u8fc7\u5171\u4eab\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u6267\u884c\u7ed3\u679c\u843d\u5730\u3002", "result": "\u5728\u534f\u4f5c\u63a8\u5757\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u8de8\u60c5\u666f\u9002\u5e94\uff0c\u52a8\u6001\u4e16\u754c\u6a21\u578b\u6355\u83b7\u53ef\u91cd\u7528\u6a21\u5f0f\uff0c\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u7b26\u53f7\u89c4\u5212\u800c\u975e\u539f\u59cb\u8f68\u8ff9\u63a8\u7406\uff0cDR.WELL\u907f\u514d\u4e86\u8106\u5f31\u7684\u6b65\u9aa4\u7ea7\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u53ef\u91cd\u7528\u3001\u53ef\u540c\u6b65\u548c\u53ef\u89e3\u91ca\u7684\u9ad8\u5c42\u64cd\u4f5c\uff0c\u4ee5\u65f6\u95f4\u5f00\u9500\u6362\u53d6\u6f14\u5316\u51fa\u66f4\u9ad8\u6548\u7684\u534f\u4f5c\u7b56\u7565\u3002"}}
{"id": "2511.04477", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04477", "abs": "https://arxiv.org/abs/2511.04477", "authors": ["Rongxiang Wang", "Kangyuan Shu", "Felix Xiaozhu Lin"], "title": "Enabling Dynamic Sparsity in Quantized LLM Inference", "comment": null, "summary": "Deploying large language models (LLMs) on end-user devices is gaining\nimportance due to benefits in responsiveness, privacy, and operational cost.\nYet the limited memory and compute capability of mobile and desktop GPUs make\nefficient execution difficult. Recent observations suggest that the internal\nactivations of LLMs are often dynamically sparse, meaning that for each input,\nonly part of the network contributes significantly to the output. Such sparsity\ncould reduce computation, but it interacts poorly with group-wise quantization,\nwhich remains the dominant approach for fitting LLMs onto resource-constrained\nhardware. To reconcile these two properties, this study proposes a set of\ntechniques that realize dynamic sparse inference under low-bit quantization.\nThe method features: (1) a zigzag-patterned quantization layout that organizes\nweights in a way consistent with activation sparsity and improves GPU memory\nlocality; (2) a specialized GEMV kernel designed for this layout to fully\nutilize parallel compute units; and (3) a compact runtime mechanism that\ngathers sparse indices with minimal overhead. Across several model scales and\nhardware configurations, the approach achieves up to 1.55x faster decoding\nthroughput while maintaining accuracy comparable to dense quantized inference,\nshowing that structured sparsity and quantization can effectively coexist on\ncommodity GPUs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0b\u5b9e\u73b0\u52a8\u6001\u7a00\u758f\u63a8\u7406\u7684\u6280\u672f\uff0c\u901a\u8fc7zigzag\u91cf\u5316\u5e03\u5c40\u3001\u4e13\u7528GEMV\u5185\u6838\u548c\u7d27\u51d1\u8fd0\u884c\u65f6\u673a\u5236\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u6700\u9ad81.55\u500d\u7684\u89e3\u7801\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u5728\u7ec8\u7aef\u8bbe\u5907\u4e0a\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u5185\u5b58\u548c\u8ba1\u7b97\u80fd\u529b\u9650\u5236\uff0c\u800c\u52a8\u6001\u7a00\u758f\u6fc0\u6d3b\u7279\u6027\u4e0e\u4e3b\u6d41\u7684\u5206\u7ec4\u91cf\u5316\u65b9\u6cd5\u5b58\u5728\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u7a00\u758f\u63a8\u7406\u4e0e\u91cf\u5316\u5171\u5b58\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528zigzag\u6a21\u5f0f\u91cf\u5316\u5e03\u5c40\u4ee5\u5339\u914d\u6fc0\u6d3b\u7a00\u758f\u6027\u5e76\u6539\u5584GPU\u5185\u5b58\u5c40\u90e8\u6027\uff0c\u8bbe\u8ba1\u4e13\u7528GEMV\u5185\u6838\u5145\u5206\u5229\u7528\u5e76\u884c\u8ba1\u7b97\u5355\u5143\uff0c\u5f00\u53d1\u7d27\u51d1\u8fd0\u884c\u65f6\u673a\u5236\u4ee5\u6700\u5c0f\u5f00\u9500\u6536\u96c6\u7a00\u758f\u7d22\u5f15\u3002", "result": "\u5728\u591a\u79cd\u6a21\u578b\u89c4\u6a21\u548c\u786c\u4ef6\u914d\u7f6e\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u9ad81.55\u500d\u89e3\u7801\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5bc6\u96c6\u91cf\u5316\u63a8\u7406\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u7ed3\u6784\u5316\u7a00\u758f\u6027\u548c\u91cf\u5316\u53ef\u4ee5\u5728\u5546\u7528GPU\u4e0a\u6709\u6548\u5171\u5b58\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.03948", "categories": ["cs.AI", "cs.HC", "I.2.6; K.3.1"], "pdf": "https://arxiv.org/pdf/2511.03948", "abs": "https://arxiv.org/abs/2511.03948", "authors": ["Kevin Hong", "Kia Karbasi", "Gregory Pottie"], "title": "Extracting Causal Relations in Deep Knowledge Tracing", "comment": "Accepted for publication in the Proceedings of the 18th International\n  Conference on Educational Data Mining, 6 pages, 1 figure", "summary": "A longstanding goal in computational educational research is to develop\nexplainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which\nleverages a Recurrent Neural Network (RNN) to predict student knowledge and\nperformance on exercises, has been proposed as a major advancement over\ntraditional KT methods. Several studies suggest that its performance gains stem\nfrom its ability to model bidirectional relationships between different\nknowledge components (KCs) within a course, enabling the inference of a\nstudent's understanding of one KC from their performance on others. In this\npaper, we challenge this prevailing explanation and demonstrate that DKT's\nstrength lies in its implicit ability to model prerequisite relationships as a\ncausal structure, rather than bidirectional relationships. By pruning exercise\nrelation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal\nsubsets of the Assistments dataset, we show that DKT's predictive capabilities\nalign strongly with these causal structures. Furthermore, we propose an\nalternative method for extracting exercise relation DAGs using DKT's learned\nrepresentations and provide empirical evidence supporting our claim. Our\nfindings suggest that DKT's effectiveness is largely driven by its capacity to\napproximate causal dependencies between KCs rather than simple relational\nmappings.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u5173\u4e8e\u6df1\u5ea6\u77e5\u8bc6\u8ffd\u8e2a(DKT)\u6a21\u578b\u6027\u80fd\u6765\u6e90\u7684\u73b0\u6709\u89e3\u91ca\uff0c\u8bc1\u660eDKT\u7684\u4f18\u52bf\u5728\u4e8e\u5176\u9690\u5f0f\u5efa\u6a21\u5148\u51b3\u5173\u7cfb\u4f5c\u4e3a\u56e0\u679c\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u800c\u975e\u53cc\u5411\u5173\u7cfb\u3002", "motivation": "\u957f\u671f\u4ee5\u6765\uff0c\u8ba1\u7b97\u6559\u80b2\u7814\u7a76\u7684\u76ee\u6807\u662f\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u3002DKT\u4f5c\u4e3a\u4f20\u7edfKT\u65b9\u6cd5\u7684\u91cd\u5927\u8fdb\u6b65\uff0c\u5176\u6027\u80fd\u63d0\u5347\u901a\u5e38\u88ab\u5f52\u56e0\u4e8e\u5efa\u6a21\u77e5\u8bc6\u7ec4\u4ef6\u95f4\u53cc\u5411\u5173\u7cfb\u7684\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u6311\u6218\u8fd9\u4e00\u4e3b\u6d41\u89e3\u91ca\u3002", "method": "\u901a\u8fc7\u5c06\u7ec3\u4e60\u5173\u7cfb\u56fe\u4fee\u526a\u4e3a\u6709\u5411\u65e0\u73af\u56fe(DAGs)\uff0c\u5e76\u5728Assistments\u6570\u636e\u96c6\u7684\u56e0\u679c\u5b50\u96c6\u4e0a\u8bad\u7ec3DKT\uff0c\u9a8c\u8bc1\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u4e0e\u56e0\u679c\u7ed3\u6784\u7684\u4e00\u81f4\u6027\u3002\u540c\u65f6\u63d0\u51fa\u57fa\u4e8eDKT\u5b66\u4e60\u8868\u793a\u63d0\u53d6\u7ec3\u4e60\u5173\u7cfbDAGs\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDKT\u7684\u9884\u6d4b\u80fd\u529b\u4e0e\u56e0\u679c\u7ed3\u6784\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5176\u5b66\u4e60\u8868\u793a\u53ef\u7528\u4e8e\u6709\u6548\u63d0\u53d6\u7ec3\u4e60\u5173\u7cfbDAGs\uff0c\u4e3a\u6a21\u578b\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u91ca\u3002", "conclusion": "DKT\u7684\u6709\u6548\u6027\u4e3b\u8981\u6e90\u4e8e\u5176\u8fd1\u4f3c\u77e5\u8bc6\u7ec4\u4ef6\u95f4\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u7684\u80fd\u529b\uff0c\u800c\u975e\u7b80\u5355\u7684\u5173\u8054\u6620\u5c04\uff0c\u8fd9\u4e3a\u7406\u89e3\u6df1\u5ea6\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2511.04523", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04523", "abs": "https://arxiv.org/abs/2511.04523", "authors": ["Silvia Bonomi", "Giovanni Farina", "Roy Friedman", "Eviatar B. Procaccia", "Sebastien Tixeuil"], "title": "A New Probabilistic Mobile Byzantine Failure Model for Self-Protecting Systems", "comment": null, "summary": "Modern distributed systems face growing security threats, as attackers\ncontinuously enhance their skills and vulnerabilities span across the entire\nsystem stack, from hardware to the application layer. In the system design\nphase, fault tolerance techniques can be employed to safeguard systems. From a\ntheoretical perspective, an attacker attempting to compromise a system can be\nabstracted by considering the presence of Byzantine processes in the system.\nAlthough this approach enhances the resilience of the distributed system, it\nintroduces certain limitations regarding the accuracy of the model in\nreflecting real-world scenarios. In this paper, we consider a self-protecting\ndistributed system based on the \\emph{Monitoring-Analyse-Plan-Execute over a\nshared Knowledge} (MAPE-K) architecture, and we propose a new probabilistic\nMobile Byzantine Failure (MBF) that can be plugged into the Analysis component.\nOur new model captures the dynamics of evolving attacks and can be used to\ndrive the self-protection and reconfiguration strategy. We analyze\nmathematically the time that it takes until the number of Byzantine nodes\ncrosses given thresholds, or for the system to self-recover back into a safe\nstate, depending on the rates of Byzantine infection spreading \\emph{vs.} the\nrate of self-recovery. We also provide simulation results that illustrate the\nbehavior of the system under such assumptions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u6027\u79fb\u52a8\u62dc\u5360\u5ead\u6545\u969c\u6a21\u578b\uff0c\u7528\u4e8e\u57fa\u4e8eMAPE-K\u67b6\u6784\u7684\u81ea\u4fdd\u62a4\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u5206\u6790\u4e86\u62dc\u5360\u5ead\u8282\u70b9\u6570\u91cf\u8d85\u8fc7\u9608\u503c\u6216\u7cfb\u7edf\u81ea\u6062\u590d\u5230\u5b89\u5168\u72b6\u6001\u6240\u9700\u7684\u65f6\u95f4\u3002", "motivation": "\u73b0\u4ee3\u5206\u5e03\u5f0f\u7cfb\u7edf\u9762\u4e34\u65e5\u76ca\u589e\u957f\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u653b\u51fb\u8005\u6280\u80fd\u4e0d\u65ad\u63d0\u5347\uff0c\u6f0f\u6d1e\u904d\u5e03\u6574\u4e2a\u7cfb\u7edf\u6808\u3002\u73b0\u6709\u62dc\u5360\u5ead\u6545\u969c\u6a21\u578b\u5728\u53cd\u6620\u73b0\u5b9e\u573a\u666f\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u57fa\u4e8eMAPE-K\u67b6\u6784\u7684\u81ea\u4fdd\u62a4\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u5728\u5206\u6790\u7ec4\u4ef6\u4e2d\u5f15\u5165\u65b0\u7684\u6982\u7387\u6027\u79fb\u52a8\u62dc\u5360\u5ead\u6545\u969c\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u6355\u6349\u4e0d\u65ad\u6f14\u5316\u7684\u653b\u51fb\u52a8\u6001\u3002", "result": "\u901a\u8fc7\u6570\u5b66\u5206\u6790\u5f97\u51fa\u4e86\u62dc\u5360\u5ead\u8282\u70b9\u6570\u91cf\u8d85\u8fc7\u7ed9\u5b9a\u9608\u503c\u6216\u7cfb\u7edf\u81ea\u6062\u590d\u5230\u5b89\u5168\u72b6\u6001\u6240\u9700\u7684\u65f6\u95f4\uff0c\u53d6\u51b3\u4e8e\u62dc\u5360\u5ead\u611f\u67d3\u4f20\u64ad\u901f\u7387\u4e0e\u81ea\u6062\u590d\u901f\u7387\u7684\u5bf9\u6bd4\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u4e86\u4eff\u771f\u7ed3\u679c\u8bf4\u660e\u7cfb\u7edf\u884c\u4e3a\u3002", "conclusion": "\u63d0\u51fa\u7684\u6982\u7387\u6027\u79fb\u52a8\u62dc\u5360\u5ead\u6545\u969c\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u53cd\u6620\u73b0\u5b9e\u653b\u51fb\u52a8\u6001\uff0c\u53ef\u7528\u4e8e\u9a71\u52a8\u7cfb\u7edf\u7684\u81ea\u4fdd\u62a4\u548c\u91cd\u914d\u7f6e\u7b56\u7565\u3002"}}
{"id": "2511.03980", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03980", "abs": "https://arxiv.org/abs/2511.03980", "authors": ["Bram Bult\u00e9", "Ayla Rigouts Terryn"], "title": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing", "comment": "Preprint under review at Computational Linguistics. Accepted with\n  minor revisions (10/10/2025); second round", "summary": "Large Language Models (LLMs) are rapidly being adopted by users across the\nglobe, who interact with them in a diverse range of languages. At the same\ntime, there are well-documented imbalances in the training data and\noptimisation objectives of this technology, raising doubts as to whether LLMs\ncan represent the cultural diversity of their broad user base. In this study,\nwe look at LLMs and cultural values and examine how prompt language and\ncultural framing influence model responses and their alignment with human\nvalues in different countries. We probe 10 LLMs with 63 items from the Hofstede\nValues Survey Module and World Values Survey, translated into 11 languages, and\nformulated as prompts with and without different explicit cultural\nperspectives. Our study confirms that both prompt language and cultural\nperspective produce variation in LLM outputs, but with an important caveat:\nWhile targeted prompting can, to a certain extent, steer LLM responses in the\ndirection of the predominant values of the corresponding countries, it does not\novercome the models' systematic bias toward the values associated with a\nrestricted set of countries in our dataset: the Netherlands, Germany, the US,\nand Japan. All tested models, regardless of their origin, exhibit remarkably\nsimilar patterns: They produce fairly neutral responses on most topics, with\nselective progressive stances on issues such as social tolerance. Alignment\nwith cultural values of human respondents is improved more with an explicit\ncultural perspective than with a targeted prompt language. Unexpectedly,\ncombining both approaches is no more effective than cultural framing with an\nEnglish prompt. These findings reveal that LLMs occupy an uncomfortable middle\nground: They are responsive enough to changes in prompts to produce variation,\nbut too firmly anchored to specific cultural defaults to adequately represent\ncultural diversity.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u4e0b\u7684\u54cd\u5e94\u5dee\u5f02\uff0c\u53d1\u73b0\u63d0\u793a\u8bed\u8a00\u548c\u6587\u5316\u6846\u67b6\u4f1a\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\uff0c\u4f46\u65e0\u6cd5\u514b\u670d\u6a21\u578b\u5bf9\u7279\u5b9a\u56fd\u5bb6\uff08\u8377\u5170\u3001\u5fb7\u56fd\u3001\u7f8e\u56fd\u3001\u65e5\u672c\uff09\u6587\u5316\u4ef7\u503c\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "motivation": "\u968f\u7740LLMs\u5728\u5168\u7403\u8303\u56f4\u5185\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u7814\u7a76\u5176\u662f\u5426\u80fd\u591f\u4ee3\u8868\u591a\u6837\u5316\u7528\u6237\u7fa4\u4f53\u7684\u6587\u5316\u591a\u6837\u6027\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u6570\u636e\u548c\u4f18\u5316\u76ee\u6807\u5b58\u5728\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u970d\u592b\u65af\u6cf0\u5fb7\u4ef7\u503c\u89c2\u8c03\u67e5\u6a21\u5757\u548c\u4e16\u754c\u4ef7\u503c\u89c2\u8c03\u67e5\u768463\u4e2a\u9879\u76ee\uff0c\u7ffb\u8bd1\u621011\u79cd\u8bed\u8a00\uff0c\u4ee5\u5e26\u6709\u548c\u4e0d\u5e26\u6709\u660e\u786e\u6587\u5316\u89c6\u89d2\u7684\u63d0\u793a\u5f62\u5f0f\u6d4b\u8bd510\u4e2aLLMs\u3002", "result": "\u63d0\u793a\u8bed\u8a00\u548c\u6587\u5316\u89c6\u89d2\u90fd\u4f1a\u5bfc\u81f4LLM\u8f93\u51fa\u53d8\u5316\uff0c\u4f46\u6a21\u578b\u663e\u793a\u51fa\u5bf9\u7279\u5b9a\u56fd\u5bb6\u6587\u5316\u4ef7\u503c\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u3002\u660e\u786e\u7684\u6587\u89c6\u89d2\u6bd4\u9488\u5bf9\u6027\u63d0\u793a\u8bed\u8a00\u66f4\u80fd\u63d0\u9ad8\u4e0e\u4eba\u7c7b\u53d7\u8bbf\u8005\u6587\u5316\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "LLMs\u5904\u4e8e\u4e00\u4e2a\u5c34\u5c2c\u7684\u4e2d\u95f4\u5730\u5e26\uff1a\u5b83\u4eec\u5bf9\u63d0\u793a\u53d8\u5316\u8db3\u591f\u654f\u611f\u4ee5\u4ea7\u751f\u53d8\u5316\uff0c\u4f46\u53c8\u8fc7\u4e8e\u56fa\u7740\u4e8e\u7279\u5b9a\u7684\u6587\u5316\u9ed8\u8ba4\u503c\uff0c\u65e0\u6cd5\u5145\u5206\u4ee3\u8868\u6587\u5316\u591a\u6837\u6027\u3002"}}
{"id": "2511.04631", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04631", "abs": "https://arxiv.org/abs/2511.04631", "authors": ["Petr Kuznetsov", "Nathan Josia Schrodt"], "title": "Resolving Conflicts with Grace: Dynamically Concurrent Universality", "comment": null, "summary": "Synchronization is the major obstacle to scalability in distributed\ncomputing. Concurrent operations on the shared data engage in synchronization\nwhen they encounter a \\emph{conflict}, i.e., their effects depend on the order\nin which they are applied. Ideally, one would like to detect conflicts in a\n\\emph{dynamic} manner, i.e., adjusting to the current system state. Indeed, it\nis very common that two concurrent operations conflict only in some rarely\noccurring states. In this paper, we define the notion of \\emph{dynamic\nconcurrency}: an operation employs strong synchronization primitives only if it\n\\emph{has} to arbitrate with concurrent operations, given the current system\nstate. We then present a dynamically concurrent universal construction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u52a8\u6001\u5e76\u53d1\u6982\u5ff5\uff0c\u4ec5\u5728\u5f53\u524d\u7cfb\u7edf\u72b6\u6001\u4e0b\u9700\u8981\u4e0e\u5e76\u53d1\u64cd\u4f5c\u4ef2\u88c1\u65f6\u624d\u4f7f\u7528\u5f3a\u540c\u6b65\u539f\u8bed\uff0c\u5e76\u63d0\u51fa\u4e86\u52a8\u6001\u5e76\u53d1\u901a\u7528\u6784\u9020\u3002", "motivation": "\u540c\u6b65\u662f\u5206\u5e03\u5f0f\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u7684\u4e3b\u8981\u969c\u788d\u3002\u5e76\u53d1\u64cd\u4f5c\u5728\u9047\u5230\u51b2\u7a81\u65f6\u9700\u8981\u8fdb\u884c\u540c\u6b65\uff0c\u800c\u51b2\u7a81\u5f80\u5f80\u53ea\u5728\u67d0\u4e9b\u7f55\u89c1\u72b6\u6001\u4e0b\u53d1\u751f\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u5e0c\u671b\u80fd\u591f\u52a8\u6001\u68c0\u6d4b\u51b2\u7a81\uff0c\u6839\u636e\u5f53\u524d\u7cfb\u7edf\u72b6\u6001\u8c03\u6574\u540c\u6b65\u7b56\u7565\u3002", "method": "\u5b9a\u4e49\u52a8\u6001\u5e76\u53d1\u6982\u5ff5\uff0c\u5373\u64cd\u4f5c\u4ec5\u5728\u5f53\u524d\u7cfb\u7edf\u72b6\u6001\u4e0b\u9700\u8981\u4e0e\u5e76\u53d1\u64cd\u4f5c\u4ef2\u88c1\u65f6\u624d\u4f7f\u7528\u5f3a\u540c\u6b65\u539f\u8bed\u3002\u63d0\u51fa\u52a8\u6001\u5e76\u53d1\u901a\u7528\u6784\u9020\u6765\u5b9e\u73b0\u8fd9\u4e00\u6982\u5ff5\u3002", "result": "\u63d0\u51fa\u4e86\u52a8\u6001\u5e76\u53d1\u901a\u7528\u6784\u9020\uff0c\u80fd\u591f\u6839\u636e\u7cfb\u7edf\u72b6\u6001\u52a8\u6001\u8c03\u6574\u540c\u6b65\u7b56\u7565\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u540c\u6b65\u5f00\u9500\u3002", "conclusion": "\u52a8\u6001\u5e76\u53d1\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u540c\u6b65\u5f00\u9500\uff0c\u901a\u8fc7\u4ec5\u5728\u5fc5\u8981\u65f6\u4f7f\u7528\u5f3a\u540c\u6b65\u539f\u8bed\u6765\u63d0\u9ad8\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.04032", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04032", "abs": "https://arxiv.org/abs/2511.04032", "authors": ["Divya Pathak", "Harshit Kumar", "Anuska Roy", "Felix George", "Mudit Verma", "Pratibha Moogi"], "title": "Detecting Silent Failures in Multi-Agentic AI Trajectories", "comment": null, "summary": "Multi-Agentic AI systems, powered by large language models (LLMs), are\ninherently non-deterministic and prone to silent failures such as drift,\ncycles, and missing details in outputs, which are difficult to detect. We\nintroduce the task of anomaly detection in agentic trajectories to identify\nthese failures and present a dataset curation pipeline that captures user\nbehavior, agent non-determinism, and LLM variation. Using this pipeline, we\ncurate and label two benchmark datasets comprising \\textbf{4,275 and 894}\ntrajectories from Multi-Agentic AI systems. Benchmarking anomaly detection\nmethods on these datasets, we show that supervised (XGBoost) and\nsemi-supervised (SVDD) approaches perform comparably, achieving accuracies up\nto 98% and 96%, respectively. This work provides the first systematic study of\nanomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,\nand insights to guide future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\uff0c\u6784\u5efa\u4e86\u4e24\u4e2a\u5305\u542b4,275\u548c894\u6761\u8f68\u8ff9\u7684\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4e86\u76d1\u7763\u548c\u534a\u76d1\u7763\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u8fbe\u523098%\u3002", "motivation": "\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u5177\u6709\u975e\u786e\u5b9a\u6027\u548c\u6613\u53d1\u751f\u9759\u9ed8\u6545\u969c\uff08\u5982\u6f02\u79fb\u3001\u5faa\u73af\u3001\u8f93\u51fa\u7ec6\u8282\u7f3a\u5931\uff09\u7684\u7279\u70b9\uff0c\u8fd9\u4e9b\u6545\u969c\u96be\u4ee5\u68c0\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\uff0c\u6355\u6349\u7528\u6237\u884c\u4e3a\u3001\u667a\u80fd\u4f53\u975e\u786e\u5b9a\u6027\u548cLLM\u53d8\u5316\uff0c\u5e76\u6784\u5efa\u4e86\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u3002\u5728\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u76d1\u7763\u65b9\u6cd5\uff08XGBoost\uff09\u548c\u534a\u76d1\u7763\u65b9\u6cd5\uff08SVDD\uff09\u7684\u6027\u80fd\u3002", "result": "\u76d1\u7763\u65b9\u6cd5\u548c\u534a\u76d1\u7763\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\uff0c\u5206\u522b\u8fbe\u523098%\u548c96%\u7684\u51c6\u786e\u7387\u3002\u8fd9\u662f\u5bf9\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u7684\u9996\u6b21\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u3001\u57fa\u51c6\u548c\u89c1\u89e3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2511.04053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04053", "abs": "https://arxiv.org/abs/2511.04053", "authors": ["Hirohane Takagi", "Gouki Minegishi", "Shota Kizawa", "Issey Sukeda", "Hitomi Yanaka"], "title": "Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models", "comment": "Accepted to IJCNLP-AACL 2025 (Main). Code available at\n  https://github.com/htkg/num_attrs", "summary": "Although behavioral studies have documented numerical reasoning errors in\nlarge language models (LLMs), the underlying representational mechanisms remain\nunclear. We hypothesize that numerical attributes occupy shared latent\nsubspaces and investigate two questions:(1) How do LLMs internally integrate\nmultiple numerical attributes of a single entity? (2)How does irrelevant\nnumerical context perturb these representations and their downstream outputs?\nTo address these questions, we combine linear probing with partial correlation\nanalysis and prompt-based vulnerability tests across models of varying sizes.\nOur results show that LLMs encode real-world numerical correlations but tend to\nsystematically amplify them. Moreover, irrelevant context induces consistent\nshifts in magnitude representations, with downstream effects that vary by model\nsize. These findings reveal a vulnerability in LLM decision-making and lay the\ngroundwork for fairer, representation-aware control under multi-attribute\nentanglement.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u6570\u503c\u63a8\u7406\u9519\u8bef\u7684\u8868\u793a\u673a\u5236\uff0c\u53d1\u73b0LLMs\u7f16\u7801\u771f\u5b9e\u4e16\u754c\u6570\u503c\u76f8\u5173\u6027\u4f46\u4f1a\u7cfb\u7edf\u6027\u653e\u5927\u5b83\u4eec\uff0c\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u5f15\u53d1\u6570\u503c\u8868\u793a\u7684\u4e00\u81f4\u504f\u79fb\uff0c\u63ed\u793a\u4e86LLM\u51b3\u7b56\u4e2d\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u5c3d\u7ba1\u884c\u4e3a\u7814\u7a76\u5df2\u8bb0\u5f55\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6570\u503c\u63a8\u7406\u9519\u8bef\uff0c\u4f46\u6f5c\u5728\u7684\u8868\u793a\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u8005\u5047\u8bbe\u6570\u503c\u5c5e\u6027\u5360\u636e\u5171\u4eab\u7684\u6f5c\u5728\u5b50\u7a7a\u95f4\uff0c\u5e76\u63a2\u7a76LLMs\u5982\u4f55\u5185\u90e8\u6574\u5408\u5355\u4e2a\u5b9e\u4f53\u7684\u591a\u4e2a\u6570\u503c\u5c5e\u6027\uff0c\u4ee5\u53ca\u65e0\u5173\u6570\u503c\u4e0a\u4e0b\u6587\u5982\u4f55\u5e72\u6270\u8fd9\u4e9b\u8868\u793a\u53ca\u5176\u4e0b\u6e38\u8f93\u51fa\u3002", "method": "\u7ed3\u5408\u7ebf\u6027\u63a2\u6d4b\u4e0e\u504f\u76f8\u5173\u5206\u6790\uff0c\u4ee5\u53ca\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u8fdb\u884c\u57fa\u4e8e\u63d0\u793a\u7684\u8106\u5f31\u6027\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793aLLMs\u7f16\u7801\u771f\u5b9e\u4e16\u754c\u7684\u6570\u503c\u76f8\u5173\u6027\u4f46\u503e\u5411\u4e8e\u7cfb\u7edf\u6027\u653e\u5927\u5b83\u4eec\u3002\u6b64\u5916\uff0c\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u5728\u6570\u503c\u8868\u793a\u4e2d\u5f15\u53d1\u4e00\u81f4\u7684\u504f\u79fb\uff0c\u5176\u4e0b\u6e38\u5f71\u54cd\u56e0\u6a21\u578b\u89c4\u6a21\u800c\u5f02\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86LLM\u51b3\u7b56\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u5728\u591a\u5c5e\u6027\u7ea0\u7f20\u4e0b\u5b9e\u73b0\u66f4\u516c\u5e73\u3001\u8868\u793a\u611f\u77e5\u7684\u63a7\u5236\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.04220", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04220", "abs": "https://arxiv.org/abs/2511.04220", "authors": ["Alan Seroul", "Th\u00e9o Fagnoni", "In\u00e8s Adnani", "Dana O. Mohamed", "Phillip Kingston"], "title": "Opus: A Quantitative Framework for Workflow Evaluation", "comment": null, "summary": "This paper introduces the Opus Workflow Evaluation Framework, a\nprobabilistic-normative formulation for quantifying Workflow quality and\nefficiency. It integrates notions of correctness, reliability, and cost into a\ncoherent mathematical model that enables direct comparison, scoring, and\noptimization of Workflows. The framework combines the Opus Workflow Reward, a\nprobabilistic function estimating expected performance through success\nlikelihood, resource usage, and output gain, with the Opus Workflow Normative\nPenalties, a set of measurable functions capturing structural and informational\nquality across Cohesion, Coupling, Observability, and Information Hygiene. It\nsupports automated Workflow assessment, ranking, and optimization within modern\nautomation systems such as Opus and can be integrated into Reinforcement\nLearning loops to guide Workflow discovery and refinement. In this paper, we\nintroduce the Opus Workflow Reward model that formalizes Workflow success as a\nprobabilistic expectation over costs and outcomes. We define measurable Opus\nWorkflow Normative Penalties capturing structural, semantic, and signal-related\nproperties of Workflows. Finally, we propose a unified optimization formulation\nfor identifying and ranking optimal Workflows under joint Reward-Penalty\ntrade-offs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Opus\u5de5\u4f5c\u6d41\u8bc4\u4f30\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u6982\u7387-\u89c4\u8303\u5316\u7684\u6570\u5b66\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u5de5\u4f5c\u6d41\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5de5\u4f5c\u6d41\u5956\u52b1\u6a21\u578b\u548c\u89c4\u8303\u5316\u60e9\u7f5a\u673a\u5236\uff0c\u652f\u6301\u5de5\u4f5c\u6d41\u7684\u81ea\u52a8\u8bc4\u4f30\u3001\u6392\u5e8f\u548c\u4f18\u5316\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5de5\u4f5c\u6d41\u8d28\u91cf\u548c\u6548\u7387\u7684\u91cf\u5316\u8bc4\u4f30\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u4e2a\u80fd\u591f\u76f4\u63a5\u6bd4\u8f83\u3001\u8bc4\u5206\u548c\u4f18\u5316\u5de5\u4f5c\u6d41\u7684\u6570\u5b66\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u73b0\u4ee3\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u5de5\u4f5c\u6d41\u7684\u81ea\u52a8\u8bc4\u4f30\u548c\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e86Opus\u5de5\u4f5c\u6d41\u5956\u52b1\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u4e2a\u6982\u7387\u51fd\u6570\uff0c\u901a\u8fc7\u6210\u529f\u6982\u7387\u3001\u8d44\u6e90\u4f7f\u7528\u548c\u8f93\u51fa\u589e\u76ca\u6765\u4f30\u8ba1\u9884\u671f\u6027\u80fd\uff1b\u540c\u65f6\u5b9a\u4e49\u4e86Opus\u5de5\u4f5c\u6d41\u89c4\u8303\u5316\u60e9\u7f5a\uff0c\u5305\u62ec\u5185\u805a\u6027\u3001\u8026\u5408\u6027\u3001\u53ef\u89c2\u6d4b\u6027\u548c\u4fe1\u606f\u536b\u751f\u7b49\u53ef\u6d4b\u91cf\u51fd\u6570\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u4f18\u5316\u516c\u5f0f\uff0c\u80fd\u591f\u5728\u5956\u52b1-\u60e9\u7f5a\u6743\u8861\u4e0b\u8bc6\u522b\u548c\u6392\u5e8f\u6700\u4f18\u5de5\u4f5c\u6d41\uff0c\u652f\u6301\u5de5\u4f5c\u6d41\u7684\u81ea\u52a8\u8bc4\u4f30\u3001\u6392\u540d\u548c\u4f18\u5316\uff0c\u5e76\u53ef\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u4e2d\u6307\u5bfc\u5de5\u4f5c\u6d41\u53d1\u73b0\u548c\u6539\u8fdb\u3002", "conclusion": "Opus\u5de5\u4f5c\u6d41\u8bc4\u4f30\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6570\u5b66\u57fa\u7840\uff0c\u80fd\u591f\u7cfb\u7edf\u5730\u8bc4\u4f30\u548c\u4f18\u5316\u5de5\u4f5c\u6d41\uff0c\u5728\u73b0\u4ee3\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u5177\u6709\u91cd\u8981\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u5de5\u4f5c\u6d41\u53d1\u73b0\u548c\u7cbe\u70bc\u8fc7\u7a0b\u4e2d\u3002"}}
{"id": "2511.04235", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.04235", "abs": "https://arxiv.org/abs/2511.04235", "authors": ["Zhengru Fang", "Yu Guo", "Jingjing Wang", "Yuang Zhang", "Haonan An", "Yinhai Wang", "Yuguang Fang"], "title": "Shared Spatial Memory Through Predictive Coding", "comment": "We have prepared the open-source code and video demonstration pages:\n  1. Code: github.com/fangzr/SSM-PC 2. Demo: fangzr.github.io/SSM-PC/index.html", "summary": "Sharing and reconstructing a consistent spatial memory is a critical\nchallenge in multi-agent systems, where partial observability and limited\nbandwidth often lead to catastrophic failures in coordination. We introduce a\nmulti-agent predictive coding framework that formulate coordination as the\nminimization of mutual uncertainty among agents. Instantiated as an information\nbottleneck objective, it prompts agents to learn not only who and what to\ncommunicate but also when. At the foundation of this framework lies a\ngrid-cell-like metric as internal spatial coding for self-localization,\nemerging spontaneously from self-supervised motion prediction. Building upon\nthis internal spatial code, agents gradually develop a bandwidth-efficient\ncommunication mechanism and specialized neural populations that encode\npartners' locations: an artificial analogue of hippocampal social place cells\n(SPCs). These social representations are further enacted by a hierarchical\nreinforcement learning policy that actively explores to reduce joint\nuncertainty. On the Memory-Maze benchmark, our approach shows exceptional\nresilience to bandwidth constraints: success degrades gracefully from 73.5% to\n64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast\nbaseline collapses from 67.6% to 28.6%. Our findings establish a theoretically\nprincipled and biologically plausible basis for how complex social\nrepresentations emerge from a unified predictive drive, leading to social\ncollective intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u9884\u6d4b\u7f16\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u667a\u80fd\u4f53\u95f4\u7684\u4e92\u4e0d\u786e\u5b9a\u6027\u6765\u89e3\u51b3\u534f\u8c03\u95ee\u9898\uff0c\u5728\u5e26\u5bbd\u53d7\u9650\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7531\u4e8e\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u6709\u9650\u5e26\u5bbd\u5bfc\u81f4\u7684\u7a7a\u95f4\u8bb0\u5fc6\u5171\u4eab\u548c\u534f\u8c03\u5931\u8d25\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u4fe1\u606f\u74f6\u9888\u76ee\u6807\uff0c\u8ba9\u667a\u80fd\u4f53\u5b66\u4e60\u901a\u4fe1\u7684\u5bf9\u8c61\u3001\u5185\u5bb9\u548c\u65f6\u673a\uff1b\u57fa\u4e8e\u7f51\u683c\u7ec6\u80de\u822c\u7684\u5185\u90e8\u7a7a\u95f4\u7f16\u7801\uff0c\u53d1\u5c55\u5e26\u5bbd\u9ad8\u6548\u7684\u901a\u4fe1\u673a\u5236\u548c\u7c7b\u4f3c\u6d77\u9a6c\u4f53\u793e\u4ea4\u4f4d\u7f6e\u7ec6\u80de\u7684\u795e\u7ecf\u7fa4\u4f53\uff1b\u91c7\u7528\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4e3b\u52a8\u63a2\u7d22\u4ee5\u51cf\u5c11\u8054\u5408\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728Memory-Maze\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5bf9\u5e26\u5bbd\u7ea6\u675f\u5177\u6709\u5353\u8d8a\u7684\u97e7\u6027\uff1a\u5e26\u5bbd\u4ece128\u4f4d/\u6b65\u7f29\u51cf\u52304\u4f4d/\u6b65\u65f6\uff0c\u6210\u529f\u7387\u4ece73.5%\u4f18\u96c5\u4e0b\u964d\u523064.4%\uff0c\u800c\u5168\u5e7f\u64ad\u57fa\u7ebf\u4ece67.6%\u5d29\u6e83\u523028.6%\u3002", "conclusion": "\u4e3a\u590d\u6742\u793e\u4ea4\u8868\u5f81\u5982\u4f55\u4ece\u7edf\u4e00\u7684\u9884\u6d4b\u9a71\u52a8\u4e2d\u6d8c\u73b0\u63d0\u4f9b\u4e86\u7406\u8bba\u539f\u5219\u548c\u751f\u7269\u5b66\u4e0a\u5408\u7406\u7684\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u793e\u4ea4\u96c6\u4f53\u667a\u80fd\u3002"}}
{"id": "2511.04285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04285", "abs": "https://arxiv.org/abs/2511.04285", "authors": ["Zeng Zhiyuan", "Jiashuo Liu", "Zhangyue Yin", "Ge Zhang", "Wenhao Huang", "Xipeng Qiu"], "title": "RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization", "comment": null, "summary": "While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for\ntraining large reasoning models, its training dynamics harbor a critical\nchallenge: RL overfitting, where models gain training rewards but lose\ngeneralization. Our analysis reveals this is driven by policy\nover-specialization and catastrophic forgetting of diverse solutions generated\nduring training. Standard optimization discards this valuable inter-step policy\ndiversity. To address this, we introduce RLoop, a self-improving framework\nbuilt on iterative policy initialization. RLoop transforms the standard\ntraining process into a virtuous cycle: it first uses RL to explore the\nsolution space from a given policy, then filters the successful trajectories to\ncreate an expert dataset. This dataset is used via Rejection-sampling\nFine-Tuning (RFT) to refine the initial policy, creating a superior starting\npoint for the next iteration. This loop of exploration and exploitation via\niterative re-initialization effectively converts transient policy variations\ninto robust performance gains. Our experiments show RLoop mitigates forgetting\nand substantially improves generalization, boosting average accuracy by 9% and\npass@32 by over 15% compared to vanilla RL.", "AI": {"tldr": "RLoop\u662f\u4e00\u4e2a\u81ea\u6539\u8fdb\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u7b56\u7565\u521d\u59cb\u5316\u89e3\u51b3RLVR\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5c06\u6807\u51c6\u8bad\u7ec3\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u826f\u6027\u5faa\u73af\uff0c\u663e\u8457\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u53ef\u9a8c\u8bc1\u5956\u52b1\u8bad\u7ec3\u4e2d\u5b58\u5728\u8fc7\u62df\u5408\u6311\u6218\uff0c\u6a21\u578b\u83b7\u5f97\u8bad\u7ec3\u5956\u52b1\u4f46\u5931\u53bb\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u7531\u7b56\u7565\u8fc7\u4e13\u4e1a\u5316\u548c\u8bad\u7ec3\u671f\u95f4\u751f\u6210\u7684\u591a\u6837\u5316\u89e3\u51b3\u65b9\u6848\u7684\u707e\u96be\u6027\u9057\u5fd8\u9a71\u52a8\u3002", "method": "RLoop\u6846\u67b6\u57fa\u4e8e\u8fed\u4ee3\u7b56\u7565\u521d\u59cb\u5316\uff0c\u9996\u5148\u4f7f\u7528RL\u4ece\u7ed9\u5b9a\u7b56\u7565\u63a2\u7d22\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\uff0c\u7136\u540e\u8fc7\u6ee4\u6210\u529f\u8f68\u8ff9\u521b\u5efa\u4e13\u5bb6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u5fae\u8c03(RFT)\u6765\u4f18\u5316\u521d\u59cb\u7b56\u7565\uff0c\u4e3a\u4e0b\u4e00\u6b21\u8fed\u4ee3\u521b\u5efa\u66f4\u597d\u7684\u8d77\u70b9\u3002", "result": "\u5b9e\u9a8c\u663e\u793aRLoop\u6709\u6548\u7f13\u89e3\u9057\u5fd8\u5e76\u663e\u8457\u6539\u5584\u6cdb\u5316\uff0c\u76f8\u6bd4\u539f\u59cbRL\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53479%\uff0cpass@32\u63d0\u5347\u8d85\u8fc715%\u3002", "conclusion": "RLoop\u901a\u8fc7\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u8fed\u4ee3\u91cd\u65b0\u521d\u59cb\u5316\uff0c\u5c06\u77ac\u6001\u7b56\u7565\u53d8\u5316\u8f6c\u5316\u4e3a\u7a33\u5065\u6027\u80fd\u589e\u76ca\uff0c\u662f\u89e3\u51b3RL\u8fc7\u62df\u5408\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.04312", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04312", "abs": "https://arxiv.org/abs/2511.04312", "authors": ["Jacob Lysn\u00e6s-Larsen", "Marte Eggen", "Inga Str\u00fcmke"], "title": "Probing the Probes: Methods and Metrics for Concept Alignment", "comment": "29 pages, 17 figures", "summary": "In explainable AI, Concept Activation Vectors (CAVs) are typically obtained\nby training linear classifier probes to detect human-understandable concepts as\ndirections in the activation space of deep neural networks. It is widely\nassumed that a high probe accuracy indicates a CAV faithfully representing its\ntarget concept. However, we show that the probe's classification accuracy alone\nis an unreliable measure of concept alignment, i.e., the degree to which a CAV\ncaptures the intended concept. In fact, we argue that probes are more likely to\ncapture spurious correlations than they are to represent only the intended\nconcept. As part of our analysis, we demonstrate that deliberately misaligned\nprobes constructed to exploit spurious correlations, achieve an accuracy close\nto that of standard probes. To address this severe problem, we introduce a\nnovel concept localization method based on spatial linear attribution, and\nprovide a comprehensive comparison of it to existing feature visualization\ntechniques for detecting and mitigating concept misalignment. We further\npropose three classes of metrics for quantitatively assessing concept\nalignment: hard accuracy, segmentation scores, and augmentation robustness. Our\nanalysis shows that probes with translation invariance and spatial alignment\nconsistently increase concept alignment. These findings highlight the need for\nalignment-based evaluation metrics rather than probe accuracy, and the\nimportance of tailoring probes to both the model architecture and the nature of\nthe target concept.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u6982\u5ff5\u6fc0\u6d3b\u5411\u91cf(CAVs)\u7684\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u95ee\u9898\uff0c\u4ec5\u4f9d\u8d56\u63a2\u9488\u5206\u7c7b\u51c6\u786e\u7387\u65e0\u6cd5\u53ef\u9760\u8861\u91cf\u6982\u5ff5\u5bf9\u9f50\u5ea6\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u7a7a\u95f4\u7ebf\u6027\u5f52\u56e0\u7684\u65b0\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e09\u7c7b\u5b9a\u91cf\u8bc4\u4f30\u6307\u6807\u6765\u68c0\u6d4b\u548c\u7f13\u89e3\u6982\u5ff5\u9519\u4f4d\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91caAI\u4e2d\uff0cCAVs\u901a\u5e38\u901a\u8fc7\u8bad\u7ec3\u7ebf\u6027\u5206\u7c7b\u5668\u63a2\u9488\u6765\u68c0\u6d4b\u53ef\u7406\u89e3\u6982\u5ff5\uff0c\u4f46\u9ad8\u63a2\u9488\u51c6\u786e\u7387\u88ab\u9519\u8bef\u5730\u8ba4\u4e3a\u662f\u6982\u5ff5\u5bf9\u9f50\u7684\u53ef\u9760\u6307\u6807\u3002\u4f5c\u8005\u53d1\u73b0\u63a2\u9488\u66f4\u53ef\u80fd\u6355\u6349\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u771f\u6b63\u6982\u5ff5\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u7a7a\u95f4\u7ebf\u6027\u5f52\u56e0\u7684\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u4e0e\u73b0\u6709\u7279\u5f81\u53ef\u89c6\u5316\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\u3002\u63d0\u51fa\u4e09\u7c7b\u5b9a\u91cf\u8bc4\u4f30\u6307\u6807\uff1a\u786c\u51c6\u786e\u7387\u3001\u5206\u5272\u5206\u6570\u548c\u589e\u5f3a\u9c81\u68d2\u6027\u3002\u5206\u6790\u5177\u6709\u5e73\u79fb\u4e0d\u53d8\u6027\u548c\u7a7a\u95f4\u5bf9\u9f50\u7684\u63a2\u9488\u5982\u4f55\u63d0\u9ad8\u6982\u5ff5\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6545\u610f\u9519\u4f4d\u7684\u63a2\u9488\u5229\u7528\u865a\u5047\u76f8\u5173\u6027\u4e5f\u80fd\u8fbe\u5230\u63a5\u8fd1\u6807\u51c6\u63a2\u9488\u7684\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4ec5\u9760\u51c6\u786e\u7387\u4e0d\u53ef\u9760\u3002\u5177\u6709\u5e73\u79fb\u4e0d\u53d8\u6027\u548c\u7a7a\u95f4\u5bf9\u9f50\u7684\u63a2\u9488\u80fd\u663e\u8457\u63d0\u9ad8\u6982\u5ff5\u5bf9\u9f50\u5ea6\u3002", "conclusion": "\u9700\u8981\u57fa\u4e8e\u5bf9\u9f50\u7684\u8bc4\u4f30\u6307\u6807\u800c\u975e\u63a2\u9488\u51c6\u786e\u7387\uff0c\u63a2\u9488\u8bbe\u8ba1\u5e94\u540c\u65f6\u8003\u8651\u6a21\u578b\u67b6\u6784\u548c\u76ee\u6807\u6982\u5ff5\u6027\u8d28\u3002\u65b0\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u6307\u6807\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e3\u6982\u5ff5\u9519\u4f4d\u95ee\u9898\u3002"}}
{"id": "2511.04316", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04316", "abs": "https://arxiv.org/abs/2511.04316", "authors": ["Tim Beyer", "Jonas Dornbusch", "Jakob Steimle", "Moritz Ladenburger", "Leo Schwinn", "Stephan G\u00fcnnemann"], "title": "AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research", "comment": null, "summary": "The rapid expansion of research on Large Language Model (LLM) safety and\nrobustness has produced a fragmented and oftentimes buggy ecosystem of\nimplementations, datasets, and evaluation methods. This fragmentation makes\nreproducibility and comparability across studies challenging, hindering\nmeaningful progress. To address these issues, we introduce AdversariaLLM, a\ntoolbox for conducting LLM jailbreak robustness research. Its design centers on\nreproducibility, correctness, and extensibility. The framework implements\ntwelve adversarial attack algorithms, integrates seven benchmark datasets\nspanning harmfulness, over-refusal, and utility evaluation, and provides access\nto a wide range of open-weight LLMs via Hugging Face. The implementation\nincludes advanced features for comparability and reproducibility such as\ncompute-resource tracking, deterministic results, and distributional evaluation\ntechniques. \\name also integrates judging through the companion package\nJudgeZoo, which can also be used independently. Together, these components aim\nto establish a robust foundation for transparent, comparable, and reproducible\nresearch in LLM safety.", "AI": {"tldr": "AdversariaLLM\u662f\u4e00\u4e2a\u7528\u4e8e\u8fdb\u884cLLM\u8d8a\u72f1\u9c81\u68d2\u6027\u7814\u7a76\u7684\u5de5\u5177\u7bb1\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524dLLM\u5b89\u5168\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u788e\u7247\u5316\u3001\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u6bd4\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u548c\u9c81\u68d2\u6027\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u5b58\u5728\u788e\u7247\u5316\u3001\u5b9e\u73b0\u9519\u8bef\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u7814\u7a76\u96be\u4ee5\u91cd\u73b0\u548c\u6bd4\u8f83\uff0c\u963b\u788d\u4e86\u6709\u610f\u4e49\u7684\u8fdb\u5c55\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ee5\u53ef\u91cd\u73b0\u6027\u3001\u6b63\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e3a\u4e2d\u5fc3\u7684\u5de5\u5177\u7bb1\uff0c\u5b9e\u73b0\u4e8612\u79cd\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\uff0c\u96c6\u6210\u4e867\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7Hugging Face\u63d0\u4f9b\u5bf9\u591a\u79cd\u5f00\u6e90LLM\u7684\u8bbf\u95ee\u3002", "result": "\u8be5\u6846\u67b6\u5305\u542b\u7528\u4e8e\u53ef\u6bd4\u6027\u548c\u53ef\u91cd\u73b0\u6027\u7684\u9ad8\u7ea7\u529f\u80fd\uff0c\u5982\u8ba1\u7b97\u8d44\u6e90\u8ddf\u8e2a\u3001\u786e\u5b9a\u6027\u7ed3\u679c\u548c\u5206\u5e03\u8bc4\u4f30\u6280\u672f\uff0c\u5e76\u4e0eJudgeZoo\u96c6\u6210\u8fdb\u884c\u8bc4\u5224\u3002", "conclusion": "\u8fd9\u4e9b\u7ec4\u4ef6\u5171\u540c\u4e3aLLM\u5b89\u5168\u9886\u57df\u7684\u900f\u660e\u3001\u53ef\u6bd4\u548c\u53ef\u91cd\u73b0\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2511.04328", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04328", "abs": "https://arxiv.org/abs/2511.04328", "authors": ["Jiahao Zhao", "Luxin Xu", "Minghuan Tan", "Lichao Zhang", "Ahmadreza Argha", "Hamid Alinejad-Rokny", "Min Yang"], "title": "RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation", "comment": "To appear in BIBM2025", "summary": "Numerous medical systems powered by Large Language Models (LLMs) have\nachieved remarkable progress in diverse healthcare tasks. However, research on\ntheir medication safety remains limited due to the lack of real world datasets,\nconstrained by privacy and accessibility issues. Moreover, evaluation of LLMs\nin realistic clinical consultation settings, particularly regarding medication\nsafety, is still underexplored. To address these gaps, we propose a framework\nthat simulates and evaluates clinical consultations to systematically assess\nthe medication safety capabilities of LLMs. Within this framework, we generate\ninquiry diagnosis dialogues with embedded medication risks and construct a\ndedicated medication safety database, RxRisk DB, containing 6,725\ncontraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.\nA two-stage filtering strategy ensures clinical realism and professional\nquality, resulting in the benchmark RxSafeBench with 2,443 high-quality\nconsultation scenarios. We evaluate leading open-source and proprietary LLMs\nusing structured multiple choice questions that test their ability to recommend\nsafe medications under simulated patient contexts. Results show that current\nLLMs struggle to integrate contraindication and interaction knowledge,\nespecially when risks are implied rather than explicit. Our findings highlight\nkey challenges in ensuring medication safety in LLM-based systems and provide\ninsights into improving reliability through better prompting and task-specific\ntuning. RxSafeBench offers the first comprehensive benchmark for evaluating\nmedication safety in LLMs, advancing safer and more trustworthy AI-driven\nclinical decision support.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u54a8\u8be2\u4e2d\u7528\u836f\u5b89\u5168\u80fd\u529b\u7684\u6846\u67b6\uff0c\u521b\u5efa\u4e86\u5305\u542b6725\u6761\u7981\u5fcc\u75c7\u300128781\u79cd\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u548c14906\u4e2a\u9002\u5e94\u75c7-\u836f\u7269\u5bf9\u7684RxRisk DB\u6570\u636e\u5e93\uff0c\u5e76\u6784\u5efa\u4e862443\u4e2a\u9ad8\u8d28\u91cf\u54a8\u8be2\u573a\u666f\u7684RxSafeBench\u57fa\u51c6\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u533b\u7597\u7cfb\u7edf\u5728\u7528\u836f\u5b89\u5168\u65b9\u9762\u7684\u7814\u7a76\u6709\u9650\uff0c\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u4e14\u5728\u771f\u5b9e\u4e34\u5e8a\u54a8\u8be2\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u62df\u548c\u8bc4\u4f30\u4e34\u5e8a\u54a8\u8be2\u7684\u6846\u67b6\uff0c\u751f\u6210\u5305\u542b\u7528\u836f\u98ce\u9669\u7684\u8bca\u65ad\u5bf9\u8bdd\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8fc7\u6ee4\u7b56\u7565\u786e\u4fdd\u4e34\u5e8a\u771f\u5b9e\u6027\u548c\u4e13\u4e1a\u8d28\u91cf\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u591a\u9009\u9898\u8bc4\u4f30LLMs\u5728\u6a21\u62df\u60a3\u8005\u60c5\u5883\u4e0b\u63a8\u8350\u5b89\u5168\u836f\u7269\u7684\u80fd\u529b\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5f53\u524dLLMs\u5728\u6574\u5408\u7981\u5fcc\u75c7\u548c\u76f8\u4e92\u4f5c\u7528\u77e5\u8bc6\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5f53\u98ce\u9669\u662f\u9690\u542b\u800c\u975e\u660e\u786e\u65f6\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\u5728\u786e\u4fdd\u7528\u836f\u5b89\u5168\u65b9\u9762\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u901a\u8fc7\u66f4\u597d\u7684\u63d0\u793a\u548c\u4efb\u52a1\u7279\u5b9a\u8c03\u4f18\u63d0\u9ad8\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0cRxSafeBench\u4e3a\u8bc4\u4f30LLMs\u7528\u836f\u5b89\u5168\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u57fa\u51c6\u3002"}}
{"id": "2511.04341", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04341", "abs": "https://arxiv.org/abs/2511.04341", "authors": ["Nick Oh", "Fernand Gobet"], "title": "Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning", "comment": "To-be presented at the Workshop on the Foundations of Reasoning in\n  Language Models at NeurIPS 2025 (non-archival)", "summary": "Test-time reasoning architectures such as those following the Generate-Verify\nparadigm -- where a model iteratively refines or verifies its own generated\noutputs -- prioritise generation and verification but exclude the monitoring\nprocesses that determine when and how reasoning should begin. This omission may\ncontribute to the prefix dominance trap, in which models commit early to\nsuboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy\nloss. We address this architectural gap by formalising Flavell's and Nelson and\nNarens' metacognitive theories into computational specifications, proposing the\nMonitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify\nparadigm by adding explicit monitoring that captures metacognitive experiences\n(from difficulty assessments to confidence judgements) before generation begins\nand refines future monitoring through verification feedback. Though we present\nno empirical validation, this work provides the first systematic computational\ntranslation of foundational metacognitive theories, offering a principled\nvocabulary for understanding reasoning system failures and suggesting specific\narchitectural interventions for future test-time reasoning designs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Monitor-Generate-Verify (MGV)\u6846\u67b6\uff0c\u901a\u8fc7\u5728Generate-Verify\u8303\u5f0f\u524d\u6dfb\u52a0\u663e\u5f0f\u76d1\u63a7\u673a\u5236\u6765\u89e3\u51b3\u524d\u7f00\u4e3b\u5bfc\u9677\u9631\u95ee\u9898\uff0c\u5c06\u5143\u8ba4\u77e5\u7406\u8bba\u8f6c\u5316\u4e3a\u8ba1\u7b97\u89c4\u8303\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u63a8\u7406\u67b6\u6784\u7f3a\u4e4f\u76d1\u63a7\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u65e9\u627f\u8bfa\u6b21\u4f18\u63a8\u7406\u8def\u5f84\u4e14\u96be\u4ee5\u6062\u590d\uff0c\u9020\u6210\u7ea620%\u7684\u51c6\u786e\u7387\u635f\u5931\u3002", "method": "\u5c06Flavell\u4ee5\u53caNelson\u548cNarens\u7684\u5143\u8ba4\u77e5\u7406\u8bba\u5f62\u5f0f\u5316\u4e3a\u8ba1\u7b97\u89c4\u8303\uff0c\u5728Generate-Verify\u8303\u5f0f\u524d\u6dfb\u52a0\u663e\u5f0f\u76d1\u63a7\uff0c\u6355\u83b7\u5143\u8ba4\u77e5\u4f53\u9a8c\u5e76\u5229\u7528\u9a8c\u8bc1\u53cd\u9988\u4f18\u5316\u76d1\u63a7\u3002", "result": "\u867d\u7136\u672a\u63d0\u4f9b\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u4f46\u8fd9\u662f\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5c06\u57fa\u7840\u5143\u8ba4\u77e5\u7406\u8bba\u8f6c\u5316\u4e3a\u8ba1\u7b97\u89c4\u8303\u3002", "conclusion": "MGV\u6846\u67b6\u4e3a\u7406\u89e3\u63a8\u7406\u7cfb\u7edf\u5931\u8d25\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8bcd\u6c47\uff0c\u5e76\u4e3a\u672a\u6765\u6d4b\u8bd5\u65f6\u63a8\u7406\u8bbe\u8ba1\u63d0\u51fa\u4e86\u5177\u4f53\u7684\u67b6\u6784\u5e72\u9884\u5efa\u8bae\u3002"}}
{"id": "2511.04393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04393", "abs": "https://arxiv.org/abs/2511.04393", "authors": ["Chanwoo Park", "Ziyang Chen", "Asuman Ozdaglar", "Kaiqing Zhang"], "title": "Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as \"agents\" for\ndecision-making (DM) in interactive and dynamic environments. Yet, since they\nwere not originally designed for DM, recent studies show that LLMs can struggle\neven in basic online DM problems, failing to achieve low regret or an effective\nexploration-exploitation tradeoff. To address this, we introduce Iterative\nRegret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure\nthat repeatedly distills low-regret decision trajectories back into the base\nmodel. At each iteration, the model rolls out multiple decision trajectories,\nselects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior\nmethods that (a) distill action sequences from known DM algorithms or (b) rely\non manually crafted chain-of-thought templates, our approach leverages the\nregret metric to elicit the model's own DM ability and reasoning rationales.\nThis reliance on model-generated reasoning avoids rigid output engineering and\nprovides more flexible, natural-language training signals. Empirical results\nshow that Iterative RMFT improves LLMs' DM performance across diverse models -\nfrom Transformers with numerical input/output, to open-weight LLMs, and\nadvanced closed-weight models like GPT-4o mini. Its flexibility in output and\nreasoning formats enables generalization across tasks with varying horizons,\naction spaces, reward processes, and natural-language contexts. Finally, we\nprovide theoretical insight showing that a single-layer Transformer under this\nparadigm can act as a no-regret learner in a simplified setting. Overall,\nIterative RMFT offers a principled and general post-training framework for\nenhancing LLMs' decision-making capabilities.", "AI": {"tldr": "\u63d0\u51faIterative Regret-Minimization Fine-Tuning (Iterative RMFT)\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cd\u590d\u84b8\u998f\u4f4e\u540e\u6094\u51b3\u7b56\u8f68\u8ff9\u6765\u589e\u5f3aLLM\u5728\u4ea4\u4e92\u52a8\u6001\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "LLM\u539f\u672c\u5e76\u975e\u4e3a\u51b3\u7b56\u8bbe\u8ba1\uff0c\u5728\u57fa\u7840\u5728\u7ebf\u51b3\u7b56\u95ee\u9898\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u5b9e\u73b0\u4f4e\u540e\u6094\u6216\u6709\u6548\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\u3002", "method": "\u8fed\u4ee3\u540e\u6094\u6700\u5c0f\u5316\u5fae\u8c03\uff1a\u6a21\u578b\u6bcf\u6b21\u8fed\u4ee3\u751f\u6210\u591a\u4e2a\u51b3\u7b56\u8f68\u8ff9\uff0c\u9009\u62e9k\u4e2a\u6700\u4f4e\u540e\u6094\u7684\u8f68\u8ff9\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u8f68\u8ff9\u8fdb\u884c\u81ea\u6211\u5fae\u8c03\u3002", "result": "Iterative RMFT\u663e\u8457\u63d0\u5347\u4e86\u5404\u79cd\u6a21\u578b\uff08\u4eceTransformer\u5230\u5f00\u6e90LLM\u548cGPT-4o mini\uff09\u7684\u51b3\u7b56\u6027\u80fd\uff0c\u80fd\u591f\u6cdb\u5316\u5230\u4e0d\u540c\u4efb\u52a1\u8bbe\u7f6e\u3002", "conclusion": "Iterative RMFT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u901a\u7528\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u53ef\u6709\u6548\u589e\u5f3aLLM\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u7406\u8bba\u5206\u6790\u8868\u660e\u5355\u5c42Transformer\u5728\u6b64\u8303\u5f0f\u4e0b\u53ef\u6210\u4e3a\u65e0\u540e\u6094\u5b66\u4e60\u5668\u3002"}}
{"id": "2511.04439", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04439", "abs": "https://arxiv.org/abs/2511.04439", "authors": ["Anisha Garg", "Ganesh Venkatesh"], "title": "The Peril of Preference: Why GRPO fails on Ordinal Rewards", "comment": null, "summary": "Group-relative Policy Optimization's (GRPO) simplicity makes it highly\ndesirable for adapting LLMs to become experts at specific tasks. But this\nsimplicity also makes it ill-specified as we seek to enhance RL training with\nricher, non-binary feedback. When using ordinal rewards to give partial credit,\nGRPO's simplicity starts to hurt, as its group-average baseline often assigns a\npositive advantage to failed trajectories and reinforces incorrect behavior.\n  We introduce Correctness Relative Policy Optimization (CoRPO), a new\nformulation that solves this flaw. CoRPO uses an adaptive baseline that\nenforces a minimum quality threshold, ensuring failed solutions are never\npositively reinforced. Once the policy consistently meets this threshold, the\nbaseline automatically transitions to a relative preference mode, pushing the\nmodel to find optimal solutions rather than just \"acceptable\" ones. We\nempirically validate CoRPO on a code verification task, where it demonstrates\nmore stable convergence and better out-of-domain generalization.\n  This work represents a critical step in our broader research program to\nenable LLMs to learn genuinely new capabilities through reinforcement learning.\nWe achieve this by enabling LLMs to learn from rich, multi-dimensional feedback\n- progressing from binary to ordinal rewards in this work, and onward to\ndenser, per-step supervision.", "AI": {"tldr": "CoRPO\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86GRPO\u5728\u90e8\u5206\u5956\u52b1\u573a\u666f\u4e0b\u5bf9\u5931\u8d25\u8f68\u8ff9\u9519\u8bef\u5f3a\u5316\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u57fa\u7ebf\u786e\u4fdd\u5931\u8d25\u89e3\u4e0d\u88ab\u6b63\u5411\u5f3a\u5316\uff0c\u5e76\u5728\u8fbe\u5230\u8d28\u91cf\u9608\u503c\u540e\u8f6c\u5411\u76f8\u5bf9\u504f\u597d\u6a21\u5f0f\u3002", "motivation": "GRPO\u7684\u7b80\u5355\u6027\u4f7f\u5176\u5728\u5904\u7406\u975e\u4e8c\u5143\u53cd\u9988\u65f6\u5b58\u5728\u7f3a\u9677\uff0c\u5f53\u4f7f\u7528\u5e8f\u6570\u5956\u52b1\u7ed9\u4e88\u90e8\u5206\u5b66\u5206\u65f6\uff0c\u5176\u7ec4\u5e73\u5747\u57fa\u7ebf\u7ecf\u5e38\u5bf9\u5931\u8d25\u8f68\u8ff9\u5206\u914d\u6b63\u4f18\u52bf\u5e76\u5f3a\u5316\u9519\u8bef\u884c\u4e3a\u3002", "method": "\u63d0\u51faCoRPO\u65b9\u6cd5\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u57fa\u7ebf\u5f3a\u5236\u6267\u884c\u6700\u4f4e\u8d28\u91cf\u9608\u503c\uff0c\u786e\u4fdd\u5931\u8d25\u89e3\u51b3\u65b9\u6848\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u6b63\u5411\u5f3a\u5316\u3002\u4e00\u65e6\u7b56\u7565\u6301\u7eed\u6ee1\u8db3\u6b64\u9608\u503c\uff0c\u57fa\u7ebf\u81ea\u52a8\u8fc7\u6e21\u5230\u76f8\u5bf9\u504f\u597d\u6a21\u5f0f\u3002", "result": "\u5728\u4ee3\u7801\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u5b9e\u8bc1\u9a8c\u8bc1\uff0cCoRPO\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u6027\u548c\u66f4\u597d\u7684\u57df\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u662f\u5728\u4f7fLLM\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u771f\u6b63\u65b0\u80fd\u529b\u7684\u7814\u7a76\u8ba1\u5212\u4e2d\u7684\u5173\u952e\u4e00\u6b65\uff0c\u901a\u8fc7\u8ba9LLM\u4ece\u4e30\u5bcc\u7684\u591a\u7ef4\u5ea6\u53cd\u9988\u4e2d\u5b66\u4e60\uff0c\u4ece\u4e8c\u5143\u5956\u52b1\u8fdb\u5c55\u5230\u5e8f\u6570\u5956\u52b1\u3002"}}
{"id": "2511.04584", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.04584", "abs": "https://arxiv.org/abs/2511.04584", "authors": ["Daniel Gomm", "Cornelius Wolff", "Madelon Hulsebos"], "title": "Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis", "comment": "Accepted to the AI for Tabular Data workshop at EurIPS 2025", "summary": "Natural language interfaces to tabular data must handle ambiguities inherent\nto queries. Instead of treating ambiguity as a deficiency, we reframe it as a\nfeature of cooperative interaction, where the responsibility of query\nspecification is shared among the user and the system. We develop a principled\nframework distinguishing cooperative queries, i.e., queries that yield a\nresolvable interpretation, from uncooperative queries that cannot be resolved.\nApplying the framework to evaluations for tabular question answering and\nanalysis, we analyze the queries in 15 popular datasets, and observe an\nuncontrolled mixing of query types neither adequate for evaluating a system's\nexecution accuracy nor for evaluating interpretation capabilities. Our\nframework and analysis of queries shifts the perspective from fixing ambiguity\nto embracing cooperation in resolving queries. This reflection enables more\ninformed design and evaluation for natural language interfaces for tabular\ndata, for which we outline implications and directions for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u7684\u6b67\u4e49\u6027\u91cd\u65b0\u5b9a\u4e49\u4e3a\u534f\u4f5c\u4ea4\u4e92\u7684\u7279\u5f81\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u533a\u5206\u53ef\u89e3\u6790\u7684\u5408\u4f5c\u67e5\u8be2\u4e0e\u4e0d\u53ef\u89e3\u6790\u7684\u975e\u5408\u4f5c\u67e5\u8be2\u7684\u539f\u5219\u6027\u6846\u67b6\uff0c\u5206\u6790\u4e8615\u4e2a\u6d41\u884c\u6570\u636e\u96c6\u4e2d\u7684\u67e5\u8be2\u7c7b\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u9762\u5411\u8868\u683c\u6570\u636e\u7684\u81ea\u7136\u8bed\u8a00\u754c\u9762\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7684\u65b0\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u7684\u6b67\u4e49\u6027\u89c6\u4e3a\u7f3a\u9677\uff0c\u672c\u6587\u65e8\u5728\u5c06\u5176\u91cd\u65b0\u5b9a\u4e49\u4e3a\u534f\u4f5c\u4ea4\u4e92\u7684\u7279\u5f81\uff0c\u5f3a\u8c03\u7528\u6237\u548c\u7cfb\u7edf\u5171\u540c\u627f\u62c5\u67e5\u8be2\u89c4\u8303\u7684\u8d23\u4efb\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\u6765\u533a\u5206\u5408\u4f5c\u67e5\u8be2\u548c\u975e\u5408\u4f5c\u67e5\u8be2\uff0c\u5e76\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e15\u4e2a\u6d41\u884c\u7684\u8868\u683c\u95ee\u7b54\u548c\u5206\u6790\u6570\u636e\u96c6\u7684\u67e5\u8be2\u5206\u6790\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u7684\u67e5\u8be2\u7c7b\u578b\u6df7\u5408\u4e0d\u5f53\uff0c\u65e2\u4e0d\u9002\u5408\u8bc4\u4f30\u7cfb\u7edf\u6267\u884c\u51c6\u786e\u6027\uff0c\u4e5f\u4e0d\u9002\u5408\u8bc4\u4f30\u89e3\u91ca\u80fd\u529b\uff0c\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u89c6\u89d2\u4ece\u6d88\u9664\u6b67\u4e49\u8f6c\u5411\u5728\u89e3\u6790\u67e5\u8be2\u4e2d\u62e5\u62b1\u534f\u4f5c\uff0c\u4e3a\u8868\u683c\u6570\u636e\u7684\u81ea\u7136\u8bed\u8a00\u754c\u9762\u63d0\u4f9b\u4e86\u66f4\u660e\u667a\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u65b9\u5411\u3002"}}
{"id": "2511.04588", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.04588", "abs": "https://arxiv.org/abs/2511.04588", "authors": ["Soham De", "Lodewijk Gelauff", "Ashish Goel", "Smitha Milli", "Ariel Procaccia", "Alice Siu"], "title": "Question the Questions: Auditing Representation in Online Deliberative Processes", "comment": null, "summary": "A central feature of many deliberative processes, such as citizens'\nassemblies and deliberative polls, is the opportunity for participants to\nengage directly with experts. While participants are typically invited to\npropose questions for expert panels, only a limited number can be selected due\nto time constraints. This raises the challenge of how to choose a small set of\nquestions that best represent the interests of all participants. We introduce\nan auditing framework for measuring the level of representation provided by a\nslate of questions, based on the social choice concept known as justified\nrepresentation (JR). We present the first algorithms for auditing JR in the\ngeneral utility setting, with our most efficient algorithm achieving a runtime\nof $O(mn\\log n)$, where $n$ is the number of participants and $m$ is the number\nof proposed questions. We apply our auditing methods to historical\ndeliberations, comparing the representativeness of (a) the actual questions\nposed to the expert panel (chosen by a moderator), (b) participants' questions\nchosen via integer linear programming, (c) summary questions generated by large\nlanguage models (LLMs). Our results highlight both the promise and current\nlimitations of LLMs in supporting deliberative processes. By integrating our\nmethods into an online deliberation platform that has been used for over\nhundreds of deliberations across more than 50 countries, we make it easy for\npractitioners to audit and improve representation in future deliberations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5408\u7406\u4ee3\u8868\u5236(JR)\u7684\u5ba1\u6838\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u516c\u6c11\u5927\u4f1a\u7b49\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\u4e13\u5bb6\u95ee\u7b54\u73af\u8282\u7684\u95ee\u9898\u4ee3\u8868\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u5ba1\u6838\u7b97\u6cd5\u3002", "motivation": "\u5728\u516c\u6c11\u5927\u4f1a\u7b49\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\uff0c\u53c2\u4e0e\u8005\u53ef\u4ee5\u5411\u4e13\u5bb6\u63d0\u95ee\uff0c\u4f46\u7531\u4e8e\u65f6\u95f4\u9650\u5236\u53ea\u80fd\u9009\u62e9\u5c11\u91cf\u95ee\u9898\u3002\u5982\u4f55\u9009\u62e9\u6700\u80fd\u4ee3\u8868\u6240\u6709\u53c2\u4e0e\u8005\u5174\u8da3\u7684\u95ee\u9898\u96c6\u5408\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5408\u7406\u4ee3\u8868\u5236(JR)\u7684\u5ba1\u6838\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u5728\u901a\u7528\u6548\u7528\u8bbe\u7f6e\u4e0b\u5ba1\u6838JR\u7684\u9996\u4e2a\u7b97\u6cd5\uff0c\u6700\u6709\u6548\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(mn log n)\u3002\u5e94\u7528\u8be5\u65b9\u6cd5\u6bd4\u8f83\u4e86\u4e3b\u6301\u4eba\u9009\u62e9\u7684\u95ee\u9898\u3001\u6574\u6570\u7ebf\u6027\u89c4\u5212\u9009\u62e9\u7684\u95ee\u9898\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u95ee\u9898\u7684\u4ee3\u8868\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u652f\u6301\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u529b\u548c\u5f53\u524d\u5c40\u9650\u6027\u3002\u901a\u8fc7\u5c06\u65b9\u6cd5\u96c6\u6210\u5230\u5df2\u572850\u591a\u4e2a\u56fd\u5bb6\u4f7f\u7528\u7684\u5728\u7ebf\u5ba1\u8bae\u5e73\u53f0\uff0c\u4f7f\u5b9e\u8df5\u8005\u80fd\u591f\u8f7b\u677e\u5ba1\u6838\u548c\u6539\u8fdb\u672a\u6765\u5ba1\u8bae\u7684\u4ee3\u8868\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\u7684\u95ee\u9898\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4ee3\u8868\u6027\u8bc4\u4f30\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5ba1\u8bae\u8fc7\u7a0b\u7684\u6c11\u4e3b\u6027\u548c\u5305\u5bb9\u6027\u3002"}}
{"id": "2511.04662", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04662", "abs": "https://arxiv.org/abs/2511.04662", "authors": ["Yu Feng", "Nathaniel Weir", "Kaj Bostrom", "Sam Bayless", "Darion Cassel", "Sapana Chaudhary", "Benjamin Kiesl-Reiter", "Huzefa Rangwala"], "title": "VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks", "comment": null, "summary": "LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but\nthey cannot reliably verify their own logic. Even when they reach correct\nanswers, the underlying reasoning may be flawed, undermining trust in\nhigh-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a\nneuro-symbolic method that extracts and verifies formal logical arguments from\nCoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order\nlogic and identifies premises that ground the argument in source context,\ncommonsense knowledge, or prior reasoning steps. The symbolic representation\nenables automated solvers to verify logical validity while the NL premises\nallow humans and systems to identify ungrounded or fallacious reasoning steps.\nExperiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT\neffectively identifies flawed reasoning, and serves as a strong predictor of\nfinal answer correctness. We also leverage VeriCoT's verification signal for\n(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on\nVeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct\npreference optimization (DPO) using verification-based pairwise rewards,\nfurther improving reasoning validity and accuracy.", "AI": {"tldr": "VeriCoT\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u601d\u7ef4\u94fe\u63a8\u7406\u5f62\u5f0f\u5316\u4e3a\u4e00\u9636\u903b\u8f91\u5e76\u9a8c\u8bc1\u903b\u8f91\u6709\u6548\u6027\uff0c\u89e3\u51b3LLMs\u65e0\u6cd5\u53ef\u9760\u9a8c\u8bc1\u81ea\u8eab\u903b\u8f91\u7684\u95ee\u9898\u3002", "motivation": "LLMs\u867d\u7136\u80fd\u901a\u8fc7\u601d\u7ef4\u94fe\u8fdb\u884c\u591a\u6b65\u63a8\u7406\uff0c\u4f46\u65e0\u6cd5\u53ef\u9760\u9a8c\u8bc1\u81ea\u8eab\u903b\u8f91\uff0c\u5373\u4f7f\u5728\u5f97\u51fa\u6b63\u786e\u7b54\u6848\u65f6\uff0c\u5e95\u5c42\u63a8\u7406\u4e5f\u53ef\u80fd\u5b58\u5728\u7f3a\u9677\uff0c\u8fd9\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u524a\u5f31\u4e86\u53ef\u4fe1\u5ea6\u3002", "method": "VeriCoT\u4ece\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u63d0\u53d6\u5f62\u5f0f\u5316\u903b\u8f91\u8bba\u8bc1\uff0c\u5c06\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u5f62\u5f0f\u5316\u4e3a\u4e00\u9636\u903b\u8f91\uff0c\u8bc6\u522b\u652f\u6491\u8bba\u8bc1\u7684\u524d\u63d0\uff08\u6e90\u4e0a\u4e0b\u6587\u3001\u5e38\u8bc6\u77e5\u8bc6\u6216\u5148\u524d\u63a8\u7406\u6b65\u9aa4\uff09\uff0c\u4f7f\u7528\u81ea\u52a8\u5316\u6c42\u89e3\u5668\u9a8c\u8bc1\u903b\u8f91\u6709\u6548\u6027\u3002", "result": "\u5728ProofWriter\u3001LegalBench\u548cBioASQ\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVeriCoT\u80fd\u6709\u6548\u8bc6\u522b\u6709\u7f3a\u9677\u7684\u63a8\u7406\uff0c\u5e76\u4f5c\u4e3a\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u7684\u5f3a\u9884\u6d4b\u6307\u6807\u3002", "conclusion": "VeriCoT\u7684\u9a8c\u8bc1\u4fe1\u53f7\u53ef\u7528\u4e8e\u63a8\u7406\u65f6\u81ea\u6211\u53cd\u601d\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u5fae\u8c03\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u63a8\u7406\u7684\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002"}}
