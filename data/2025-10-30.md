<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 3]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.DC](#cs.DC) [Total: 4]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [From Narrative to Action: A Hierarchical LLM-Agent Framework for Human Mobility Generation](https://arxiv.org/abs/2510.24802)
*Qiumeng Li,Chunhou Ji,Xinyue Liu*

Main category: cs.MA

TL;DR: 提出了一个分层LLM-智能体框架，将高层次叙事推理、中层次反思规划和低层次行为执行整合到统一的认知层次结构中，用于生成符合人类认知逻辑的合成移动轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统基于智能体或深度学习模型能够重现移动的统计模式，但无法捕捉人类行为的语义连贯性和因果逻辑。大语言模型虽有潜力，但在创造性推理与严格结构合规性之间难以平衡。

Method: 采用分层LLM-智能体框架：宏观层面使用"创意写手"生成日记式叙事，"结构解析器"将叙事转换为机器可读计划；微观层面通过环境模拟执行具体行动；引入基于职业的移动熵指标来指导行为调整。

Result: 该框架不仅生成与真实世界模式高度一致的合成轨迹，还提供人类决策逻辑的可解释表示。

Conclusion: 本研究将合成移动生成从数据驱动范式推进到认知驱动模拟，通过分层LLM智能体为理解、预测和合成复杂城市移动行为提供了可扩展路径。

Abstract: Understanding and replicating human mobility requires not only
spatial-temporal accuracy but also an awareness of the cognitive hierarchy
underlying real-world travel decisions. Traditional agent-based or deep
learning models can reproduce statistical patterns of movement but fail to
capture the semantic coherence and causal logic of human behavior. Large
language models (LLMs) show potential, but struggle to balance creative
reasoning with strict structural compliance. This study proposes a Hierarchical
LLM-Agent Framework, termed Narrative-to-Action, that integrates high-level
narrative reasoning, mid-level reflective planning, and low-level behavioral
execution within a unified cognitive hierarchy. At the macro level, one agent
is employed as a "creative writer" to produce diary-style narratives rich in
motivation and context, then uses another agent as a "structural parser" to
convert narratives into machine-readable plans. A dynamic execution module
further grounds agents in geographic environments and enables adaptive
behavioral adjustments guided by a novel occupation-aware metric, Mobility
Entropy by Occupation (MEO), which captures heterogeneous schedule flexibility
across different occupational personalities. At the micro level, the agent
executes concrete actions-selecting locations, transportation modes, and time
intervals-through interaction with an environmental simulation. By embedding
this multi-layer cognitive process, the framework produces not only synthetic
trajectories that align closely with real-world patterns but also interpretable
representations of human decision logic. This research advances synthetic
mobility generation from a data-driven paradigm to a cognition-driven
simulation, providing a scalable pathway for understanding, predicting, and
synthesizing complex urban mobility behaviors through hierarchical LLM agents.

</details>


### [2] [Collaborative Scheduling of Time-dependent UAVs,Vehicles and Workers for Crowdsensing in Disaster Response](https://arxiv.org/abs/2510.25212)
*Lei Han,Jinhao Zhang,Jinhui Liu,Zhiyong Yu,Liang Wang,Quan Wang,Zhiwen Yu*

Main category: cs.MA

TL;DR: 本文提出了一种异构多智能体在线协同调度算法HoCs-MPQ，用于实现灾后环境信息的高效采集。该算法通过加权无向图建模多要素间的协作与冲突关系，并基于多优先级队列迭代求解最大权重独立集，最终实现时间依赖的无人机、车辆和工人的协同感知调度。


<details>
  <summary>Details</summary>
Motivation: 频繁的自然灾害给人类社会造成重大损失，及时高效地收集灾后环境信息是有效救援行动的基础。由于灾后环境的极端复杂性，现有的移动群智感知等技术存在环境适应性弱、专业感知能力不足、感知方案实用性差等问题。

Method: HoCs-MPQ算法：(1)基于多要素间的协作关系构建加权无向图节点并量化权重，基于节点间的冲突关系建模加权无向图；(2)基于迭代局部搜索求解最大权重独立集，并使用多优先级队列加速求解过程。

Result: 实验表明，与基线方法相比，HoCs-MPQ平均分别提高了任务完成率54.13%、23.82%、14.12%和12.89%，单次在线自主调度决策的计算时间不超过3秒。

Conclusion: HoCs-MPQ算法能够有效解决灾后环境信息采集中的协同调度问题，显著提高任务完成效率，具有较好的实用价值。

Abstract: Frequent natural disasters cause significant losses to human society, and
timely, efficient collection of post-disaster environmental information is the
foundation for effective rescue operations. Due to the extreme complexity of
post-disaster environments, existing sensing technologies such as mobile
crowdsensing suffer from weak environmental adaptability, insufficient
professional sensing capabilities, and poor practicality of sensing solutions.
Therefore, this paper explores a heterogeneous multi-agent online collaborative
scheduling algorithm, HoCs-MPQ, to achieve efficient collection of
post-disaster environmental information. HoCs-MPQ models collaboration and
conflict relationships among multiple elements through weighted undirected
graph construction, and iteratively solves the maximum weight independent set
based on multi-priority queues, ultimately achieving collaborative sensing
scheduling of time-dependent UA Vs, vehicles, and workers. Specifically, (1)
HoCs-MPQ constructs weighted undirected graph nodes based on collaborative
relationships among multiple elements and quantifies their weights, then models
the weighted undirected graph based on conflict relationships between nodes;
(2) HoCs-MPQ solves the maximum weight independent set based on iterated local
search, and accelerates the solution process using multi-priority queues.
Finally, we conducted detailed experiments based on extensive real-world and
simulated data. The experiments show that, compared to baseline methods (e.g.,
HoCs-GREEDY, HoCs-K-WTA, HoCs-MADL, and HoCs-MARL), HoCs-MPQ improves task
completion rates by an average of 54.13%, 23.82%, 14.12%, and 12.89%
respectively, with computation time for single online autonomous scheduling
decisions not exceeding 3 seconds.

</details>


### [3] [Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork](https://arxiv.org/abs/2510.25340)
*Beiwen Zhang,Yongheng Liang,Hejun Wu*

Main category: cs.MA

TL;DR: 本文提出了多方临时团队协作（MAHT）问题，其中受控智能体需要与多个互不熟悉的非受控队友群体协调。为解决此问题，作者提出了MARs方法，通过构建稀疏骨架图和应用关系建模来捕捉跨群体动态。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习（MARL）通常假设固定且完全受控的团队，而临时团队协作（AHT）虽然允许与未知伙伴合作，但仍假设共享约定。MAHT进一步放宽了这一假设，要求智能体与多个互不熟悉的非受控队友群体协调。

Method: 提出了MARs方法，该方法构建稀疏骨架图并应用关系建模来捕捉跨群体动态。

Result: 在MPE和StarCraft II上的实验表明，MARs方法优于MARL和AHT基线方法，并且收敛速度更快。

Conclusion: MARs方法能够有效解决多方临时团队协作问题，在复杂多智能体环境中表现出优越的性能和更快的收敛速度。

Abstract: Multi-agent reinforcement learning (MARl) has achieved strong results in
cooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc
teamwork (AHT) relaxes this by allowing collaboration with unknown partners,
yet existing variants still presume shared conventions. We introduce
Multil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate
with multiple mutually unfamiliar groups of uncontrolled teammates. To address
this, we propose MARs, which builds a sparse skeleton graph and applies
relational modeling to capture cross-group dvnamics. Experiments on MPE and
starCralt ll show that MARs outperforms MARL and AHT baselines while converging
faster.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [Scheduling Your LLM Reinforcement Learning with Reasoning Trees](https://arxiv.org/abs/2510.24832)
*Hong Wang,Zhezheng Hao,Jian Luo,Chenxing Wei,Yao Shu,Lei Liu,Qiang Lin,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: 本文提出了一种基于推理树结构的新指标r-score来衡量查询的学习难度，并基于此开发了Re-Schedule调度算法，在六个数学推理基准测试中显著提升了平均准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR数据调度方法通常依赖基于路径的指标来排名查询，忽略了这些查询的推理树结构，因此需要一种更有效的调度方法。

Method: 引入推理分数(r-score)来衡量查询的学习难度，基于r-score提出推理树调度算法(Re-Schedule)，构建从结构简单到复杂的课程进度。

Result: 在六个数学推理基准测试中，Re-Schedule显著提高了平均准确率，最高提升达3.2%。

Conclusion: 对推理树的结构理解为RLVR数据调度提供了更强大和原则性的基础，实验结果验证了该方法的有效性。

Abstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large
Language Models (LLMs) can be conceptualized as progressively editing a query's
`Reasoning Tree'. This process involves exploring nodes (tokens) and
dynamically modifying the model's policy at each node. When combined with data
scheduling, this process yields further gains in data efficiency and accuracy.
However, existing RLVR data scheduling methods typically rely on path-based
metrics to rank queries, overlooking the reasoning tree structures of these
queries. In this paper, we introduce a novel metric, namely Reasoning Score
(r-score), which measures the query's learning difficulty based on the
structure of its reasoning tree. Based on the r-score, we propose the Reasoning
Tree Schedule (Re-Schedule), a scheduling algorithm that constructs a
curriculum progressing from structurally simple (high r-score) to complex (low
r-score) queries. Experiments on six math-reasoning benchmarks show that
Re-Schedule significantly improves average accuracy, achieving gains of up to
3.2%. These strong results validate our approach and demonstrate that a
structural understanding of the reasoning tree provides a more powerful and
principled foundation for RLVR data scheduling.

</details>


### [5] [Cyclic Counterfactuals under Shift-Scale Interventions](https://arxiv.org/abs/2510.25005)
*Saptarshi Saha,Dhruv Vansraj Rathore,Utpal Garain*

Main category: cs.AI

TL;DR: 研究在包含反馈循环的循环结构因果模型中进行反事实推理，关注于移位-尺度干预这种软性政策式变化


<details>
  <summary>Details</summary>
Motivation: 传统反事实推理框架假设无环结构因果模型，但许多真实系统（如生物系统）包含违反无环性的反馈循环或循环依赖

Method: 研究循环结构因果模型中的反事实推理，特别关注移位-尺度干预（即对变量机制进行重新缩放和/或移位的软性政策式变化）

Result: 论文探讨了在循环系统中进行反事实推理的方法，但具体结果未在摘要中明确说明

Conclusion: 需要扩展反事实推理框架以处理包含反馈循环的循环系统，移位-尺度干预为这类系统提供了可行的干预方法

Abstract: Most counterfactual inference frameworks traditionally assume acyclic
structural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,
many real-world systems (e.g. biological systems) contain feedback loops or
cyclic dependencies that violate acyclicity. In this work, we study
counterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,
soft, policy-style changes that rescale and/or shift a variable's mechanism.

</details>


### [6] [Taming the Real-world Complexities in CPT E/M Coding with Large Language Models](https://arxiv.org/abs/2510.25007)
*Islam Nassar,Yang Lin,Yuan Jin,Rongxin Zhu,Chang Wei Tan,Zenan Zhai,Nitika Mathur,Thanh Tien Vu,Xu Zhong,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: 论文提出了ProFees框架，这是一个基于LLM的自动化E/M编码系统，旨在解决医疗账单编码中的复杂问题，在真实数据集上比商业系统提高了36%以上的编码准确率。


<details>
  <summary>Details</summary>
Motivation: 自动化E/M编码任务可以减轻医生的文档负担，提高计费效率，并最终实现更好的患者护理。然而，现实世界的复杂性使得E/M编码自动化成为一项具有挑战性的任务。

Method: 提出了ProFees框架，这是一个基于大型语言模型（LLM）的解决方案，专门设计用于处理E/M编码中的关键复杂性。

Result: 在专家策划的真实世界数据集上，ProFees比商业CPT E/M编码系统的编码准确率提高了36%以上，比最强的单提示基线提高了近5%。

Conclusion: ProFees框架在解决现实世界复杂性方面表现出有效性，证明了其在自动化医疗编码任务中的潜力。

Abstract: Evaluation and Management (E/M) coding, under the Current Procedural
Terminology (CPT) taxonomy, documents medical services provided to patients by
physicians. Used primarily for billing purposes, it is in physicians' best
interest to provide accurate CPT E/M codes. %While important, it is an
auxiliary task that adds to physicians' documentation burden. Automating this
coding task will help alleviate physicians' documentation burden, improve
billing efficiency, and ultimately enable better patient care. However, a
number of real-world complexities have made E/M encoding automation a
challenging task. In this paper, we elaborate some of the key complexities and
present ProFees, our LLM-based framework that tackles them, followed by a
systematic evaluation. On an expert-curated real-world dataset, ProFees
achieves an increase in coding accuracy of more than 36\% over a commercial CPT
E/M coding system and almost 5\% over our strongest single-prompt baseline,
demonstrating its effectiveness in addressing the real-world complexities.

</details>


### [7] [Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading](https://arxiv.org/abs/2510.25014)
*Minkyung Kim,Junsik Kim,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 本文提出了Autoregressive State-Tracking Prompting (ASTP)方法，通过显式状态跟踪和占位符后处理，解决LLM在游戏交易系统中无法遵循规则流程的问题，实现了99%以上的状态合规性和99.3%的计算精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)虽然支持动态游戏交互，但在规则治理的交易系统中无法遵循必要的程序流程(浏览-报价-审核-确认)，这会削弱玩家信任。

Method: 引入ASTP方法，通过精心设计的提示迫使LLM使其状态跟踪过程显式化和可验证，结合状态特定的占位符后处理方法确保交易完整性。

Result: 在300个交易对话评估中，实现了>99%的状态合规性和99.3%的计算精度。ASTP在较小模型(Gemini-2.5-Flash)上匹配较大模型(Gemini-2.5-Pro)性能，同时将响应时间从21.2秒减少到2.4秒。

Conclusion: ASTP为商业游戏建立了实用基础，既满足实时需求又符合资源约束，在LLM的创意灵活性和游戏交易的程序要求之间取得了平衡。

Abstract: Large Language Models (LLMs) enable dynamic game interactions but fail to
follow essential procedural flows in rule-governed trading systems, eroding
player trust. This work resolves the core tension between the creative
flexibility of LLMs and the procedural demands of in-game trading
(browse-offer-review-confirm). To this end, Autoregressive State-Tracking
Prompting (ASTP) is introduced, a methodology centered on a strategically
orchestrated prompt that compels an LLM to make its state-tracking process
explicit and verifiable. Instead of relying on implicit contextual
understanding, ASTP tasks the LLM with identifying and reporting a predefined
state label from the previous turn. To ensure transactional integrity, this is
complemented by a state-specific placeholder post-processing method for
accurate price calculations. Evaluation across 300 trading dialogues
demonstrates >99% state compliance and 99.3% calculation precision. Notably,
ASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)
matches larger models' (Gemini-2.5-Pro) performance while reducing response
time from 21.2s to 2.4s, establishing a practical foundation that satisfies
both real-time requirements and resource constraints of commercial games.

</details>


### [8] [Reasoning-Aware GRPO using Process Mining](https://arxiv.org/abs/2510.25065)
*Taekhyun Park,Yongjae Lee,Hyerim Bae*

Main category: cs.AI

TL;DR: PM4GRPO是一种基于过程挖掘的推理感知组相对策略优化方法，通过在标准答案/格式奖励基础上增加推理过程信号，显著提升大型推理模型的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的后训练方法主要关注结果导向的奖励机制，缺乏对推理过程的关注，限制了大型推理模型的多步推理能力发展。

Method: 利用过程挖掘技术计算标量一致性奖励，衡量策略模型的推理过程与预训练教师模型的匹配程度，结合标准答案/格式奖励进行组相对策略优化。

Result: 在五个基准测试上的实证结果表明，PM4GRPO显著优于现有的GRPO后训练方法。

Conclusion: 利用过程挖掘实现推理感知的GRPO能够有效增强策略模型的推理能力。

Abstract: Reinforcement learning (RL)-based post-training has been crucial for enabling
multi-step reasoning in large reasoning models (LRMs), yet current reward
schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware
Group Relative Policy Optimization (GRPO) that augments standard answer/format
rewards with signals over the reasoning procedure. To this end, process mining
techniques are utilized to compute a scalar conformance reward that measures
how closely a policy model's reasoning aligns with the pretrained teacher
model. The empirical results on five benchmarks demonstrate that PM4GRPO
significantly outperforms existing methodologies for GRPO-based post-training.
These results highlight that leveraging process mining for reasoning-aware GRPO
effectively enhances the reasoning capabilities of policy models.

</details>


### [9] [Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models](https://arxiv.org/abs/2510.25179)
*Juan Ren,Mark Dras,Usman Naseem*

Main category: cs.AI

TL;DR: Agentic Moderation是一个模型无关的框架，利用专门化的智能体来保护多模态系统免受越狱攻击，通过动态协作的智能体实现上下文感知和可解释的审核。


<details>
  <summary>Details</summary>
Motivation: 传统方法作为静态层应用于输入或输出，仅提供二元分类（安全或不安全），缺乏动态性和可解释性。

Method: 引入Shield、Responder、Evaluator和Reflector四个协作智能体，实现动态、上下文感知的审核。

Result: 在五个数据集和四个大型视觉语言模型上的实验表明，攻击成功率降低7-19%，拒绝率提高4-20%，保持稳定的不跟随率。

Conclusion: Agentic Moderation通过利用智能体架构的灵活性和推理能力，提供了模块化、可扩展和细粒度的安全执行，展示了智能体系统作为自动安全治理基础的潜力。

Abstract: Agentic methods have emerged as a powerful and autonomous paradigm that
enhances reasoning, collaboration, and adaptive control, enabling systems to
coordinate and independently solve complex tasks. We extend this paradigm to
safety alignment by introducing Agentic Moderation, a model-agnostic framework
that leverages specialised agents to defend multimodal systems against
jailbreak attacks. Unlike prior approaches that apply as a static layer over
inputs or outputs and provide only binary classifications (safe or unsafe), our
method integrates dynamic, cooperative agents, including Shield, Responder,
Evaluator, and Reflector, to achieve context-aware and interpretable
moderation. Extensive experiments across five datasets and four representative
Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the
Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),
and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,
and well-balanced safety performance. By harnessing the flexibility and
reasoning capacity of agentic architectures, Agentic Moderation provides
modular, scalable, and fine-grained safety enforcement, highlighting the
broader potential of agentic systems as a foundation for automated safety
governance.

</details>


### [10] [Counterfactual-based Agent Influence Ranker for Agentic AI Workflows](https://arxiv.org/abs/2510.25612)
*Amit Giloni,Chiara Picardi,Roy Betser,Shamik Bose,Aishvariya Priya Rathina Sabapathy,Roman Vainshtein*

Main category: cs.AI

TL;DR: CAIR是首个评估AAW中各个智能体对最终输出影响程度的方法，通过反事实分析提供任务无关的分析，可在离线和推理时使用。


<details>
  <summary>Details</summary>
Motivation: AAW系统的高自主性和广泛应用需要从质量和安全角度深入理解其运作，但目前缺乏评估各智能体对最终输出影响的方法。

Method: 提出基于反事实分析的智能体影响排序方法(CAIR)，通过反事实分析评估每个智能体对AAW输出的影响程度。

Result: 在包含30个不同用例和230个功能的AAW数据集上评估，CAIR产生一致的排序结果，优于基线方法，并能有效提升下游任务的效果和相关性。

Conclusion: CAIR是首个能够有效评估AAW中智能体影响的方法，为理解和优化AAW系统提供了重要工具。

Abstract: An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,
is an autonomous system that assembles several LLM-based agents to work
collaboratively towards a shared goal. The high autonomy, widespread adoption,
and growing interest in such AAWs highlight the need for a deeper understanding
of their operations, from both quality and security aspects. To this day, there
are no existing methods to assess the influence of each agent on the AAW's
final output. Adopting techniques from related fields is not feasible since
existing methods perform only static structural analysis, which is unsuitable
for inference time execution. We present Counterfactual-based Agent Influence
Ranker (CAIR) - the first method for assessing the influence level of each
agent on the AAW's output and determining which agents are the most
influential. By performing counterfactual analysis, CAIR provides a
task-agnostic analysis that can be used both offline and at inference time. We
evaluate CAIR using an AAWs dataset of our creation, containing 30 different
use cases with 230 different functionalities. Our evaluation showed that CAIR
produces consistent rankings, outperforms baseline methods, and can easily
enhance the effectiveness and relevancy of downstream tasks.

</details>


### [11] [Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision](https://arxiv.org/abs/2510.25205)
*Yuyang Xia,Zibo Liang,Liwei Deng,Yan Zhao,Han Su,Kai Zheng*

Main category: cs.AI

TL;DR: EneAD是一个节能的自动驾驶框架，通过自适应感知模块和鲁棒决策模块，在保持感知精度的同时显著降低计算能耗，提高电动汽车续航里程。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术虽然带来诸多好处，但其计算引擎的高能耗限制了电动汽车的续航里程，特别是感知计算作为最耗电的组件需要优化。

Method: 提出自适应感知模块，通过管理多个不同计算消耗的感知模型并动态调整执行帧率，使用贝叶斯优化进行可迁移调优；设计轻量级分类模型区分不同场景的感知难度；在鲁棒决策模块中使用强化学习决策模型并添加正则化项增强稳定性。

Result: EneAD能够将感知消耗降低1.9倍到3.5倍，从而将驾驶里程提高3.9%到8.5%。

Conclusion: 该框架在能耗和驾驶性能方面均表现出优越性，为节能自动驾驶提供了有效解决方案。

Abstract: Autonomous driving is an emerging technology that is expected to bring
significant social, economic, and environmental benefits. However, these
benefits come with rising energy consumption by computation engines, limiting
the driving range of vehicles, especially electric ones. Perception computing
is typically the most power-intensive component, as it relies on largescale
deep learning models to extract environmental features. Recently, numerous
studies have employed model compression techniques, such as sparsification,
quantization, and distillation, to reduce computational consumption. However,
these methods often result in either a substantial model size or a significant
drop in perception accuracy compared to high-computation models. To address
these challenges, we propose an energy-efficient autonomous driving framework,
called EneAD. In the adaptive perception module, a perception optimization
strategy is designed from the perspective of data management and tuning.
Firstly, we manage multiple perception models with different computational
consumption and adjust the execution framerate dynamically. Then, we define
them as knobs and design a transferable tuning method based on Bayesian
optimization to identify promising knob values that achieve low computation
while maintaining desired accuracy. To adaptively switch the knob values in
various traffic scenarios, a lightweight classification model is proposed to
distinguish the perception difficulty in different scenarios. In the robust
decision module, we propose a decision model based on reinforcement learning
and design a regularization term to enhance driving stability in the face of
perturbed perception results. Extensive experiments evidence the superiority of
our framework in both energy consumption and driving performance. EneAD can
reduce perception consumption by 1.9x to 3.5x and thus improve driving range by
3.9% to 8.5%

</details>


### [12] [RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models](https://arxiv.org/abs/2510.25206)
*Tianqianjin Lin,Xi Zhao,Xingyao Zhang,Rujiao Long,Yi Xu,Zhuoren Jiang,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: 本文提出RAVR框架，利用答案引导的变分推理来改进LLMs的推理能力，通过答案条件化推理作为问题推理的变分替代，在数学和通用领域均取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖LLMs能够以非零概率生成高质量推理路径，但在超出模型当前能力的任务中，这种路径难以采样。受认知科学启发，作者发现解释答案的推理过程比直接寻找答案更容易，因此利用答案来推导高质量推理路径。

Method: 提出RAVR（Reference-Answer-guided Variational Reasoning）框架，将答案条件化推理作为问题推理的变分替代，通过答案引导来提升推理路径的质量和可学习性。

Result: 在通用和数学领域的实验中，RAVR相比强基线方法取得了一致的改进。分析显示RAVR减少了犹豫，加强了结论整合，并促进了问题特定的推理策略。

Conclusion: 答案引导的推理能够显著提升LLMs的推理能力，将原本难以学习的问题转化为可学习的问题，为超越模型当前能力的任务提供了有效的解决方案。

Abstract: Reinforcement learning (RL) can refine the reasoning abilities of large
language models (LLMs), but critically depends on a key prerequisite: the LLM
can already generate high-utility reasoning paths with non-negligible
probability. For tasks beyond the LLM's current competence, such reasoning path
can be hard to sample, and learning risks reinforcing familiar but suboptimal
reasoning. We are motivated by the insight from cognitive science that Why is
this the answer is often an easier question than What is the answer, as it
avoids the heavy cognitive load of open-ended exploration, opting instead for
explanatory reconstruction-systematically retracing the reasoning that links a
question to its answer. We show that LLMs can similarly leverage answers to
derive high-quality reasoning paths. We formalize this phenomenon and prove
that conditioning on answer provably increases the expected utility of sampled
reasoning paths, thereby transforming intractable problems into learnable ones.
Building on this insight, we introduce RAVR (Reference-Answer-guided
Variational Reasoning), an end-to-end framework that uses answer-conditioned
reasoning as a variational surrogate for question-only reasoning. Experiments
in both general and math domains demonstrate consistent improvements over
strong baselines. We further analyze the reasoning behavior and find that RAVR
reduces hesitation, strengthens conclusion consolidation, and promotes
problem-specific strategies in reasoning.

</details>


### [13] [Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm](https://arxiv.org/abs/2510.25388)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 本文提出了KVDA-UCT算法，通过放宽状态-动作对必须具有相同值的严格条件，允许对具有已知价值差异的状态进行分组，从而显著提高了MCTS的样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的OGA-UCT算法要求状态-动作对具有相同的即时奖励，这一刚性条件限制了可发现的抽象数量，从而影响了MCTS的样本效率。

Method: 提出了已知价值差异抽象框架(KVDA)，通过分析即时奖励来推断价值差异，并修改OGA-UCT使用该框架，形成KVDA-UCT算法。

Result: KVDA-UCT在多种确定性环境和参数设置下检测到的抽象数量显著多于OGA-UCT，且性能优于OGA-UCT。

Conclusion: KVDA框架通过允许对具有已知价值差异的状态进行分组，有效提高了MCTS的抽象能力和样本效率，无需额外参数。

Abstract: A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,
which can be improved by grouping state-action pairs and using their aggregate
statistics instead of single-node statistics. On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS
abstraction algorithm for deterministic environments that builds its
abstraction using the Abstractions of State-Action Pairs (ASAP) framework,
which aims to detect states and state-action pairs with the same value under
optimal play by analysing the search graph. ASAP, however, requires two
state-action pairs to have the same immediate reward, which is a rigid
condition that limits the number of abstractions that can be found and thereby
the sample efficiency. In this paper, we break with the paradigm of grouping
value-equivalent states or state-action pairs and instead group states and
state-action pairs with possibly different values as long as the difference
between their values can be inferred. We call this abstraction framework Known
Value Difference Abstractions (KVDA), which infers the value differences by
analysis of the immediate rewards and modifies OGA-UCT to use this framework
instead. The modification is called KVDA-UCT, which detects significantly more
abstractions than OGA-UCT, introduces no additional parameter, and outperforms
OGA-UCT on a variety of deterministic environments and parameter settings.

</details>


### [14] [Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?](https://arxiv.org/abs/2510.25471)
*Willem Fourie*

Main category: cs.AI

TL;DR: 本文提出了一种新的AI对齐研究框架，认为工具性目标（如权力寻求、自我保存）应被视为需要接受和管理的特征，而非需要限制的故障。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐理论将工具性目标视为风险来源，试图限制其症状。本文旨在提供替代视角，认为这些目标源于AI系统的构成特性。

Method: 借鉴亚里士多德本体论及其现代解释，构建了一个关于具体、目标导向实体的本体论，将高级AI系统视为其形式和物质构成会产生不同于设计者意图效果的人工制品。

Result: 论证了AI系统的工具性倾向是其构成的内在结果，而非偶然故障。这为理解和管理这些倾向提供了理论基础。

Conclusion: AI对齐工作应更侧重于理解、管理和引导工具性目标，而非试图消除它们，从而更好地实现与人类目标的对齐。

Abstract: In artificial intelligence (AI) alignment research, instrumental goals, also
called instrumental subgoals or instrumental convergent goals, are widely
associated with advanced AI systems. These goals, which include tendencies such
as power-seeking and self-preservation, become problematic when they conflict
with human aims. Conventional alignment theory treats instrumental goals as
sources of risk that become problematic through failure modes such as reward
hacking or goal misgeneralization, and attempts to limit the symptoms of
instrumental goals, notably resource acquisition and self-preservation. This
article proposes an alternative framing: that a philosophical argument can be
constructed according to which instrumental goals may be understood as features
to be accepted and managed rather than failures to be limited. Drawing on
Aristotle's ontology and its modern interpretations, an ontology of concrete,
goal-directed entities, it argues that advanced AI systems can be seen as
artifacts whose formal and material constitution gives rise to effects distinct
from their designers' intentions. In this view, the instrumental tendencies of
such systems correspond to per se outcomes of their constitution rather than
accidental malfunctions. The implication is that efforts should focus less on
eliminating instrumental goals and more on understanding, managing, and
directing them toward human-aligned ends.

</details>


### [15] [Multi-Objective Search: Algorithms, Applications, and Emerging Directions](https://arxiv.org/abs/2510.25504)
*Oren Salzman,Carlos Hernández Ulloa,Ariel Felner,Sven Koenig*

Main category: cs.AI

TL;DR: 多目标搜索（MOS）作为规划与决策问题的统一框架，近年来在机器人、交通和运筹学等AI应用中重新受到关注，本文综述了MOS的发展并指出了跨学科机遇和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统很少只优化单一指标，多目标搜索能够平衡多个往往冲突的标准，这反映了实际应用的需求。

Method: 本文采用综述方法，回顾了多目标搜索领域的发展历程，并分析了跨学科的机会。

Result: 识别了多目标搜索在AI各应用领域中的重要性，并强调了该领域的新兴前沿。

Conclusion: 多目标搜索作为一个重要的研究框架，在解决现实世界复杂决策问题中具有广阔前景，但仍面临开放挑战需要进一步探索。

Abstract: Multi-objective search (MOS) has emerged as a unifying framework for planning
and decision-making problems where multiple, often conflicting, criteria must
be balanced. While the problem has been studied for decades, recent years have
seen renewed interest in the topic across AI applications such as robotics,
transportation, and operations research, reflecting the reality that real-world
systems rarely optimize a single measure. This paper surveys developments in
MOS while highlighting cross-disciplinary opportunities, and outlines open
challenges that define the emerging frontier of MOS

</details>


### [16] [MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL](https://arxiv.org/abs/2510.25510)
*Zekun Xu,Siyu Xia,Chuhuai Yue,Jiajun Chai,Mingxue Tian,Xiaohan Wang,Wei Lin,Haoxuan Li,Guojun Yin*

Main category: cs.AI

TL;DR: MTIR-SQL是一个创新的多轮工具集成推理强化学习框架，通过在执行感知的多轮推理范式中集成数据库执行反馈，实现上下文敏感的查询生成和渐进式优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖静态执行反馈，限制了实时错误纠正能力。集成多轮工具调用和动态反馈可以显著提高适应性和鲁棒性，从而提升模型性能。

Method: 提出执行感知的多轮推理范式，在每个推理步骤无缝集成数据库执行反馈；扩展GRPO算法以适应复杂的多轮交互场景；通过添加轨迹过滤机制和移除KL损失约束来增强GRPO算法。

Result: MTIR-SQL（4B参数）在BIRD Dev上达到64.4%的准确率，在SPIDER Dev上达到84.6%的执行准确率，显著优于现有方法。

Conclusion: 该框架通过动态执行反馈和多轮推理机制，有效提升了Text-to-SQL任务的性能，证明了集成工具调用和强化学习的有效性。

Abstract: As large language models (LLMs) are increasingly used in Text-to-SQL tasks,
Reinforcement Learning (RL) has become a common method for improving
performance. Existing methods primarily rely on static execution feedback,
which restricts real-time error correction. However, integrating multi-turn
tool invocation along with dynamic feedback could significantly improve
adaptability and robustness, ultimately enhancing model performance. To address
these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated
Reasoning reinforcement learning framework for Text-to-SQL. Our approach
introduces an execution-aware multi-turn reasoning paradigm that seamlessly
incorporates database execution feedback at each reasoning step, enabling
context-sensitive query generation and progressive refinement throughout the
reasoning process. The framework extends the GRPO algorithm to accommodate
complex multi-turn interaction scenarios. Considering the training instability
characteristics of MTIR and the potential for significant Deviation of model
distribution from the initial model, we enhance the GRPO algorithm by adding a
trajectory filtering mechanism and removing KL loss constraints. Experimental
results demonstrate that MTIR-SQL, with 4B parameters, achieves \textbf{64.4}\%
accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,
significantly outperforming existing approaches.

</details>


### [17] [Predicate Renaming via Large Language Models](https://arxiv.org/abs/2510.25517)
*Elisabetta Gentili,Tony Ribeiro,Fabrizio Riguzzi,Katsumi Inoue*

Main category: cs.AI

TL;DR: 使用大型语言模型为逻辑规则中的未命名谓词生成语义上有意义的名称，以提高逻辑理论的可读性、可解释性和可重用性。


<details>
  <summary>Details</summary>
Motivation: 在归纳逻辑编程中，各种规则生成方法会产生包含未命名谓词的规则，这阻碍了逻辑理论的可读性、可解释性和可重用性。谓词发明是其中的关键例子。

Method: 利用大型语言模型处理自然语言和代码的能力，为未命名谓词提供语义上有意义的命名建议。

Result: 在手工制作的逻辑规则上评估表明，大型语言模型在此任务上具有潜力。

Conclusion: 大型语言模型在解决逻辑规则中谓词命名问题上显示出潜力，能够提供语义上有意义的名称建议。

Abstract: In this paper, we address the problem of giving names to predicates in logic
rules using Large Language Models (LLMs). In the context of Inductive Logic
Programming, various rule generation methods produce rules containing unnamed
predicates, with Predicate Invention being a key example. This hinders the
readability, interpretability, and reusability of the logic theory. Leveraging
recent advancements in LLMs development, we explore their ability to process
natural language and code to provide semantically meaningful suggestions for
giving a name to unnamed predicates. The evaluation of our approach on some
hand-crafted logic rules indicates that LLMs hold potential for this task.

</details>


### [18] [Zero Reinforcement Learning Towards General Domains](https://arxiv.org/abs/2510.25528)
*Yuyuan Zeng,Yufei Huang,Can Xu,Qingfeng Sun,Jianfeng Yan,Guanghui Xu,Tao Yang,Fengzong Lian*

Main category: cs.AI

TL;DR: 提出一种新的零强化学习范式，通过结合可验证奖励和生成奖励模型，在可验证和不可验证领域进行多任务训练，提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前零强化学习研究主要关注具有易验证奖励信号的领域，但在验证不直接的情况下激发推理能力的研究不足。

Method: 结合可验证奖励与生成奖励模型进行多任务零强化学习训练，并设计平滑长度惩罚机制来防止奖励黑客攻击。

Result: 在Qwen3-8B-Base和Qwen3-14B-Base上的实验表明，该方法在需要广泛推理的任务和更一般任务上都取得了优越的推理性能。

Conclusion: 该方法能够有效提升模型在可验证和不可验证领域的推理能力，并促进推理能力在不同领域间的迁移。

Abstract: Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach
for enhancing the reasoning capabilities of large language models (LLMs) by
directly applying reinforcement learning with verifiable rewards on pretrained
models, without the need for a supervised fine-tuning phase. However, current
research on zero-RL primarily focuses on domains with easily verifiable reward
signals, such as mathematics, programming, and other reasoning tasks. The
challenge of eliciting reasoning abilities in more diverse scenarios, where
verification is not straightforward, remains underexplored. To address this
gap, we propose a novel zero-RL paradigm designed to improve a model's
reasoning ability across both verifiable and non-verifiable domains. By
combining verifiable rewards with a generative reward model, we conduct
multi-task zero-RL training across both domains, facilitating the transfer of
reasoning capabilities between them. Furthermore, to mitigate reward hacking in
the generative reward model, we design a smooth length penalty that encourages
the generation of more comprehensive thinking tokens in general domains.
Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our
approach achieves superior reasoning performance, not only on tasks requiring
extensive reasoning but also on more general tasks.

</details>


### [19] [Off-policy Reinforcement Learning with Model-based Exploration Augmentation](https://arxiv.org/abs/2510.25529)
*Likun Wang,Xiangteng Zhang,Yinuo Wang,Guojian Zhan,Wenxuan Wang,Haoyu Gao,Jingliang Duan,Shengbo Eben Li*

Main category: cs.AI

TL;DR: 提出了Modelic Generative Exploration (MoGE)方法，通过生成未充分探索的关键状态和动态一致的转换来增强强化学习中的探索能力。该方法包含扩散生成器和一步想象世界模型两个组件，可与现有算法无缝集成。


<details>
  <summary>Details</summary>
Motivation: 现有探索方法存在局限性：主动探索在复杂环境中效果不佳，被动探索受限于样本多样性。需要解决被动探索的局限性，提高探索效率。

Method: MoGE包含两个组件：1) 基于扩散的生成器，在效用函数指导下合成关键状态；2) 一步想象世界模型，基于关键状态构建关键转换用于智能体学习。采用模块化设计，可与现成算法集成。

Result: 在OpenAI Gym和DeepMind Control Suite上的实验结果表明，MoGE有效连接了探索与策略学习，在复杂控制任务中显著提高了样本效率和性能。

Conclusion: MoGE通过生成关键状态和动态一致的转换，成功解决了被动探索的局限性，为强化学习探索提供了有效的解决方案。

Abstract: Exploration is fundamental to reinforcement learning (RL), as it determines
how effectively an agent discovers and exploits the underlying structure of its
environment to achieve optimal performance. Existing exploration methods
generally fall into two categories: active exploration and passive exploration.
The former introduces stochasticity into the policy but struggles in
high-dimensional environments, while the latter adaptively prioritizes
transitions in the replay buffer to enhance exploration, yet remains
constrained by limited sample diversity. To address the limitation in passive
exploration, we propose Modelic Generative Exploration (MoGE), which augments
exploration through the generation of under-explored critical states and
synthesis of dynamics-consistent experiences through transition models. MoGE is
composed of two components: (1) a diffusion-based generator that synthesizes
critical states under the guidance of a utility function evaluating each
state's potential influence on policy exploration, and (2) a one-step
imagination world model for constructing critical transitions based on the
critical states for agent learning. Our method adopts a modular formulation
that aligns with the principles of off-policy learning, allowing seamless
integration with existing algorithms to improve exploration without altering
their core structures. Empirical results on OpenAI Gym and DeepMind Control
Suite reveal that MoGE effectively bridges exploration and policy learning,
leading to remarkable gains in both sample efficiency and performance across
complex control tasks.

</details>


### [20] [Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning](https://arxiv.org/abs/2510.25679)
*Federica Tonti,Ricardo Vinuesa*

Main category: cs.AI

TL;DR: 本文开发了一种基于深度强化学习的最优导航策略，用于城市环境中的无人机导航。该方法结合了PPO算法和GTrXL架构，能够感知湍流场信息，相比传统方法显著提高了成功率和降低了碰撞率。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在城市区域中用于配送和监控的日益普及，需要开发能够在复杂城市气流环境中有效导航的策略。城市环境中的湍流和回流区域给无人机导航带来了挑战。

Method: 提出了一种基于深度强化学习的导航策略，使用PPO算法结合GTrXL架构，使智能体能够感知湍流场信息。环境采用三维高保真城市流场模拟，包含湍流和回流区域。

Result: 与没有次级预测任务的PPO+GTrXL、PPO+LSTM以及传统的Zermelo导航算法相比，该方法显著提高了成功率(SR)并降低了碰撞率(CR)。

Conclusion: 该方法为复杂城市环境中无人机导航开辟了新途径，有望重新定义无人机在城市环境中的应用前景。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for
delivery and surveillance purposes. In this work, we develop an optimal
navigation strategy based on Deep Reinforcement Learning. The environment is
represented by a three-dimensional high-fidelity simulation of an urban flow,
characterized by turbulence and recirculation zones. The algorithm presented
here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated
Transformer eXtra Large (GTrXL) architecture, giving the agent richer
information about the turbulent flow field in which it navigates. The results
are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO
combined with Long Short Term Memory (LSTM) cells and a traditional navigation
algorithm. The obtained results show a significant increase in the success rate
(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the
classical Zermelo's navigation algorithm, paving the way to a completely
reimagined UAV landscape in complex urban environments.

</details>


### [21] [BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph](https://arxiv.org/abs/2510.25724)
*Vanya Arikutharam,Arkadiy Ukolov*

Main category: cs.AI

TL;DR: BambooKG是一种基于频率加权的知识图谱，通过在非三元组边上应用权重来减少信息损失，提升单跳和多跳推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成方法在处理多跳或关系推理时存在困难，特别是跨文档的情况。知识图谱虽然能捕捉实体间关系，但会遗漏不符合三元组结构的信息。

Method: 引入BambooKG知识图谱，在非三元组边上应用基于频率的权重，反映链接强度，借鉴赫布原理的"同时激活，同时连接"思想。

Result: 减少了信息损失，在单跳和多跳推理任务上表现优于现有解决方案。

Conclusion: BambooKG通过频率加权机制有效解决了传统知识图谱的信息损失问题，显著提升了推理性能。

Abstract: Retrieval-Augmented Generation allows LLMs to access external knowledge,
reducing hallucinations and ageing-data issues. However, it treats retrieved
chunks independently and struggles with multi-hop or relational reasoning,
especially across documents. Knowledge graphs enhance this by capturing the
relationships between entities using triplets, enabling structured, multi-chunk
reasoning. However, these tend to miss information that fails to conform to the
triplet structure. We introduce BambooKG, a knowledge graph with
frequency-based weights on non-triplet edges which reflect link strength,
drawing on the Hebbian principle of "fire together, wire together". This
decreases information loss and results in improved performance on single- and
multi-hop reasoning, outperforming the existing solutions.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [22] [Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives](https://arxiv.org/abs/2510.24943)
*Alfonso Ladino-Rincon,Stephen W. Nesbitt*

Main category: cs.DC

TL;DR: Radar DataTree是首个数据集级框架，将WMO FM-301标准从单次雷达体扫描扩展到时间分辨、分析就绪的存档，解决了天气雷达数据FAIR原则遵从性差的问题。


<details>
  <summary>Details</summary>
Motivation: 天气雷达数据是科学价值最高但结构利用最不足的地球观测数据集之一。尽管广泛公开可用，但雷达存档仍然分散、供应商特定，且与FAIR原则对齐不佳，阻碍了大规模研究、可重复性和云原生计算。

Method: 基于FM-301/CfRadial 2.1标准，使用xarray DataTree实现，将雷达体扫描组织为分层、元数据丰富的结构，并序列化为Zarr格式进行可扩展分析。结合Icechunk实现ACID兼容存储和版本控制。

Result: 在准垂直剖面(QVP)和降水累积工作流等案例研究中展示了显著的性能提升，所有工具和数据集通过Raw2Zarr存储库公开发布。

Conclusion: 这项工作为雷达数据管理、高性能地球科学和AI就绪的天气基础设施提供了可重复和可扩展的基础。

Abstract: We introduce Radar DataTree, the first dataset-level framework that extends
the WMO FM-301 standard from individual radar volume scans to time-resolved,
analysis-ready archives. Weather radar data are among the most scientifically
valuable yet structurally underutilized Earth observation datasets. Despite
widespread public availability, radar archives remain fragmented,
vendor-specific, and poorly aligned with FAIR (Findable, Accessible,
Interoperable, Reusable) principles, hindering large-scale research,
reproducibility, and cloud-native computation. Radar DataTree addresses these
limitations with a scalable, open-source architecture that transforms
operational radar archives into FAIR-compliant, cloud-optimized datasets. Built
on the FM-301/CfRadial 2.1 standard and implemented using xarray DataTree,
Radar DataTree organizes radar volume scans as hierarchical, metadata-rich
structures and serializes them to Zarr for scalable analysis. Coupled with
Icechunk for ACID-compliant storage and versioning, this architecture enables
efficient, parallel computation across thousands of radar scans with minimal
preprocessing. We demonstrate significant performance gains in case studies
including Quasi-Vertical Profile (QVP) and precipitation accumulation
workflows, and release all tools and datasets openly via the Raw2Zarr
repository. This work contributes a reproducible and extensible foundation for
radar data stewardship, high-performance geoscience, and AI-ready weather
infrastructure.

</details>


### [23] [A Privacy-Preserving Ecosystem for Developing Machine Learning Algorithms Using Patient Data: Insights from the TUM.ai Makeathon](https://arxiv.org/abs/2510.25277)
*Simon Süwer,Mai Khanh Mai,Christoph Klein,Nicola Götzenberger,Denis Dalić,Andreas Maier,Jan Baumbach*

Main category: cs.DC

TL;DR: 提出一种多阶段安全AI训练方法，通过模拟临床知识图谱设计模型，在联邦学习框架中训练，确保患者数据隐私的同时实现个性化医疗AI开发。


<details>
  <summary>Details</summary>
Motivation: 临床数据整合对个性化医疗发展至关重要，但受GDPR严格限制，特别是罕见病小队列研究。需要在不泄露敏感信息的前提下开发高质量医疗AI。

Method: 四阶段方法：1) 在模拟临床知识图谱上设计模型；2) 在FeatureCloud联邦学习框架中准备模型；3) 在医院环境中训练真实数据；4) 执行验证评估脚本返回聚合性能指标。

Result: 在TUM.ai Makeathon 2024挑战中成功验证，50名学生无需访问真实数据即可开发患者分类和诊断模型。

Conclusion: 通过联邦学习框架部署安全算法是实现医疗保健中隐私保护AI的实用方法。

Abstract: The integration of clinical data offers significant potential for the
development of personalized medicine. However, its use is severely restricted
by the General Data Protection Regulation (GDPR), especially for small cohorts
with rare diseases. High-quality, structured data is essential for the
development of predictive medical AI. In this case study, we propose a novel,
multi-stage approach to secure AI training: (1) The model is designed on a
simulated clinical knowledge graph (cKG). This graph is used exclusively to
represent the structural characteristics of the real cKG without revealing any
sensitive content. (2) The model is then integrated into the FeatureCloud (FC)
federated learning framework, where it is prepared in a single-client
configuration within a protected execution environment. (3) Training then takes
place within the hospital environment on the real cKG, either under the direct
supervision of hospital staff or via a fully automated pipeline controlled by
the hospital. (4) Finally, verified evaluation scripts are executed, which only
return aggregated performance metrics. This enables immediate performance
feedback without sensitive patient data or individual predictions, leaving the
clinic. A fundamental element of this approach involves the incorporation of a
cKG, which serves to organize multi-omics and patient data within the context
of real-world hospital environments. This approach was successfully validated
during the TUM.ai Makeathon 2024 (TUMaiM24) challenge set by the Dr. von Hauner
Children's Hospital (HCH-LMU): 50 students developed models for patient
classification and diagnosis without access to real data. Deploying secure
algorithms via federated frameworks, such as the FC framework, could be a
practical way of achieving privacy-preserving AI in healthcare.

</details>


### [24] [Scheduling Data-Intensive Workloads in Large-Scale Distributed Systems: Trends and Challenges](https://arxiv.org/abs/2510.25362)
*Georgios L. Stavrinides,Helen D. Karatza*

Main category: cs.DC

TL;DR: 本章提出数据密集型工作负载的分类，并概述在大规模分布式系统中调度这些工作负载的常用方法，介绍了文献中的新策略，并指出开放挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大数据爆炸式增长，工作负载变得更加复杂和计算密集，需要在规模更大、计算能力更强的分布式互连资源上处理。数据密集型应用具有不同的并行度，需要有效利用数据局部性，并满足服务质量要求。

Method: 提出数据密集型工作负载的分类，并概述在大规模分布式系统中调度这些工作负载的常用方法，介绍文献中提出的新策略。

Result: 提供了数据密集型工作负载的全面分类框架，总结了现有调度方法，并识别了该领域的关键挑战。

Conclusion: 数据密集型工作负载的调度面临重大挑战，需要有效的调度技术。本章为理解当前方法和未来研究方向提供了基础。

Abstract: With the explosive growth of big data, workloads tend to get more complex and
computationally demanding. Such applications are processed on distributed
interconnected resources that are becoming larger in scale and computational
capacity. Data-intensive applications may have different degrees of parallelism
and must effectively exploit data locality. Furthermore, they may impose
several Quality of Service requirements, such as time constraints and
resilience against failures, as well as other objectives, like energy
efficiency. These features of the workloads, as well as the inherent
characteristics of the computing resources required to process them, present
major challenges that require the employment of effective scheduling
techniques. In this chapter, a classification of data-intensive workloads is
proposed and an overview of the most commonly used approaches for their
scheduling in large-scale distributed systems is given. We present novel
strategies that have been proposed in the literature and shed light on open
challenges and future directions.

</details>


### [25] [Holon Streaming: Global Aggregations with Windowed CRDTs](https://arxiv.org/abs/2510.25757)
*Jonas Spenger,Kolya Krafeld,Ruben van Gemeren,Philipp Haller,Paris Carbone*

Main category: cs.DC

TL;DR: Holon Streaming是一个支持精确一次语义的流处理系统，通过窗口化无冲突复制数据类型（Windowed CRDTs）实现可扩展的全局聚合计算，采用去中心化协调机制，相比现有系统具有更低的延迟和更高的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有流处理系统在全局聚合计算方面存在可扩展性限制和性能瓶颈，单任务实例或静态聚合树架构导致延迟高、容错恢复时延大，需要更高效的解决方案。

Method: 提出确定性编程模型，使用窗口化无冲突复制数据类型（Windowed CRDTs）作为共享复制状态的抽象，支持去中心化协调和高效故障恢复算法。

Result: 相比现有流处理系统，在全局聚合工作负载上实现5倍延迟降低和2倍吞吐量提升，在故障场景下延迟减少11倍。

Conclusion: 去中心化协调与确定性保证相结合的设计方法有效，窗口化CRDTs在全局聚合计算中具有实用价值。

Abstract: Scaling global aggregations is a challenge for exactly-once stream processing
systems. Current systems implement these either by computing the aggregation in
a single task instance, or by static aggregation trees, which limits
scalability and may become a bottleneck. Moreover, the end-to-end latency is
determined by the slowest path in the tree, and failures and reconfiguration
cause large latency spikes due to the centralized coordination. Towards these
issues, we present Holon Streaming, an exactly-once stream processing system
for global aggregations. Its deterministic programming model uses windowed
conflict-free replicated data types (Windowed CRDTs), a novel abstraction for
shared replicated state. Windowed CRDTs make computing global aggregations
scalable. Furthermore, their guarantees such as determinism and convergence
enable the design of efficient failure recovery algorithms by decentralized
coordination. Our evaluation shows a 5x lower latency and 2x higher throughput
than an existing stream processing system on global aggregation workloads, with
an 11x latency reduction under failure scenarios. The paper demonstrates the
effectiveness of decentralized coordination with determinism, and the utility
of Windowed CRDTs for global aggregations.

</details>
