{"id": "2511.19577", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.19577", "abs": "https://arxiv.org/abs/2511.19577", "authors": ["Abhay Goyal", "Navin Kumar", "Kimberly DiMeola", "Rafael Trujillo", "Soorya Ram Shimgekar", "Christian Poellabauer", "Pi Zonooz", "Ermonda Gjoni-Markaj", "Declan Barry", "Lynn Madden"], "title": "Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder", "comment": null, "summary": "Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u53ef\u7a7f\u6234\u8bbe\u5907\u548cAI\u65b9\u6cd5\u76d1\u6d4b\u6162\u6027\u75bc\u75db\u548c\u963f\u7247\u7c7b\u836f\u7269\u4f7f\u7528\u969c\u788d\u60a3\u8005\u7684\u75bc\u75db\u5cf0\u503c\uff0c\u53d1\u73b0\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u7387\u8f83\u9ad8\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u8868\u73b0\u6709\u9650\u3002", "motivation": "\u6162\u6027\u75bc\u75db\u548c\u963f\u7247\u7c7b\u836f\u7269\u4f7f\u7528\u969c\u788d\u662f\u5e38\u89c1\u4e14\u76f8\u4e92\u5173\u8054\u7684\u6162\u6027\u75be\u75c5\uff0c\u76ee\u524d\u7f3a\u4e4f\u57fa\u4e8e\u8bc1\u636e\u7684\u7efc\u5408\u6cbb\u7597\u65b9\u6cd5\u3002\u53ef\u7a7f\u6234\u8bbe\u5907\u6709\u6f5c\u529b\u76d1\u6d4b\u590d\u6742\u60a3\u8005\u4fe1\u606f\uff0c\u4e3aOUD\u548cCP\u60a3\u8005\u5f00\u53d1\u6cbb\u7597\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u53ef\u7a7f\u6234\u8bbe\u5907\u76d1\u6d4b\u60a3\u8005\u6570\u636e\uff0c\u5e94\u7528\u591a\u79cdAI\u65b9\u6cd5\uff08\u5305\u62ec\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5206\u6790\u75bc\u75db\u5cf0\u503c\u7684\u4e34\u5e8a\u76f8\u5173\u6027\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u75bc\u75db\u5cf0\u503c\u65b9\u9762\u8fbe\u5230\u76f8\u5bf9\u8f83\u9ad8\u7684\u51c6\u786e\u7387\uff08>0.7\uff09\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u4f9b\u75bc\u75db\u5cf0\u503c\u6d1e\u5bdf\u65b9\u9762\u8868\u73b0\u6709\u9650\u3002", "conclusion": "\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u5b9e\u65f6\u76d1\u6d4b\u7ed3\u5408\u5148\u8fdbAI\u6a21\u578b\u53ef\u4ee5\u4fc3\u8fdb\u75bc\u75db\u5cf0\u503c\u7684\u65e9\u671f\u68c0\u6d4b\uff0c\u652f\u6301\u4e2a\u6027\u5316\u5e72\u9884\uff0c\u4f46\u9700\u8981\u5f00\u53d1\u80fd\u591f\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6d1e\u5bdf\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2511.19669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19669", "abs": "https://arxiv.org/abs/2511.19669", "authors": ["Souradip Poddar", "Chia-Tung Ho", "Ziming Wei", "Weidong Cao", "Haoxing Ren", "David Z. Pan"], "title": "HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization", "comment": null, "summary": "Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHeaRT\u63a8\u7406\u5f15\u64ce\uff0c\u7528\u4e8eAMS\u8bbe\u8ba1\u81ea\u52a8\u5316\uff0c\u5b9e\u73b0\u667a\u80fd\u3001\u81ea\u9002\u5e94\u3001\u7c7b\u4eba\u8bbe\u8ba1\u4f18\u5316\uff0c\u572840\u7535\u8def\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387>97%\uff0c\u6027\u80fd>98%\uff0c\u4e14\u8fd0\u884c\u6210\u672c\u4ec5\u4e3aSOTA\u57fa\u7ebf\u76840.5\u500d\u3002", "motivation": "\u4f20\u7edfAI\u9a71\u52a8\u7684AMS\u8bbe\u8ba1\u81ea\u52a8\u5316\u7b97\u6cd5\u53d7\u9650\u4e8e\u5bf9\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u4f9d\u8d56\u3001\u8de8\u67b6\u6784\u53ef\u79fb\u690d\u6027\u5dee\u4ee5\u53ca\u7f3a\u4e4f\u81ea\u9002\u5e94\u673a\u5236\u3002", "method": "\u63d0\u51faHeaRT\u57fa\u7840\u63a8\u7406\u5f15\u64ce\uff0c\u4f5c\u4e3a\u81ea\u52a8\u5316\u5faa\u73af\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u667a\u80fd\u81ea\u9002\u5e94\u8bbe\u8ba1\u4f18\u5316\u3002", "result": "HeaRT\u572840\u7535\u8def\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63a8\u7406\u51c6\u786e\u7387>97%\uff0cPass@1\u6027\u80fd>98%\uff0c\u8fd0\u884c\u6210\u672c\u4ec5\u4e3aSOTA\u57fa\u7ebf\u76840.5\u500d\uff0c\u5728\u5c3a\u5bf8\u548c\u62d3\u6251\u8bbe\u8ba1\u9002\u5e94\u4efb\u52a1\u4e2d\u5b9e\u73b0>3\u500d\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "conclusion": "HeaRT\u662f\u8fc8\u5411\u667a\u80fd\u81ea\u9002\u5e94\u8bbe\u8ba1\u4f18\u5316\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u80fd\u591f\u4fdd\u6301\u5148\u524d\u7684\u8bbe\u8ba1\u610f\u56fe\uff0c\u663e\u8457\u63d0\u5347\u8bbe\u8ba1\u6548\u7387\u3002"}}
{"id": "2511.19671", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19671", "abs": "https://arxiv.org/abs/2511.19671", "authors": ["Rishab Sharma", "Iman Saberi", "Elham Alipour", "Jie JW Wu", "Fatemeh Fard"], "title": "FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking", "comment": "3 tables, 11 pages, 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Generative AI in Finance", "summary": "Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).", "AI": {"tldr": "FISCAL\u6846\u67b6\u901a\u8fc7\u751f\u6210\u91d1\u878d\u4e8b\u5b9e\u6838\u67e5\u7684\u5408\u6210\u6570\u636e\uff0c\u8bad\u7ec3\u51fa\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668MiniCheck-FISCAL\uff0c\u5728\u591a\u4e2a\u91d1\u878d\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1\u5927\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5e94\u7528\u4e2d\u5b58\u5728\u4e8b\u5b9e\u53ef\u9760\u6027\u4e0d\u8db3\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u51c6\u786e\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faFISCAL\u6846\u67b6\u751f\u6210\u91d1\u878d\u5408\u6210\u6570\u636e\uff0c\u5e76\u8bad\u7ec3MiniCheck-FISCAL\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668\u6765\u6838\u67e5\u6570\u503c\u91d1\u878d\u58f0\u660e\u3002", "result": "MiniCheck-FISCAL\u5728\u591a\u4e2a\u91d1\u878d\u6570\u636e\u96c6\u4e0a\u8d85\u8d8aGPT-3.5 Turbo\u548c\u540c\u7c7b\u5f00\u6e90\u6a21\u578b\uff0c\u63a5\u8fd1Mixtral-8x22B\u7b49\u5927\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u53ef\u4e0eGPT-4o\u548cClaude-3.5\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u9886\u57df\u7279\u5b9a\u7684\u5408\u6210\u6570\u636e\u7ed3\u5408\u9ad8\u6548\u5fae\u8c03\uff0c\u53ef\u4f7f\u7d27\u51d1\u6a21\u578b\u5728\u91d1\u878dAI\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.19445", "categories": ["cs.DC", "cs.DM"], "pdf": "https://arxiv.org/pdf/2511.19445", "abs": "https://arxiv.org/abs/2511.19445", "authors": ["Luca Accorsi", "Demetrio Lagan\u00e0", "Federico Michelotto", "Roberto Musmanno", "Daniele Vigo"], "title": "Asynchronous Cooperative Optimization of a Capacitated Vehicle Routing Problem Solution", "comment": null, "summary": "We propose a parallel shared-memory schema to cooperatively optimize the solution of a Capacitated Vehicle Routing Problem instance with minimal synchronization effort and without the need for an explicit decomposition. To this end, we design FILO2$^x$ as a single-trajectory parallel adaptation of the FILO2 algorithm originally proposed for extremely large-scale instances and described in Accorsi and Vigo (2024). Using the locality of the FILO2 optimization applications, in FILO2$^x$ several possibly unrelated solution areas are concurrently asynchronously optimized. The overall search trajectory emerges as an iteration-based parallelism obtained by the simultaneous optimization of the same underlying solution performed by several solvers. Despite the high efficiency exhibited by the single-threaded FILO2 algorithm, the computational results show that, by better exploiting the available computing resources, FILO2$^x$ can greatly enhance the resolution time compared to the original approach, still maintaining a similar final solution quality for instances ranging from hundreds to hundreds of thousands customers.", "AI": {"tldr": "\u63d0\u51fa\u4e86FILO2^x\u5e76\u884c\u5171\u4eab\u5185\u5b58\u67b6\u6784\uff0c\u7528\u4e8e\u534f\u540c\u4f18\u5316\u5e26\u5bb9\u91cf\u7ea6\u675f\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff0c\u65e0\u9700\u663e\u5f0f\u5206\u89e3\u4e14\u540c\u6b65\u5f00\u9500\u6700\u5c0f\u3002\u8fd9\u662fFILO2\u7b97\u6cd5\u7684\u5355\u8f68\u8ff9\u5e76\u884c\u9002\u914d\u7248\u672c\uff0c\u901a\u8fc7\u540c\u65f6\u5f02\u6b65\u4f18\u5316\u591a\u4e2a\u53ef\u80fd\u4e0d\u76f8\u5173\u7684\u89e3\u533a\u57df\u6765\u5b9e\u73b0\u8fed\u4ee3\u7ea7\u5e76\u884c\u3002", "motivation": "\u4e3a\u4e86\u5145\u5206\u5229\u7528\u53ef\u7528\u8ba1\u7b97\u8d44\u6e90\uff0c\u5728\u4fdd\u6301\u7c7b\u4f3c\u6700\u7ec8\u89e3\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4ece\u6570\u767e\u5230\u6570\u5341\u4e07\u5ba2\u6237\u89c4\u6a21\u5b9e\u4f8b\u7684\u6c42\u89e3\u65f6\u95f4\u3002", "method": "\u8bbe\u8ba1FILO2^x\u4f5c\u4e3aFILO2\u7b97\u6cd5\u7684\u5e76\u884c\u7248\u672c\uff0c\u5229\u7528FILO2\u4f18\u5316\u5e94\u7528\u7684\u5c40\u90e8\u6027\uff0c\u591a\u4e2a\u6c42\u89e3\u5668\u540c\u65f6\u5f02\u6b65\u4f18\u5316\u540c\u4e00\u5e95\u5c42\u89e3\u7684\u4e0d\u540c\u533a\u57df\uff0c\u5f62\u6210\u8fed\u4ee3\u7ea7\u5e76\u884c\u3002", "result": "\u8ba1\u7b97\u7ed3\u679c\u8868\u660e\uff0cFILO2^x\u76f8\u6bd4\u539f\u59cb\u65b9\u6cd5\u53ef\u4ee5\u5927\u5e45\u63d0\u5347\u6c42\u89e3\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u4f3c\u7684\u6700\u7ec8\u89e3\u8d28\u91cf\u3002", "conclusion": "\u5c3d\u7ba1\u5355\u7ebf\u7a0bFILO2\u7b97\u6cd5\u5df2\u8868\u73b0\u51fa\u9ad8\u6548\u7387\uff0c\u4f46\u901a\u8fc7\u66f4\u597d\u5730\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\uff0cFILO2^x\u80fd\u591f\u663e\u8457\u589e\u5f3a\u6c42\u89e3\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u4ece\u6570\u767e\u5230\u6570\u5341\u4e07\u5ba2\u6237\u89c4\u6a21\u7684\u95ee\u9898\u5b9e\u4f8b\u3002"}}
{"id": "2511.19562", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19562", "abs": "https://arxiv.org/abs/2511.19562", "authors": ["Abraham Itzhak Weinberg"], "title": "Trust-Based Social Learning for Communication (TSLEC) Protocol Evolution in Multi-Agent Reinforcement Learning", "comment": null, "summary": "Emergent communication in multi-agent systems typically occurs through independent learning, resulting in slow convergence and potentially suboptimal protocols. We introduce TSLEC (Trust-Based Social Learning with Emergent Communication), a framework where agents explicitly teach successful strategies to peers, with knowledge transfer modulated by learned trust relationships. Through experiments with 100 episodes across 30 random seeds, we demonstrate that trust-based social learning reduces episodes-to-convergence by 23.9% (p < 0.001, Cohen's d = 1.98) compared to independent emergence, while producing compositional protocols (C = 0.38) that remain robust under dynamic objectives (Phi > 0.867 decoding accuracy). Trust scores strongly correlate with teaching quality (r = 0.743, p < 0.001), enabling effective knowledge filtering. Our results establish that explicit social learning fundamentally accelerates emergent communication in multi-agent coordination.", "AI": {"tldr": "TSLEC\u6846\u67b6\u901a\u8fc7\u4fe1\u4efb\u5173\u7cfb\u8c03\u8282\u7684\u663e\u5f0f\u793e\u4f1a\u5b66\u4e60\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6d8c\u73b0\u901a\u4fe1\u6536\u655b\u65f6\u95f4\u51cf\u5c1123.9%\uff0c\u540c\u65f6\u4ea7\u751f\u7ec4\u5408\u6027\u534f\u8bae\u5e76\u4fdd\u6301\u52a8\u6001\u76ee\u6807\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6d8c\u73b0\u901a\u4fe1\u901a\u5e38\u901a\u8fc7\u72ec\u7acb\u5b66\u4e60\u5b9e\u73b0\uff0c\u5bfc\u81f4\u6536\u655b\u7f13\u6162\u4e14\u53ef\u80fd\u4ea7\u751f\u6b21\u4f18\u534f\u8bae\u3002", "method": "\u5f15\u5165TSLEC\u6846\u67b6\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u5b66\u4e60\u7684\u4fe1\u4efb\u5173\u7cfb\u8c03\u8282\u5411\u540c\u4f34\u663e\u5f0f\u6559\u6388\u6210\u529f\u7b56\u7565\u3002", "result": "\u4fe1\u4efb\u57fa\u793e\u4f1a\u5b66\u4e60\u5c06\u6536\u655b\u6240\u9700\u56de\u5408\u6570\u51cf\u5c1123.9%\uff0c\u4ea7\u751f\u7ec4\u5408\u6027\u534f\u8bae\uff0c\u5728\u52a8\u6001\u76ee\u6807\u4e0b\u4fdd\u6301\u9ad8\u89e3\u7801\u51c6\u786e\u7387\uff0c\u4fe1\u4efb\u5206\u6570\u4e0e\u6559\u5b66\u8d28\u91cf\u5f3a\u76f8\u5173\u3002", "conclusion": "\u663e\u5f0f\u793e\u4f1a\u5b66\u4e60\u4ece\u6839\u672c\u4e0a\u52a0\u901f\u4e86\u591a\u667a\u80fd\u4f53\u534f\u8c03\u4e2d\u7684\u6d8c\u73b0\u901a\u4fe1\u3002"}}
{"id": "2511.19749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19749", "abs": "https://arxiv.org/abs/2511.19749", "authors": ["Farzan Karimi-Malekabadi", "Pooya Razavi", "Sonya Powers"], "title": "Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions", "comment": null, "summary": "As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u52a0\u901f\u6559\u80b2\u8bc4\u4f30\u9879\u76ee\u4e0e\u5185\u5bb9\u6807\u51c6\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\u6548\u679c\uff0c\u901a\u8fc7\u4e09\u4e2a\u5b9e\u9a8c\u6d4b\u8bd5\u4e86GPT\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLMs\u80fd\u591f\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5ba1\u67e5\u8d1f\u62c5\u5e76\u4fdd\u6301\u5bf9\u9f50\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u4eba\u5de5\u5bf9\u9f50\u5ba1\u67e5\u867d\u7136\u51c6\u786e\u4f46\u901f\u5ea6\u6162\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u7279\u522b\u662f\u5728\u5927\u578b\u9879\u76ee\u5e93\u4e2d\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u662f\u5426\u80fd\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u52a0\u901f\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u8d85\u8fc712,000\u4e2a\u9879\u76ee-\u6280\u80fd\u5bf9\uff0c\u5728K-5\u5e74\u7ea7\u6d4b\u8bd5\u4e86\u4e09\u79cdLLMs(GPT-3.5 Turbo\u3001GPT-4o-mini\u548cGPT-4o)\uff0c\u6db5\u76d6\u4e09\u4e2a\u4efb\u52a1\uff1a\u8bc6\u522b\u672a\u5bf9\u9f50\u9879\u76ee\u3001\u4ece\u5b8c\u6574\u6807\u51c6\u96c6\u4e2d\u9009\u62e9\u6b63\u786e\u6280\u80fd\u3001\u5728\u5206\u7c7b\u524d\u7f29\u5c0f\u5019\u9009\u5217\u8868\u3002", "result": "GPT-4o-mini\u5728\u8bc6\u522b\u5bf9\u9f50\u72b6\u6001\u65b9\u9762\u8fbe\u523083-94%\u7684\u51c6\u786e\u7387\uff1b\u6570\u5b66\u9886\u57df\u8868\u73b0\u5f3a\u52b2\u4f46\u9605\u8bfb\u9886\u57df\u8f83\u4f4e\uff1b\u9884\u8fc7\u6ee4\u5019\u9009\u6280\u80fd\u663e\u8457\u6539\u5584\u7ed3\u679c\uff0c\u6b63\u786e\u6280\u80fd\u51fa\u73b0\u5728\u524d\u4e94\u5efa\u8bae\u4e2d\u7684\u6982\u7387\u8d85\u8fc795%\u3002", "conclusion": "LLMs\u7279\u522b\u662f\u7ed3\u5408\u5019\u9009\u8fc7\u6ee4\u7b56\u7565\u65f6\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u9879\u76ee\u5ba1\u67e5\u7684\u4eba\u5de5\u8d1f\u62c5\u540c\u65f6\u4fdd\u6301\u5bf9\u9f50\u51c6\u786e\u6027\u3002\u5efa\u8bae\u5f00\u53d1\u6df7\u5408\u6d41\u7a0b\uff0c\u5c06\u57fa\u4e8eLLM\u7684\u7b5b\u9009\u4e0e\u6a21\u7cca\u60c5\u51b5\u4e0b\u7684\u4eba\u5de5\u5ba1\u67e5\u76f8\u7ed3\u5408\uff0c\u4e3a\u6301\u7eed\u9879\u76ee\u9a8c\u8bc1\u548c\u6559\u5b66\u5bf9\u9f50\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19450", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.19450", "abs": "https://arxiv.org/abs/2511.19450", "authors": ["M. Zeeshan Haider", "Tayyaba Noreen", "M. D. Assuncao", "Kaiwen Zhang"], "title": "AI-driven Predictive Shard Allocation for Scalable Next Generation Blockchains", "comment": null, "summary": "Sharding has emerged as a key technique to address blockchain scalability by partitioning the ledger into multiple shards that process transactions in parallel. Although this approach improves throughput, static or heuristic shard allocation often leads to workload skew, congestion, and excessive cross-shard communication diminishing the scalability benefits of sharding. To overcome these challenges, we propose the Predictive Shard Allocation Protocol (PSAP), a dynamic and intelligent allocation framework that proactively assigns accounts and transactions to shards based on workload forecasts. PSAP integrates a Temporal Workload Forecasting (TWF) model with a safety-constrained reinforcement learning (Safe-PPO) controller, jointly enabling multi-block-ahead prediction and adaptive shard reconfiguration. The protocol enforces deterministic inference across validators through a synchronized quantized runtime and a safety gate that limits stake concentration, migration gas, and utilization thresholds. By anticipating hotspot formation and executing bounded, atomic migrations, PSAP achieves stable load balance while preserving Byzantine safety. Experimental evaluation on heterogeneous datasets, including Ethereum, NEAR, and Hyperledger Fabric mapped via address-clustering heuristics, demonstrates up to 2x throughput improvement, 35\\% lower latency, and 20\\% reduced cross-shard overhead compared to existing dynamic sharding baselines. These results confirm that predictive, deterministic, and security-aware shard allocation is a promising direction for next-generation scalable blockchain systems.", "AI": {"tldr": "PSAP\u662f\u4e00\u79cd\u9884\u6d4b\u6027\u5206\u7247\u5206\u914d\u534f\u8bae\uff0c\u901a\u8fc7\u52a8\u6001\u667a\u80fd\u5206\u914d\u8d26\u6237\u548c\u4ea4\u6613\u5230\u5206\u7247\u6765\u89e3\u51b3\u533a\u5757\u94fe\u5206\u7247\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u7ed3\u5408\u65f6\u95f4\u5e8f\u5217\u8d1f\u8f7d\u9884\u6d4b\u548c\u5b89\u5168\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u548c\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u9759\u6001\u6216\u542f\u53d1\u5f0f\u5206\u7247\u5206\u914d\u5bfc\u81f4\u8d1f\u8f7d\u503e\u659c\u3001\u62e5\u585e\u548c\u8de8\u5206\u7247\u901a\u4fe1\u8fc7\u591a\uff0c\u524a\u5f31\u4e86\u5206\u7247\u7684\u53ef\u6269\u5c55\u6027\u4f18\u52bf\u3002", "method": "\u96c6\u6210\u65f6\u95f4\u5e8f\u5217\u8d1f\u8f7d\u9884\u6d4b\u6a21\u578b\u548c\u5b89\u5168\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u591a\u5757\u63d0\u524d\u9884\u6d4b\u548c\u81ea\u9002\u5e94\u5206\u7247\u91cd\u914d\u7f6e\uff0c\u901a\u8fc7\u540c\u6b65\u91cf\u5316\u8fd0\u884c\u65f6\u548c\u5b89\u5168\u95e8\u63a7\u673a\u5236\u786e\u4fdd\u786e\u5b9a\u6027\u63a8\u7406\u3002", "result": "\u5728\u4ee5\u592a\u574a\u3001NEAR\u548cHyperledger Fabric\u7b49\u5f02\u6784\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u73b0\u6709\u52a8\u6001\u5206\u7247\u57fa\u7ebf\uff0c\u541e\u5410\u91cf\u63d0\u53472\u500d\uff0c\u5ef6\u8fdf\u964d\u4f4e35%\uff0c\u8de8\u5206\u7247\u5f00\u9500\u51cf\u5c1120%\u3002", "conclusion": "\u9884\u6d4b\u6027\u3001\u786e\u5b9a\u6027\u548c\u5b89\u5168\u611f\u77e5\u7684\u5206\u7247\u5206\u914d\u662f\u4e0b\u4e00\u4ee3\u53ef\u6269\u5c55\u533a\u5757\u94fe\u7cfb\u7edf\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2511.19726", "categories": ["cs.MA", "cs.AI", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19726", "abs": "https://arxiv.org/abs/2511.19726", "authors": ["Roberto Garrone"], "title": "An Adaptive, Data-Integrated Agent-Based Modeling Framework for Explainable and Contestable Policy Design", "comment": "27 pages, 2 case studies (emissions and smart grids). Preprint prepared during the author's PhD research at the Open University of Cyprus and the University of Milano-Bicocca. Introduces a unified framework for adaptive multi-agent learning with information-theoretic, causal, and clustering diagnostics", "summary": "Multi-agent systems often operate under feedback, adaptation, and non-stationarity, yet many simulation studies retain static decision rules and fixed control parameters. This paper introduces a general adaptive multi-agent learning framework that integrates: (i) four dynamic regimes distinguishing static versus adaptive agents and fixed versus adaptive system parameters; (ii) information-theoretic diagnostics (entropy rate, statistical complexity, and predictive information) to assess predictability and structure; (iii) structural causal models for explicit intervention semantics; (iv) procedures for generating agent-level priors from aggregate or sample data; and (v) unsupervised methods for identifying emergent behavioral regimes. The framework offers a domain-neutral architecture for analyzing how learning agents and adaptive controls jointly shape system trajectories, enabling systematic comparison of stability, performance, and interpretability across non-equilibrium, oscillatory, or drifting dynamics. Mathematical definitions, computational operators, and an experimental design template are provided, yielding a structured methodology for developing explainable and contestable multi-agent decision processes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u81ea\u9002\u5e94\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u6846\u67b6\uff0c\u6574\u5408\u4e86\u52a8\u6001\u673a\u5236\u3001\u4fe1\u606f\u8bba\u8bca\u65ad\u3001\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u3001\u5148\u9a8c\u751f\u6210\u65b9\u6cd5\u548c\u65e0\u76d1\u7763\u884c\u4e3a\u8bc6\u522b\uff0c\u7528\u4e8e\u5206\u6790\u5b66\u4e60\u667a\u80fd\u4f53\u548c\u81ea\u9002\u5e94\u63a7\u5236\u5982\u4f55\u5171\u540c\u5f71\u54cd\u7cfb\u7edf\u8f68\u8ff9\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u5728\u53cd\u9988\u3001\u9002\u5e94\u548c\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u8fd0\u884c\uff0c\u4f46\u8bb8\u591a\u6a21\u62df\u7814\u7a76\u4ecd\u4f7f\u7528\u9759\u6001\u51b3\u7b56\u89c4\u5219\u548c\u56fa\u5b9a\u63a7\u5236\u53c2\u6570\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u56db\u79cd\u52a8\u6001\u673a\u5236\uff08\u9759\u6001vs\u81ea\u9002\u5e94\u667a\u80fd\u4f53\u3001\u56fa\u5b9avs\u81ea\u9002\u5e94\u53c2\u6570\uff09\u3001\u4fe1\u606f\u8bba\u8bca\u65ad\uff08\u71b5\u7387\u3001\u7edf\u8ba1\u590d\u6742\u6027\u3001\u9884\u6d4b\u4fe1\u606f\uff09\u3001\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u3001\u5148\u9a8c\u751f\u6210\u65b9\u6cd5\u548c\u65e0\u76d1\u7763\u884c\u4e3a\u8bc6\u522b\u65b9\u6cd5\u7684\u7efc\u5408\u6846\u67b6\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9886\u57df\u65e0\u5173\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u7cfb\u7edf\u6bd4\u8f83\u975e\u5e73\u8861\u3001\u632f\u8361\u6216\u6f02\u79fb\u52a8\u6001\u4e2d\u7684\u7a33\u5b9a\u6027\u3001\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u53ef\u89e3\u91ca\u548c\u53ef\u4e89\u8bae\u7684\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u6570\u5b66\u5b9a\u4e49\u3001\u8ba1\u7b97\u7b97\u5b50\u548c\u5b9e\u9a8c\u8bbe\u8ba1\u6a21\u677f\u3002"}}
{"id": "2511.19453", "categories": ["cs.DC", "cs.DB", "cs.OS", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19453", "abs": "https://arxiv.org/abs/2511.19453", "authors": ["Yuxin Wang", "Yuankai He", "Weisong Shi"], "title": "AVS: A Computational and Hierarchical Storage System for Autonomous Vehicles", "comment": null, "summary": "Autonomous vehicles (AVs) are evolving into mobile computing platforms, equipped with powerful processors and diverse sensors that generate massive heterogeneous data, for example 14 TB per day. Supporting emerging third-party applications calls for a general-purpose, queryable onboard storage system. Yet today's data loggers and storage stacks in vehicles fail to deliver efficient data storage and retrieval. This paper presents AVS, an Autonomous Vehicle Storage system that co-designs computation with a hierarchical layout: modality-aware reduction and compression, hot-cold tiering with daily archival, and a lightweight metadata layer for indexing. The design is grounded with system-level benchmarks on AV data that cover SSD and HDD filesystems and embedded indexing, and is validated on embedded hardware with real L4 autonomous driving traces. The prototype delivers predictable real-time ingest, fast selective retrieval, and substantial footprint reduction under modest resource budgets. The work also outlines observations and next steps toward more scalable and longer deployments to motivate storage as a first-class component in AV stacks.", "AI": {"tldr": "AVS\u662f\u4e00\u4e2a\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u8bbe\u8ba1\u7684\u5b58\u50a8\u7cfb\u7edf\uff0c\u901a\u8fc7\u8ba1\u7b97\u4e0e\u5206\u5c42\u5e03\u5c40\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6570\u636e\u5b58\u50a8\u548c\u68c0\u7d22\uff0c\u5305\u62ec\u6a21\u6001\u611f\u77e5\u7684\u964d\u7ef4\u538b\u7f29\u3001\u70ed\u51b7\u6570\u636e\u5206\u5c42\u5b58\u50a8\u548c\u8f7b\u91cf\u7ea7\u5143\u6570\u636e\u7d22\u5f15\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4f5c\u4e3a\u79fb\u52a8\u8ba1\u7b97\u5e73\u53f0\uff0c\u6bcf\u5929\u4ea7\u751f\u5927\u91cf\u5f02\u6784\u6570\u636e\uff08\u598214TB\uff09\uff0c\u9700\u8981\u652f\u6301\u7b2c\u4e09\u65b9\u5e94\u7528\u7684\u9ad8\u6548\u6570\u636e\u5b58\u50a8\u548c\u68c0\u7d22\uff0c\u800c\u73b0\u6709\u7684\u8f66\u8f7d\u6570\u636e\u8bb0\u5f55\u5668\u548c\u5b58\u50a8\u7cfb\u7edf\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1\u4e86AVS\u7cfb\u7edf\uff0c\u91c7\u7528\u5206\u5c42\u5e03\u5c40\uff1a\u6a21\u6001\u611f\u77e5\u7684\u964d\u7ef4\u548c\u538b\u7f29\u3001\u70ed\u51b7\u6570\u636e\u5206\u5c42\u5b58\u50a8\u4e0e\u6bcf\u65e5\u5f52\u6863\u3001\u8f7b\u91cf\u7ea7\u5143\u6570\u636e\u5c42\u7d22\u5f15\u3002\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u4f7f\u7528\u771f\u5b9eL4\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u5b9e\u73b0\u4e86\u53ef\u9884\u6d4b\u7684\u5b9e\u65f6\u6570\u636e\u6444\u53d6\u3001\u5feb\u901f\u9009\u62e9\u6027\u68c0\u7d22\uff0c\u5e76\u5728\u9002\u5ea6\u8d44\u6e90\u9884\u7b97\u4e0b\u663e\u8457\u51cf\u5c11\u4e86\u5b58\u50a8\u7a7a\u95f4\u5360\u7528\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5c06\u5b58\u50a8\u4f5c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5806\u6808\u4e2d\u7684\u4e00\u7b49\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u89c2\u5bdf\u548c\u5efa\u8bae\uff0c\u5e76\u6307\u51fa\u4e86\u5411\u66f4\u53ef\u6269\u5c55\u548c\u957f\u671f\u90e8\u7f72\u53d1\u5c55\u7684\u4e0b\u4e00\u6b65\u65b9\u5411\u3002"}}
{"id": "2511.19885", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19885", "abs": "https://arxiv.org/abs/2511.19885", "authors": ["Chenglu Sun", "Shuo Shen", "Haonan Hu", "Wei Zhou", "Chen Chen"], "title": "Complex Instruction Following with Diverse Style Policies in Football Games", "comment": "21 pages, 13 figures, accepted by AAAI2026", "summary": "Despite advancements in language-controlled reinforcement learning (LC-RL) for basic domains and straightforward commands (e.g., object manipulation and navigation), effectively extending LC-RL to comprehend and execute high-level or abstract instructions in complex, multi-agent environments, such as football games, remains a significant challenge. To address this gap, we introduce Language-Controlled Diverse Style Policies (LCDSP), a novel LC-RL paradigm specifically designed for complex scenarios. LCDSP comprises two key components: a Diverse Style Training (DST) method and a Style Interpreter (SI). The DST method efficiently trains a single policy capable of exhibiting a wide range of diverse behaviors by modulating agent actions through style parameters (SP). The SI is designed to accurately and rapidly translate high-level language instructions into these corresponding SP. Through extensive experiments in a complex 5v5 football environment, we demonstrate that LCDSP effectively comprehends abstract tactical instructions and accurately executes the desired diverse behavioral styles, showcasing its potential for complex, real-world applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8bed\u8a00\u63a7\u5236\u591a\u6837\u5316\u98ce\u683c\u7b56\u7565\uff08LCDSP\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u4e13\u95e8\u4e3a\u590d\u6742\u591a\u667a\u80fd\u4f53\u73af\u5883\u8bbe\u8ba1\u7684\u65b0\u578bLC-RL\u8303\u5f0f\uff0c\u901a\u8fc7\u591a\u6837\u5316\u98ce\u683c\u8bad\u7ec3\u65b9\u6cd5\u548c\u98ce\u683c\u89e3\u91ca\u5668\uff0c\u80fd\u591f\u7406\u89e3\u5e76\u6267\u884c\u9ad8\u7ea7\u62bd\u8c61\u6307\u4ee4\u3002", "motivation": "\u5c3d\u7ba1\u8bed\u8a00\u63a7\u5236\u5f3a\u5316\u5b66\u4e60\u5728\u57fa\u7840\u9886\u57df\u548c\u7b80\u5355\u6307\u4ee4\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u590d\u6742\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7406\u89e3\u548c\u6267\u884c\u9ad8\u7ea7\u62bd\u8c61\u6307\u4ee4\uff08\u5982\u8db3\u7403\u6bd4\u8d5b\u4e2d\u7684\u6218\u672f\u6307\u4ee4\uff09\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "method": "LCDSP\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u591a\u6837\u5316\u98ce\u683c\u8bad\u7ec3\u65b9\u6cd5\uff08DST\uff09\u901a\u8fc7\u98ce\u683c\u53c2\u6570\u8c03\u8282\u667a\u80fd\u4f53\u884c\u4e3a\u6765\u8bad\u7ec3\u5355\u4e00\u7b56\u7565\uff0c\u98ce\u683c\u89e3\u91ca\u5668\uff08SI\uff09\u5c06\u9ad8\u7ea7\u8bed\u8a00\u6307\u4ee4\u5feb\u901f\u51c6\u786e\u5730\u8f6c\u6362\u4e3a\u76f8\u5e94\u7684\u98ce\u683c\u53c2\u6570\u3002", "result": "\u5728\u590d\u6742\u76845v5\u8db3\u7403\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cLCDSP\u80fd\u591f\u6709\u6548\u7406\u89e3\u62bd\u8c61\u6218\u672f\u6307\u4ee4\uff0c\u5e76\u51c6\u786e\u6267\u884c\u6240\u9700\u7684\u591a\u6837\u5316\u884c\u4e3a\u98ce\u683c\u3002", "conclusion": "LCDSP\u5c55\u793a\u4e86\u5728\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u9ad8\u7ea7\u8bed\u8a00\u6307\u4ee4\u5e76\u751f\u6210\u591a\u6837\u5316\u884c\u4e3a\u7b56\u7565\u3002"}}
{"id": "2511.19456", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.19456", "abs": "https://arxiv.org/abs/2511.19456", "authors": ["Anton Reinhard", "Simeon Ehrig", "Ren\u00e9 Widera", "Michael Bussmann", "Uwe Hernandez Acosta"], "title": "Optimizations on Graph-Level for Domain Specific Computations in Julia and Application to QED", "comment": null, "summary": "Complex computational problems in science often consist of smaller parts that can have largely distinct compute requirements from one another. For optimal efficiency, analyzing each subtask and scheduling it on the best-suited hardware would be necessary. Other considerations must be taken into account, too, such as parallelism, dependencies between different subtasks, and data transfer speeds between devices. To achieve this, directed acyclic graphs are often employed to represent these problems and enable utilizing as much hardware as possible on a given machine. In this paper, we present a software framework written in Julia capable of automatically and dynamically producing statically scheduled and compiled code. We lay theoretical foundations and add domain-specific information about the computation to the existing concepts of DAG scheduling, enabling optimizations that would otherwise be impossible. To illustrate the theory we implement an example application: the computation of matrix elements for scattering processes with many external particles in quantum electrodynamics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eJulia\u7684\u8f6f\u4ef6\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u52a8\u6001\u751f\u6210\u9759\u6001\u8c03\u5ea6\u548c\u7f16\u8bd1\u4ee3\u7801\uff0c\u901a\u8fc7\u6269\u5c55DAG\u8c03\u5ea6\u7406\u8bba\u5e76\u6dfb\u52a0\u9886\u57df\u7279\u5b9a\u4fe1\u606f\u6765\u5b9e\u73b0\u4f18\u5316\uff0c\u4ee5\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u4e2d\u591a\u7c92\u5b50\u6563\u5c04\u8fc7\u7a0b\u7684\u77e9\u9635\u5143\u8ba1\u7b97\u4e3a\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u590d\u6742\u95ee\u9898\u901a\u5e38\u5305\u542b\u5177\u6709\u4e0d\u540c\u8ba1\u7b97\u9700\u6c42\u7684\u5b50\u4efb\u52a1\uff0c\u4e3a\u4e86\u8fbe\u5230\u6700\u4f18\u6548\u7387\uff0c\u9700\u8981\u5206\u6790\u6bcf\u4e2a\u5b50\u4efb\u52a1\u5e76\u5c06\u5176\u8c03\u5ea6\u5230\u6700\u9002\u5408\u7684\u786c\u4ef6\u4e0a\uff0c\u540c\u65f6\u8003\u8651\u5e76\u884c\u6027\u3001\u4efb\u52a1\u95f4\u4f9d\u8d56\u5173\u7cfb\u548c\u8bbe\u5907\u95f4\u6570\u636e\u4f20\u8f93\u901f\u5ea6\u7b49\u56e0\u7d20\u3002", "method": "\u4f7f\u7528\u6709\u5411\u65e0\u73af\u56fe\u8868\u793a\u8ba1\u7b97\u95ee\u9898\uff0c\u6269\u5c55\u73b0\u6709\u7684DAG\u8c03\u5ea6\u7406\u8bba\u5e76\u6dfb\u52a0\u9886\u57df\u7279\u5b9a\u8ba1\u7b97\u4fe1\u606f\uff0c\u5f00\u53d1\u57fa\u4e8eJulia\u7684\u8f6f\u4ef6\u6846\u67b6\u6765\u81ea\u52a8\u52a8\u6001\u751f\u6210\u9759\u6001\u8c03\u5ea6\u548c\u7f16\u8bd1\u4ee3\u7801\u3002", "result": "\u5b9e\u73b0\u4e86\u80fd\u591f\u5229\u7528\u7ed9\u5b9a\u673a\u5668\u4e0a\u5c3d\u53ef\u80fd\u591a\u786c\u4ef6\u7684\u8c03\u5ea6\u7cfb\u7edf\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u4fe1\u606f\u5b9e\u73b0\u4e86\u539f\u672c\u4e0d\u53ef\u80fd\u7684\u4f18\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u7406\u8bba\u6269\u5c55\u548c\u9886\u57df\u7279\u5b9a\u4fe1\u606f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u590d\u6742\u79d1\u5b66\u8ba1\u7b97\u95ee\u9898\u7684\u4f18\u5316\u8c03\u5ea6\u95ee\u9898\uff0c\u5728\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u8ba1\u7b97\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.19798", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19798", "abs": "https://arxiv.org/abs/2511.19798", "authors": ["Weizhi Liu", "Xi Chen", "Zekun Jiang", "Liang Zhao", "Kunyuan Jiang", "Ruisi Tang", "Li Wang", "Mingke You", "Hanyu Zhou", "Hongyu Chen", "Qiankun Xiong", "Yong Nie", "Kang Li", "Jian Li"], "title": "KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)", "comment": null, "summary": "Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.", "AI": {"tldr": "KOM\u662f\u4e00\u4e2a\u7528\u4e8e\u819d\u9aa8\u5173\u8282\u708e\u81ea\u52a8\u5316\u8bc4\u4f30\u3001\u98ce\u9669\u9884\u6d4b\u548c\u6cbb\u7597\u5904\u65b9\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u8f85\u52a9\u4e34\u5e8a\u533b\u751f\u5e76\u751f\u6210\u4e2a\u6027\u5316\u7ba1\u7406\u8ba1\u5212\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u819d\u9aa8\u5173\u8282\u708e\u5f71\u54cd\u5168\u74036\u4ebf\u591a\u4eba\uff0c\u4f46\u4e2a\u6027\u5316\u591a\u5b66\u79d1\u5e72\u9884\u9700\u8981\u5927\u91cf\u533b\u7597\u8d44\u6e90\uff0c\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u96be\u4ee5\u5b9e\u65bd\u3002", "method": "\u5f00\u53d1KOM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u81ea\u52a8\u5316KOA\u8bc4\u4f30\u3001\u98ce\u9669\u9884\u6d4b\u548c\u6cbb\u7597\u5904\u65b9\uff0c\u57fa\u4e8e\u60a3\u8005\u4e2a\u4f53\u7279\u5f81\u3001\u75be\u75c5\u72b6\u6001\u3001\u98ce\u9669\u56e0\u7d20\u548c\u7981\u5fcc\u75c7\u751f\u6210\u5b9a\u5236\u7ba1\u7406\u8ba1\u5212\u3002", "result": "\u57fa\u51c6\u5b9e\u9a8c\u663e\u793aKOM\u5728\u5f71\u50cf\u5206\u6790\u548c\u5904\u65b9\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u591a\u4e2a\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff1b\u968f\u673a\u4e09\u81c2\u6a21\u62df\u7814\u7a76\u8868\u660eKOM\u4e0e\u4e34\u5e8a\u533b\u751f\u534f\u4f5c\u53ef\u5c06\u8bca\u65ad\u548c\u89c4\u5212\u65f6\u95f4\u51cf\u5c1138.5%\uff0c\u5e76\u63d0\u9ad8\u6cbb\u7597\u8d28\u91cf\u3002", "conclusion": "KOM\u6709\u52a9\u4e8e\u4fc3\u8fdbKOA\u7684\u81ea\u52a8\u5316\u7ba1\u7406\uff0c\u6574\u5408\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u6709\u6f5c\u529b\u63d0\u9ad8\u62a4\u7406\u6548\u7387\uff0c\u5176\u6a21\u5757\u5316\u67b6\u6784\u4e5f\u4e3a\u5f00\u53d1\u5176\u4ed6\u6162\u6027\u75c5\u7684AI\u8f85\u52a9\u7ba1\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2511.19829", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19829", "abs": "https://arxiv.org/abs/2511.19829", "authors": ["Ke Chen", "Yifeng Wang", "Hassan Almosapeeh", "Haohan Wang"], "title": "A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization", "comment": null, "summary": "Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bc4\u4f30\u6307\u5bfc\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u63d0\u793a\u8bc4\u4f30\u6846\u67b6\u548c\u8bad\u7ec3\u6267\u884c\u65e0\u5173\u7684\u8bc4\u4f30\u5668\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u3001\u67e5\u8be2\u76f8\u5173\u7684\u63d0\u793a\u91cd\u5199\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u4f18\u5316\u9759\u6001\u6a21\u677f\uff0c\u5728\u590d\u6742\u52a8\u6001\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff1b\u67e5\u8be2\u76f8\u5173\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u7a33\u5b9a\u7684\u6587\u672c\u53cd\u9988\u6216\u9ed1\u76d2\u5956\u52b1\u6a21\u578b\uff0c\u63d0\u4f9b\u5f31\u4e14\u4e0d\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u4fe1\u53f7\uff1b\u63d0\u793a\u8d28\u91cf\u672c\u8eab\u7f3a\u4e4f\u7edf\u4e00\u7cfb\u7edf\u5b9a\u4e49\uff0c\u5bfc\u81f4\u8bc4\u4f30\u4fe1\u53f7\u788e\u7247\u5316\u4e0d\u53ef\u9760\u3002", "method": "\u9996\u5148\u5efa\u7acb\u6027\u80fd\u5bfc\u5411\u7684\u7cfb\u7edf\u5316\u63d0\u793a\u8bc4\u4f30\u6846\u67b6\uff0c\u5f00\u53d1\u5e76\u5fae\u8c03\u6267\u884c\u65e0\u5173\u7684\u8bc4\u4f30\u5668\u76f4\u63a5\u9884\u6d4b\u591a\u7ef4\u5ea6\u8d28\u91cf\u5206\u6570\uff1b\u8bc4\u4f30\u5668\u6307\u5bfc\u6307\u6807\u611f\u77e5\u7684\u4f18\u5316\u5668\u8bca\u65ad\u5931\u8d25\u6a21\u5f0f\u5e76\u4ee5\u53ef\u89e3\u91ca\u65b9\u5f0f\u91cd\u5199\u63d0\u793a\u3002", "result": "\u8bc4\u4f30\u5668\u5728\u9884\u6d4b\u63d0\u793a\u6027\u80fd\u65b9\u9762\u8fbe\u5230\u6700\u5f3a\u51c6\u786e\u7387\uff1b\u8bc4\u4f30\u6307\u5bfc\u7684\u4f18\u5316\u57288\u4e2a\u6570\u636e\u96c6\u548c3\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u6301\u7eed\u8d85\u8d8a\u9759\u6001\u6a21\u677f\u548c\u67e5\u8be2\u76f8\u5173\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u3001\u57fa\u4e8e\u6307\u6807\u7684\u63d0\u793a\u8d28\u91cf\u89c6\u89d2\uff0c\u8bc1\u660e\u8bc4\u4f30\u6307\u5bfc\u7684\u4f18\u5316\u7ba1\u9053\u80fd\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u63d0\u4f9b\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u4e14\u6a21\u578b\u65e0\u5173\u7684\u6539\u8fdb\u3002"}}
{"id": "2511.19460", "categories": ["cs.DC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19460", "abs": "https://arxiv.org/abs/2511.19460", "authors": ["Sofiane Ben Amor", "Guillaume Guerard", "Loup-No\u00e9 Levy"], "title": "Systemic approach for modeling a generic smart grid", "comment": null, "summary": "Smart grid technological advances present a recent class of complex interdisciplinary modeling and increasingly difficult simulation problems to solve using traditional computational methods. To simulate a smart grid requires a systemic approach to integrated modeling of power systems, energy markets, demand-side management, and much other resources and assets that are becoming part of the current paradigm of the power grid. This paper presents a backbone model of a smart grid to test alternative scenarios for the grid. This tool simulates disparate systems to validate assumptions before the human scale model. Thanks to a distributed optimization of subsystems, the production and consumption scheduling is achieved while maintaining flexibility and scalability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u667a\u80fd\u7535\u7f51\u7684\u9aa8\u5e72\u6a21\u578b\uff0c\u7528\u4e8e\u6d4b\u8bd5\u7535\u7f51\u7684\u66ff\u4ee3\u573a\u666f\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u4f18\u5316\u5b50\u7cfb\u7edf\u5b9e\u73b0\u751f\u4ea7\u548c\u6d88\u8d39\u8c03\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u667a\u80fd\u7535\u7f51\u6280\u672f\u53d1\u5c55\u5e26\u6765\u4e86\u590d\u6742\u8de8\u5b66\u79d1\u5efa\u6a21\u95ee\u9898\uff0c\u4f20\u7edf\u8ba1\u7b97\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u96c6\u6210\u5efa\u6a21\u65b9\u6cd5\u6765\u6a21\u62df\u7535\u529b\u7cfb\u7edf\u3001\u80fd\u6e90\u5e02\u573a\u3001\u9700\u6c42\u4fa7\u7ba1\u7406\u7b49\u8d44\u6e90\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u4f18\u5316\u5b50\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u6784\u5efa\u667a\u80fd\u7535\u7f51\u9aa8\u5e72\u6a21\u578b\uff0c\u6a21\u62df\u4e0d\u540c\u7cfb\u7edf\u4ee5\u5728\u4eba\u7c7b\u89c4\u6a21\u6a21\u578b\u4e4b\u524d\u9a8c\u8bc1\u5047\u8bbe\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u6d4b\u8bd5\u7535\u7f51\u66ff\u4ee3\u573a\u666f\u7684\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u751f\u4ea7\u548c\u6d88\u8d39\u8c03\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u667a\u80fd\u7535\u7f51\u9aa8\u5e72\u6a21\u578b\u4e3a\u89e3\u51b3\u590d\u6742\u7535\u7f51\u4eff\u771f\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u4f18\u5316\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u7cfb\u7edf\u96c6\u6210\u548c\u8c03\u5ea6\u529f\u80fd\u3002"}}
{"id": "2511.19849", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19849", "abs": "https://arxiv.org/abs/2511.19849", "authors": ["Dominik Wagner", "Leon Witzman", "Luke Ong"], "title": "Reinforcement Learning with $\u03c9$-Regular Objectives and Constraints", "comment": null, "summary": "Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $\u03c9$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.\n  We address both limitations simultaneously by combining $\u03c9$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $\u03c9$-regular objective while also adhering to $\u03c9$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u03c9-\u6b63\u5219\u76ee\u6807\u4e0e\u663e\u5f0f\u7ea6\u675f\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6807\u91cf\u5956\u52b1\u5728\u8868\u8fbe\u590d\u6742\u884c\u4e3a\u5c5e\u6027\u548c\u5b89\u5168\u6027\u80fd\u6743\u8861\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4f9d\u8d56\u6807\u91cf\u5956\u52b1\uff0c\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u65e0\u6cd5\u51c6\u786e\u8868\u8fbe\u65f6\u95f4\u6027\u3001\u6761\u4ef6\u6027\u6216\u5b89\u5168\u5173\u952e\u76ee\u6807\uff0c\u4e14\u5bb9\u6613\u5bfc\u81f4\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u3002\u540c\u65f6\uff0c\u5355\u4e00\u6807\u91cf\u6027\u80fd\u5ea6\u91cf\u63a9\u76d6\u4e86\u5728\u53ef\u63a5\u53d7\u98ce\u9669\u6c34\u5e73\u4e0b\u7684\u5b89\u5168\u6027\u80fd\u6743\u8861\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5c06\u03c9-\u6b63\u5219\u76ee\u6807\u4e0e\u7ea6\u675f\u5206\u5f00\u5904\u7406\uff0c\u5728\u6ee1\u8db3\u03c9-\u6b63\u5219\u7ea6\u675f\u9608\u503c\u7684\u524d\u63d0\u4e0b\u6700\u5927\u5316\u76ee\u6807\u6ee1\u8db3\u6982\u7387\uff0c\u5e76\u5efa\u7acb\u4e86\u5230\u7ea6\u675f\u6781\u9650\u5e73\u5747\u95ee\u9898\u7684\u8f6c\u6362\u3002", "result": "\u8be5\u7b97\u6cd5\u5728\u6781\u9650\u60c5\u51b5\u4e0b\u80fd\u591f\u751f\u6210\u4e00\u4e2a\u7b56\u7565\uff0c\u5728\u6ee1\u8db3\u03c9-\u6b63\u5219\u7ea6\u675f\u9608\u503c\u7684\u540c\u65f6\u6700\u5927\u5316\u03c9-\u6b63\u5219\u76ee\u6807\u7684\u6ee1\u8db3\u6982\u7387\uff0c\u5e76\u4fdd\u6301\u4e86\u6700\u4f18\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u03c9-\u6b63\u5219\u76ee\u6807\u548c\u663e\u5f0f\u7ea6\u675f\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u540c\u65f6\u89e3\u51b3\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u8868\u8fbe\u80fd\u529b\u548c\u5b89\u5168\u6027\u80fd\u6743\u8861\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u590d\u6742\u884c\u4e3a\u89c4\u8303\u548c\u5b89\u5168\u5173\u952e\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u6846\u67b6\u3002"}}
{"id": "2511.19463", "categories": ["cs.DC", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2511.19463", "abs": "https://arxiv.org/abs/2511.19463", "authors": ["Aldo Canfora", "Eleonora Bergamaschi", "Riccardo Mioli", "Federico Battini", "Mirko Degli Esposti", "Giorgio Pedrazzi", "Chiara Dellacasa"], "title": "Urban Buildings Energy Consumption Estimation Using HPC: A Case Study of Bologna", "comment": "Preprint submitted for publication", "summary": "Urban Building Energy Modeling (UBEM) plays a central role in understanding and forecasting energy consumption at the city scale. In this work, we present a UBEM pipeline that integrates EnergyPlus simulations, high-performance computing (HPC), and open geospatial datasets to estimate the energy demand of buildings in Bologna, Italy. Geometric information including building footprints and heights was obtained from the Bologna Open Data portal and enhanced with aerial LiDAR measurements. Non-geometric attributes such as construction materials, insulation characteristics, and window performance were derived from regional building regulations and the European TABULA database. The computation was carried out on Leonardo, the Cineca-hosted supercomputer, enabling the simulation of approximately 25,000 buildings in under 30 minutes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210EnergyPlus\u6a21\u62df\u3001\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u5f00\u653e\u5730\u7406\u6570\u636e\u96c6\u7684UBEM\u6d41\u7a0b\uff0c\u7528\u4e8e\u4f30\u7b97\u610f\u5927\u5229\u535a\u6d1b\u5c3c\u4e9a\u5efa\u7b51\u7684\u80fd\u6e90\u9700\u6c42\u3002", "motivation": "\u57ce\u5e02\u5efa\u7b51\u80fd\u6e90\u5efa\u6a21\u5728\u7406\u89e3\u548c\u9884\u6d4b\u57ce\u5e02\u5c3a\u5ea6\u80fd\u6e90\u6d88\u8017\u4e2d\u53d1\u6325\u6838\u5fc3\u4f5c\u7528\u3002", "method": "\u4f7f\u7528\u535a\u6d1b\u5c3c\u4e9a\u5f00\u653e\u6570\u636e\u95e8\u6237\u7684\u5efa\u7b51\u8db3\u8ff9\u548c\u9ad8\u5ea6\u4fe1\u606f\uff0c\u7ed3\u5408\u822a\u7a7aLiDAR\u6d4b\u91cf\uff1b\u4ece\u533a\u57df\u5efa\u7b51\u6cd5\u89c4\u548c\u6b27\u6d32TABULA\u6570\u636e\u5e93\u83b7\u53d6\u5efa\u7b51\u6750\u6599\u3001\u9694\u70ed\u7279\u6027\u548c\u7a97\u6237\u6027\u80fd\u7b49\u975e\u51e0\u4f55\u5c5e\u6027\uff1b\u5728Leonardo\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u8fdb\u884cEnergyPlus\u6a21\u62df\u3002", "result": "\u572830\u5206\u949f\u5185\u5b8c\u6210\u4e86\u7ea625,000\u680b\u5efa\u7b51\u7684\u6a21\u62df\u8ba1\u7b97\u3002", "conclusion": "\u8be5UBEM\u6d41\u7a0b\u6210\u529f\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u57ce\u5e02\u5efa\u7b51\u80fd\u6e90\u9700\u6c42\u7684\u9ad8\u6548\u4f30\u7b97\u3002"}}
{"id": "2511.19864", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19864", "abs": "https://arxiv.org/abs/2511.19864", "authors": ["Valerie Lockhart", "Dan McCreary", "Troy A. Peterson"], "title": "MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support", "comment": "42 pages, 4 figures", "summary": "Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.", "AI": {"tldr": "MicroSims\u662f\u4e00\u4e2a\u7528\u4e8e\u521b\u5efa\u8f7b\u91cf\u7ea7\u4ea4\u4e92\u5f0f\u6559\u80b2\u6a21\u62df\u7684AI\u9a71\u52a8\u6846\u67b6\uff0c\u652f\u6301\u5feb\u901f\u751f\u6210\u3001\u8de8\u5e73\u53f0\u5d4c\u5165\u548c\u65e0\u4ee3\u7801\u5b9a\u5236\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u62df\u5f00\u53d1\u6210\u672c\u9ad8\u3001\u6280\u672f\u590d\u6742\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6559\u80b2\u6a21\u62df\u5f00\u53d1\u9700\u8981\u5927\u91cf\u8d44\u6e90\u548c\u6280\u672f\u4e13\u957f\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002MicroSims\u65e8\u5728\u901a\u8fc7AI\u8f85\u52a9\u751f\u6210\u3001\u901a\u7528\u5d4c\u5165\u548c\u65e0\u4ee3\u7801\u5b9a\u5236\uff0c\u964d\u4f4e\u6559\u80b2\u6a21\u62df\u7684\u521b\u5efa\u95e8\u69db\uff0c\u4fc3\u8fdb\u6559\u80b2\u516c\u5e73\u3002", "method": "\u91c7\u7528\u6807\u51c6\u5316\u8bbe\u8ba1\u6a21\u5f0f\u5b9e\u73b0AI\u8f85\u52a9\u751f\u6210\uff0c\u57fa\u4e8eiframe\u67b6\u6784\u63d0\u4f9b\u901a\u7528\u5d4c\u5165\u548c\u5b89\u5168\u6c99\u7bb1\uff0c\u4f7f\u7528\u900f\u660e\u53ef\u4fee\u6539\u4ee3\u7801\u652f\u6301\u5b9a\u5236\u548c\u6559\u5b66\u900f\u660e\u5ea6\u3002", "result": "\u7814\u7a76\u8868\u660e\u4ea4\u4e92\u5f0f\u6a21\u62df\u76f8\u6bd4\u4f20\u7edf\u6559\u5b66\u53ef\u5c06\u6982\u5ff5\u7406\u89e3\u63d0\u534730-40%\u3002MicroSims\u5728\u4fdd\u6301\u8fd9\u4e9b\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u89e3\u51b3\u4e86\u6210\u672c\u3001\u6280\u672f\u590d\u6742\u6027\u548c\u5e73\u53f0\u4f9d\u8d56\u7b49\u957f\u671f\u969c\u788d\u3002", "conclusion": "MicroSims\u6846\u67b6\u4e3a\u6559\u80b2\u516c\u5e73\u548c\u4f4e\u6210\u672c\u667a\u80fd\u4ea4\u4e92\u5f0f\u6559\u79d1\u4e66\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u4f7f\u5168\u7403\u6559\u80b2\u5de5\u4f5c\u8005\u80fd\u591f\u6309\u9700\u521b\u5efa\u5b9a\u5236\u5316\u3001\u4e0e\u8bfe\u7a0b\u5bf9\u9f50\u7684\u6a21\u62df\uff0c\u5e76\u4e3a\u57fa\u4e8eAI\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.19464", "categories": ["cs.DC", "cs.AI", "cs.CR", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.19464", "abs": "https://arxiv.org/abs/2511.19464", "authors": ["Marcio Pohlmann", "Alex Severo", "Geft\u00e9 Almeida", "Diego Kreutz", "Tiago Heinrich", "Louren\u00e7o Pereira"], "title": "Temperature in SLMs: Impact on Incident Categorization in On-Premises Environments", "comment": "5 pages, 3 figures, 2 tables, submitted to ERRC/WRSeg 2025", "summary": "SOCs and CSIRTs face increasing pressure to automate incident categorization, yet the use of cloud-based LLMs introduces costs, latency, and confidentiality risks. We investigate whether locally executed SLMs can meet this challenge. We evaluated 21 models ranging from 1B to 20B parameters, varying the temperature hyperparameter and measuring execution time and precision across two distinct architectures. The results indicate that temperature has little influence on performance, whereas the number of parameters and GPU capacity are decisive factors.", "AI": {"tldr": "\u8bc4\u4f30\u672c\u5730\u8fd0\u884c\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLMs)\u5728\u81ea\u52a8\u5316\u4e8b\u4ef6\u5206\u7c7b\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e0e\u57fa\u4e8e\u4e91\u7684LLMs\u76f8\u6bd4\uff0c\u89e3\u51b3\u4e86\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u673a\u5bc6\u6027\u95ee\u9898\u3002", "motivation": "SOC\u548cCSIRT\u9762\u4e34\u81ea\u52a8\u5316\u4e8b\u4ef6\u5206\u7c7b\u7684\u538b\u529b\uff0c\u4f46\u4f7f\u7528\u57fa\u4e8e\u4e91\u7684LLMs\u5b58\u5728\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u673a\u5bc6\u6027\u98ce\u9669\uff0c\u56e0\u6b64\u7814\u7a76\u672c\u5730\u6267\u884c\u7684SLMs\u662f\u5426\u80fd\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u8bc4\u4f30\u4e8621\u4e2a\u53c2\u6570\u4ece1B\u523020B\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u6539\u53d8\u6e29\u5ea6\u8d85\u53c2\u6570\uff0c\u6d4b\u91cf\u4e0d\u540c\u67b6\u6784\u4e0b\u7684\u6267\u884c\u65f6\u95f4\u548c\u7cbe\u5ea6\u3002", "result": "\u6e29\u5ea6\u5bf9\u6027\u80fd\u5f71\u54cd\u5f88\u5c0f\uff0c\u800c\u53c2\u6570\u6570\u91cf\u548cGPU\u5bb9\u91cf\u662f\u51b3\u5b9a\u6027\u56e0\u7d20\u3002", "conclusion": "\u672c\u5730\u6267\u884c\u7684SLMs\u5728\u81ea\u52a8\u5316\u4e8b\u4ef6\u5206\u7c7b\u4e2d\u5177\u6709\u53ef\u884c\u6027\uff0c\u6027\u80fd\u4e3b\u8981\u53d6\u51b3\u4e8e\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u548c\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2511.19468", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19468", "abs": "https://arxiv.org/abs/2511.19468", "authors": ["Blaise Ag\u00fcera y Arcas", "Travis Beals", "Maria Biggs", "Jessica V. Bloom", "Thomas Fischbacher", "Konstantin Gromov", "Urs K\u00f6ster", "Rishiraj Pravahan", "James Manyika"], "title": "Towards a future space-based, highly scalable AI infrastructure system design", "comment": "19 pages, 4 figures", "summary": "If AI is a foundational general-purpose technology, we should anticipate that demand for AI compute -- and energy -- will continue to grow. The Sun is by far the largest energy source in our solar system, and thus it warrants consideration how future AI infrastructure could most efficiently tap into that power. This work explores a scalable compute system for machine learning in space, using fleets of satellites equipped with solar arrays, inter-satellite links using free-space optics, and Google tensor processing unit (TPU) accelerator chips. To facilitate high-bandwidth, low-latency inter-satellite communication, the satellites would be flown in close proximity. We illustrate the basic approach to formation flight via a 81-satellite cluster of 1 km radius, and describe an approach for using high-precision ML-based models to control large-scale constellations. Trillium TPUs are radiation tested. They survive a total ionizing dose equivalent to a 5 year mission life without permanent failures, and are characterized for bit-flip errors. Launch costs are a critical part of overall system cost; a learning curve analysis suggests launch to low-Earth orbit (LEO) may reach $\\lesssim$\\$200/kg by the mid-2030s.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u592a\u7a7a\u4e2d\u6784\u5efa\u53ef\u6269\u5c55\u7684\u673a\u5668\u5b66\u4e60\u8ba1\u7b97\u7cfb\u7edf\uff0c\u4f7f\u7528\u914d\u5907\u592a\u9633\u80fd\u7535\u6c60\u677f\u3001\u5149\u5b66\u536b\u661f\u95f4\u94fe\u8def\u7684\u536b\u661f\u7fa4\u548c\u8c37\u6b4cTPU\u82af\u7247\uff0c\u65e8\u5728\u5229\u7528\u592a\u9633\u80fd\u6e90\u4e3aAI\u8ba1\u7b97\u63d0\u4f9b\u52a8\u529b\u3002", "motivation": "\u968f\u7740AI\u8ba1\u7b97\u9700\u6c42\u7684\u6301\u7eed\u589e\u957f\uff0c\u9700\u8981\u5bfb\u627e\u53ef\u6301\u7eed\u7684\u80fd\u6e90\u89e3\u51b3\u65b9\u6848\u3002\u592a\u9633\u662f\u592a\u9633\u7cfb\u4e2d\u6700\u5927\u7684\u80fd\u6e90\uff0c\u56e0\u6b64\u7814\u7a76\u5982\u4f55\u9ad8\u6548\u5229\u7528\u592a\u9633\u80fd\u4e3a\u672a\u6765AI\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u52a8\u529b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u536b\u661f\u7fa4\u6784\u5efa\u592a\u7a7a\u8ba1\u7b97\u7cfb\u7edf\uff0c\u5305\u62ec\uff1a\u914d\u5907\u592a\u9633\u80fd\u7535\u6c60\u677f\u7684\u536b\u661f\u3001\u4f7f\u7528\u81ea\u7531\u7a7a\u95f4\u5149\u5b66\u7684\u536b\u661f\u95f4\u94fe\u8def\u3001\u8c37\u6b4cTPU\u52a0\u901f\u5668\u82af\u7247\u3002\u536b\u661f\u4ee5\u7d27\u5bc6\u7f16\u961f\u98de\u884c\uff08\u598281\u9897\u536b\u661f\u7ec4\u62101\u516c\u91cc\u534a\u5f84\u7684\u96c6\u7fa4\uff09\uff0c\u5e76\u91c7\u7528\u9ad8\u7cbe\u5ea6ML\u6a21\u578b\u63a7\u5236\u5927\u89c4\u6a21\u661f\u5ea7\u3002", "result": "Trillium TPU\u7ecf\u8fc7\u8f90\u5c04\u6d4b\u8bd5\uff0c\u5728\u76f8\u5f53\u4e8e5\u5e74\u4efb\u52a1\u5bff\u547d\u7684\u603b\u7535\u79bb\u5242\u91cf\u4e0b\u65e0\u6c38\u4e45\u6027\u6545\u969c\uff0c\u4ec5\u51fa\u73b0\u6bd4\u7279\u7ffb\u8f6c\u9519\u8bef\u3002\u53d1\u5c04\u6210\u672c\u5206\u6790\u663e\u793a\u52302030\u5e74\u4ee3\u4e2d\u671f\uff0cLEO\u53d1\u5c04\u6210\u672c\u53ef\u80fd\u964d\u81f3\u2264200\u7f8e\u5143/\u516c\u65a4\u3002", "conclusion": "\u592a\u7a7a\u4e2d\u7684\u592a\u9633\u80fd\u9a71\u52a8AI\u8ba1\u7b97\u7cfb\u7edf\u662f\u53ef\u884c\u7684\uff0c\u901a\u8fc7\u536b\u661f\u7fa4\u3001\u5149\u5b66\u901a\u4fe1\u548c\u8f90\u5c04\u786c\u5316TPU\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u53ef\u4e3a\u672a\u6765AI\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u53ef\u6301\u7eed\u7684\u80fd\u6e90\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19872", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19872", "abs": "https://arxiv.org/abs/2511.19872", "authors": ["Daniel I Jackson", "Emma L Jensen", "Syed-Amad Hussain", "Emre Sezgin"], "title": "Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy", "comment": "25 pages,5 tables, 3 figures", "summary": "Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u901a\u7528\u81ea\u6211\u6548\u80fd\u611f\u91cf\u8868(GSES)\u5e94\u7528\u4e8e10\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u56db\u79cd\u4efb\u52a1\u6761\u4ef6\u4e0b\u8bc4\u4f30\u5176\u6a21\u62df\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\u6a21\u578b\u81ea\u6211\u8bc4\u4f30\u9ad8\u5ea6\u7a33\u5b9a\u4f46\u666e\u904d\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\uff0c\u4e14\u81ea\u6211\u8bc4\u4f30\u4e0e\u771f\u5b9e\u80fd\u529b\u4e0d\u5339\u914d\uff0c\u5b58\u5728\u8f7b\u5fae\u9ad8\u4f30\u503e\u5411\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u800c\u5ffd\u89c6\u4e86\u81ea\u6211\u8bc4\u4f30\u8fd9\u4e00\u53ef\u9760\u667a\u80fd\u7684\u5173\u952e\u65b9\u9762\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30LLMs\u7684\u81ea\u6211\u6548\u80fd\u611f\u53ca\u5176\u4e0e\u4efb\u52a1\u8868\u73b0\u7684\u5173\u7cfb\u3002", "method": "\u91c7\u752810\u9879\u901a\u7528\u81ea\u6211\u6548\u80fd\u611f\u91cf\u8868(GSES)\uff0c\u572810\u4e2aLLMs\u4e0a\u8fdb\u884c\u56db\u79cd\u6761\u4ef6\u6d4b\u8bd5\uff1a\u65e0\u4efb\u52a1\u3001\u8ba1\u7b97\u63a8\u7406\u3001\u793e\u4f1a\u63a8\u7406\u548c\u6458\u8981\u4efb\u52a1\u3002\u5206\u6790\u81ea\u6211\u8bc4\u4f30\u7684\u7a33\u5b9a\u6027\u3001\u51c6\u786e\u6027\u4ee5\u53ca\u4e0e\u4efb\u52a1\u8868\u73b0\u7684\u5173\u7cfb\u3002", "result": "\u6a21\u578b\u81ea\u6211\u8bc4\u4f30\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u603b\u4f53\u5f97\u5206\u4f4e\u4e8e\u4eba\u7c7b\u6807\u51c6\u3002\u6240\u6709\u6a21\u578b\u5728\u8ba1\u7b97\u548c\u793e\u4f1a\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u5b8c\u7f8e\uff0c\u4f46\u6458\u8981\u4efb\u52a1\u8868\u73b0\u5dee\u5f02\u5f88\u5927\u3002\u81ea\u6211\u8bc4\u4f30\u4e0d\u80fd\u53ef\u9760\u53cd\u6620\u5b9e\u9645\u80fd\u529b\uff0c\u5b58\u5728\u8f7b\u5fae\u9ad8\u4f30\u503e\u5411\u3002", "conclusion": "\u5fc3\u7406\u6d4b\u91cf\u63d0\u793a\u4e3a\u7406\u89e3LLM\u6c9f\u901a\u884c\u4e3a\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u6d1e\u5bdf\uff0c\u4f46\u4e0d\u80fd\u63d0\u4f9b\u6821\u51c6\u7684\u6027\u80fd\u4f30\u8ba1\u3002\u81ea\u6211\u6548\u80fd\u611f\u8f83\u9ad8\u7684\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u81ea\u4fe1\u3001\u62df\u4eba\u5316\u7684\u63a8\u7406\u98ce\u683c\uff0c\u800c\u5f97\u5206\u8f83\u4f4e\u7684\u6a21\u578b\u5219\u91c7\u7528\u8c28\u614e\u3001\u53bb\u62df\u4eba\u5316\u7684\u89e3\u91ca\u65b9\u5f0f\u3002"}}
{"id": "2511.19479", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19479", "abs": "https://arxiv.org/abs/2511.19479", "authors": ["Sangam Ghimire", "Paribartan Timalsina", "Nirjal Bhurtel", "Bishal Neupane", "Bigyan Byanju Shrestha", "Subarna Bhattarai", "Prajwal Gaire", "Jessica Thapa", "Sudan Jha"], "title": "Federated Learning Framework for Scalable AI in Heterogeneous HPC and Cloud Environments", "comment": null, "summary": "As the demand grows for scalable and privacy-aware AI systems, Federated Learning (FL) has emerged as a promising solution, allowing decentralized model training without moving raw data. At the same time, the combination of high- performance computing (HPC) and cloud infrastructure offers vast computing power but introduces new complexities, especially when dealing with heteroge- neous hardware, communication limits, and non-uniform data. In this work, we present a federated learning framework built to run efficiently across mixed HPC and cloud environments. Our system addresses key challenges such as system het- erogeneity, communication overhead, and resource scheduling, while maintaining model accuracy and data privacy. Through experiments on a hybrid testbed, we demonstrate strong performance in terms of scalability, fault tolerance, and convergence, even under non-Independent and Identically Distributed (non-IID) data distributions and varied hardware. These results highlight the potential of federated learning as a practical approach to building scalable Artificial Intelligence (AI) systems in modern, distributed computing settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5728\u6df7\u5408\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u4e91\u73af\u5883\u4e2d\u9ad8\u6548\u8fd0\u884c\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u7cfb\u7edf\u5f02\u6784\u6027\u3001\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u8c03\u5ea6\u7b49\u5173\u952e\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\u548c\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u968f\u7740\u5bf9\u53ef\u6269\u5c55\u548c\u9690\u79c1\u611f\u77e5AI\u7cfb\u7edf\u7684\u9700\u6c42\u589e\u957f\uff0c\u8054\u90a6\u5b66\u4e60\u6210\u4e3a\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u4e91\u57fa\u7840\u8bbe\u65bd\u7684\u7ed3\u5408\u5e26\u6765\u4e86\u65b0\u7684\u590d\u6742\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5f02\u6784\u786c\u4ef6\u3001\u901a\u4fe1\u9650\u5236\u548c\u975e\u5747\u5300\u6570\u636e\u65f6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5728\u6df7\u5408HPC\u548c\u4e91\u73af\u5883\u4e2d\u9ad8\u6548\u8fd0\u884c\uff0c\u89e3\u51b3\u4e86\u7cfb\u7edf\u5f02\u6784\u6027\u3001\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u8c03\u5ea6\u7b49\u5173\u952e\u6311\u6218\u3002", "result": "\u5728\u6df7\u5408\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5206\u5e03\u548c\u4e0d\u540c\u786c\u4ef6\u6761\u4ef6\u4e0b\uff0c\u7cfb\u7edf\u5728\u53ef\u6269\u5c55\u6027\u3001\u5bb9\u9519\u6027\u548c\u6536\u655b\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u8054\u90a6\u5b66\u4e60\u4f5c\u4e3a\u5728\u73b0\u4ee3\u5206\u5e03\u5f0f\u8ba1\u7b97\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u6269\u5c55AI\u7cfb\u7edf\u7684\u5b9e\u7528\u65b9\u6cd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.19895", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19895", "abs": "https://arxiv.org/abs/2511.19895", "authors": ["Yuanyuan Lin", "Xiangyu Ouyang", "Teng Zhang", "Kaixin Sui"], "title": "RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation", "comment": "Accepted at AAAI 2026", "summary": "Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.", "AI": {"tldr": "RPM-MCTS\u662f\u4e00\u79cd\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u68c0\u7d22\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u6765\u8bc4\u4f30\u4e2d\u95f4\u7b97\u6cd5\u6b65\u9aa4\uff0c\u65e0\u9700\u590d\u6742\u8bad\u7ec3\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u540c\u65f6\u5229\u7528\u6c99\u7bb1\u6267\u884c\u53cd\u9988\u5b9a\u4f4d\u548c\u7ea0\u6b63\u9519\u8bef\u6b65\u9aa4\uff0c\u5728\u51cf\u5c1115%\u4ee4\u724c\u6d88\u8017\u7684\u540c\u65f6\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u6811\u641c\u7d22\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc4\u4f30\u4e2d\u95f4\u7b97\u6cd5\u6b65\u9aa4\u3001\u65e0\u6cd5\u5b9a\u4f4d\u548c\u53ca\u65f6\u7ea0\u6b63\u9519\u8bef\u6b65\u9aa4\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u9650\u5236\u5bfc\u81f4\u751f\u6210\u9519\u8bef\u4ee3\u7801\u548c\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51faRPM-MCTS\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u77e5\u8bc6\u68c0\u7d22\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u4e2d\u95f4\u6b65\u9aa4\uff1b2) \u5728\u6269\u5c55\u9636\u6bb5\u91c7\u7528\u76f8\u4f3c\u6027\u8fc7\u6ee4\u53bb\u9664\u5197\u4f59\u8282\u70b9\uff1b3) \u5229\u7528\u6c99\u7bb1\u6267\u884c\u53cd\u9988\u5b9a\u4f4d\u9519\u8bef\u6b65\u9aa4\u5e76\u8fdb\u884c\u9488\u5bf9\u6027\u7ea0\u6b63\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRPM-MCTS\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b0\u7ea615%\u7684\u4ee4\u724c\u6d88\u8017\u51cf\u5c11\u3002\u4f7f\u7528RPM-MCTS\u6784\u5efa\u7684\u6570\u636e\u5bf9\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5168\u5fae\u8c03\u53ef\u663e\u8457\u63d0\u5347\u5176\u4ee3\u7801\u80fd\u529b\u3002", "conclusion": "RPM-MCTS\u662f\u4e00\u79cd\u6709\u6548\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u68c0\u7d22\u548c\u6c99\u7bb1\u53cd\u9988\u673a\u5236\u89e3\u51b3\u4e86\u4e2d\u95f4\u6b65\u9aa4\u8bc4\u4f30\u548c\u9519\u8bef\u7ea0\u6b63\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2511.19832", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.19832", "abs": "https://arxiv.org/abs/2511.19832", "authors": ["Aurelio Vivas", "Harold Castro"], "title": "Enabling Scientific Workflow Scheduling Research in Non-Uniform Memory Access Architectures", "comment": null, "summary": "Data-intensive scientific workflows increasingly rely on high-performance computing (HPC) systems, complementing traditional Grid and Cloud platforms. However, workflow scheduling on HPC infrastructures remains challenging due to the prevalence of non-uniform memory access (NUMA) architectures. These systems require schedulers to account for data locality not only across distributed environments but also within each node. Modern HPC nodes integrate multiple NUMA domains and heterogeneous memory regions, such as high-bandwidth memory (HBM) and DRAM, and frequently attach accelerators (GPUs or FPGAs) and network interface cards (NICs) to specific NUMA nodes. This design increases the variability of data-access latency and complicates the placement of both tasks and data. Despite these constraints, most workflow scheduling strategies were originally developed for Grid or Cloud environments and rarely incorporate NUMA-aware considerations. To address this gap, this work introduces nFlows, a NUMA-aware Workflow Execution Runtime System that enables the modeling, bare-metal execution, simulation, and validation of scheduling algorithms for data-intensive workflows on NUMA-based HPC systems. The system's design, implementation, and validation methodology are presented. nFlows supports the construction of simulation models and their direct execution on physical systems, enabling studies of NUMA effects on scheduling, the design of NUMA-aware algorithms, the analysis of data-movement behavior, the identification of performance bottlenecks, and the exploration of in-memory workflow execution.", "AI": {"tldr": "nFlows\u662f\u4e00\u4e2aNUMA\u611f\u77e5\u7684\u5de5\u4f5c\u6d41\u6267\u884c\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728NUMA\u67b6\u6784\u7684HPC\u7cfb\u7edf\u4e0a\u5efa\u6a21\u3001\u6267\u884c\u3001\u6a21\u62df\u548c\u9a8c\u8bc1\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u6d41\u7684\u8c03\u5ea6\u7b97\u6cd5\u3002", "motivation": "\u73b0\u4ee3HPC\u7cfb\u7edf\u666e\u904d\u91c7\u7528NUMA\u67b6\u6784\uff0c\u5305\u542b\u591a\u4e2aNUMA\u57df\u548c\u5f02\u6784\u5185\u5b58\u533a\u57df\uff0c\u8fd9\u589e\u52a0\u4e86\u6570\u636e\u8bbf\u95ee\u5ef6\u8fdf\u7684\u53d8\u5f02\u6027\uff0c\u4f7f\u4efb\u52a1\u548c\u6570\u636e\u653e\u7f6e\u590d\u6742\u5316\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u5de5\u4f5c\u6d41\u8c03\u5ea6\u7b56\u7565\u662f\u4e3aGrid\u6216Cloud\u73af\u5883\u8bbe\u8ba1\u7684\uff0c\u5f88\u5c11\u8003\u8651NUMA\u611f\u77e5\u3002", "method": "\u5f00\u53d1\u4e86nFlows\u7cfb\u7edf\uff0c\u652f\u6301\u6784\u5efa\u6a21\u62df\u6a21\u578b\u5e76\u5728\u7269\u7406\u7cfb\u7edf\u4e0a\u76f4\u63a5\u6267\u884c\uff0c\u80fd\u591f\u7814\u7a76NUMA\u5bf9\u8c03\u5ea6\u7684\u5f71\u54cd\u3001\u8bbe\u8ba1NUMA\u611f\u77e5\u7b97\u6cd5\u3001\u5206\u6790\u6570\u636e\u79fb\u52a8\u884c\u4e3a\u3001\u8bc6\u522b\u6027\u80fd\u74f6\u9888\uff0c\u5e76\u63a2\u7d22\u5185\u5b58\u5185\u5de5\u4f5c\u6d41\u6267\u884c\u3002", "result": "\u63d0\u51fa\u4e86nFlows\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5bf9NUMA\u67b6\u6784HPC\u7cfb\u7edf\u4e0a\u7684\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u6d41\u8fdb\u884c\u5efa\u6a21\u548c\u8c03\u5ea6\u7b97\u6cd5\u7814\u7a76\u3002", "conclusion": "nFlows\u586b\u8865\u4e86NUMA\u611f\u77e5\u5de5\u4f5c\u6d41\u8c03\u5ea6\u5728HPC\u7cfb\u7edf\u4e2d\u7684\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76NUMA\u6548\u5e94\u3001\u8bbe\u8ba1\u4f18\u5316\u7b97\u6cd5\u548c\u5206\u6790\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.19925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19925", "abs": "https://arxiv.org/abs/2511.19925", "authors": ["Qiyao Wei", "Edward Morrell", "Lea Goetz", "Mihaela van der Schaar"], "title": "Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity", "comment": null, "summary": "Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u8f93\u51fa\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u5728\u751f\u6210\u6210\u672c\u3001\u9886\u57df\u9002\u7528\u6027\u548c\u7b49\u4ef7\u5b9a\u4e49\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30LLM\u751f\u6210\u6587\u672c\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff1a\u53ef\u80fd\u66f4\u5173\u6ce8\u8bed\u6cd5\u6216\u8bcd\u6c47\u5f62\u5f0f\u800c\u975e\u8bed\u4e49\u5185\u5bb9\uff0c\u73b0\u6709\u57fa\u51c6\u4f9d\u8d56\u4e3b\u89c2\u4eba\u5de5\u5224\u65ad\u5bfc\u81f4\u751f\u6210\u6210\u672c\u9ad8\uff0c\u9886\u57df\u9002\u7528\u6027\u6709\u9650\uff0c\u4e14\u8bed\u4e49\u7b49\u4ef7\u5b9a\u4e49\u4e0d\u660e\u786e\u3002", "method": "\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u8bed\u4e49\u76f8\u4f3c\u6216\u4e0d\u540c\u7684\u81ea\u7136\u8bed\u8a00\u9648\u8ff0\u5bf9\uff0c\u5c06\u4e0d\u540c\u5bf9\u5206\u4e3a\u56db\u4e2a\u5b50\u7c7b\u578b\uff0c\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\uff08\u901a\u7528\u77e5\u8bc6\u3001\u751f\u7269\u533b\u5b66\u3001\u91d1\u878d\u3001\u751f\u7269\u5b66\uff09\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4f20\u7edfNLP\u8bc4\u5206\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bed\u4e49\u53d8\u5316\u7684\u5b50\u7c7b\u578b\u4ee5\u53ca\u57fa\u51c6\u9886\u57df\u90fd\u4f1a\u5f71\u54cd\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\u59cb\u7ec8\u8868\u73b0\u6700\u4f18\u3002\u7ed3\u679c\u5bf9\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u68c0\u6d4b\u6587\u672c\u8bed\u4e49\u5185\u5bb9\u5177\u6709\u91cd\u8981\u542f\u793a\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u57fa\u51c6\u751f\u6210\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027\uff0c\u63ed\u793a\u4e86\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u7684\u6027\u80fd\u53d7\u8bed\u4e49\u53d8\u5316\u7c7b\u578b\u548c\u9886\u57df\u5f71\u54cd\uff0c\u4e3aLLM\u4f5c\u4e3a\u8bed\u4e49\u8bc4\u5224\u8005\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2511.19933", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19933", "abs": "https://arxiv.org/abs/2511.19933", "authors": ["Vaishali Vinay"], "title": "A System-Level Taxonomy of Failure Modes in Large Language Model Applications", "comment": null, "summary": "Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b15\u79cd\u9690\u85cf\u6545\u969c\u6a21\u5f0f\u7684\u7cfb\u7edf\u7ea7\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86LLM\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u63a2\u8ba8\u4e86\u8bc4\u4f30\u4e0e\u76d1\u63a7\u5b9e\u8df5\u7684\u5dee\u8ddd\uff0c\u6700\u540e\u4e3a\u6784\u5efa\u53ef\u9760\u3001\u53ef\u7ef4\u62a4\u548c\u6210\u672c\u611f\u77e5\u7684LLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6b63\u88ab\u5feb\u901f\u96c6\u6210\u5230\u51b3\u7b56\u652f\u6301\u5de5\u5177\u548c\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4f46\u5b83\u4eec\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u5176\u6545\u969c\u6a21\u5f0f\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6709\u6839\u672c\u6027\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u7684\u6545\u969c\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff0c\u5305\u542b\u591a\u6b65\u63a8\u7406\u6f02\u79fb\u3001\u6f5c\u5728\u4e0d\u4e00\u81f4\u6027\u3001\u4e0a\u4e0b\u6587\u8fb9\u754c\u9000\u5316\u3001\u9519\u8bef\u5de5\u5177\u8c03\u7528\u3001\u7248\u672c\u6f02\u79fb\u548c\u6210\u672c\u9a71\u52a8\u6027\u80fd\u5d29\u6e83\u7b4915\u79cd\u9690\u85cf\u6545\u969c\u6a21\u5f0f\u3002", "result": "\u5206\u6790\u4e86\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u4e0e\u751f\u4ea7\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u6d4b\u91cf\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5bf9\u7a33\u5b9a\u6027\u3001\u53ef\u91cd\u73b0\u6027\u3001\u6f02\u79fb\u548c\u5de5\u4f5c\u6d41\u96c6\u6210\u63d0\u4f9b\u7684\u4fe1\u606f\u6709\u9650\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u53ef\u9760\u6027\u89c6\u4e3a\u7cfb\u7edf\u5de5\u7a0b\u95ee\u9898\u800c\u975e\u7eaf\u6a21\u578b\u4e2d\u5fc3\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u5173\u4e8e\u8bc4\u4f30\u65b9\u6cd5\u3001AI\u7cfb\u7edf\u9c81\u68d2\u6027\u548c\u53ef\u9760LLM\u90e8\u7f72\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5206\u6790\u57fa\u7840\u3002"}}
{"id": "2511.19949", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.19949", "abs": "https://arxiv.org/abs/2511.19949", "authors": ["Qingda Hu", "Xinjun Yang", "Feifei Li", "Junru Li", "Ya Lin", "Yuqi Zhou", "Yicong Zhu", "Junwei Zhang", "Rongbiao Xie", "Ling Zhou", "Bin Wu", "Wenchao Zhou"], "title": "PolarStore: High-Performance Data Compression for Large-Scale Cloud-Native Databases", "comment": "13 pages, accepted by FAST'26", "summary": "In recent years, resource elasticity and cost optimization have become essential for RDBMSs. While cloud-native RDBMSs provide elastic computing resources via disaggregated computing and storage, storage costs remain a critical user concern. Consequently, data compression emerges as an effective strategy to reduce storage costs. However, existing compression approaches in RDBMSs present a stark trade-off: software-based approaches incur significant performance overheads, while hardware-based alternatives lack the flexibility required for diverse database workloads. In this paper, we present PolarStore, a compressed shared storage system for cloud-native RDBMSs. PolarStore employs a dual-layer compression mechanism that combines in-storage compression in PolarCSD hardware with lightweight compression in software. This design leverages the strengths of both approaches. PolarStore also incorporates database-oriented optimizations to maintain high performance on critical I/O paths. Drawing from large-scale deployment experiences, we also introduce hardware improvements for PolarCSD to ensure host-level stability and propose a compression-aware scheduling scheme to improve cluster-level space efficiency. PolarStore is currently deployed on thousands of storage servers within PolarDB, managing over 100 PB of data. It achieves a compression ratio of 3.55 and reduces storage costs by approximately 60%. Remarkably, these savings are achieved while maintaining performance comparable to uncompressed clusters.", "AI": {"tldr": "PolarStore\u662f\u4e00\u4e2a\u7528\u4e8e\u4e91\u539f\u751f\u5173\u7cfb\u6570\u636e\u5e93\u7684\u538b\u7f29\u5171\u4eab\u5b58\u50a8\u7cfb\u7edf\uff0c\u901a\u8fc7\u8f6f\u786c\u4ef6\u7ed3\u5408\u7684\u538b\u7f29\u673a\u5236\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u6210\u672c\u3002", "motivation": "\u4e91\u539f\u751fRDBMS\u867d\u7136\u63d0\u4f9b\u4e86\u5f39\u6027\u8ba1\u7b97\u8d44\u6e90\uff0c\u4f46\u5b58\u50a8\u6210\u672c\u4ecd\u7136\u662f\u5173\u952e\u95ee\u9898\u3002\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u5f00\u9500\u5927\u6216\u7075\u6d3b\u6027\u4e0d\u8db3\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u7ea7\u538b\u7f29\u673a\u5236\uff1a\u786c\u4ef6\u5c42\u4f7f\u7528PolarCSD\u8fdb\u884c\u5b58\u50a8\u5185\u538b\u7f29\uff0c\u8f6f\u4ef6\u5c42\u8fdb\u884c\u8f7b\u91cf\u7ea7\u538b\u7f29\uff0c\u5e76\u7ed3\u5408\u6570\u636e\u5e93\u5bfc\u5411\u7684\u4f18\u5316\u548c\u538b\u7f29\u611f\u77e5\u8c03\u5ea6\u65b9\u6848\u3002", "result": "\u5df2\u5728\u6570\u5343\u53f0\u5b58\u50a8\u670d\u52a1\u5668\u4e0a\u90e8\u7f72\uff0c\u7ba1\u7406\u8d85\u8fc7100PB\u6570\u636e\uff0c\u538b\u7f29\u6bd4\u8fbe\u52303.55\uff0c\u5b58\u50a8\u6210\u672c\u964d\u4f4e\u7ea660%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u672a\u538b\u7f29\u96c6\u7fa4\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "PolarStore\u6210\u529f\u89e3\u51b3\u4e86\u4e91\u539f\u751fRDBMS\u4e2d\u538b\u7f29\u6027\u80fd\u4e0e\u7075\u6d3b\u6027\u7684\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5b58\u50a8\u6210\u672c\u8282\u7ea6\u800c\u4e0d\u727a\u7272\u6027\u80fd\u3002"}}
{"id": "2511.20100", "categories": ["cs.DC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20100", "abs": "https://arxiv.org/abs/2511.20100", "authors": ["Xinguo Zhu", "Shaohui Peng", "Jiaming Guo", "Yunji Chen", "Qi Guo", "Yuanbo Wen", "Hang Qin", "Ruizhi Chen", "Qirui Zhou", "Ke Gao", "Yanjun Wu", "Chen Zhao", "Ling Li"], "title": "QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based High-Performance GPU Kernel Generation", "comment": "9 pages, 2 figures, accepted by AAAI 2026", "summary": "Developing high-performance GPU kernels is critical for AI and scientific computing, but remains challenging due to its reliance on expert crafting and poor portability. While LLMs offer promise for automation, both general-purpose and finetuned LLMs suffer from two fundamental and conflicting limitations: correctness and efficiency. The key reason is that existing LLM-based approaches directly generate the entire optimized low-level programs, requiring exploration of an extremely vast space encompassing both optimization policies and implementation codes. To address the challenge of exploring an intractable space, we propose Macro Thinking Micro Coding (MTMC), a hierarchical framework inspired by the staged optimization strategy of human experts. It decouples optimization strategy from implementation details, ensuring efficiency through high-level strategy and correctness through low-level implementation. Specifically, Macro Thinking employs reinforcement learning to guide lightweight LLMs in efficiently exploring and learning semantic optimization strategies that maximize hardware utilization. Micro Coding leverages general-purpose LLMs to incrementally implement the stepwise optimization proposals from Macro Thinking, avoiding full-kernel generation errors. Together, they effectively navigate the vast optimization space and intricate implementation details, enabling LLMs for high-performance GPU kernel generation. Comprehensive results on widely adopted benchmarks demonstrate the superior performance of MTMC on GPU kernel generation in both accuracy and running time. On KernelBench, MTMC achieves near 100% and 70% accuracy at Levels 1-2 and 3, over 50% than SOTA general-purpose and domain-finetuned LLMs, with up to 7.3x speedup over LLMs, and 2.2x over expert-optimized PyTorch Eager kernels. On the more challenging TritonBench, MTMC attains up to 59.64% accuracy and 34x speedup.", "AI": {"tldr": "MTMC\u662f\u4e00\u4e2a\u5206\u5c42\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4f18\u5316\u7b56\u7565\u4e0e\u5b9e\u73b0\u7ec6\u8282\u89e3\u8026\u6765\u89e3\u51b3GPU\u5185\u6838\u751f\u6210\u7684\u6311\u6218\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6307\u5bfc\u8f7b\u91cf\u7ea7LLM\u63a2\u7d22\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u5229\u7528\u901a\u7528LLM\u9010\u6b65\u5b9e\u73b0\u4f18\u5316\u65b9\u6848\u3002", "motivation": "\u5f00\u53d1\u9ad8\u6027\u80fdGPU\u5185\u6838\u5bf9AI\u548c\u79d1\u5b66\u8ba1\u7b97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709LLM\u65b9\u6cd5\u5728\u6b63\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5b58\u5728\u51b2\u7a81\u9650\u5236\uff0c\u9700\u8981\u63a2\u7d22\u6781\u5176\u5e9e\u5927\u7684\u4f18\u5316\u7a7a\u95f4\u548c\u5b9e\u73b0\u4ee3\u7801\u7a7a\u95f4\u3002", "method": "\u63d0\u51faMacro Thinking Micro Coding\u6846\u67b6\uff1aMacro Thinking\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6307\u5bfc\u8f7b\u91cf\u7ea7LLM\u5b66\u4e60\u8bed\u4e49\u4f18\u5316\u7b56\u7565\uff1bMicro Coding\u5229\u7528\u901a\u7528LLM\u9010\u6b65\u5b9e\u73b0\u4f18\u5316\u63d0\u6848\uff0c\u907f\u514d\u5168\u5185\u6838\u751f\u6210\u9519\u8bef\u3002", "result": "\u5728KernelBench\u4e0a\uff0cMTMC\u5728Levels 1-2\u8fbe\u5230\u8fd1100%\u51c6\u786e\u7387\uff0cLevel 3\u8fbe\u523070%\u51c6\u786e\u7387\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u534750%\u4ee5\u4e0a\uff0c\u901f\u5ea6\u6bd4LLM\u5feb7.3\u500d\uff0c\u6bd4\u4e13\u5bb6\u4f18\u5316\u7684PyTorch Eager\u5185\u6838\u5feb2.2\u500d\u3002\u5728TritonBench\u4e0a\u8fbe\u523059.64%\u51c6\u786e\u7387\u548c34\u500d\u52a0\u901f\u3002", "conclusion": "MTMC\u901a\u8fc7\u5206\u5c42\u65b9\u6cd5\u6709\u6548\u5bfc\u822a\u5e9e\u5927\u7684\u4f18\u5316\u7a7a\u95f4\u548c\u590d\u6742\u7684\u5b9e\u73b0\u7ec6\u8282\uff0c\u4f7fLLM\u80fd\u591f\u751f\u6210\u9ad8\u6027\u80fdGPU\u5185\u6838\uff0c\u5728\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u65b9\u9762\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.20172", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20172", "abs": "https://arxiv.org/abs/2511.20172", "authors": ["Xinjun Yang", "Qingda Hu", "Junru Li", "Feifei Li", "Yuqi Zhou", "Yicong Zhu", "Qiuru Lin", "Jian Dai", "Yang Kong", "Jiayu Zhang", "Guoqiang Xu", "Qiang Liu"], "title": "Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM KVCache Management", "comment": "13 pages, accepted by SIGMOD'26", "summary": "The rapid increase in LLM model sizes and the growing demand for long-context inference have made memory a critical bottleneck in GPU-accelerated serving systems. Although high-bandwidth memory (HBM) on GPUs offers fast access, its limited capacity necessitates reliance on host memory (CPU DRAM) to support larger working sets such as the KVCache. However, the maximum DRAM capacity is constrained by the limited number of memory channels per CPU socket. To overcome this limitation, current systems often adopt RDMA-based disaggregated memory pools, which introduce significant challenges including high access latency, complex communication protocols, and synchronization overhead. Fortunately, the emerging CXL technology introduces new opportunities in KVCache design. In this paper, we propose Beluga, a novel memory architecture that enables GPUs and CPUs to access a shared, large-scale memory pool through CXL switches. By supporting native load/store access semantics over the CXL fabric, our design delivers near-local memory latency, while reducing programming complexity and minimizing synchronization overhead. We conduct a systematic characterization of a commercial CXL switch-based memory pool and propose a set of design guidelines. Based on Beluga, we design and implement Beluga-KVCache, a system tailored for managing the large-scale KVCache in LLM inference. Beluga-KVCache achieves an 89.6% reduction in Time-To-First-Token (TTFT) and 7.35x throughput improvement in the vLLM inference engine compared to RDMA-based solutions. To the best of our knowledge, Beluga is the first system that enables GPUs to directly access large-scale memory pools through CXL switches, marking a significant step toward low-latency, shared access to vast memory resources by GPUs.", "AI": {"tldr": "Beluga\u662f\u4e00\u79cd\u57fa\u4e8eCXL\u6280\u672f\u7684\u65b0\u578b\u5185\u5b58\u67b6\u6784\uff0c\u4f7fGPU\u548cCPU\u80fd\u591f\u901a\u8fc7CXL\u4ea4\u6362\u673a\u8bbf\u95ee\u5171\u4eab\u7684\u5927\u89c4\u6a21\u5185\u5b58\u6c60\uff0c\u663e\u8457\u964d\u4f4eLLM\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\u3002", "motivation": "LLM\u6a21\u578b\u89c4\u6a21\u5feb\u901f\u589e\u957f\u548c\u5bf9\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u9700\u6c42\u4f7f\u5185\u5b58\u6210\u4e3aGPU\u52a0\u901f\u670d\u52a1\u7cfb\u7edf\u7684\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709RDMA\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u9ad8\u5ef6\u8fdf\u3001\u590d\u6742\u901a\u4fe1\u534f\u8bae\u548c\u540c\u6b65\u5f00\u9500\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faBeluga\u5185\u5b58\u67b6\u6784\uff0c\u5229\u7528CXL\u4ea4\u6362\u673a\u5b9e\u73b0GPU\u548cCPU\u5bf9\u5171\u4eab\u5185\u5b58\u6c60\u7684\u539f\u751fload/store\u8bbf\u95ee\u8bed\u4e49\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1Beluga-KVCache\u7cfb\u7edf\u6765\u7ba1\u7406LLM\u63a8\u7406\u4e2d\u7684\u5927\u89c4\u6a21KVCache\u3002", "result": "\u4e0e\u57fa\u4e8eRDMA\u7684\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\uff0cBeluga-KVCache\u5728vLLM\u63a8\u7406\u5f15\u64ce\u4e2d\u5b9e\u73b0\u4e8689.6%\u7684\u9996\u4ee4\u724c\u65f6\u95f4\u51cf\u5c11\u548c7.35\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "Beluga\u662f\u9996\u4e2a\u901a\u8fc7CXL\u4ea4\u6362\u673a\u4f7fGPU\u76f4\u63a5\u8bbf\u95ee\u5927\u89c4\u6a21\u5185\u5b58\u6c60\u7684\u7cfb\u7edf\uff0c\u4e3a\u5b9e\u73b0GPU\u4f4e\u5ef6\u8fdf\u5171\u4eab\u8bbf\u95ee\u6d77\u91cf\u5185\u5b58\u8d44\u6e90\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.20200", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20200", "abs": "https://arxiv.org/abs/2511.20200", "authors": ["Yitian Huang", "Yuxuan Lei", "Jianxun Lian", "Hao Liao"], "title": "Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025", "comment": null, "summary": "This report presents the solution and results of our team MSRA\\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u6846\u67b6\uff0c\u5728CPDC 2025\u7ade\u8d5b\u4e2d\u7edf\u4e00\u6539\u8fdb\u4e86GPU\u548cAPI\u8d5b\u9053\u3002\u6838\u5fc3\u5305\u62ec\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff08\u52a8\u6001\u5de5\u5177\u526a\u679d\u3001\u89d2\u8272\u88c1\u526a\uff09\u548cGRPO\u8bad\u7ec3\uff08\u5f3a\u5316\u5b66\u4e60\u66ff\u4ee3\u76d1\u7763\u5fae\u8c03\uff09\uff0c\u6700\u7ec8\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\u3002", "motivation": "\u89e3\u51b3\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u5de5\u5177\u8c03\u7528\u7a33\u5b9a\u6027\u3001\u6267\u884c\u53ef\u9760\u6027\u548c\u89d2\u8272\u626e\u6f14\u6307\u5bfc\u7684\u95ee\u9898\uff0c\u540c\u65f6\u7f13\u89e3\u5c0f\u6837\u672c\u8fc7\u62df\u5408\uff0c\u63d0\u5347\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u6027\u80fd\u3002", "method": "1. \u4e0a\u4e0b\u6587\u5de5\u7a0b\uff1a\u52a8\u6001\u5de5\u5177\u526a\u679d\u548c\u89d2\u8272\u88c1\u526a\u8fdb\u884c\u8f93\u5165\u538b\u7f29\uff0c\u7ed3\u5408\u53c2\u6570\u5f52\u4e00\u5316\u548c\u51fd\u6570\u5408\u5e76\u7b49\u540e\u5904\u7406\u6280\u672f\uff1b2. GPU\u8d5b\u9053\u91c7\u7528GRPO\u8bad\u7ec3\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u66ff\u4ee3\u76d1\u7763\u5fae\u8c03\uff0c\u76f4\u63a5\u4f18\u5316\u5956\u52b1\u4fe1\u53f7\u3002", "result": "\u56e2\u961f\u5728\u6700\u7ec8\u8bc4\u4f30\u4e2d\u6392\u540d\uff1aTask 2 API\u7b2c1\u540d\uff0cTask 1 API\u7b2c2\u540d\uff0cTask 3 API\u548cGPU\u8d5b\u9053\u5747\u7b2c3\u540d\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u4e0a\u4e0b\u6587\u5de5\u7a0b\u548cGRPO\u8bad\u7ec3\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5728CPDC 2025\u7ade\u8d5b\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u7ee9\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2511.20216", "categories": ["cs.AI", "cs.CE", "cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20216", "abs": "https://arxiv.org/abs/2511.20216", "authors": ["Haebin Seong", "Sungmin Kim", "Minchan Kim", "Yongjun Cho", "Myunchul Joe", "Suhwan Choi", "Jaeyoon Jung", "Jiyong Youn", "Yoonshik Kim", "Samwoo Seong", "Yubeen Park", "Youngjae Yu", "Yunsung Lee"], "title": "CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents", "comment": null, "summary": "Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.", "AI": {"tldr": "CostNav\u662f\u9996\u4e2a\u5fae\u5bfc\u822a\u7ecf\u6d4e\u6d4b\u8bd5\u5e73\u53f0\uff0c\u901a\u8fc7\u6210\u672c-\u6536\u76ca\u5206\u6790\u8bc4\u4f30\u81ea\u4e3b\u914d\u9001\u673a\u5668\u4eba\u7684\u5546\u4e1a\u53ef\u884c\u6027\uff0c\u63ed\u793a\u5bfc\u822a\u7814\u7a76\u6307\u6807\u4e0e\u5546\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u5bfc\u822a\u57fa\u51c6\u53ea\u5173\u6ce8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5ffd\u89c6\u4e86\u5546\u4e1a\u90e8\u7f72\u6240\u9700\u7684\u7ecf\u6d4e\u53ef\u884c\u6027\uff0c\u8fd9\u5bf9\u81ea\u4e3b\u914d\u9001\u673a\u5668\u4eba\u7684\u5546\u4e1a\u5316\u81f3\u5173\u91cd\u8981\u3002", "method": "CostNav\u5efa\u6a21\u5b8c\u6574\u7ecf\u6d4e\u751f\u547d\u5468\u671f\uff0c\u5305\u62ec\u786c\u4ef6\u3001\u8bad\u7ec3\u3001\u80fd\u6e90\u3001\u7ef4\u62a4\u6210\u672c\u548c\u914d\u9001\u6536\u5165\uff0c\u4f7f\u7528\u884c\u4e1a\u53c2\u6570\uff0c\u4ece\u7f29\u5c0f\u89c4\u6a21\u6a21\u62df\u6269\u5c55\u5230\u73b0\u5b9e\u914d\u9001\u573a\u666f\u3002", "result": "\u57fa\u7ebf\u6a21\u578b\u8fbe\u523043.0%\u7684\u670d\u52a1\u6c34\u5e73\u534f\u8bae\u5408\u89c4\u7387\uff0c\u4f46\u5546\u4e1a\u4e0a\u4e0d\u53ef\u884c\uff1a\u6bcf\u6b21\u8fd0\u884c\u4e8f\u635f30.009\u7f8e\u5143\u4e14\u65e0\u76c8\u4e8f\u5e73\u8861\u70b9\uff0c\u78b0\u649e\u5bfc\u81f4\u7684\u7ef4\u62a4\u6210\u672c\u5360\u8fd0\u884c\u6210\u672c\u768499.7%\u3002", "conclusion": "CostNav\u586b\u8865\u4e86\u5bfc\u822a\u7814\u7a76\u4e0e\u5546\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u8bc4\u4f30\u57fa\u4e8e\u89c4\u5219\u7684\u5bfc\u822a\u3001\u6a21\u4eff\u5b66\u4e60\u548c\u6210\u672c\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u652f\u6301\u8de8\u5bfc\u822a\u8303\u5f0f\u7684\u7ecf\u6d4e\u6743\u8861\u51b3\u7b56\u3002"}}
{"id": "2511.20297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20297", "abs": "https://arxiv.org/abs/2511.20297", "authors": ["Shashank Kirtania", "Param Biyani", "Priyanshu Gupta", "Yasharth Bajpai", "Roshni Iyer", "Sumit Gulwani", "Gustavo Soares"], "title": "Improving Language Agents through BREW", "comment": null, "summary": "Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $\u03c4^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\\%$ improvement in task precision, $10-15\\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.", "AI": {"tldr": "BREW\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u548c\u7cbe\u70bc\u7ecf\u9a8c\u5b66\u4e60\u77e5\u8bc6\u5e93\u6765\u4f18\u5316LLM\u667a\u80fd\u4f53\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4efb\u52a1\u7cbe\u5ea6\u548c\u51cf\u5c11API\u8c03\u7528\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8ePPO\u548cGRPO\u7684\u667a\u80fd\u4f53\u8bad\u7ec3\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u4e14\u751f\u6210\u7684\u7b56\u7565\u96be\u4ee5\u89e3\u91ca\u3001\u9002\u5e94\u6216\u589e\u91cf\u6539\u8fdb\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5b9e\u7528\u3001\u53ef\u89e3\u91ca\u7684\u667a\u80fd\u4f53\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5f15\u5165BREW\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u5e93\u6784\u5efa\u548c\u7cbe\u70bc\u6765\u4f18\u5316\u667a\u80fd\u4f53\u3002\u91c7\u7528\u6709\u6548\u7684\u8bb0\u5fc6\u5206\u533a\u65b9\u6cd5\u63d0\u9ad8\u68c0\u7d22\u6548\u7387\uff0c\u4f7f\u7528\u4efb\u52a1\u8bc4\u5206\u5668\u548c\u884c\u4e3a\u51c6\u5219\u5b66\u4e60\u6d1e\u5bdf\uff0c\u5e76\u5229\u7528\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "result": "\u5728OSWorld\u3001\u03c4\u00b2Bench\u548cSpreadsheetBench\u7b49\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBREW\u5b9e\u73b0\u4e8610-20%\u7684\u4efb\u52a1\u7cbe\u5ea6\u63d0\u5347\uff0c10-15%\u7684API/\u5de5\u5177\u8c03\u7528\u51cf\u5c11\uff0c\u6267\u884c\u65f6\u95f4\u66f4\u5feb\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "BREW\u5c06\u77e5\u8bc6\u5e93\u786e\u7acb\u4e3a\u6a21\u5757\u5316\u3001\u53ef\u63a7\u7684\u667a\u80fd\u4f53\u4f18\u5316\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u900f\u660e\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u884c\u4e3a\u5851\u9020\u673a\u5236\uff0c\u4e0e\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u9759\u6001\u4e0a\u4e0b\u6587\u7684\u5148\u524d\u5de5\u4f5c\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\u3002"}}
{"id": "2511.20321", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20321", "abs": "https://arxiv.org/abs/2511.20321", "authors": ["Patrick Kenny"], "title": "Active Inference in Discrete State Spaces from First Principles", "comment": "56 pages", "summary": "We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u6f84\u6e05\u4e3b\u52a8\u63a8\u7406\u7684\u6982\u5ff5\uff0c\u5c06\u5176\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u5206\u79bb\uff0c\u63d0\u51fa\u5728\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e3b\u52a8\u63a8\u7406\u7684\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u8868\u8ff0\u4e3a\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5e76\u53ef\u901a\u8fc7\u6807\u51c6\u5e73\u5747\u573a\u65b9\u6cd5\u6c42\u89e3\u3002", "motivation": "\u6f84\u6e05\u4e3b\u52a8\u63a8\u7406\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5c55\u793a\u4e3b\u52a8\u63a8\u7406\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u671f\u671b\u81ea\u7531\u80fd\u6982\u5ff5\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u3002", "method": "\u5c06\u4e3b\u52a8\u63a8\u7406\u7684\u4f18\u5316\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u6807\u51c6\u5e73\u5747\u573a\u65b9\u6cd5\u6c42\u89e3\uff0c\u63d0\u51fa\u7684\u611f\u77e5/\u884c\u52a8\u6563\u5ea6\u51c6\u5219\u5728\u5efa\u6a21\u611f\u77e5\u65f6\u4e0e\u53d8\u5206\u81ea\u7531\u80fd\u4e00\u81f4\uff0c\u5728\u5efa\u6a21\u884c\u52a8\u65f6\u4e0e\u671f\u671b\u81ea\u7531\u80fd\u6cdb\u51fd\u76f8\u5dee\u4e00\u4e2a\u71b5\u6b63\u5219\u5316\u9879\u3002", "result": "\u8bc1\u660e\u4e86\u4e3b\u52a8\u63a8\u7406\u53ef\u4ee5\u5728\u4e0d\u8bc9\u8bf8\u671f\u671b\u81ea\u7531\u80fd\u6982\u5ff5\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u4e2d\u6709\u6548\u3002", "conclusion": "\u4e3b\u52a8\u63a8\u7406\u53ef\u4ee5\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u5206\u79bb\uff0c\u901a\u8fc7\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u65b9\u6cd5\u5b9e\u73b0\uff0c\u4e3a\u7406\u89e3\u4e3b\u52a8\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2511.20422", "categories": ["cs.AI", "cs.CV", "cs.GR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20422", "abs": "https://arxiv.org/abs/2511.20422", "authors": ["Bo Pang", "Chenxi Xu", "Jierui Ren", "Guoping Wang", "Sheng Li"], "title": "VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning", "comment": null, "summary": "Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.", "AI": {"tldr": "VibraVerse\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u51e0\u4f55-\u58f0\u5b66\u5bf9\u9f50\u6570\u636e\u96c6\uff0c\u901a\u8fc7CLASP\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5efa\u7acb3D\u51e0\u4f55\u4e0e\u58f0\u5b66\u4fe1\u53f7\u4e4b\u95f4\u7684\u56e0\u679c\u5bf9\u5e94\u5173\u7cfb\uff0c\u4e3a\u7269\u7406\u4e00\u81f4\u7684\u591a\u6a21\u6001\u5b66\u4e60\u63d0\u4f9b\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\u7f3a\u4e4f\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5ffd\u89c6\u4e86\u7269\u4f53\u51e0\u4f55\u3001\u6750\u6599\u3001\u632f\u52a8\u6a21\u5f0f\u548c\u4ea7\u751f\u58f0\u97f3\u4e4b\u95f4\u7684\u5185\u5728\u56e0\u679c\u5173\u7cfb\u3002\u9700\u8981\u5efa\u7acb\u57fa\u4e8e\u7269\u7406\u5b9a\u5f8b\u800c\u975e\u7edf\u8ba1\u76f8\u5173\u6027\u7684\u611f\u77e5\u6a21\u578b\u3002", "method": "\u6784\u5efaVibraVerse\u6570\u636e\u96c6\uff0c\u5305\u542b3D\u6a21\u578b\u7684\u7269\u7406\u5c5e\u6027\uff08\u5bc6\u5ea6\u3001\u6768\u6c0f\u6a21\u91cf\u3001\u6cca\u677e\u6bd4\uff09\u548c\u4f53\u79ef\u51e0\u4f55\uff0c\u8ba1\u7b97\u6a21\u6001\u7279\u5f81\u9891\u7387\u548c\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u649e\u51fb\u58f0\u97f3\u5408\u6210\u3002\u4f7f\u7528CLASP\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5b9e\u73b0\u8de8\u6a21\u6001\u5bf9\u9f50\u3002", "result": "\u5728\u51e0\u4f55\u5230\u58f0\u97f3\u9884\u6d4b\u3001\u58f0\u97f3\u5f15\u5bfc\u5f62\u72b6\u91cd\u5efa\u548c\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u7b49\u57fa\u51c6\u4efb\u52a1\u4e0a\uff0c\u57fa\u4e8eVibraVerse\u8bad\u7ec3\u7684\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8de8\u6a21\u6001\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "VibraVerse\u4e3a\u7269\u7406\u4e00\u81f4\u548c\u56e0\u679c\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u5b66\u4e60\u5efa\u7acb\u4e86\u57fa\u51c6\uff0c\u4e3a\u58f0\u97f3\u5f15\u5bfc\u7684\u5177\u8eab\u611f\u77e5\u548c\u7269\u7406\u4e16\u754c\u7406\u89e3\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6570\u636e\u96c6\u5c06\u5f00\u6e90\u3002"}}
