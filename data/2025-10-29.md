<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 36]
- [cs.DC](#cs.DC) [Total: 4]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments](https://arxiv.org/abs/2510.23899)
*Maria G. Mendoza,Addison Kalanther,Daniel Bostwick,Emma Stephan,Chinmay Maheshwari,Shankar Sastry*

Main category: cs.MA

TL;DR: 提出一个多智能体协调框架，使用异构无人机在火灾疏散中实时定位、拦截和引导疏散人员到安全区域，基于POMDP建模和PPO算法训练，显著减少疏散时间。


<details>
  <summary>Details</summary>
Motivation: 现有模型往往忽略极端压力下人类行为的心理和情感复杂性，真实火灾场景中疏散人员常因恐慌和不确定性偏离安全路线，需要无人机实时协助疏散。

Method: 采用部分可观察马尔可夫决策过程(POMDP)建模，两个异构无人机智能体(高层救援者和低层救援者)通过共享观察和互补能力协调，基于经验心理学的智能体模型捕捉恐慌对决策和移动的影响，使用PPO算法和循环策略进行训练。

Result: 仿真结果显示，无人机团队能够快速定位和拦截疏散人员，相比无无人机协助的情况，显著减少了疏散人员到达安全区域所需的时间。

Conclusion: 该多智能体协调框架有效解决了动态实时疏散支持中的挑战，无人机在不确定条件下能够成功协助人类疏散，为紧急响应提供了有前景的技术方案。

Abstract: Autonomous drone technology holds significant promise for enhancing search
and rescue operations during evacuations by guiding humans toward safety and
supporting broader emergency response efforts. However, their application in
dynamic, real-time evacuation support remains limited. Existing models often
overlook the psychological and emotional complexity of human behavior under
extreme stress. In real-world fire scenarios, evacuees frequently deviate from
designated safe routes due to panic and uncertainty. To address these
challenges, this paper presents a multi-agent coordination framework in which
autonomous Unmanned Aerial Vehicles (UAVs) assist human evacuees in real-time
by locating, intercepting, and guiding them to safety under uncertain
conditions. We model the problem as a Partially Observable Markov Decision
Process (POMDP), where two heterogeneous UAV agents, a high-level rescuer (HLR)
and a low-level rescuer (LLR), coordinate through shared observations and
complementary capabilities. Human behavior is captured using an agent-based
model grounded in empirical psychology, where panic dynamically affects
decision-making and movement in response to environmental stimuli. The
environment features stochastic fire spread, unknown evacuee locations, and
limited visibility, requiring UAVs to plan over long horizons to search for
humans and adapt in real-time. Our framework employs the Proximal Policy
Optimization (PPO) algorithm with recurrent policies to enable robust
decision-making in partially observable settings. Simulation results
demonstrate that the UAV team can rapidly locate and intercept evacuees,
significantly reducing the time required for them to reach safety compared to
scenarios without UAV assistance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents](https://arxiv.org/abs/2510.23691)
*Zihao Wang,Xujing Li,Yining Ye,Junjie Fang,Haoming Wang,Longxiang Liu,Shihao Liang,Junting Lu,Zhiyong Wu,Jiazhan Feng,Wanjun Zhong,Zili Li,Yu Wang,Yu Miao,Bo Zhou,Yuanfan Li,Hao Wang,Zhongkai Zhao,Faming Wu,Zhengxuan Jiang,Weihao Tan,Heyuan Yao,Shi Yan,Xiangyang Li,Yitao Liang,Yujia Qin,Guang Shi*

Main category: cs.AI

TL;DR: Game-TARS是一个通用游戏智能体，使用统一、可扩展的动作空间进行训练，基于人类对齐的键盘鼠标输入。通过大规模持续预训练，在开放世界Minecraft任务中达到之前最佳模型2倍的成功率，在未见过的3D网页游戏中接近人类水平，并在FPS基准测试中超越GPT-5等模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够跨异构领域（操作系统、网页、模拟游戏）进行大规模持续预训练的通用游戏智能体，克服API或GUI方法的限制。

Method: 使用统一、可扩展的动作空间锚定到人类对齐的键盘鼠标输入；在500B tokens的多样化轨迹和多模态数据上进行预训练；采用衰减持续损失减少因果混淆；使用高效的稀疏思考策略平衡推理深度和推理成本。

Result: 在开放世界Minecraft任务中成功率是之前最佳模型的2倍；在未见过的3D网页游戏中接近人类水平；在FPS基准测试中超越GPT-5、Gemini-2.5-Pro和Claude-4-Sonnet；训练时间和测试时间的扩展结果证实统一动作空间在跨游戏和多模态数据扩展时持续改进。

Conclusion: 简单、可扩展的动作表示与大规模预训练相结合，为开发具有广泛计算机使用能力的通用智能体提供了一条有前景的路径。

Abstract: We present Game-TARS, a generalist game agent trained with a unified,
scalable action space anchored to human-aligned native keyboard-mouse inputs.
Unlike API- or GUI-based approaches, this paradigm enables large-scale
continual pre-training across heterogeneous domains, including OS, web, and
simulation games. Game-TARS is pre-trained on over 500B tokens with diverse
trajectories and multimodal data. Key techniques include a decaying continual
loss to reduce causal confusion and an efficient Sparse-Thinking strategy that
balances reasoning depth and inference cost. Experiments show that Game-TARS
achieves about 2 times the success rate over the previous sota model on
open-world Minecraft tasks, is close to the generality of fresh humans in
unseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet
in FPS benchmarks. Scaling results on training-time and test-time confirm that
the unified action space sustains improvements when scaled to cross-game and
multimodal data. Our results demonstrate that simple, scalable action
representations combined with large-scale pre-training provide a promising path
toward generalist agents with broad computer-use abilities.

</details>


### [3] [AI and the Decentering of Disciplinary Creativity](https://arxiv.org/abs/2510.23734)
*Eamon Duede*

Main category: cs.AI

TL;DR: 本文探讨人工智能在科学问题解决中的作用，重点关注其对学科创造力的影响。通过区分创造性方法和创造性产品，引入学科创造力的概念，并通过数学案例说明AI可能取代而非扩展学科创造力，从而改变科学追求的价值。


<details>
  <summary>Details</summary>
Motivation: 研究人工智能在科学问题解决中的角色，特别是其对学科创造力的潜在影响，旨在理解AI技术如何改变科学实践的价值和意义。

Method: 基于创造力哲学理论，区分创造性方法和创造性产品，提出学科创造力的概念，并通过两个数学案例进行实证分析。

Result: 研究发现计算可以扩展学科创造力，但某些AI方法可能取代学科创造力，这种取代可能改变科学追求的价值。

Conclusion: AI在科学问题解决中的应用需要谨慎考虑其对学科创造力的影响，避免因技术应用而削弱科学实践的内在价值。

Abstract: This paper examines the role of artificial intelligence in scientific
problem-solving, with a focus on its implications for disciplinary creativity.
Drawing on recent work in the philosophy of creativity, I distinguish between
creative approaches and creative products, and introduce the concept of
disciplinary creativity -the creative application of discipline-specific
expertise to a valued problem within that field. Through two cases in
mathematics, I show that while computation can extend disciplinary creativity,
certain approaches involving AI can serve to displace it. This displacement has
the potential to alter (and, perhaps, diminish) the value of scientific
pursuit.

</details>


### [4] [Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability](https://arxiv.org/abs/2510.23744)
*Eline M. Bovy,Caleb Probine,Marnix Suilen,Ufuk Topcu,Nils Jansen*

Main category: cs.AI

TL;DR: 本文提出多环境POMDP（ME-POMDP）模型，处理离散模型不确定性，通过将ME-POMDP转化为对抗信念POMDP（AB-POMDP），开发精确和近似算法计算鲁棒策略。


<details>
  <summary>Details</summary>
Motivation: 当多个领域专家对问题建模存在分歧时，需要找到能在所有可能POMDP模型下都表现良好的单一鲁棒策略，最大化最坏情况下的奖励。

Method: 将ME-POMDP推广为具有初始信念集合的AB-POMDP，证明ME-POMDP可简化为仅变化转移/奖励函数或观察/奖励函数的等价形式，开发精确和基于点的近似算法。

Result: 能够在标准POMDP基准测试的多环境扩展中计算鲁棒策略。

Conclusion: ME-POMDP框架有效处理模型不确定性，通过AB-POMDP转化和相应算法能够计算多环境下的鲁棒策略。

Abstract: Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete
model uncertainty. ME-POMDPs represent a finite set of POMDPs that share the
same state, action, and observation spaces, but may arbitrarily vary in their
transition, observation, and reward models. Such models arise, for instance,
when multiple domain experts disagree on how to model a problem. The goal is to
find a single policy that is robust against any choice of POMDP within the set,
i.e., a policy that maximizes the worst-case reward across all POMDPs. We
generalize and expand on existing work in the following way. First, we show
that ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which
we call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any
arbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its
transition and reward functions or only in its observation and reward
functions, while preserving (optimal) policies. We then devise exact and
approximate (point-based) algorithms to compute robust policies for AB-POMDPs,
and thus ME-POMDPs. We demonstrate that we can compute policies for standard
POMDP benchmarks extended to the multi-environment setting.

</details>


### [5] [Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra](https://arxiv.org/abs/2510.23746)
*Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani*

Main category: cs.AI

TL;DR: 提出了一种基于测试时调优的框架，通过增强预训练transformer模型，直接从串联质谱和分子式进行端到端的从头分子结构生成，无需数据库匹配或中间步骤。


<details>
  <summary>Details</summary>
Motivation: 当前串联质谱分析方法依赖数据库匹配或需要中间片段预测的多步骤流程，难以识别参考数据库中不存在的化合物。

Method: 利用测试时调优增强预训练transformer模型，直接从串联质谱和分子式进行端到端分子结构生成，无需手动注释和中间步骤。

Result: 在两个流行基准测试NPLIB1和MassSpecGym上分别超过当前最先进方法DiffMS 100%和20%，测试时调优在MassSpecGym上比传统微调性能提升62%。

Conclusion: 该框架能够动态适应新质谱数据，即使预测与真实值有偏差，生成的分子候选结构仍然准确，为人工解释和更可靠的识别提供有价值指导。

Abstract: Tandem Mass Spectrometry enables the identification of unknown compounds in
crucial fields such as metabolomics, natural product discovery and
environmental analysis. However, current methods rely on database matching from
previously observed molecules, or on multi-step pipelines that require
intermediate fragment or fingerprint prediction. This makes finding the correct
molecule highly challenging, particularly for compounds absent from reference
databases. We introduce a framework that, by leveraging test-time tuning,
enhances the learning of a pre-trained transformer model to address this gap,
enabling end-to-end de novo molecular structure generation directly from the
tandem mass spectra and molecular formulae, bypassing manual annotations and
intermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on
two popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.
Test-time tuning on experimental spectra allows the model to dynamically adapt
to novel spectra, and the relative performance gain over conventional
fine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground
truth, the generated molecular candidates remain structurally accurate,
providing valuable guidance for human interpretation and more reliable
identification.

</details>


### [6] [Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions](https://arxiv.org/abs/2510.23772)
*Vivek Veeriah,Federico Barbero,Marcus Chiam,Xidong Feng,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Johan Obando-Ceron,Jiaxin Shi,Shaobo Hou,Satinder Singh,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 研究探讨生成式AI在象棋谜题创作中的创造力，开发了能生成具有美学吸引力、新颖性、反直觉和独特解法的象棋谜题AI系统，并由三位世界级象棋专家评估其创造性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的快速发展，需要验证其是否能够产生真正具有创造性和新颖性的输出，特别是在象棋谜题创作这一需要高度创造力的领域。

Method: 开发专门的AI系统生成象棋谜题，然后邀请三位世界知名的象棋专家（国际象棋排局大师Amatzia Avni、特级大师Jonathan Levitt和Matthew Sadler）对AI生成的谜题进行评审，评估其创造性、挑战性和美学设计。

Result: 三位象棋专家对AI生成的谜题进行了评估，选出了他们最喜欢的谜题，并解释了这些谜题在创造性、挑战水平或美学设计方面的吸引力。

Conclusion: 该研究表明生成式AI在象棋谜题创作领域能够产生具有创造性和美学价值的输出，得到了专业象棋专家的认可。

Abstract: The rapid advancement of Generative AI has raised significant questions
regarding its ability to produce creative and novel outputs. Our recent work
investigates this question within the domain of chess puzzles and presents an
AI system designed to generate puzzles characterized by aesthetic appeal,
novelty, counter-intuitive and unique solutions. We briefly discuss our method
below and refer the reader to the technical paper for more details. To assess
our system's creativity, we presented a curated booklet of AI-generated puzzles
to three world-renowned experts: International Master for chess compositions
Amatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All
three are noted authors on chess aesthetics and the evolving role of computers
in the game. They were asked to select their favorites and explain what made
them appealing, considering qualities such as their creativity, level of
challenge, or aesthetic design.

</details>


### [7] [Why Foundation Models in Pathology Are Failing](https://arxiv.org/abs/2510.23807)
*Hamid R. Tizhoosh*

Main category: cs.AI

TL;DR: 病理学基础模型在癌症诊断和预后方面存在根本性弱点，包括诊断准确性低、鲁棒性差、几何不稳定、计算需求大和安全漏洞等问题，这些源于通用基础模型假设与人体组织内在复杂性之间的概念不匹配。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在非医学领域取得了革命性进展，但在计算病理学中的快速应用未能实现预期的突破，因此需要系统评估其根本弱点。

Method: 通过分析七个相互关联的原因来识别病理学基础模型的缺陷：生物复杂性、无效的自监督、过度泛化、过度架构复杂性、缺乏领域特定创新、数据不足以及与组织切片大小相关的基本设计缺陷。

Result: 发现当前病理学基础模型在诊断准确性、鲁棒性、几何稳定性、计算效率和安全方面存在显著不足，表明这些模型与组织形态学本质存在概念性不匹配。

Conclusion: 当前病理学基础模型的概念框架需要根本性重新思考，以更好地适应人体组织的复杂特性。

Abstract: In non-medical domains, foundation models (FMs) have revolutionized computer
vision and language processing through large-scale self-supervised and
multimodal learning. Consequently, their rapid adoption in computational
pathology was expected to deliver comparable breakthroughs in cancer diagnosis,
prognostication, and multimodal retrieval. However, recent systematic
evaluations reveal fundamental weaknesses: low diagnostic accuracy, poor
robustness, geometric instability, heavy computational demands, and concerning
safety vulnerabilities. This short paper examines these shortcomings and argues
that they stem from deeper conceptual mismatches between the assumptions
underlying generic foundation modeling in mainstream AI and the intrinsic
complexity of human tissue. Seven interrelated causes are identified:
biological complexity, ineffective self-supervision, overgeneralization,
excessive architectural complexity, lack of domain-specific innovation,
insufficient data, and a fundamental design flaw related to tissue patch size.
These findings suggest that current pathology foundation models remain
conceptually misaligned with the nature of tissue morphology and call for a
fundamental rethinking of the paradigm itself.

</details>


### [8] [ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents](https://arxiv.org/abs/2510.23822)
*Zhenyu Zhang,Tianyi Chen,Weiran Xu,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: ReCAP是一个用于大语言模型的递归上下文感知推理和规划框架，通过计划前瞻分解、结构化父计划重注入和内存高效执行三种机制，解决长时程任务中的上下文漂移和目标信息丢失问题，显著提升了子目标对齐和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在处理需要多步推理和动态重规划的长时程任务时面临的挑战，包括顺序提示方法容易产生上下文漂移、目标信息丢失和重复失败循环，以及分层提示方法削弱跨级连续性或产生大量运行时开销的问题。

Method: ReCAP框架结合三种关键机制：(1)计划前瞻分解：模型生成完整子任务列表，执行第一项并优化剩余任务；(2)结构化父计划重注入：在递归返回时保持一致的跨级上下文；(3)内存高效执行：限制活动提示使成本随任务深度线性扩展。

Result: 在各种长时程推理基准测试中，ReCAP显著提高了子目标对齐和成功率，在严格pass@1协议下，同步Robotouille任务提升了32%，异步Robotouille任务提升了29%。

Conclusion: ReCAP通过将高层目标与低层动作对齐、减少冗余提示和保持跨递归的连贯上下文更新，有效解决了长时程任务中的规划问题，为大语言模型的多步推理提供了高效解决方案。

Abstract: Long-horizon tasks requiring multi-step reasoning and dynamic re-planning
remain challenging for large language models (LLMs). Sequential prompting
methods are prone to context drift, loss of goal information, and recurrent
failure cycles, while hierarchical prompting methods often weaken cross-level
continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive
Context-Aware Reasoning and Planning), a hierarchical framework with shared
context for reasoning and planning in LLMs. ReCAP combines three key
mechanisms: (i) plan-ahead decomposition, in which the model generates a full
subtask list, executes the first item, and refines the remainder; (ii)
structured re-injection of parent plans, maintaining consistent multi-level
context during recursive return; and (iii) memory-efficient execution, bounding
the active prompt so costs scale linearly with task depth. Together these
mechanisms align high-level goals with low-level actions, reduce redundant
prompting, and preserve coherent context updates across recursion. Experiments
demonstrate that ReCAP substantially improves subgoal alignment and success
rates on various long-horizon reasoning benchmarks, achieving a 32% gain on
synchronous Robotouille and a 29% improvement on asynchronous Robotouille under
the strict pass@1 protocol.

</details>


### [9] [Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models](https://arxiv.org/abs/2510.23824)
*Murad Ismayilov,Edwin Meriaux,Shuo Wen,Gregory Dudek*

Main category: cs.AI

TL;DR: 该研究探讨了多智能体路径规划中的去中心化目标分配问题，通过比较贪婪启发式、最优分配和基于大语言模型的方法，发现LLM智能体在适当提示下能达到接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 解决在去中心化条件下协调多个自主智能体在共享环境中的长期挑战，特别是在多智能体路径规划中的目标分配问题。

Method: 智能体基于环境结构化表示独立生成目标偏好排序，然后交换排序信息，通过固定的确定性冲突解决规则进行目标分配，无需协商或迭代协调。系统比较了贪婪启发式、最优分配和基于LLM的方法。

Result: LLM智能体在提供精心设计的提示和相关定量信息时，能够实现接近最优的完成时间，并持续优于传统启发式方法。

Conclusion: 研究结果强调了语言模型在多智能体路径规划中去中心化目标分配方面的潜力，并突出了此类系统中信息结构的重要性。

Abstract: Coordinating multiple autonomous agents in shared environments under
decentralized conditions is a long-standing challenge in robotics and
artificial intelligence. This work addresses the problem of decentralized goal
assignment for multi-agent path planning, where agents independently generate
ranked preferences over goals based on structured representations of the
environment, including grid visualizations and scenario data. After this
reasoning phase, agents exchange their goal rankings, and assignments are
determined by a fixed, deterministic conflict-resolution rule (e.g., agent
index ordering), without negotiation or iterative coordination. We
systematically compare greedy heuristics, optimal assignment, and large
language model (LLM)-based agents in fully observable grid-world settings. Our
results show that LLM-based agents, when provided with well-designed prompts
and relevant quantitative information, can achieve near-optimal makespans and
consistently outperform traditional heuristics. These findings underscore the
potential of language models for decentralized goal assignment in multi-agent
path planning and highlight the importance of information structure in such
systems.

</details>


### [10] [Law in Silico: Simulating Legal Society with LLM-Based Agents](https://arxiv.org/abs/2510.24442)
*Yiding Wang,Yuxuan Chen,Fanxu Meng,Xifan Chen,Xiaolei Yang,Muhan Zhang*

Main category: cs.AI

TL;DR: 本文介绍了一个基于大语言模型的法律社会模拟框架Law in Silico，通过模拟立法、裁决和执行等制度机制，验证了LLM能够重现宏观犯罪趋势并为法律理论发展提供支持。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界中的法律实验成本高昂或难以实施，利用人工智能系统模拟法律社会成为验证和发展法律理论的有效替代方案。LLM凭借其世界知识和角色扮演能力，是构建法律社会模拟的理想基础。

Method: 提出了Law in Silico框架，这是一个基于LLM的智能体框架，能够模拟包含个体决策以及立法、裁决和执行等制度机制的法律场景。

Result: 实验表明，基于LLM的智能体能够很大程度上重现宏观层面的犯罪趋势，并提供与现实世界观察一致的见解。微观层面的模拟揭示了一个运作良好、透明且适应性的法律系统能更好地保护弱势个体的权利。

Conclusion: LLM在模拟法律系统方面具有巨大潜力，能够有效支持法律理论验证和行政决策，同时强调了建立完善法律体系对保护弱势群体权利的重要性。

Abstract: Since real-world legal experiments are often costly or infeasible, simulating
legal societies with Artificial Intelligence (AI) systems provides an effective
alternative for verifying and developing legal theory, as well as supporting
legal administration. Large Language Models (LLMs), with their world knowledge
and role-playing capabilities, are strong candidates to serve as the foundation
for legal society simulation. However, the application of LLMs to simulate
legal systems remains underexplored. In this work, we introduce Law in Silico,
an LLM-based agent framework for simulating legal scenarios with individual
decision-making and institutional mechanisms of legislation, adjudication, and
enforcement. Our experiments, which compare simulated crime rates with
real-world data, demonstrate that LLM-based agents can largely reproduce
macro-level crime trends and provide insights that align with real-world
observations. At the same time, micro-level simulations reveal that a
well-functioning, transparent, and adaptive legal system offers better
protection of the rights of vulnerable individuals.

</details>


### [11] [Generating Creative Chess Puzzles](https://arxiv.org/abs/2510.23881)
*Xidong Feng,Vivek Veeriah,Marcus Chiam,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Federico Barbero,Johan Obando-Ceron,Jiaxin Shi,Satinder Singh,Shaobo Hou,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的框架，通过设计基于国际象棋引擎搜索统计的新型奖励机制，显著提高了生成反直觉、创造性国际象棋谜题的能力，生成的反直觉谜题比例从0.22%提升到2.5%，超越了现有数据集和最佳模型。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在生成真正具有创造性、美学价值和反直觉性的输出方面仍面临挑战，特别是在国际象棋谜题领域。

Method: 首先对生成式AI架构进行基准测试，然后引入基于国际象棋引擎搜索统计的强化学习框架，设计奖励机制来增强谜题的独特性、反直觉性、多样性和真实性。

Result: 强化学习方法将反直觉谜题生成比例从0.22%（监督学习）提高到2.5%，超过了现有数据集（2.1%）和最佳Lichess训练模型（0.4%）。生成的谜题满足新颖性和多样性基准，保留了美学主题，并被人类专家评为比书籍谜题更具创造性、趣味性和反直觉性。

Conclusion: 该方法成功生成了高质量的AI生成国际象棋谜题，三位世界知名专家认可其创造性，最终成果是一本精心策划的AI生成谜题手册。

Abstract: While Generative AI rapidly advances in various domains, generating truly
creative, aesthetic, and counter-intuitive outputs remains a challenge. This
paper presents an approach to tackle these difficulties in the domain of chess
puzzles. We start by benchmarking Generative AI architectures, and then
introduce an RL framework with novel rewards based on chess engine search
statistics to overcome some of those shortcomings. The rewards are designed to
enhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.
Our RL approach dramatically increases counter-intuitive puzzle generation by
10x, from 0.22\% (supervised) to 2.5\%, surpassing existing dataset rates
(2.1\%) and the best Lichess-trained model (0.4\%). Our puzzles meet novelty
and diversity benchmarks, retain aesthetic themes, and are rated by human
experts as more creative, enjoyable, and counter-intuitive than composed book
puzzles, even approaching classic compositions. Our final outcome is a curated
booklet of these AI-generated puzzles, which is acknowledged for creativity by
three world-renowned experts.

</details>


### [12] [Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins](https://arxiv.org/abs/2510.23882)
*Adil Rasheed,Oscar Ravik,Omer San*

Main category: cs.AI

TL;DR: 该研究比较了四种预测模型（线性、物理建模、LSTM、混合建模）和三种控制策略（MPC、RL、LLM）在数字孪生系统中的应用，发现HAM模型在精度、泛化性和计算效率方面表现最均衡，而MPC控制器性能最稳健。


<details>
  <summary>Details</summary>
Motivation: 研究数字孪生在动态系统建模和控制中的应用，整合物理基础、数据驱动和混合方法，比较传统与AI驱动控制器的性能差异。

Method: 使用微型温室作为测试平台，开发四种预测模型（线性、PBM、LSTM、HAM）和三种控制策略（MPC、RL、LLM），在插值和外推场景下进行比较评估。

Result: HAM模型在精度、泛化性和计算效率方面表现最均衡；LSTM精度高但资源消耗大；MPC控制器性能稳健可预测；RL控制器适应性强；LLM控制器结合预测工具可实现灵活的人机交互。

Conclusion: HAM提供了建模中最平衡的性能，MPC在控制中表现最稳健，不同方法在精度、适应性和实现复杂度方面存在权衡，为数字孪生系统设计提供了实用指导。

Abstract: This work investigates the use of digital twins for dynamical system modeling
and control, integrating physics-based, data-driven, and hybrid approaches with
both traditional and AI-driven controllers. Using a miniature greenhouse as a
test platform, four predictive models Linear, Physics-Based Modeling (PBM),
Long Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are
developed and compared under interpolation and extrapolation scenarios. Three
control strategies Model Predictive Control (MPC), Reinforcement Learning (RL),
and Large Language Model (LLM) based control are also implemented to assess
trade-offs in precision, adaptability, and implementation effort. Results show
that in modeling HAM provides the most balanced performance across accuracy,
generalization, and computational efficiency, while LSTM achieves high
precision at greater resource cost. Among controllers, MPC delivers robust and
predictable performance, RL demonstrates strong adaptability, and LLM-based
controllers offer flexible human-AI interaction when coupled with predictive
tools.

</details>


### [13] [Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges](https://arxiv.org/abs/2510.23883)
*Shrestha Datta,Shahriar Kabir Nahin,Anshuman Chhabra,Prasant Mohapatra*

Main category: cs.AI

TL;DR: 本文调查了基于大语言模型的智能AI系统带来的安全风险，提出了威胁分类法，回顾了评估方法和防御策略，旨在支持安全设计的智能系统开发。


<details>
  <summary>Details</summary>
Motivation: 随着具备规划、工具使用、记忆和自主能力的智能AI系统在web、软件和物理环境中自主执行任务，它们创造了与传统AI安全和软件安全不同的新型放大安全风险，需要专门研究。

Method: 通过构建智能AI特有的威胁分类法，回顾最近的基准测试和评估方法，并从技术和治理角度讨论防御策略，综合当前研究。

Result: 提出了针对智能AI系统的威胁分类框架，识别了独特的安全风险，并总结了现有的评估方法和防御措施。

Conclusion: 智能AI系统带来了新的安全挑战，需要安全设计的方法来开发，当前研究为构建安全的智能系统提供了基础，但仍存在开放挑战。

Abstract: Agentic AI systems powered by large language models (LLMs) and endowed with
planning, tool use, memory, and autonomy, are emerging as powerful, flexible
platforms for automation. Their ability to autonomously execute tasks across
web, software, and physical environments creates new and amplified security
risks, distinct from both traditional AI safety and conventional software
security. This survey outlines a taxonomy of threats specific to agentic AI,
reviews recent benchmarks and evaluation methodologies, and discusses defense
strategies from both technical and governance perspectives. We synthesize
current research and highlight open challenges, aiming to support the
development of secure-by-design agent systems.

</details>


### [14] [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)
*Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.AI

TL;DR: 本文提出了一种基于摊销变分推理的可扩展训练算法，将大型视觉语言模型中的推理重新表述为后验推断，通过多样性寻求强化学习算法和贝叶斯推理扩展策略，在七个推理基准测试中提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的训练算法（如SFT、PPO、GRPO）在未见推理任务上泛化能力不足，且严重依赖有偏的奖励模型，这限制了大型视觉语言模型推理能力的可解释性和可靠性。

Method: 将LVLMs中的推理重新表述为后验推断，提出基于摊销变分推理的可扩展训练算法；利用多样性寻求强化学习算法引入稀疏奖励函数，鼓励多样化的高似然潜在CoT；采用贝叶斯推理扩展策略，用边际似然替代昂贵的Best-of-N和Beam Search来高效排序最优推理路径和答案。

Result: 在七个推理基准测试上，所提出的方法在有效性、泛化性和可解释性方面提升了最先进的LVLMs性能。

Conclusion: 该方法通过变分推理框架和多样性强化学习，有效解决了现有训练算法的局限性，显著提升了大型视觉语言模型的推理能力、泛化性和可解释性。

Abstract: Chain-of-thought (CoT) reasoning is critical for improving the
interpretability and reliability of Large Vision-Language Models (LVLMs).
However, existing training algorithms such as SFT, PPO, and GRPO may not
generalize well across unseen reasoning tasks and heavily rely on a biased
reward model. To address this challenge, we reformulate reasoning in LVLMs as
posterior inference and propose a scalable training algorithm based on
amortized variational inference. By leveraging diversity-seeking reinforcement
learning algorithms, we introduce a novel sparse reward function for
token-level learning signals that encourage diverse, high-likelihood latent
CoT, overcoming deterministic sampling limitations and avoiding reward hacking.
Additionally, we implement a Bayesian inference-scaling strategy that replaces
costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank
optimal rationales and answers. We empirically demonstrate that the proposed
method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in
terms of effectiveness, generalization, and interpretability.

</details>


### [15] [Decentralized Causal Discovery using Judo Calculus](https://arxiv.org/abs/2510.23942)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 提出直觉主义去中心化因果发现框架judo calculus，使用j-stable因果推断和j-do-calculus在层拓扑中形式化处理现实应用中因果效应的情境依赖性。


<details>
  <summary>Details</summary>
Motivation: 现实应用中因果效应依赖于情境（年龄、国家、剂量、基因型等），需要形式化处理这种情境依赖性。

Method: 使用judo calculus结合层拓扑理论，通过Lawvere-Tierney模态算子j选择相关情境，实现j-stable因果推断，并与标准因果发现方法结合。

Result: 实验结果表明该方法在计算效率上优于经典因果发现方法，得益于层拓扑因果发现的去中心化特性。

Conclusion: judo calculus为处理情境依赖的因果发现提供了形式化框架，在计算效率和性能上均有提升。

Abstract: We describe a theory and implementation of an intuitionistic decentralized
framework for causal discovery using judo calculus, which is formally defined
as j-stable causal inference using j-do-calculus in a topos of sheaves. In
real-world applications -- from biology to medicine and social science --
causal effects depend on regime (age, country, dose, genotype, or lab
protocol). Our proposed judo calculus formalizes this context dependence
formally as local truth: a causal claim is proven true on a cover of regimes,
not everywhere at once. The Lawvere-Tierney modal operator j chooses which
regimes are relevant; j-stability means the claim holds constructively and
consistently across that family. We describe an algorithmic and implementation
framework for judo calculus, combining it with standard score-based,
constraint-based, and gradient-based causal discovery methods. We describe
experimental results on a range of domains, from synthetic to real-world
datasets from biology and economics. Our experimental results show the
computational efficiency gained by the decentralized nature of sheaf-theoretic
causal discovery, as well as improved performance over classical causal
discovery methods.

</details>


### [16] [The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity](https://arxiv.org/abs/2510.23965)
*Aymane El Gadarri,Ali Aouad,Vivek F. Farias*

Main category: cs.AI

TL;DR: 提出了一种名为符号估计器的新方法，通过将交叉熵损失替换为二元分类损失，解决了传统LLM对齐方法在人类偏好异质性下的不一致性问题，实现了可证明的一致性和多项式有限样本误差边界。


<details>
  <summary>Details</summary>
Motivation: 传统LLM对齐方法对人类偏好的异质性很脆弱，拟合简单的概率模型到成对比较数据会产生不一致的群体平均效用估计，这是社会福利的规范度量。

Method: 提出符号估计器方法，在聚合步骤中用二元分类损失替换交叉熵损失，在温和假设下恢复一致的有序对齐，并实现该设置下的首个多项式有限样本误差边界。

Result: 在基于数字孪生的LLM对齐现实模拟中，符号估计器显著减少了模拟人物面板上的偏好失真，将（角度）估计误差降低了近35%，与真实群体偏好的不一致性从12%降至8%，优于标准RLHF。

Conclusion: 符号估计器在保持现有LLM对齐管道实现简单性的同时，优于需要显式建模用户异质性和跟踪个体级偏好数据的面板数据启发式方法。

Abstract: Traditional LLM alignment methods are vulnerable to heterogeneity in human
preferences. Fitting a na\"ive probabilistic model to pairwise comparison data
(say over prompt-completion pairs) yields an inconsistent estimate of the
population-average utility -a canonical measure of social welfare. We propose a
new method, dubbed the sign estimator, that provides a simple, provably
consistent, and efficient estimator by replacing cross-entropy with binary
classification loss in the aggregation step. This simple modification recovers
consistent ordinal alignment under mild assumptions and achieves the first
polynomial finite-sample error bounds in this setting. In realistic simulations
of LLM alignment using digital twins, the sign estimator substantially reduces
preference distortion over a panel of simulated personas, cutting (angular)
estimation error by nearly 35% and decreasing disagreement with true population
preferences from 12% to 8% compared to standard RLHF. Our method also compares
favorably to panel data heuristics that explicitly model user heterogeneity and
require tracking individual-level preference data-all while maintaining the
implementation simplicity of existing LLM alignment pipelines.

</details>


### [17] [Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance](https://arxiv.org/abs/2510.23989)
*Shangde Gao,Zelin Xu,Zhe Jiang*

Main category: cs.AI

TL;DR: 本研究提出了一种条件深度学习模型，通过整合个体的社会基础设施韧性(SIR)和空间上下文，来预测破坏性事件后个体移动模式的变化。


<details>
  <summary>Details</summary>
Motivation: 预测破坏性事件前个体移动模式变化具有挑战性，因为缺乏衡量个体异质性社会基础设施韧性的指标，复杂个体移动模式与空间上下文的交互关系未被充分捕捉，以及个体级移动数据稀疏且不适合传统预测方法。

Method: 开发了一个条件深度学习模型，整合个体的社会基础设施韧性(SIR)，利用大规模稀疏个体级数据捕捉个体移动模式与局部空间上下文之间的复杂关系。

Result: 实验表明，整合个体SIR和空间上下文能够增强模型预测事件后个体移动模式的能力。条件模型能够捕捉到具有相似事件前移动模式但SIR不同的个体之间移动模式的差异变化。

Conclusion: 通过整合个体社会基础设施韧性和空间上下文，条件深度学习模型能够有效预测破坏性事件后个体移动模式的变化，特别是对于具有相似事件前模式但韧性不同的个体。

Abstract: Shifts in individual movement patterns following disruptive events can reveal
changing demands for community resources. However, predicting such shifts
before disruptive events remains challenging for several reasons. First,
measures are lacking for individuals' heterogeneous social infrastructure
resilience (SIR), which directly influences their movement patterns, and
commonly used features are often limited or unavailable at scale, e.g.,
sociodemographic characteristics. Second, the complex interactions between
individual movement patterns and spatial contexts have not been sufficiently
captured. Third, individual-level movement may be spatially sparse and not
well-suited to traditional decision-making methods for movement predictions.
This study incorporates individuals' SIR into a conditioned deep learning model
to capture the complex relationships between individual movement patterns and
local spatial context using large-scale, sparse individual-level data. Our
experiments demonstrate that incorporating individuals' SIR and spatial context
can enhance the model's ability to predict post-event individual movement
patterns. The conditioned model can capture the divergent shifts in movement
patterns among individuals who exhibit similar pre-event patterns but differ in
SIR.

</details>


### [18] [OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2510.24028)
*Tingyue Pan,Mingyue Cheng,Shilong Zhang,Zhiding Liu,Xiaoyu Tao,Yucong Luo,Jintao Zhang,Qi Liu*

Main category: cs.AI

TL;DR: OneCast是一个模块化的跨域时间序列预测框架，通过将时间序列分解为季节性和趋势组件，分别使用轻量级投影模块和基于离散扩散的token化机制进行建模，在多个领域实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决跨域时间序列预测中面临的领域特定趋势变化和不一致周期性模式的挑战，现有方法将时间序列视为未分化的序列，没有显式解耦其固有结构组件。

Method: 提出OneCast框架：1）将时间序列分解为季节性和趋势组件；2）季节性组件通过轻量级投影模块使用可解释基函数重建周期性模式；3）趋势组件通过语义感知tokenizer编码为离散token，使用掩码离散扩散机制进行推断；4）两分支输出结合生成最终预测。

Result: 在八个领域的广泛实验中，OneCast大多优于最先进的基线方法。

Conclusion: 通过结构化分解和模块化建模方法，OneCast能够有效捕捉季节性模式同时跟踪领域特定趋势，在跨域时间序列预测任务中表现出色。

Abstract: Cross-domain time series forecasting is a valuable task in various web
applications. Despite its rapid advancement, achieving effective generalization
across heterogeneous time series data remains a significant challenge. Existing
methods have made progress by extending single-domain models, yet often fall
short when facing domain-specific trend shifts and inconsistent periodic
patterns. We argue that a key limitation lies in treating temporal series as
undifferentiated sequence, without explicitly decoupling their inherent
structural components. To address this, we propose OneCast, a structured and
modular forecasting framework that decomposes time series into seasonal and
trend components, each modeled through tailored generative pathways.
Specifically, the seasonal component is captured by a lightweight projection
module that reconstructs periodic patterns via interpretable basis functions.
In parallel, the trend component is encoded into discrete tokens at segment
level via a semantic-aware tokenizer, and subsequently inferred through a
masked discrete diffusion mechanism. The outputs from both branches are
combined to produce a final forecast that captures seasonal patterns while
tracking domain-specific trends. Extensive experiments across eight domains
demonstrate that OneCast mostly outperforms state-of-the-art baselines.

</details>


### [19] [Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach](https://arxiv.org/abs/2510.24085)
*Md. Shihab Uddin,Md Nazmus Shakib,Rahul Bhadani*

Main category: cs.AI

TL;DR: 本研究比较了经典模型和机器学习模型在电动汽车跟驰行为建模中的表现，发现随机森林模型在所有场景下都优于物理模型，特别是在不同跟车间距条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车的普及，需要理解其驾驶行为以提高交通安全和开发智能驾驶系统，特别是在混合交通环境中。

Method: 使用经典模型（IDM、OVM、OVRV、简化CACC）和机器学习方法（随机森林回归器），基于真实世界电动汽车跟随内燃机车辆的数据集进行模型校准和预测。

Result: 随机森林模型表现最佳，在不同跟车间距条件下的RMSE分别为0.0046（中等间距）、0.0016（长间距）和0.0025（超长间距）；在物理模型中，CACC模型表现最好，长间距RMSE为2.67。

Conclusion: 机器学习模型在电动汽车跟驰行为建模中具有优越性能，对于模拟电动汽车行为和分析混合自主交通动态具有重要价值。

Abstract: The increasing adoption of electric vehicles (EVs) necessitates an
understanding of their driving behavior to enhance traffic safety and develop
smart driving systems. This study compares classical and machine learning
models for EV car following behavior. Classical models include the Intelligent
Driver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative
Velocity (OVRV), and a simplified CACC model, while the machine learning
approach employs a Random Forest Regressor. Using a real world dataset of an EV
following an internal combustion engine (ICE) vehicle under varied driving
conditions, we calibrated classical model parameters by minimizing the RMSE
between predictions and real data. The Random Forest model predicts
acceleration using spacing, speed, and gap type as inputs. Results demonstrate
the Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),
0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,
CACC performed best, with an RMSE of 2.67 for long gaps. These findings
highlight the machine learning model's performance across all scenarios. Such
models are valuable for simulating EV behavior and analyzing mixed autonomy
traffic dynamics in EV integrated environments.

</details>


### [20] [HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology](https://arxiv.org/abs/2510.24115)
*Sandeep Vissapragada,Vikrant Sahu,Gagan Raj Gupta,Vandita Singh*

Main category: cs.AI

TL;DR: HistoLens是一个透明的AI助手，允许病理学家用自然语言提问组织切片问题，提供结构化报告和可视化证据，帮助医生更快、更自信地做出诊断。


<details>
  <summary>Details</summary>
Motivation: 为了让医生真正信任人工智能，AI不能是黑盒，需要像咨询同事一样理解其推理过程。

Method: 创建HistoLens系统，将自然语言问题转换为AI引擎的精确查询，提供结构化报告和热图可视化证据，并训练AI专注于患者组织而忽略背景噪声。

Result: 实现了病理学家主导的工作流程，医生可以使用可信赖的AI助手验证见解，做出更快、更自信的诊断。

Conclusion: HistoLens作为透明的协作伙伴，让病理学家保持专家主导地位，同时利用AI助手提高诊断效率和信心。

Abstract: For doctors to truly trust artificial intelligence, it can't be a black box.
They need to understand its reasoning, almost as if they were consulting a
colleague. We created HistoLens1 to be that transparent, collaborative partner.
It allows a pathologist to simply ask a question in plain English about a
tissue slide--just as they would ask a trainee. Our system intelligently
translates this question into a precise query for its AI engine, which then
provides a clear, structured report. But it doesn't stop there. If a doctor
ever asks, "Why?", HistoLens can instantly provide a 'visual proof' for any
finding--a heatmap that points to the exact cells and regions the AI used for
its analysis. We've also ensured the AI focuses only on the patient's tissue,
just like a trained pathologist would, by teaching it to ignore distracting
background noise. The result is a workflow where the pathologist remains the
expert in charge, using a trustworthy AI assistant to verify their insights and
make faster, more confident diagnoses.

</details>


### [21] [From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems](https://arxiv.org/abs/2510.24145)
*Yu Luo,Jiamin Jiang,Jingfei Feng,Lei Tao,Qingliang Zhang,Xidao Wen,Yongqian Sun,Shenglin Zhang,Jielong Huang,Nan Qi,Dan Pei*

Main category: cs.AI

TL;DR: OpsAgent是一个轻量级、自演进的多智能体系统，用于云系统事件管理，通过免训练数据处理将异构可观测数据转换为结构化文本描述，并采用多智能体协作框架实现透明诊断推理，具有双自演进机制支持持续能力增长。


<details>
  <summary>Details</summary>
Motivation: 传统手动事件管理在面临海量异构可观测数据时劳动密集且易出错，现有自动化方法存在跨系统泛化能力差、可解释性有限、部署成本高等问题，阻碍了实际应用。

Method: 采用免训练数据处理将异构可观测数据转换为结构化文本描述，构建多智能体协作框架实现透明诊断推理，引入双自演进机制（内部模型更新和外部经验积累）支持持续能力增长。

Result: 在OPENRCA基准测试中表现出最先进的性能，证明OpsAgent具有通用性、可解释性、成本效益和自演进能力。

Conclusion: OpsAgent是一个实际可部署且可持续的解决方案，适用于真实云系统的长期运维。

Abstract: Incident management (IM) is central to the reliability of large-scale cloud
systems. Yet manual IM, where on-call engineers examine metrics, logs, and
traces is labor-intensive and error-prone in the face of massive and
heterogeneous observability data. Existing automated IM approaches often
struggle to generalize across systems, provide limited interpretability, and
incur high deployment costs, which hinders adoption in practice. In this paper,
we present OpsAgent, a lightweight, self-evolving multi-agent system for IM
that employs a training-free data processor to convert heterogeneous
observability data into structured textual descriptions, along with a
multi-agent collaboration framework that makes diagnostic inference transparent
and auditable. To support continual capability growth, OpsAgent also introduces
a dual self-evolution mechanism that integrates internal model updates with
external experience accumulation, thereby closing the deployment loop.
Comprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art
performance and show that OpsAgent is generalizable, interpretable,
cost-efficient, and self-evolving, making it a practically deployable and
sustainable solution for long-term operation in real-world cloud systems.

</details>


### [22] [BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning](https://arxiv.org/abs/2510.24161)
*Wentao Tan,Bowen Wang,Heng Zhi,Chenyu Liu,Zhe Li,Jian Liu,Zengrong Lin,Yukun Dai,Yipeng Chen,Wenjie Yang,Enci Xie,Hao Xue,Baixu Ji,Chen Xu,Zhibin Wang,Tianshi Wang,Lei Zhu,Heng Tao Shen*

Main category: cs.AI

TL;DR: BLM₁是一个多模态空间基础模型，通过两阶段训练实现了跨空间迁移、跨任务学习和跨具身泛化，在数字和物理任务中均优于现有模型家族。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在数字-物理空间和具身化之间泛化能力差，VLAs缺乏鲁棒的高层具身推理能力，而大多数ELLMs局限于数字空间且难以泛化到物理世界，因此需要能够无缝跨数字和物理空间操作、同时跨具身化和任务泛化的统一模型。

Method: 采用两阶段训练范式：第一阶段通过精选数字语料向MLLM注入具身知识同时保持语言能力；第二阶段通过意图桥接接口训练策略模块，从MLLM提取高层语义来指导控制，无需微调MLLM主干。该方法基于自收集的跨具身演示套件，涵盖四种机器人具身和六个渐进挑战性任务。

Result: 在数字和物理基准测试中，单个BLM₁实例优于四个模型家族（MLLMs、ELLMs、VLAs和GMLMs），在数字任务中提升约6%，在物理任务中提升约3%。

Conclusion: BLM₁成功实现了跨空间、跨任务和跨具身的统一建模，为构建能够在数字和物理空间中无缝操作的多模态具身智能系统提供了有效解决方案。

Abstract: Multimodal large language models (MLLMs) have advanced vision-language
reasoning and are increasingly deployed in embodied agents. However,
significant limitations remain: MLLMs generalize poorly across digital-physical
spaces and embodiments; vision-language-action models (VLAs) produce low-level
actions yet lack robust high-level embodied reasoning; and most embodied large
language models (ELLMs) are constrained to digital-space with poor
generalization to the physical world. Thus, unified models that operate
seamlessly across digital and physical spaces while generalizing across
embodiments and tasks remain absent. We introduce the \textbf{Boundless Large
Model (BLM$_1$)}, a multimodal spatial foundation model that preserves
instruction following and reasoning, incorporates embodied knowledge, and
supports robust cross-embodiment control. BLM$_1$ integrates three key
capabilities -- \textit{cross-space transfer, cross-task learning, and
cross-embodiment generalization} -- via a two-stage training paradigm. Stage I
injects embodied knowledge into the MLLM through curated digital corpora while
maintaining language competence. Stage II trains a policy module through an
intent-bridging interface that extracts high-level semantics from the MLLM to
guide control, without fine-tuning the MLLM backbone. This process is supported
by a self-collected cross-embodiment demonstration suite spanning four robot
embodiments and six progressively challenging tasks. Evaluations across digital
and physical benchmarks show that a single BLM$_1$ instance outperforms four
model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving
$\sim\!\textbf{6%}$ gains in digital tasks and $\sim\!\textbf{3%}$ in physical
tasks.

</details>


### [23] [MGA: Memory-Driven GUI Agent for Observation-Centric Interaction](https://arxiv.org/abs/2510.24168)
*Weihua Cheng,Ersheng Ni,Wenlong Wang,Yifei Sun,Junming Liu,Wangyu Shen,Yirong Chen,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid progress of Large Language Models (LLMs) and their multimodal
extensions (MLLMs) has enabled agentic systems capable of perceiving and acting
across diverse environments. A challenging yet impactful frontier is the
development of GUI agents, which must navigate complex desktop and web
interfaces while maintaining robustness and generalization. Existing paradigms
typically model tasks as long-chain executions, concatenating historical
trajectories into the context. While approaches such as Mirage and GTA1 refine
planning or introduce multi-branch action selection, they remain constrained by
two persistent issues: Dependence on historical trajectories, which amplifies
error propagation. And Local exploration bias, where "decision-first,
observation-later" mechanisms overlook critical interface cues. We introduce
the Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the
principle of observe first, then decide. MGA models each step as an
independent, context-rich environment state represented by a triad: current
screenshot, task-agnostic spatial information, and a dynamically updated
structured memory. Experiments on OSworld benchmarks, real desktop applications
(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves
substantial gains in robustness, generalization, and efficiency compared to
state-of-the-art baselines. The code is publicly available at:
{https://anonymous.4open.science/r/MGA-3571}.

</details>


### [24] [Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms](https://arxiv.org/abs/2510.24297)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 本文针对MCTS中抽象方法存在的同层节点UCB值相同的问题，提出了多种内部抽象策略来替代随机断点规则，并在多个环境中验证了这些策略的性能优势。


<details>
  <summary>Details</summary>
Motivation: MCTS的样本效率问题可以通过状态和动作抽象来解决，但现有方法如pruned OGA在多个动作属于同一抽象节点时，它们的UCB值会相同，只能依赖随机断点规则，这影响了算法性能。

Method: 提出并实证评估了多种替代随机策略的内部抽象策略，用于处理同一抽象节点中多个动作的UCB值相同情况。

Result: 实验结果表明，提出的多个内部抽象策略在大多数环境和参数设置下都优于随机策略。

Conclusion: 通过设计更智能的内部抽象策略可以有效解决MCTS抽象方法中的UCB值相同问题，提升算法性能。

Abstract: One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which
can be addressed by building and using state and/or action abstractions in
parallel to the tree search such that information can be shared among nodes of
the same layer. The primary usage of abstractions for MCTS is to enhance the
Upper Confidence Bound (UCB) value during the tree policy by aggregating visits
and returns of an abstract node. However, this direct usage of abstractions
does not take the case into account where multiple actions with the same parent
might be in the same abstract node, as these would then all have the same UCB
value, thus requiring a tiebreak rule. In state-of-the-art abstraction
algorithms such as pruned On the Go Abstractions (pruned OGA), this case has
not been noticed, and a random tiebreak rule was implicitly chosen. In this
paper, we propose and empirically evaluate several alternative
intra-abstraction policies, several of which outperform the random policy
across a majority of environments and parameter settings.

</details>


### [25] [Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank](https://arxiv.org/abs/2510.24299)
*Jiayu Liu,Wei Dai,Zhenya Huang,Ning Miao,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM内部行为的相关性矩阵秩作为推理路径可信度指标的方法，无需外部资源即可有效检测LLM输出的正确性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型具有强大的推理能力，但它们容易产生错误和幻觉。现有检查方法严重依赖外部资源，导致计算开销大且仅适用于特定领域。

Method: 研究发现输入问题与输出推理路径之间的相关性矩阵秩是推理正确性的稳健指标。基于此设计了Self-Indicator方法，通过重加权候选推理路径来提升性能。

Result: 该方法在区分正确与错误推理路径方面达到超过75%的准确率，并在三个推理基准测试中将准确率提高了8%以上。

Conclusion: LLM内部行为本身已包含其推理路径可信度的信息，Self-Indicator方法简单有效且计算开销小，适用于不同规模和类型的LLM。

Abstract: Despite the strong reasoning ability of large language models~(LLMs), they
are prone to errors and hallucinations. As a result, how to check their outputs
effectively and efficiently has become a critical problem in their
applications. Existing checking methods heavily rely on external resources,
such as trained verifiers (e.g., process/outcome reward models) or elaborate
prompts, which lead to high computational overhead and are only applicable to
specific domains. In this paper, we investigate whether the internal behaviors
of LLMs have already implied the credibility of their reasoning paths.
Specifically, we find that the rank of the correlation matrix between the input
problem and the output reasoning path is a robust indicator of reasoning
correctness. Different from other correctness indicators for LLMs, the
calculation of the correlation matrix only relies on the LLM itself, which
avoids the hassle of training a separate model or designing complicated
prompts. Based on it, we design a simple, plug-and-play Self-Indicator method
to reweight candidate reasoning paths, which achieves significant performance
improvements than other voting and verification methods with very few
computational overhead. Our experiments across multiple LLMs of varying scales
and model families have further shown the effectiveness of Self-Indicator. It
achieves over 75% accuracy in distinguishing correct reasoning paths from
incorrect ones, and, in turn, improves the accuracies on three reasoning
benchmarks by more than 8%.

</details>


### [26] [Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting](https://arxiv.org/abs/2510.24303)
*Deniz Gorur,Antoni Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的多智能体框架用于声明验证，通过不同智能体对声明真实性产生分歧并分别提供支持和反对证据，构建定量双极论证框架(QBAFs)，并利用大型语言模型实现多种智能体类型，实验表明多智能体组合证据能提高预测准确性并提供可解释的证据组合。


<details>
  <summary>Details</summary>
Motivation: 将判断预测视为声明验证任务，需要评估未来事件的合理性。现有方法在证据收集和验证方面存在局限性，需要更全面、可解释的验证框架。

Method: 提出多智能体声明验证框架，使用三种基于LLM的智能体：ArgLLM智能体（生成和评估QBAFs）、RbAM智能体（从外部源进行关系型论证挖掘生成QBAFs）、RAG-ArgLLM智能体（结合检索增强生成从外部源获取论证）。在标准判断预测数据集上进行2-3个智能体的实验。

Result: 实验结果表明，组合多个智能体的证据可以改善预测准确性，特别是在三个智能体的情况下，同时为声明验证提供了可解释的证据组合。

Conclusion: 多智能体框架通过整合不同视角的证据，不仅提高了判断预测的准确性，还提供了透明和可解释的验证过程，为声明验证任务提供了有效解决方案。

Abstract: Judgmental forecasting is the task of making predictions about future events
based on human judgment. This task can be seen as a form of claim verification,
where the claim corresponds to a future event and the task is to assess the
plausibility of that event. In this paper, we propose a novel multi-agent
framework for claim verification, whereby different agents may disagree on
claim veracity and bring specific evidence for and against the claims,
represented as quantitative bipolar argumentation frameworks (QBAFs). We then
instantiate the framework for supporting claim verification, with a variety of
agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an
existing approach for claim verification that generates and evaluates QBAFs;
(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)
from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,
extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of
arguments from external sources. Finally, we conduct experiments with two
standard judgmental forecasting datasets, with instances of our framework with
two or three agents, empowered by six different base LLMs. We observe that
combining evidence from agents can improve forecasting accuracy, especially in
the case of three agents, while providing an explainable combination of
evidence for claim verification.

</details>


### [27] [Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research](https://arxiv.org/abs/2510.24337)
*Daria Kravets-Meinke,Hannah Schmid-Petri,Sonja Niemann,Ute Schmid*

Main category: cs.AI

TL;DR: 本文探讨了生成式大语言模型在传播研究内容分析中的应用，指出gLLMs在编码任务中优于人工编码员且成本更低，但存在七大挑战需要解决，旨在为研究者提供最佳实践指南。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式大语言模型在传播研究内容分析中展现出巨大潜力，能够解码隐含意义、使用自然语言指令且成本低廉，但其在方法论工具包中的整合仍不成熟，需要解决影响结果质量的七大关键挑战。

Method: 综合新兴研究，提出全面的最佳实践指南，涵盖代码本开发、提示工程、模型选择、参数调优、迭代优化、可靠性验证和性能提升等七个关键环节。

Result: gLLMs在传播科学相关编码任务中表现优于众包工作者和训练有素的编码员，能以更少的时间和成本完成工作，并能解码隐含意义和上下文信息。

Conclusion: 本文旨在使基于gLLM的内容分析对更广泛的传播研究者更加可及，并确保遵守有效性、可靠性、可重复性和研究伦理等学科质量标准。

Abstract: Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly
being used in communication research for content analysis. Studies show that
gLLMs can outperform both crowd workers and trained coders, such as research
assistants, on various coding tasks relevant to communication science, often at
a fraction of the time and cost. Additionally, gLLMs can decode implicit
meanings and contextual information, be instructed using natural language,
deployed with only basic programming skills, and require little to no annotated
data beyond a validation dataset - constituting a paradigm shift in automated
content analysis. Despite their potential, the integration of gLLMs into the
methodological toolkit of communication research remains underdeveloped. In
gLLM-assisted quantitative content analysis, researchers must address at least
seven critical challenges that impact result quality: (1) codebook development,
(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)
iterative refinement, (6) validation of the model's reliability, and
optionally, (7) performance enhancement. This paper synthesizes emerging
research on gLLM-assisted quantitative content analysis and proposes a
comprehensive best-practice guide to navigate these challenges. Our goal is to
make gLLM-based content analysis more accessible to a broader range of
communication researchers and ensure adherence to established disciplinary
quality standards of validity, reliability, reproducibility, and research
ethics.

</details>


### [28] [VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation](https://arxiv.org/abs/2510.24339)
*Yunxuan Jiang,Silan Hu,Xiaoning Wang,Yuanyuan Zhang,Xiangyu Chang*

Main category: cs.AI

TL;DR: VDSAgents是一个基于可预测性-可计算性-稳定性(PCS)原则的多智能体系统，用于改进LLM驱动的数据科学自动化，在多个数据集上优于现有端到端系统。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的数据科学系统仅依赖模型内部推理，缺乏科学和理论原则指导，限制了在嘈杂复杂现实数据集中的可信度和鲁棒性。

Method: 基于PCS原则构建多智能体系统，采用模块化工作流处理数据清洗、特征工程、建模和评估，每个阶段由专门智能体负责，结合扰动分析、单元测试和模型验证。

Result: 在9个不同特征数据集上的评估显示，VDSAgents持续优于AutoKaggle和DataInterpreter等最先进的端到端数据科学系统。

Conclusion: 将PCS原则嵌入LLM驱动的数据科学自动化是可行的，能够显著提升系统性能。

Abstract: Large language models (LLMs) become increasingly integrated into data science
workflows for automated system design. However, these LLM-driven data science
systems rely solely on the internal reasoning of LLMs, lacking guidance from
scientific and theoretical principles. This limits their trustworthiness and
robustness, especially when dealing with noisy and complex real-world datasets.
This paper provides VDSAgents, a multi-agent system grounded in the
Predictability-Computability-Stability (PCS) principles proposed in the
Veridical Data Science (VDS) framework. Guided by PCS principles, the system
implements a modular workflow for data cleaning, feature engineering, modeling,
and evaluation. Each phase is handled by an elegant agent, incorporating
perturbation analysis, unit testing, and model validation to ensure both
functionality and scientific auditability. We evaluate VDSAgents on nine
datasets with diverse characteristics, comparing it with state-of-the-art
end-to-end data science systems, such as AutoKaggle and DataInterpreter, using
DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the
results of AutoKaggle and DataInterpreter, which validates the feasibility of
embedding PCS principles into LLM-driven data science automation.

</details>


### [29] [An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine](https://arxiv.org/abs/2510.24359)
*Pedram Fard,Alaleh Azhir,Neguine Rezaii,Jiazi Tian,Hossein Estiri*

Main category: cs.AI

TL;DR: 提出了一种多智能体生态系统用于N-of-1决策支持，旨在解决传统医疗AI面向平均患者的问题，通过协调多个专业智能体为个体患者提供更精准、透明的决策支持。


<details>
  <summary>Details</summary>
Motivation: 传统医疗AI系统通过最小化大数据集上的错误来获得强聚合准确性，但在边缘病例（罕见变异、多病共存、代表性不足人群）上表现不佳，这种平均患者谬误损害了公平性和信任度。

Method: 构建多智能体生态系统，智能体按器官系统、患者群体和分析模式聚类，共享模型库和证据合成工具，通过协调层权衡可靠性、不确定性和数据密度，生成包含风险估计、置信区间、异常标志和相关证据的决策支持包。

Result: 验证方法从群体平均转向个体可靠性，通过低密度区域错误、小样本校准和风险-覆盖权衡来评估系统性能。

Conclusion: 通过从单一模型转向协调智能，该方法旨在使医疗AI与医学首要原则保持一致：提供透明、公平且以个体为中心的护理。

Abstract: Artificial intelligence in medicine is built to serve the average patient. By
minimizing error across large datasets, most systems deliver strong aggregate
accuracy yet falter at the margins: patients with rare variants,
multimorbidity, or underrepresented demographics. This average patient fallacy
erodes both equity and trust. We propose a different design: a multi-agent
ecosystem for N-of-1 decision support. In this environment, agents clustered by
organ systems, patient populations, and analytic modalities draw on a shared
library of models and evidence synthesis tools. Their results converge in a
coordination layer that weighs reliability, uncertainty, and data density
before presenting the clinician with a decision-support packet: risk estimates
bounded by confidence ranges, outlier flags, and linked evidence. Validation
shifts from population averages to individual reliability, measured by error in
low-density regions, calibration in the small, and risk--coverage trade-offs.
Anticipated challenges include computational demands, automation bias, and
regulatory fit, addressed through caching strategies, consensus checks, and
adaptive trial frameworks. By moving from monolithic models to orchestrated
intelligence, this approach seeks to align medical AI with the first principle
of medicine: care that is transparent, equitable, and centered on the
individual.

</details>


### [30] [Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion](https://arxiv.org/abs/2510.24390)
*Xianjun Gao,Jianchun Liu,Hongli Xu,Liusheng Huang*

Main category: cs.AI

TL;DR: Orion是一个高效推理框架，通过依赖感知的查询分解和逻辑并行内容扩展，解决了LLM在实时Web应用中的延迟和吞吐量瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法在计算效率和推理质量之间难以平衡，无法满足现代Web平台对低延迟、高吞吐量和高推理质量的双重要求。

Method: 将单查询推理分解为两个协同阶段：关键点生成（通过检索增强的few-shot提示提取逻辑结构关键点）和内容并行扩展（基于依赖图并发扩展内容）。引入流水线调度机制，利用两个阶段的计算特性实现跨查询并行。

Result: 在多样化基准测试中，Orion相比基线方法实现了最高4.33倍的token生成速度提升、3.42倍的答案延迟降低，以及18.75%的推理质量提升。

Conclusion: Orion通过显式建模关键点间的依赖关系，在保持逻辑一致性的同时显著提升了LLM推理的效率和品质，为实时Web应用提供了可行的解决方案。

Abstract: The integration of Large Language Models (LLMs) into real-time Web
applications, such as AI-powered search and conversational agents, presents a
fundamental Web infrastructure challenge: reconciling the demand for
high-quality, complex reasoning with the stringent low-latency and
high-throughput requirements of interactive services. Current LLM reasoning,
hindered by computationally inefficient sequential generation and rigid
reasoning strategies, creates a critical bottleneck for the Web services.
Existing approaches typically optimize the LLM reasoning for either efficiency
or quality but struggle to achieve both, and thus fail to meet the dual
requirements of modern Web platforms. To overcome these limitations, we propose
Orion, a novel and efficient reasoning framework that enables dependency-aware
query decomposition and logic-parallel content expansion. Concretely, Orion
decomposes a single query reasoning process into two synergistic phases: (1)
\textit{key point generation}, which distills logically structured key points
through retrieval-augmented few-shot prompting, and (2) \textit{content
parallel expansion}, which concurrently elaborates on these points based on a
dependency graph to ensure logical consistency. Furthermore, Orion introduces a
pipeline scheduling mechanism that exploits the complementary computational
characteristics of the two phases (generation imposes pressure on GPU computing
and expansion stresses on GPU memory) across multiple queries, enabling
cross-query parallelism and dramatically improving reasoning performance (\ie,
efficiency and quality). Experiments on diverse benchmarks show that Orion not
only delivers up to 4.33x higher token generation speed and 3.42x lower answer
latency over the baselines but also improves reasoning quality by up to 18.75%
through explicitly modeling inter-point dependencies.

</details>


### [31] [Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning](https://arxiv.org/abs/2510.24435)
*Benjamin Grando Moreira*

Main category: cs.AI

TL;DR: 本研究比较了多个大型语言模型（GPT、Claude、DeepSeek等）的逻辑和抽象推理能力，使用8个定制推理问题，并与人类表现进行基准测试，揭示了LLMs在演绎推理方面的显著不足。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型的推理能力对于推进人工智能发展至关重要，因为这超越了单纯的语言任务表现，涉及理解模型是否真正理解信息、进行推理并以逻辑有效的方式得出结论。

Method: 使用8个定制设计的推理问题，比较多个LLMs（GPT、Claude、DeepSeek、Gemini等）的逻辑和抽象推理技能，并将结果与人类在相同任务上的表现进行基准测试。

Result: LLMs的结果与人类表现相比存在显著差异，表明LLMs在演绎推理方面存在困难。

Conclusion: 大型语言模型在逻辑和抽象推理能力方面仍有明显不足，特别是在演绎推理任务上表现较差，需要进一步改进。

Abstract: Evaluating reasoning ability in Large Language Models (LLMs) is important for
advancing artificial intelligence, as it transcends mere linguistic task
performance. It involves understanding whether these models truly understand
information, perform inferences, and are able to draw conclusions in a logical
and valid way. This study compare logical and abstract reasoning skills of
several LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,
Perplexity, and Sabi\'a - using a set of eight custom-designed reasoning
questions. The LLM results are benchmarked against human performance on the
same tasks, revealing significant differences and indicating areas where LLMs
struggle with deduction.

</details>


### [32] [From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning](https://arxiv.org/abs/2510.24528)
*Zihan Chen,Song Wang,Xingbo Fu,Chengshuai Shi,Zhenyu Lei,Cong Shen,Jundong Li*

Main category: cs.AI

TL;DR: 提出了一种成本效益高的两阶段管道，通过交叉任务示例伪标记少量目标实例，然后使用图标签传播方法扩展标签，减少对LLM的依赖，降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 收集高质量示例进行上下文学习成本高昂且劳动密集，需要减少对LLM数据标注的依赖。

Method: 两阶段管道：首先利用交叉任务示例提示LLM伪标记少量目标实例，然后引入图标签传播方法将标签信息传播到剩余目标示例中，无需额外LLM查询。

Result: 在五个任务上的实验表明，该方法在降低标注成本的同时实现了强大的性能。

Conclusion: 该管道结合了交叉任务监督的灵活性和无LLM传播的可扩展性，为上下文学习提供了一种成本效益高的解决方案。

Abstract: The capability of in-context learning (ICL) enables large language models
(LLMs) to perform novel tasks without parameter updates by conditioning on a
few input-output examples. However, collecting high-quality examples for new or
challenging tasks can be costly and labor-intensive. In this work, we propose a
cost-efficient two-stage pipeline that reduces reliance on LLMs for data
labeling. Our approach first leverages readily available cross-task examples to
prompt an LLM and pseudo-label a small set of target task instances. We then
introduce a graph-based label propagation method that spreads label information
to the remaining target examples without additional LLM queries. The resulting
fully pseudo-labeled dataset is used to construct in-task demonstrations for
ICL. This pipeline combines the flexibility of cross-task supervision with the
scalability of LLM-free propagation. Experiments across five tasks demonstrate
that our method achieves strong performance while lowering labeling costs.

</details>


### [33] [Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives](https://arxiv.org/abs/2510.24551)
*Gang Chen,Changshuo Liu,Gene Anne Ooi,Marcus Tan,Zhongle Xie,Jianwei Yin,James Wei Luen Yip,Wenqiao Zhang,Jiaqi Zhu,Beng Chin Ooi*

Main category: cs.AI

TL;DR: 本文提出了一种以数据为中心的方法来设计和部署生成式人工智能（GenAI）在医疗保健领域的应用，通过重新定位数据生命周期，将医疗数据生态系统作为生成式医疗系统的基石。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能在医疗保健领域具有巨大潜力，但需要深入理解医疗任务及其可实现性。现有方法缺乏对医疗数据生态系统的系统性整合。

Method: 构建医疗数据生态系统作为基础平台，支持多样医疗数据和知识的集成、表示和检索，采用语义向量搜索和上下文查询等高效数据处理管道。

Result: 该生态系统能够为上游模型组件提供高质量多模态数据进行预训练和领域特定微调，同时作为知识检索后端支持任务特定推理。

Conclusion: 这种以数据为中心的方法能够实现高质量、有效的生成式人工智能医疗保健服务部署。

Abstract: Generative Artificial Intelligence (GenAI) is taking the world by storm. It
promises transformative opportunities for advancing and disrupting existing
practices, including healthcare. From large language models (LLMs) for clinical
note synthesis and conversational assistance to multimodal systems that
integrate medical imaging, electronic health records, and genomic data for
decision support, GenAI is transforming the practice of medicine and the
delivery of healthcare, such as diagnosis and personalized treatments, with
great potential in reducing the cognitive burden on clinicians, thereby
improving overall healthcare delivery. However, GenAI deployment in healthcare
requires an in-depth understanding of healthcare tasks and what can and cannot
be achieved. In this paper, we propose a data-centric paradigm in the design
and deployment of GenAI systems for healthcare. Specifically, we reposition the
data life cycle by making the medical data ecosystem as the foundational
substrate for generative healthcare systems. This ecosystem is designed to
sustainably support the integration, representation, and retrieval of diverse
medical data and knowledge. With effective and efficient data processing
pipelines, such as semantic vector search and contextual querying, it enables
GenAI-powered operations for upstream model components and downstream clinical
applications. Ultimately, it not only supplies foundation models with
high-quality, multimodal data for large-scale pretraining and domain-specific
fine-tuning, but also serves as a knowledge retrieval backend to support
task-specific inference via the agentic layer. The ecosystem enables the
deployment of GenAI for high-quality and effective healthcare delivery.

</details>


### [34] [FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling](https://arxiv.org/abs/2510.24645)
*Zengzhuang Xu,Bingguang Hao,Zechuan Wang,Yuntao Wen,Maolin Wang,Yang Liu,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Chenyi Zhuang,Jinjie Gu,Leilei Gan,Xiangyu Zhao,Shi Gu*

Main category: cs.AI

TL;DR: FunReason-MT是一个用于真实世界多轮工具使用的数据合成框架，通过环境-API图交互、高级工具查询合成和引导迭代链来解决多轮函数调用数据的复杂性挑战，在BFCL基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据合成方法（如随机环境采样或多智能体角色扮演）不足以在真实世界环境中生成高质量的多轮函数调用训练数据，存在目标模型训练、工具架构隔离和多轮逻辑依赖三个主要挑战。

Method: FunReason-MT采用三种核心技术：1）环境-API图交互收集多样化高质量轨迹；2）高级工具查询合成简化困难查询构建；3）引导迭代链生成复杂思维链。

Result: 在Berkeley函数调用排行榜（BFCLv3）上，基于FunReason-MT生成数据构建的4B模型在同等规模模型中达到最先进性能，优于大多数闭源模型。在BFCLv4上的进一步性能改进证实了该框架的可靠性。

Conclusion: FunReason-MT为智能体学习提供了可靠且强大的数据源，能够有效解决真实世界多轮工具使用的数据合成挑战。

Abstract: Function calling (FC) empowers large language models (LLMs) and autonomous
agents to interface with external tools, a critical capability for solving
complex, real-world problems. As this ability becomes increasingly central to
advanced AI systems, the need for high-quality, multi-turn training data to
develop and refine it cannot be overstated. Existing data synthesis methods,
such as random environment sampling or multi-agent role-playing, are not
powerful enough to generate high-quality data in real-world environments.
Practical challenges come in three folds: targeted model training, isolation of
tool architecture, and multi-turn logical dependency. To address these
structural deficiencies, we present FunReason-MT, a novel data synthesis
framework for real-world multi-turn tool use. FunReason-MT resolves the
complexity barrier in multi-turn FC data by employing 1) Environment-API Graph
Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query
Synthesis to simplify hard query construction, and 3) Guided Iterative Chain
for sophisticated CoT generation. Evaluations on Berkeley Function-Calling
Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built
upon FunReason-MT generated data achieves state-of-the-art performance among
comparable-sized models, outperforming most close-source models. Further
performance improvements on BFCLv4 confirm that FunReason-MT provides a
reliable and robust source for agentic learning.

</details>


### [35] [Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning](https://arxiv.org/abs/2510.24650)
*Nitin Rai,Daeun,Choi,Nathan S. Boyd,Arnold W. Schumann*

Main category: cs.AI

TL;DR: 该综述分析了约40篇关于基础模型在作物病害精准管理中的应用文献，重点讨论了大型语言模型和视觉语言模型在自适应学习、强化学习和数字孪生框架中的作用。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和深度学习在实时计算机视觉中的快速发展，作物病害精准管理从手工特征提取发展到大规模自动化特征学习。基础模型通过整合视觉和文本数据，为病害管理提供了新的处理方式。

Method: 通过文献综述方法，筛选约40篇相关论文，分析基础模型（特别是LLMs和VLMs）在自适应学习、强化学习和数字孪生框架中的应用。

Result: 主要发现包括：基础模型应用在2023-24年快速增长；VLMs发展速度远超LLMs；RL和AL在智能喷洒中仍处于早期阶段；数字孪生结合RL可模拟靶向喷洒；解决模拟到现实的差距是关键挑战；人机协作仍有局限。

Conclusion: 多模态基础模型结合实时反馈将推动下一代作物病害精准管理的发展，需要关注模拟到现实的差距和人机协作的改进。

Abstract: Site-specific disease management (SSDM) in crops has advanced rapidly through
machine and deep learning (ML and DL) for real-time computer vision. Research
evolved from handcrafted feature extraction to large-scale automated feature
learning. With foundation models (FMs), crop disease datasets are now processed
in fundamentally new ways. Unlike traditional neural networks, FMs integrate
visual and textual data, interpret symptoms in text, reason about
symptom-management relationships, and support interactive QA for growers and
educators. Adaptive and imitation learning in robotics further enables
field-based disease management. This review screened approx. 40 articles on FM
applications for SSDM, focusing on large-language models (LLMs) and
vision-language models (VLMs), and discussing their role in adaptive learning
(AL), reinforcement learning (RL), and digital twin frameworks for targeted
spraying. Key findings: (a) FMs are gaining traction with surging literature in
2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL
and AL are still nascent for smart spraying; (d) digital twins with RL can
simulate targeted spraying virtually; (e) addressing the sim-to-real gap is
critical for real-world deployment; (f) human-robot collaboration remains
limited, especially in human-in-the-loop approaches where robots detect early
symptoms and humans validate uncertain cases; (g) multi-modal FMs with
real-time feedback will drive next-gen SSDM. For updates, resources, and
contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to
submit papers, code, or datasets.

</details>


### [36] [OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs](https://arxiv.org/abs/2510.24663)
*Yifu Lu,Shengjie Liu,Li Dong*

Main category: cs.AI

TL;DR: OrchDAG是一个合成数据生成管道，将工具执行建模为具有可控复杂度的有向无环图，用于多轮工具交互的基准测试和强化学习训练。


<details>
  <summary>Details</summary>
Motivation: 现有工作大多忽略了多轮工具交互的复杂性，需要更好的方法来建模和训练智能体的多轮工具使用能力。

Method: 引入OrchDAG合成数据生成管道，将工具执行建模为有向无环图；提出基于图的奖励来增强RLVR训练。

Result: 实验表明该数据集提供了具有挑战性但可解决的基准，所提出的奖励与GRPO风格算法结合时效果显著。

Conclusion: 在多轮工具使用中，利用拓扑结构和数据复杂度至关重要，图结构方法能有效提升模型性能。

Abstract: Agentic tool use has gained traction with the rise of agentic tool calling,
yet most existing work overlooks the complexity of multi-turn tool
interactions. We introduce OrchDAG, a synthetic data generation pipeline that
models tool execution as directed acyclic graphs (DAGs) with controllable
complexity. Using this dataset, we benchmark model performance and propose a
graph-based reward to enhance RLVR training. Experiments show that the dataset
presents a challenging but solvable benchmark, and the proposed reward is
effective when combined with GRPO-style algorithms, highlighting the importance
of leveraging topological structure and data complexity in multi-turn tool use.

</details>


### [37] [Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning](https://arxiv.org/abs/2510.24690)
*Shengjie Liu,Li Dong,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 提出了一个通过构建工具知识图谱和文档知识图谱来增强示例工件生成的框架，通过深度-稀疏集成策略对齐工具依赖关系和程序知识。


<details>
  <summary>Details</summary>
Motivation: 为了揭示和利用工具与文档之间的依赖关系，以改进示例工件的生成质量。

Method: 从工具模式构建工具知识图谱，从内部文档和SOP构建文档知识图谱，然后将两者融合，采用深度-稀疏集成策略对齐结构工具依赖与程序知识。

Result: 实验表明该统一框架能有效建模工具交互并改进计划生成。

Conclusion: 将工具图谱与领域知识图谱连接对于工具增强推理和规划具有显著益处。

Abstract: We present a framework for uncovering and exploiting dependencies among tools
and documents to enhance exemplar artifact generation. Our method begins by
constructing a tool knowledge graph from tool schemas,including descriptions,
arguments, and output payloads, using a DeepResearch-inspired analysis. In
parallel, we derive a complementary knowledge graph from internal documents and
SOPs, which is then fused with the tool graph. To generate exemplar plans, we
adopt a deep-sparse integration strategy that aligns structural tool
dependencies with procedural knowledge. Experiments demonstrate that this
unified framework effectively models tool interactions and improves plan
generation, underscoring the benefits of linking tool graphs with domain
knowledge graphs for tool-augmented reasoning and planning.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [38] [The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing](https://arxiv.org/abs/2510.23911)
*Arno Uhlig,Iris Braun,Matthias Wählisch*

Main category: cs.DC

TL;DR: 本文分析了SAP云平台中虚拟机调度和放置问题，基于1800台虚拟化主机和48000个VM的30天数据，揭示了资源分配中的多个低效问题，包括CPU资源争用超过40%、CPU就绪时间达220秒、主机负载严重不平衡等问题。


<details>
  <summary>Details</summary>
Motivation: 研究分布式环境中资源分配的基本挑战，特别是在企业级云平台中优化虚拟机调度和资源管理，以提高资源利用效率。

Method: 通过可观测性工具收集30天内1800台虚拟化主机和48000个虚拟机的细粒度时间序列遥测数据，分析SAP S/4HANA和其他通用应用的资源使用模式。

Result: 发现多个次优调度情况：CPU资源争用超过40%，CPU就绪时间高达220秒，主机间CPU利用率严重不平衡（最高达99%），超过80%的VM使用不到70%的分配资源。

Conclusion: 基于研究发现提出了新型调度算法的设计需求，为优化资源分配提供指导，并将完整数据集公开以支持未来大规模云基础设施调度方法的数据驱动评估。

Abstract: Allocating resources in a distributed environment is a fundamental challenge.
In this paper, we analyze the scheduling and placement of virtual machines
(VMs) in the cloud platform of SAP, the world's largest enterprise resource
planning software vendor. Based on data from roughly 1,800 hypervisors and
48,000 VMs within a 30-day observation period, we highlight potential
improvements for workload management. The data was measured through
observability tooling that tracks resource usage and performance metrics across
the entire infrastructure. In contrast to existing datasets, ours uniquely
offers fine-grained time-series telemetry data of fully virtualized
enterprise-level workloads from both long-running and memory-intensive SAP
S/4HANA and diverse, general-purpose applications. Our key findings include
several suboptimal scheduling situations, such as CPU resource contention
exceeding 40%, CPU ready times of up to 220 seconds, significantly imbalanced
compute hosts with a maximum CPU~utilization on intra-building block hosts of
up to 99%, and overprovisioned CPU and memory resources resulting into over 80%
of VMs using less than 70% of the provided resources. Bolstered by these
findings, we derive requirements for the design and implementation of novel
placement and scheduling algorithms and provide guidance to optimize resource
allocations. We make the full dataset used in this study publicly available to
enable data-driven evaluations of scheduling approaches for large-scale cloud
infrastructures in future research.

</details>


### [39] [A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales](https://arxiv.org/abs/2510.23993)
*Anthony Carreon,Jagmohan Singh,Shivank Sharma,Shuzhi Zhang,Venkat Raman*

Main category: cs.DC

TL;DR: 提出了一种基于AMReX框架的高性能可压缩反应流求解器，针对多GPU环境优化，解决了内存访问模式、计算负载变化和多GPU负载分配等性能瓶颈，在燃烧应用中实现了2-5倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 高速化学反应流由于空间和时间尺度的巨大差异带来显著计算挑战，其中刚性化学动力学通常主导模拟时间。现有的基于GPU的可压缩燃烧求解器在内存管理、负载平衡和处理化学反应高度局部化特性方面存在关键限制。

Method: 基于AMReX框架构建多GPU优化的反应流求解器，采用列优先存储优化内存访问模式，使用批量稀疏积分策略处理化学动力学计算负载变化，并针对自适应网格细化应用优化多GPU负载分配，将现有基于矩阵的化学动力学公式适配到多重网格环境。

Result: 在氢-空气爆轰和超声速横流中射流等代表性燃烧应用中，相比初始GPU实现实现了2-5倍的性能提升，在1-96个NVIDIA H100 GPU上表现出接近理想的弱扩展性。屋顶线分析显示对流和化学动力学例程的算术强度分别提高了约10倍和4倍。

Conclusion: 该求解器通过优化内存访问模式、计算负载平衡和多GPU负载分配，有效利用了GPU内存带宽和计算资源，显著提升了可压缩反应流模拟的性能和扩展性。

Abstract: High-speed chemically active flows present significant computational
challenges due to their disparate space and time scales, where stiff chemistry
often dominates simulation time. While modern supercomputing scientific codes
achieve exascale performance by leveraging graphics processing units (GPUs),
existing GPU-based compressible combustion solvers face critical limitations in
memory management, load balancing, and handling the highly localized nature of
chemical reactions. To this end, we present a high-performance compressible
reacting flow solver built on the AMReX framework and optimized for multi-GPU
settings. Our approach addresses three GPU performance bottlenecks: memory
access patterns through column-major storage optimization, computational
workload variability via a bulk-sparse integration strategy for chemical
kinetics, and multi-GPU load distribution for adaptive mesh refinement
applications. The solver adapts existing matrix-based chemical kinetics
formulations to multigrid contexts. Using representative combustion
applications including hydrogen-air detonations and jet in supersonic crossflow
configurations, we demonstrate $2-5\times$ performance improvements over
initial GPU implementations with near-ideal weak scaling across $1-96$ NVIDIA
H100 GPUs. Roofline analysis reveals substantial improvements in arithmetic
intensity for both convection ($\sim 10 \times$) and chemistry ($\sim 4
\times$) routines, confirming efficient utilization of GPU memory bandwidth and
computational resources.

</details>


### [40] [Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System](https://arxiv.org/abs/2510.24175)
*Nitin Shukla,Alessandro Romeo,Caterina Caravita,Michael Redenti,Radim Vavrik,Lubomir Riha,Andrea Mignone,Marco Rossazza,Stefano Truzzi,Luca Tornatore,Antonio Ragagnin,Tiago Castro,Geray S. Karademir,Klaus Dolag,Pranab J. Deka,Fabio Bacchini,Rostislav-Paul Wilhelm,Daniele Gregori,Elisabetta Boella*

Main category: cs.DC

TL;DR: SPACE中心通过优化gPLUTO、OpenGadget3和iPIC3D三个旗舰代码，在Leonardo系统上实现了高达1024个GPU的80%可扩展性，为天体物理和宇宙学的大规模模拟提供支持。


<details>
  <summary>Details</summary>
Motivation: 为现有和下一代加速器开发和重新设计天体物理、宇宙学和空间等离子体数值代码，以支持大规模模拟，应对高性能计算挑战。

Method: 使用性能分析工具分析单节点和多节点上的性能，优化三个旗舰代码（gPLUTO、OpenGadget3和iPIC3D）在CINECA的Leonardo系统上。

Result: 初步测试显示所有三个代码都能高效扩展，在1024个GPU上达到80%的可扩展性。

Conclusion: SPACE中心通过科学家、代码开发者和高性能计算专家之间的合作，成功优化了关键应用，为百亿亿次计算时代做好了准备。

Abstract: Developing and redesigning astrophysical, cosmological, and space plasma
numerical codes for existing and next-generation accelerators is critical for
enabling large-scale simulations. To address these challenges, the SPACE Center
of Excellence (SPACE-CoE) fosters collaboration between scientists, code
developers, and high-performance computing experts to optimize applications for
the exascale era. This paper presents our strategy and initial results on the
Leonardo system at CINECA for three flagship codes, namely gPLUTO, OpenGadget3
and iPIC3D, using profiling tools to analyze performance on single and multiple
nodes. Preliminary tests show all three codes scale efficiently, reaching 80%
scalability up to 1,024 GPUs.

</details>


### [41] [CoMPSeT: A Framework for Comparing Multiparty Session Types](https://arxiv.org/abs/2510.24205)
*Telmo Ribeiro,José Proença,Mário Florido*

Main category: cs.DC

TL;DR: 提出了一个名为CoMPSeT的工具，用于分析和比较不同多党会话类型（MPST）的特性，帮助研究人员和教师更好地理解全局编排协议。


<details>
  <summary>Details</summary>
Motivation: 并发系统设计复杂，现有的MPST变体各有特定功能和特性，缺乏统一的比较工具来清晰展示不同特性。

Method: 选择代表性MPST示例，提供机制组合不同特性，通过动画和比较具体示例的语义来展示差异。

Result: 开发了开源的CoMPSeT工具，编译为JavaScript，可在浏览器中直接运行。

Conclusion: CoMPSeT为研究人员理解MPST领域和教师讲解全局编排提供了实用工具。

Abstract: Concurrent systems are often complex and difficult to design. Choreographic
languages, such as Multiparty Session Types (MPST), allow the description of
global protocols of interactions by capturing valid patterns of interactions
between participants. Many variations of MPST exist, each one with its rather
specific features and idiosyncrasies. Here we propose a tool (CoMPSeT) that
provides clearer insights over different features in existing MPST. We select a
representative set of MPST examples and provide mechanisms to combine different
features and to animate and compare the semantics of concrete examples. CoMPSeT
is open-source, compiled into JavaScript, and can be directly executed from any
browser, becoming useful both for researchers who want to better understand the
landscape of MPST and for teachers who want to explain global choreographies.

</details>
