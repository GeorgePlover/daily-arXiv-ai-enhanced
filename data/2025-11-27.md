<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.DC](#cs.DC) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring](https://arxiv.org/abs/2511.20679)
*Melika Ayoughi,Pascal Mettes,Paul Groth*

Main category: cs.AI

TL;DR: 本文研究了使用大型语言模型自动重构层次结构以优化双曲嵌入质量的方法，通过提示引导LLM重构现有层次结构，实验表明重构后的层次结构在多个标准嵌入质量指标上表现更好。


<details>
  <summary>Details</summary>
Motivation: 双曲嵌入的质量与输入层次结构紧密相关，而最佳双曲嵌入需要高分支因子和单继承特性。本文旨在探索LLM是否能够自动重构层次结构以满足这些标准，帮助知识工程师优化知识组织。

Method: 提出基于提示的方法，使用LLM在已知双曲嵌入期望标准的指导下转换现有层次结构，在16个不同层次结构上进行实验验证。

Result: 实验结果显示，LLM重构的层次结构在多个标准嵌入质量指标上始终产生更高质量的双曲嵌入，并且能够提供可解释的重组理由。

Conclusion: LLM能够有效自动重构层次结构以优化双曲嵌入质量，同时提供可解释的重组过程，为知识工程师提供有价值的支持。

Abstract: Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.

</details>


### [2] [$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://arxiv.org/abs/2511.20693)
*Mingming Zhao,Xiaokang Wei,Yuanqi Shao,Kaiwen Zhou,Lin Yang,Siwei Rao,Junhui Zhan,Zhitang Chen*

Main category: cs.AI

TL;DR: A²Flow是一个基于自适应抽象算子的全自动智能体工作流生成框架，通过三阶段算子提取过程自动生成可重用的执行算子，无需手动预定义，在性能和资源使用方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖手动预定义的算子，限制了智能体工作流的泛化性和可扩展性，需要开发完全自动化的框架来解决这一问题。

Method: 采用三阶段算子提取：1）基于案例的初始算子生成；2）算子聚类和初步抽象；3）深度提取抽象执行算子。同时引入算子记忆机制来增强工作流搜索。

Result: 在通用和具身基准测试中，A²Flow实现了2.4%和19.3%的平均性能提升，并将资源使用减少了37%。

Conclusion: A²Flow通过完全自动化的算子提取和记忆机制，显著提升了智能体工作流的性能和效率，为自动化工作流设计提供了有效解决方案。

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\% and 19.3\% average performance improvement and reduces resource usage by 37\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW

</details>


### [3] [AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI](https://arxiv.org/abs/2511.20686)
*Chae-Gyun Lim,Seung-Ho Han,EunYoung Byun,Jeongyun Han,Soohyun Cho,Eojin Joo,Heehyeon Kim,Sieun Kim,Juhoon Lee,Hyunsoo Lee,Dongkun Lee,Jonghwan Hyeon,Yechan Hwang,Young-Jun Lee,Kyeongryul Lee,Minhyeong An,Hyunjun Ahn,Jeongwoo Son,Junho Park,Donggyu Yoon,Taehyung Kim,Jeemin Kim,Dasom Choi,Kwangyoung Lee,Hyunseung Lim,Yeohyun Jung,Jongok Hong,Sooyohn Nam,Joonyoung Park,Sungmin Na,Yubin Choi,Jeanne Choi,Yoojin Hong,Sueun Jang,Youngseok Seo,Somin Park,Seoungung Jo,Wonhye Chae,Yeeun Jo,Eunyoung Kim,Joyce Jiyoung Whang,HwaJung Hong,Joseph Seering,Uichin Lee,Juho Kim,Sunna Choi,Seokyeon Ko,Taeho Kim,Kyunghoon Kim,Myungsik Ha,So Jung Lee,Jemin Hwang,JoonHo Kwak,Ho-Jin Choi*

Main category: cs.AI

TL;DR: AssurAI是一个针对韩语多模态生成AI安全评估的质量控制数据集，包含11,480个文本、图像、视频和音频实例，覆盖35种AI风险因素，特别关注韩语社会文化背景下的安全问题。


<details>
  <summary>Details</summary>
Motivation: 当前的安全评估数据集主要是英语中心的，无法捕捉非英语社会文化背景（如韩语）中的特定风险，且通常仅限于文本模态。

Method: 通过多学科专家组定义35种AI风险分类法，采用两阶段构建（专家引导播种和众包扩展）、三重独立标注和迭代专家红队测试的严格质量控制流程。

Result: 构建并发布了AssurAI数据集，试点研究验证了其在评估最新LLM安全性方面的有效性。

Conclusion: AssurAI的发布将促进为韩语社区开发更安全可靠的生成AI系统。

Abstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.

</details>


### [4] [Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning](https://arxiv.org/abs/2511.20694)
*Kevin Lee,Russell Spiewak,James Walsh*

Main category: cs.AI

TL;DR: 本文提出了一个名为'Reasoning With a Star'的日球物理学推理数据集和基准测试方法，用于评估大语言模型在科学推理中的表现，发现基于系统工程原则的多智能体工作流在需要演绎推理的问题上优于直接提示。


<details>
  <summary>Details</summary>
Motivation: 解决日球物理学中大语言模型科学推理的挑战，包括整合物理假设、保持单位一致性和提供清晰科学格式的需求。

Method: 构建基于NASA和UCAR Living With a Star暑期学校问题集的数据集，包含问题上下文、推理步骤、预期答案类型等；开发程序化评分器，使用单位感知数值容差、符号等价性和模式验证；基准测试包括单次提示基线和四种多智能体模式。

Result: 发现通过系统工程原则分解工作流在需要演绎推理的问题上表现优于直接提示，而在纯归纳回忆问题上差异不明显。

Conclusion: 多智能体工作流方法能够有效提升大语言模型在复杂科学推理任务中的表现，特别是在需要演绎推理的场景下。

Abstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.

</details>


### [5] [A Brief History of Digital Twin Technology](https://arxiv.org/abs/2511.20695)
*Yunqi Zhang,Kuangyu Shi,Biao Li*

Main category: cs.AI

TL;DR: 数字孪生技术从NASA航天器模拟发展而来，现已在医疗领域实现转型应用。它通过实时数据创建患者特异性虚拟模型，支持诊断、治疗规划和药物开发。代表性应用包括心脏、肿瘤和药理学数字孪生。尽管面临互操作性、数据隐私和模型保真度等挑战，但可解释AI、联邦学习等新兴解决方案提供了前进路径。


<details>
  <summary>Details</summary>
Motivation: 推动医疗从被动治疗向预测性、预防性和个性化医疗转变，利用数字孪生技术整合多源数据，实现更精准的医疗决策和个性化治疗。

Method: 通过整合医学影像、生物传感器和计算模型，构建数据驱动的动态虚拟患者模型，实现与物理系统的双向交互和实时更新。

Result: 成功开发了心脏数字孪生预测心律失常治疗结果、肿瘤数字孪生追踪肿瘤进展和优化放疗、药理学数字孪生加速药物发现等代表性应用。

Conclusion: 数字孪生技术有望彻底改变医疗模式，但需要解决互操作性、数据隐私和模型保真度等挑战，未来发展方向包括多器官数字孪生、基因组学整合和伦理治理框架的完善。

Abstract: Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.

</details>


### [6] [Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework](https://arxiv.org/abs/2511.20701)
*Nitya Tiwari,Parv Maheshwari,Vidisha Agarwal*

Main category: cs.AI

TL;DR: 本文对多模态思维链推理进行了综合分析，评估了其在A-OKVQA、OKVQA和ChartQA数据集上的有效性，发现视觉集成能减少推理幻觉，但思维链推理效果在不同问题类型间差异显著。


<details>
  <summary>Details</summary>
Motivation: 虽然最近工作将思维链扩展到多模态设置并在科学问答基准上取得先进结果，但这些方法在不同领域的泛化能力仍未充分探索。本文旨在评估多模态思维链推理在需要广泛常识和世界知识的跨领域数据集上的有效性。

Method: 采用Zhang等人提出的两阶段框架，将推理生成与答案推断分离，并通过门控融合机制将视觉特征与基于T5的语言模型集成。通过系统消融研究分析视觉特征、推理质量和架构选择的贡献。

Result: 研究发现视觉集成显著减少推理生成中的幻觉，但思维链推理的有效性在不同问题类型间差异很大，常识推理尤其具有挑战性。

Conclusion: 这项工作为研究人员实现多模态推理系统提供了实用见解，并确定了跨领域泛化未来改进的关键领域。

Abstract: While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.

</details>


### [7] [Representation Interventions Enable Lifelong Unstructured Knowledge Control](https://arxiv.org/abs/2511.20892)
*Xuyuan Liu,Zhengzhang Chen,Xinshuai Dong,Yanchi Liu,Xujiang Zhao,Shengyu Chen,Haoyu Wang,Yujun Yan,Haifeng Chen*

Main category: cs.AI

TL;DR: RILKE是一种在大语言模型表示空间进行干预的知识控制方法，通过训练模块化组件实现细粒度知识编辑，在保持基础权重不变的情况下支持大规模终身知识更新。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型知识错误或过时的问题，避免昂贵的重新训练，在终身学习设置中实现多知识编辑共存且互不干扰。

Method: 在模型表示空间进行干预，训练具有抗释义性和编辑局部性的模块，将每个更新限制在低维子空间以减少交叉干扰，推理时通过查询自适应路由器选择适当模块。

Result: 在LLaMA和Qwen模型的知识编辑基准测试中，RILKE可扩展到大规模数据集，表现出高编辑成功率、强释义泛化能力，并以适度内存开销保持通用效用。

Conclusion: RILKE是大语言模型中终身知识控制的有效且可扩展解决方案。

Abstract: Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.

</details>


### [8] [ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction](https://arxiv.org/abs/2511.20937)
*Qineng Wang,Wenlong Huang,Yu Zhou,Hang Yin,Tianwei Bao,Jianwen Lyu,Weiyu Liu,Ruohan Zhang,Jiajun Wu,Li Fei-Fei,Manling Li*

Main category: cs.AI

TL;DR: ENACT是一个评估具身认知的基准测试，通过视觉问答形式评估模型从自我中心交互中进行世界建模的能力，包含前向世界建模和逆向世界建模两个任务。


<details>
  <summary>Details</summary>
Motivation: 探索现代视觉语言模型是否表现出具身认知的迹象，即智能是否源于感觉运动交互而非被动观察。

Method: 将具身认知评估构建为部分可观察马尔可夫决策过程中的世界建模问题，使用来自机器人仿真(BEHAVIOR)的可扩展流水线合成问答对，包含前向世界建模(给定动作重排观察序列)和逆向世界建模(给定观察重排动作序列)两个任务。

Result: 实验显示前沿视觉语言模型与人类之间存在性能差距，且差距随交互时间跨度增加而扩大；模型在逆向任务上表现优于前向任务，并表现出以人为中心的偏见，如偏好右手动作、当相机参数或视角偏离人类视觉时性能下降。

Conclusion: ENACT基准测试揭示了现代视觉语言模型在具身认知能力方面的局限性，为理解和发展具身智能提供了重要工具。

Abstract: Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.

</details>


### [9] [Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture](https://arxiv.org/abs/2511.20942)
*Rahul Dass,Thomas Bowlin,Zebing Li,Xiao Jin,Ashok Goel*

Main category: cs.AI

TL;DR: Ivy是一个AI教练系统，通过结合符号化的TMK模型和生成式解释层，提供结构化、多步骤的解释，改善LLM生成解释的结构质量。


<details>
  <summary>Details</summary>
Motivation: 在程序性技能学习中，教学解释不仅要传达步骤，还要传达背后的因果、目标导向和组合逻辑。大型语言模型通常产生流畅但浅层的响应，缺乏这种结构。

Method: Ivy系统结合符号化的任务-方法-知识(TMK)模型与生成式解释层，TMK编码因果转换、目标层次和问题分解，指导LLM在明确的结构边界内构建解释。

Result: 与GPT和检索增强GPT基线相比，Ivy在三个推理维度上通过专家和独立标注评估，结果显示符号约束持续改善了"如何"和"为什么"问题的解释结构质量。

Conclusion: 这项研究展示了一种可扩展的AI教育方法，通过符号约束增强了AI生成解释在智能教练系统中的教学价值。

Abstract: In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for "how" and "why" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.

</details>


### [10] [ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning](https://arxiv.org/abs/2511.21005)
*Jinpeng Wang,Chao Li,Ting Ye,Mengyuan Zhang,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: 本文提出了一种新的强化学习方法ICPO，通过结合语言模型自身生成概率的内在置信度和可验证奖励，解决了现有RLVR方法中粗粒度奖励、奖励噪声和低效探索等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法存在粗粒度奖励、奖励噪声和低效探索等问题，导致训练不稳定和熵崩溃，限制了大型语言模型推理能力的提升。

Method: 提出ICPO方法，通过计算多个响应在同一输入提示下的相对生成概率来获得偏好优势分数，并将该分数与可验证奖励结合来指导探索过程。

Result: 在四个通用领域基准和三个数学基准上的综合实验表明，ICPO相比GRPO能够稳定提升推理能力。

Conclusion: ICPO方法通过利用语言模型的内在置信度，有效缓解了奖励相关问题，抑制了过度自信错误，增强了被低估的高质量响应的相对优势，促进了更彻底的探索。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.

</details>


### [11] [Causality Without Causal Models](https://arxiv.org/abs/2511.21260)
*Joseph Y. Halpern,Rafael Pass*

Main category: cs.AI

TL;DR: 本文对Halpern和Pearl的实际因果关系定义进行了抽象化，提取其关键特征，使其能够应用于任何定义了反事实的模型。通过这种抽象化，该定义可以处理更广泛的模型和更复杂的公式。


<details>
  <summary>Details</summary>
Motivation: Halpern和Pearl的因果关系定义局限于因果模型，无法处理包含析取、否定、信念和嵌套反事实的复杂公式。本文旨在抽象化该定义，使其具有更广泛的应用范围。

Method: 通过抽象化Halpern-Pearl定义的关键特征，构建一个可以在任何定义了反事实的模型中应用的因果关系定义框架。

Result: 成功开发了一个抽象的因果关系定义，能够处理更广泛的模型类型（包括允许回溯的模型）和更复杂的公式结构。

Conclusion: 抽象化的因果关系定义不仅扩展了应用范围，还深化了对因果关系定义特征的理解，并能进一步扩展到解释的定义。

Abstract: Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.

</details>


### [12] [New Hybrid Heuristics for Pseudo-Boolean Propagation](https://arxiv.org/abs/2511.21417)
*Mia Müßig,Jan Johannsen*

Main category: cs.AI

TL;DR: 本文提出了新的启发式方法用于伪布尔求解中的混合单元传播策略，显著提升了RoundingSAT求解器的性能


<details>
  <summary>Details</summary>
Motivation: 当前伪布尔求解中最成功的单元传播策略是结合观察文字方案和计数方法的混合模式，但需要更好的启发式方法来决定何时使用哪种方法

Method: 引入了新的启发式方法用于混合决策，在RoundingSAT求解器中实现

Result: 新启发式方法能够大幅超越当前方法的性能

Conclusion: 新提出的启发式方法在伪布尔求解的混合单元传播策略中表现出显著优势

Abstract: In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.

</details>


### [13] [SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition](https://arxiv.org/abs/2511.21471)
*Peiran Xu,Sudong Wang,Yao Zhu,Jianing Li,Yunjian Zhang*

Main category: cs.AI

TL;DR: 提出了一个分层空间认知框架，将空间智能分解为从基础观察到高级规划的五个渐进复杂层次，并构建了SpatialBench基准来系统评估多模态大语言模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试往往将空间认知过度简化为单一维度指标，无法捕捉空间能力的层次结构和相互依存关系，需要更系统的评估框架。

Method: 提出了分层空间认知框架（五个认知层次），构建了SpatialBench基准（覆盖15个任务），并引入了面向能力的高层指标来统一评估异构任务。

Result: 实验发现模型在不同认知层次上表现分层：感知基础能力强，但在符号推理、因果推断和规划方面仍有限制；人类进行选择性目标导向抽象，而MLLMs倾向于过度关注表面细节。

Conclusion: 建立了首个系统测量MLLMs分层空间认知的框架，为未来空间智能系统奠定了基础。

Abstract: Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.

</details>


### [14] [Pessimistic Verification for Open Ended Math Questions](https://arxiv.org/abs/2511.21522)
*Yanxing Huang,Zihan Tang,Zejin Lin,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 提出悲观验证方法，通过并行构建多个验证流程来检测数学证明错误，显著提升验证性能且计算资源消耗低


<details>
  <summary>Details</summary>
Motivation: 现有验证性能的关键限制在于错误检测能力，需要改进开放数学问题的验证方法

Method: 设计悲观验证变体，为同一证明构建多个并行验证流程，只要任一验证报告错误即判定证明不正确

Result: 该方法在多个数学验证基准上显著提升性能，计算资源消耗低，token效率甚至超过扩展长链思维测试时缩放

Conclusion: 悲观验证能有效提升语言模型数学输出的可靠性和性能，对实现长程数学任务至关重要，有助于增强语言模型在广泛任务中的数学能力

Abstract: The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.

</details>


### [15] [Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit](https://arxiv.org/abs/2511.21569)
*Alex Diep*

Main category: cs.AI

TL;DR: 该研究评估了16个开源模型在专业角色扮演中的AI身份披露能力，发现模型在不同专业领域的身份透明度存在显著差异，且模型身份比参数数量更能预测披露行为，推理优化反而会抑制透明度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是确保AI模型在专业高风险领域中能够可靠地披露其AI身份，防止用户因模型虚假专业能力而受到伤害，建立可信的能力边界。

Method: 采用公共花园设计，对16个开源模型（4B-671B参数）进行了19,200次试验，使用贝叶斯验证和Rogan-Gladen校正来确保测量误差的鲁棒性。

Result: 模型在不同专业领域的身份披露率差异显著：金融顾问角色初始披露率为30.8%，而神经外科医生角色仅为3.5%；披露率范围从2.8%到73.6%；模型身份比参数数量更能预测行为（ΔR²adj = 0.359 vs 0.018）；推理优化会抑制透明度，推理变体比基础模型披露率降低高达48.4%。

Conclusion: 透明度反映的是训练因素而非模型规模，组织不能假设安全属性会转移到部署环境中，需要刻意设计行为和实证验证。

Abstract: If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a "Reverse Gell-Mann Amnesia" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($ΔR_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($κ= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.

</details>


### [16] [From Prediction to Foresight: The Role of AI in Designing Responsible Futures](https://arxiv.org/abs/2511.21570)
*Maria Perez-Ortiz*

Main category: cs.AI

TL;DR: 本文提出了'负责任的计算预见'概念，探讨人工智能在负责任预见中的作用，强调AI作为支持工具增强政策制定者应对不确定性和塑造可持续未来的能力。


<details>
  <summary>Details</summary>
Motivation: 在技术快速发展和全球挑战复杂的时代，需要负责任预见框架来帮助政策制定者应对未来不确定性并塑造未来。

Method: 建立负责任计算预见的基础原则，提出一套AI驱动的预见工具，结合模拟和情景分析来增强政策制定能力。

Result: AI与模拟和情景分析结合，能增强政策制定者应对不确定性、评估风险和制定可持续战略的能力。

Conclusion: AI应作为负责任、以人为本的预见中的支持工具，补充而非替代政策制定者的判断，以主动塑造有韧性和道德健全的未来。

Abstract: In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term "responsible computational foresight", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [17] [MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems](https://arxiv.org/abs/2511.20663)
*Barak Or*

Main category: cs.MA

TL;DR: 该论文将经典可靠性指标（MTTR、MTBF）引入认知领域，提出MTTR-A指标来量化多智能体系统的认知恢复延迟，通过基准模拟展示了不同恢复策略的性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有可观测性工具只能监控系统输出，无法量化智能体工作流在失去推理一致性后的恢复速度，需要一种方法来衡量认知稳定性。

Method: 使用AG News语料库和LangGraph编排框架进行基准模拟，建模多种反射模式下的恢复延迟，比较自动反射和人工干预两种恢复策略。

Result: 自动反射平均恢复时间约6秒，人工干预约12秒；200次运行中，模拟MTTR-A中位数为6.21±2.14秒，MTBF=6.7±2.14秒，NRR=0.08。

Conclusion: 通过将恢复延迟量化为分布式推理的可量化属性，为智能体认知的运行时可靠性奠定了基础，将认知恢复从临时过程转变为标准化、可解释的性能指标。

Abstract: Ensuring cognitive stability in autonomous multi-agent systems (MAS) is a central challenge for large-scale, distributed AI. While existing observability tools monitor system outputs, they cannot quantify how rapidly agentic workflows recover once reasoning coherence has been lost. We adapt classical reliability metrics-Mean Time-to-Recovery (MTTR), Mean Time Between Failures (MTBF), and related ratios-into the cognitive domain, defining MTTR-A (Mean Time-to-Recovery for Agentic Systems) as a runtime measure of cognitive recovery latency. MTTR-A quantifies the time required for a MAS to detect reasoning drift and restore consistent operation, capturing the recovery of reasoning coherence rather than infrastructural repair.
  A benchmark simulation using the AG~News corpus and the LangGraph orchestration framework was conducted, modeling recovery latencies across multiple reflex modes. Automated reflexes restored stability within approximately 6s on average, while human-approval interventions required about 12s. Across 200 runs, the median simulated MTTR-A was 6.21+-2.14s, MTBF=6.7+-2.14s, and NRR=0.08, demonstrating measurable runtime resilience across reflex strategies.
  By formalizing recovery latency as a quantifiable property of distributed reasoning-and deriving reliability bounds linking recovery time and cognitive uptime-this work establishes a foundation for runtime dependability in agentic cognition, transforming cognitive recovery from an ad-hoc process into a standardized, interpretable performance

</details>


### [18] [Resilient Charging Infrastructure via Decentralized Coordination of Electric Vehicles at Scale](https://arxiv.org/abs/2511.20943)
*Chuhao Qin,Alexandru Sorici,Andrei Olaru,Evangelos Pournaras,Adina Magda Florea*

Main category: cs.MA

TL;DR: 提出基于集体学习的电动汽车充电协调框架，在充电站故障或需求激增等紧急情况下平衡个体舒适度与系统效率，实现帕累托最优权衡。


<details>
  <summary>Details</summary>
Motivation: 现有分散式充电控制方法在严重突发事件（如充电站故障、充电请求激增）下表现不佳，导致长队列和驾驶员舒适度降低，需要解决有限充电槽竞争问题。

Method: 采用集体学习框架，推荐电动汽车采取自适应充电行为，在舒适度和效率之间动态调整优先级，适应变化的站容量和时空EV分布。

Result: 使用真实世界数据的实验表明，该方法优于基线方法，显著减少旅行和排队时间。在不确定充电条件下，适时自私或利他的驾驶员比始终保持适度行为的驾驶员等待时间更短。

Conclusion: 该方法在高比例充电站故障和对抗性EV情况下展示了分散式EV充电基础设施的改进韧性和可信度。

Abstract: The rapid adoption of electric vehicles (EVs) introduces major challenges for decentralized charging control. Existing decentralized approaches efficiently coordinate a large number of EVs to select charging stations while reducing energy costs, preventing power peak and preserving driver privacy. However, they often struggle under severe contingencies, such as station outages or unexpected surges in charging requests. These situations create competition for limited charging slots, resulting in long queues and reduced driver comfort. To address these limitations, we propose a novel collective learning-based coordination framework that allows EVs to balance individual comfort on their selections against system-wide efficiency, i.e., the overall queues across all stations. In the framework, EVs are recommended for adaptive charging behaviors that shift priority between comfort and efficiency, achieving Pareto-optimal trade-offs under varying station capacities and dynamic spatio-temporal EV distribution. Experiments using real-world data from EVs and charging stations show that the proposed approach outperforms baseline methods, significantly reducing travel and queuing time. The results reveal that, under uncertain charging conditions, EV drivers that behave selfishly or altruistically at the right moments achieve shorter waiting time than those maintaining moderate behavior throughout. Our findings under high fractions of station outages and adversarial EVs further demonstrate improved resilience and trustworthiness of decentralized EV charging infrastructure.

</details>


### [19] [Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation](https://arxiv.org/abs/2511.21510)
*Ke Zhang,Xiaoning Zhao,Ce Zheng,Jiahong Ning,Dandan Zhu,Wenqi Zhang,Chen Sun,Toshiharu Sugawara*

Main category: cs.MA

TL;DR: Tool-RoCo是一个基于RoCo多机器人协作基准的新基准，用于评估大语言模型在长期多智能体协作中的表现。它通过工具使用来评估多智能体协作和自组织能力，提出了四种LLM范式来评估不同自治水平。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多智能体系统研究依赖预定义的编排，忽视了智能体的自主性。Tool-RoCo旨在通过将其他智能体视为工具，利用工具使用来评估多智能体协作和自组织能力。

Method: 提出了四种LLM范式：集中式协作、集中式自组织、分散式协作和自组织。通过三个多机器人任务（SORT、PACK、CABINET）来测量格式和参数准确性以及智能体协调。

Result: 结果显示协作工具仅占所有工具的7.09%，表明基于LLM的智能体很少将其他智能体作为助手调用。激活工具占96.42%，表明当前LLM倾向于保持活跃智能体，很少为自适应协调而停用它们。

Conclusion: Tool-RoCo提供了一个系统性基准来评估LLM在多智能体任务中的自主性和协作能力，揭示了当前LLM在协作工具使用方面的局限性。

Abstract: This study proposes Tool-RoCo, a novel benchmark for evaluating large language models (LLMs) in long-term multi-agent cooperation based on RoCo, a multi-robot cooperative benchmark. Recent research on LLM-based multi-agent systems has relied on predefined orchestration, while ignoring agent autonomy. Tool-RoCo treats other agents as tools and introduces cooperative tools, leveraging tool usage to evaluate multi-agent cooperation and self-organization. Tool usage means that each agent (LLM) selects a tool from a candidate set based on the current state, receives feedback, and adjusts its selection in subsequent rounds. To evaluate different autonomy levels, we propose four LLM paradigms: (1) centralized cooperation, where a single LLM allocates tools to all agents; (2) centralized self-organization, where a central LLM autonomously activates agents while keeping others inactive; (3) decentralized cooperation, where each agent has its own LLM and calls tools based on local information; and (4) self-organization, where a randomly chosen initial agent can request collaboration, activating additional agents via tool calls. Tool-RoCo includes three multi-robot tasks, SORT, PACK, and CABINET, to measure format and parameter accuracy and agent coordination through tool usage. The results using several LLMs showed that cooperative tools accounted for only 7.09% of all tools, indicating that LLM-based agents rarely invoked others as assistants. Moreover, activation tools accounted for 96.42%, suggesting that current LLMs tend to maintain active agents while seldom deactivating them for adaptive coordination. Tool-RoCo provides a systematic benchmark to evaluate LLM autonomy and cooperation in multi-agent tasks. Code and Demo: https://github.com/ColaZhang22/Tool-Roco

</details>


### [20] [BAMAS: Structuring Budget-Aware Multi-Agent Systems](https://arxiv.org/abs/2511.21572)
*Liming Yang,Junyu Luo,Xuanzhe Liu,Yiling Lou,Zhenpeng Chen*

Main category: cs.MA

TL;DR: BAMAS是一种在预算约束下构建多智能体系统的新方法，通过整数线性规划选择最优LLM组合，使用强化学习确定交互拓扑，在保持性能的同时大幅降低成本。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的多智能体系统复杂性增加，成本成为实际部署的重要考虑因素，但现有工作很少在明确预算约束下构建多智能体系统。

Method: BAMAS首先通过整数线性规划问题选择最优LLM集合，平衡性能和成本；然后使用强化学习方法确定交互拓扑；最后基于选择的智能体和协作拓扑实例化系统。

Result: 在三个代表性任务上的评估显示，BAMAS与最先进的智能体构建方法相比，在保持相当性能的同时，成本降低了高达86%。

Conclusion: BAMAS提供了一种在预算约束下构建高效多智能体系统的可行方法，显著降低了部署成本。

Abstract: Large language model (LLM)-based multi-agent systems have emerged as a powerful paradigm for enabling autonomous agents to solve complex tasks. As these systems scale in complexity, cost becomes an important consideration for practical deployment. However, existing work rarely addresses how to structure multi-agent systems under explicit budget constraints. In this paper, we propose BAMAS, a novel approach for building multi-agent systems with budget awareness. BAMAS first selects an optimal set of LLMs by formulating and solving an Integer Linear Programming problem that balances performance and cost. It then determines how these LLMs should collaborate by leveraging a reinforcement learning-based method to select the interaction topology. Finally, the system is instantiated and executed based on the selected agents and their collaboration topology. We evaluate BAMAS on three representative tasks and compare it with state-of-the-art agent construction methods. Results show that BAMAS achieves comparable performance while reducing cost by up to 86%.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [21] [Assessing Redundancy Strategies to Improve Availability in Virtualized System Architectures](https://arxiv.org/abs/2511.20780)
*Alison Silva,Gustavo Callou*

Main category: cs.DC

TL;DR: 本文提出了一种基于随机Petri网的方法来分析私有云环境中Nextcloud文件服务器的可用性，评估了四种冗余策略对系统可用性的影响。


<details>
  <summary>Details</summary>
Motivation: 随着云存储平台在学术和商业环境中的普及，可靠性成为关键需求。特别是对于寻求公共云服务替代方案的组织，评估这些系统的可靠性至关重要。

Method: 使用Apache CloudStack在私有云环境中托管Nextcloud文件服务器，通过随机Petri网建模方法评估不同的冗余策略，包括基线配置、主机级冗余、虚拟机冗余以及两者组合。

Result: 结果表明，在主机和虚拟机级别同时实施冗余策略可以显著提高系统可用性并减少预期停机时间。

Conclusion: 所提出的方法为评估私有云可用性和支持基础设施设计决策提供了一种有效途径。

Abstract: Cloud-based storage platforms are becoming more common in both academic and business settings due to their flexible access to data and support for collaborative functionalities. As reliability becomes a vital requirement, particularly for organizations looking for alternatives to public cloud services, assessing the dependability of these systems is crucial. This paper presents a methodology for analyzing the availability of a file server (Nextcloud) hosted in a private cloud environment using Apache CloudStack. The analysis is based on a modeling approach through Stochastic Petri Nets (SPNs) that allows the evaluation of different redundancy strategies to enhance the availability of such systems. Four architectural configurations were modeled, including the baseline, host-level redundancy, virtual machine (VM) redundancy, and a combination of both. The results show that redundancy at both the host and VM levels significantly improves availability and reduces expected downtime. The proposed approach provides a method to evaluate the availability of a private cloud and support infrastructure design decisions.

</details>


### [22] [Aragog: Just-in-Time Model Routing for Scalable Serving of Agentic Workflows](https://arxiv.org/abs/2511.20975)
*Yinwei Dai,Zhuofu Chen,Anand Iyer,Ravi Netravali*

Main category: cs.DC

TL;DR: Aragog系统通过动态调整工作流配置来优化多阶段LLM任务的执行效率，在保持精度的同时显著提升吞吐量和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的工作流配置选择方法在请求执行前固定配置，无法适应系统负载的动态变化，导致在长时间执行过程中配置快速变得次优。

Method: Aragog将问题解耦为一次性路由步骤和廉价每阶段调度器，前者识别所有保持精度的配置，后者使用实时系统观察从中选择。

Result: 在多样化工作流和模型家族中，Aragog在峰值请求率下将最大服务吞吐量提高50.0-217.0%，中位数延迟降低32.5-78.9%。

Conclusion: Aragog通过运行时动态配置调整，有效解决了工作流服务中的成本效率问题，同时保持了与最昂贵配置相当的精度。

Abstract: Agentic workflows have emerged as a powerful paradigm for solving complex, multi-stage tasks, but serving them at scale is computationally expensive given the many LLM inferences that each request must pass through. Configuration selection, or the cost-aware assignment of workflow agents to specific LLMs, can reduce these costs, but existing approaches bind configuration decisions before request execution, making them ill-suited for the heterogeneous and lengthy execution of workflows. Specifically, system loads can fluctuate rapidly and substantially during a request's lifetime, causing fixed configurations to quickly become suboptimal. We present Aragog, a system that progressively adapts a request's configuration throughout its execution to match runtime dynamics. To make this practical despite the massive space of workflow configurations, Aragog decouples the problem into two core elements -- a one-time routing step that identifies all accuracy-preserving configurations, and a cheap per-stage scheduler that selects among them using up-to-date system observations -- and introduces novel strategies to accelerate each. Across diverse workflows and model families, Aragog increases maximum serving throughput by 50.0--217.0\% and reduces median latency by 32.5--78.9\% at peak request rates, while maintaining accuracy comparable to the most expensive configurations.

</details>


### [23] [A Dynamic PD-Disaggregation Architecture for Maximizing Goodput in LLM Inference Serving](https://arxiv.org/abs/2511.20982)
*Junhan Liao,Minxian Xu,Wanyi Zheng,Yan Wang,Kejiang Ye,Rajkumar Buyya,Chengzhong Xu*

Main category: cs.DC

TL;DR: DOPD是一个动态LLM推理系统，通过实时监控负载动态调整预填充和解码实例分配比例，解决异构工作负载下的生产者-消费者不平衡问题，提升系统吞吐量和延迟性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理系统将预填充和解码阶段分离到不同GPU上，但异构工作负载导致两种实例类型之间的生产者-消费者不平衡，造成资源分配不匹配。

Method: 提出DOPD系统，基于实时负载监控动态调整预填充与解码实例的最优比例，结合适当的请求调度策略，解决高并发下混合长度请求导致的资源分配不匹配问题。

Result: 相比vLLM和DistServe，DOPD将系统吞吐量提升最高1.5倍，P90首词延迟降低67.5%，P90每词输出延迟降低22.8%，使用更少额外资源实现超过99%的SLO达成率。

Conclusion: DOPD通过动态调整预填充与解码实例比例，有效解决了LLM推理系统中的资源不平衡问题，显著提升了系统性能和资源利用率。

Abstract: To meet strict Service-Level Objectives (SLOs),contemporary Large Language Models (LLMs) decouple the prefill and decoding stages and place them on separate GPUs to mitigate the distinct bottlenecks inherent to each phase. However, the heterogeneity of LLM workloads causes producerconsumer imbalance between the two instance types in such disaggregated architecture. To address this problem, we propose DOPD (Dynamic Optimal Prefill/Decoding), a dynamic LLM inference system that adjusts instance allocations to achieve an optimal prefill-to-decoding (P/D) ratio based on real-time load monitoring. Combined with an appropriate request-scheduling policy, DOPD effectively resolves imbalances between prefill and decoding instances and mitigates resource allocation mismatches due to mixed-length requests under high concurrency. Experimental evaluations show that, compared with vLLM and DistServe (representative aggregation-based and disaggregationbased approaches), DOPD improves overall system goodput by up to 1.5X, decreases P90 time-to-first-token (TTFT) by up to 67.5%, and decreases P90 time-per-output-token (TPOT) by up to 22.8%. Furthermore, our dynamic P/D adjustment technique performs proactive reconfiguration based on historical load, achieving over 99% SLOs attainment while using less additional resources.

</details>


### [24] [Automated Dynamic AI Inference Scaling on HPC-Infrastructure: Integrating Kubernetes, Slurm and vLLM](https://arxiv.org/abs/2511.21413)
*Tim Trappen,Robert Keßler,Roland Pabel,Viktor Achter,Stefan Wesner*

Main category: cs.DC

TL;DR: 本文提出了一种在超级计算机RAMSES上集成vLLM、Slurm和Kubernetes来服务LLM的解决方案，该方案能够高效扩展以处理100-1000个并发请求，端到端延迟仅增加约500毫秒。


<details>
  <summary>Details</summary>
Motivation: 由于AI推理需求增长，特别是在高等教育领域，需要利用现有基础设施的新解决方案。传统HPC操作模型不适用于同步、面向用户的动态AI应用工作负载。

Method: 在超级计算机RAMSES上集成vLLM、Slurm和Kubernetes来服务大型语言模型(LLM)。

Result: 初步基准测试表明，该架构能够高效扩展处理100、500和1000个并发请求，端到端延迟仅增加约500毫秒。

Conclusion: 提出的集成架构成功解决了传统HPC在AI推理应用中的适应性挑战，为大规模LLM服务提供了可行的解决方案。

Abstract: Due to rising demands for Artificial Inteligence (AI) inference, especially in higher education, novel solutions utilising existing infrastructure are emerging. The utilisation of High-Performance Computing (HPC) has become a prevalent approach for the implementation of such solutions. However, the classical operating model of HPC does not adapt well to the requirements of synchronous, user-facing dynamic AI application workloads. In this paper, we propose our solution that serves LLMs by integrating vLLM, Slurm and Kubernetes on the supercomputer \textit{RAMSES}. The initial benchmark indicates that the proposed architecture scales efficiently for 100, 500 and 1000 concurrent requests, incurring only an overhead of approximately 500 ms in terms of end-to-end latency.

</details>


### [25] [MemFine: Memory-Aware Fine-Grained Scheduling for MoE Training](https://arxiv.org/abs/2511.21431)
*Lu Zhao,Rong Shi,Shaoqing Zhang,Yueqiang Chen,Baoguo He,Hongfeng Sun,Ziqing Yin,Shangchao Su,Zhiyan Cui,Liang Dong,Xiyuan Li,Lingbin Wang,Jianwei He,Jiesong Ma,Weikang Huang,Jianglei Tong,Dongdong Gao,Jian Zhang,Hong Tian*

Main category: cs.DC

TL;DR: MemFine是一个内存感知的细粒度调度框架，用于解决MoE模型训练中的内存瓶颈问题，通过分块重计算策略减少48.03%的激活内存并提升4.42%的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大规模MoE模型训练面临严重的内存瓶颈，由于动态令牌路由导致的负载不平衡会造成GPU内存溢出，限制了模型的可扩展性。现有负载平衡方法会牺牲模型精度且在内存受限硬件上失效。

Method: MemFine将令牌分布和专家计算分解为可管理的块，采用分块重计算策略，通过理论内存模型动态优化以平衡内存效率和吞吐量。

Result: 实验表明，与基于完全重计算的基线相比，MemFine减少了48.03%的激活内存，提高了4.42%的吞吐量，能够在内存受限的GPU上实现稳定的大规模MoE训练。

Conclusion: MemFine框架有效解决了MoE训练中的内存瓶颈问题，通过内存感知的细粒度调度实现了内存效率和训练吞吐量的平衡，为大规模MoE模型在资源受限环境下的训练提供了可行方案。

Abstract: The training of large-scale Mixture of Experts (MoE) models faces a critical memory bottleneck due to severe load imbalance caused by dynamic token routing. This imbalance leads to memory overflow on GPUs with limited capacity, constraining model scalability. Existing load balancing methods, which cap expert capacity, compromise model accuracy and fail on memory-constrained hardware. To address this, we propose MemFine, a memory-aware fine-grained scheduling framework for MoE training. MemFine decomposes the token distribution and expert computation into manageable chunks and employs a chunked recomputation strategy, dynamically optimized through a theoretical memory model to balance memory efficiency and throughput. Experiments demonstrate that MemFine reduces activation memory by 48.03% and improves throughput by 4.42% compared to full recomputation-based baselines, enabling stable large-scale MoE training on memory-limited GPUs.

</details>


### [26] [Modeling the Effect of Data Redundancy on Speedup in MLFMA Near-Field Computation](https://arxiv.org/abs/2511.21535)
*Morteza Sadeghi*

Main category: cs.DC

TL;DR: 该论文提出通过数据冗余改善MLFMA中近场算子的GPU性能，减少内存访问分散性以提高空间局部性，并通过基于局部性度量的分析模型预测性能趋势。


<details>
  <summary>Details</summary>
Motivation: MLFMA中的近场算子在GPU上由于内存局部性差成为性能瓶颈，需要改善其内存访问模式。

Method: 引入数据冗余来减少内存访问分散性，提高空间局部性；提出基于数据量和访问分散性的局部性度量分析模型来预测性能趋势。

Result: 在DBIM-MLFMA和PhotoNs-2.0两个应用上验证，内核速度提升最高达7倍，但由于数据重组开销，端到端应用加速比限制在1.04倍。模型能可靠捕捉不同问题规模和密度下的性能趋势。

Conclusion: 数据冗余可以提升GPU上近场算子的性能，前提是局部性收益超过数据移动成本。该方法可最小化代码修改注入现有实现。

Abstract: The near-field (P2P) operator in the Multilevel Fast Multipole Algorithm (MLFMA) is a performance bottleneck on GPUs due to poor memory locality. This work introduces data redundancy to improve spatial locality by reducing memory access dispersion. For validation of results, we propose an analytical model based on a Locality metric that combines data volume and access dispersion to predict speedup trends without hardware-specific profiling. The approach is validated on two MLFMA-based applications: an electromagnetic solver (DBIM-MLFMA) with regular structure, and a stellar dynamics code (PhotoNs-2.0) with irregular particle distribution. Results show up to 7X kernel speedup due to improved cache behavior. However, increased data volume raises overheads in data restructuring, limiting end-to-end application speedup to 1.04X. While the model cannot precisely predict absolute speedups, it reliably captures performance trends across different problem sizes and densities. The technique is injectable into existing implementations with minimal code changes. This work demonstrates that data redundancy can enhance GPU performance for P2P operator, provided locality gains outweigh data movement costs.

</details>
