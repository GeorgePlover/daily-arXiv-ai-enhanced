<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 5]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.AI](#cs.AI) [Total: 24]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications](https://arxiv.org/abs/2512.02300)
*Haoyu Zheng,Shouwei Gao,Jie Ren,Wenqian Dong*

Main category: cs.DC

TL;DR: DOLMA是一个为HPC应用设计的数据对象级内存解聚合框架，通过智能识别和卸载数据对象到远程内存，在减少本地内存使用的同时将性能下降控制在16%以内。


<details>
  <summary>Details</summary>
Motivation: 内存解聚合技术有望扩展HPC系统的内存容量并提高利用率，但访问远程内存的性能开销对计算密集型HPC应用构成重大挑战，这些应用的执行时间对数据局部性高度敏感。

Method: DOLMA框架智能识别并卸载数据对象到远程内存，提供定量分析以确定合适的本地内存大小。它利用HPC应用典型可预测的内存访问模式，通过双缓冲区设计实现远程内存预取，并仔细平衡本地和远程内存使用，同时保持多线程并发性。

Result: 在八个HPC工作负载和计算内核的评估中，DOLMA将性能下降限制在16%以内，同时将本地内存使用减少高达63%（平均）。

Conclusion: DOLMA为HPC领域提供了一个灵活高效的内存解聚合解决方案，在最小化影响应用性能的同时有效利用解聚合内存。

Abstract: Memory disaggregation is promising to scale memory capacity and improves utilization in HPC systems. However, the performance overhead of accessing remote memory poses a significant chal- lenge, particularly for compute-intensive HPC applications where execution times are highly sensitive to data locality. In this work, we present DOLMA, a Data Object Level M emory dis Aggregation framework designed for HPC applications. DOLMA intelligently identifies and offloads data objects to remote memory, while pro- viding quantitative analysis to decide a suitable local memory size. Furthermore, DOLMA leverages the predictable memory access patterns typical in HPC applications and enables remote memory prefetch via a dual-buffer design. By carefully balancing local and remote memory usage and maintaining multi-thread concurrency, DOLMA provides a flexible and efficient solution for leveraging dis- aggregated memory in HPC domains while minimally compromis- ing application performance. Evaluating with eight HPC workloads and computational kernels, DOLMA limits performance degrada- tion to less than 16% while reducing local memory usage by up to 63%, on average.

</details>


### [2] [Solutions for Distributed Memory Access Mechanism on HPC Clusters](https://arxiv.org/abs/2512.02546)
*Jan Meizner,Maciej Malawski*

Main category: cs.DC

TL;DR: 论文评估了基于两个不同HPC集群的分布式系统中远程内存访问机制，比较了基于共享存储和MPI的解决方案与本地内存访问的性能，发现基于MPI的远程访问性能接近本地内存访问


<details>
  <summary>Details</summary>
Motivation: 研究分布式系统中远程内存访问机制的性能，为需要跨节点内存访问的应用（特别是医疗用例）提供高效解决方案

Method: 在两个不同的HPC集群上，比较基于共享存储（Infiniband和Slingshot）的MPI解决方案与本地内存访问的性能

Result: 基于MPI的远程内存访问性能与本地内存访问相似，特别是在医疗用例中表现出良好效果

Conclusion: 基于MPI的远程内存访问机制在分布式系统中是可行的，性能接近本地访问，特别适用于医疗等需要跨节点内存共享的应用场景

Abstract: Paper presents and evaluates various mechanisms for remote access to memory in distributed systems based on two distinct HPC clusters. We are comparing solutions based on the shared storage and MPI (over Infiniband and Slingshot) to the local memory access. This paper also mentions medical use-cases that would mostly benefit from the described solution. We have found out that results for remote access esp. backed by MPI are similar to local memory access.

</details>


### [3] [Offloading Artificial Intelligence Workloads across the Computing Continuum by means of Active Storage Systems](https://arxiv.org/abs/2512.02646)
*Alex Barceló,Sebastián A. Cajas Ordoñez,Jaydeep Samanta,Andrés L. Suárez-Cetrulo,Romila Ghosh,Ricardo Simón Carbajo,Anna Queralt*

Main category: cs.DC

TL;DR: 提出基于主动存储的计算连续体软件架构，用于优化AI工作负载分布，通过将计算嵌入存储减少数据传输开销，提升内存效率和训练速度


<details>
  <summary>Details</summary>
Motivation: AI工作负载需求增长，传统云架构难以处理海量高速数据，现有框架缺乏计算连续体所需的灵活性和适应性，无法应对设备异构性和快速变化的算法模型

Method: 提出软件架构，将AI工作负载无缝分布到计算连续体，使用主流Python库和active storage平台dataClay实现，通过主动存储将计算嵌入存储架构

Result: 实验显示主动存储卸载工作负载显著提升内存效率和训练速度，同时保持准确性，在不同设备上评估了内存消耗、存储需求、训练时间和执行效率的权衡

Conclusion: 主动存储有潜力彻底改变AI工作负载管理，使分布式AI部署更具可扩展性和资源效率，为领域专家和应用开发者提供极低入门门槛

Abstract: The increasing demand for artificial intelligence (AI) workloads across diverse computing environments has driven the need for more efficient data management strategies. Traditional cloud-based architectures struggle to handle the sheer volume and velocity of AI-driven data, leading to inefficiencies in storage, computation, and data movement. This paper explores the integration of active storage systems within the computing continuum to optimize AI workload distribution.
  By embedding computation directly into storage architectures, active storage is able to reduce data transfer overhead, enhancing performance and improving resource utilization. Other existing frameworks and architectures offer mechanisms to distribute certain AI processes across distributed environments; however, they lack the flexibility and adaptability that the continuum requires, both regarding the heterogeneity of devices and the rapid-changing algorithms and models being used by domain experts and researchers.
  This article proposes a software architecture aimed at seamlessly distributing AI workloads across the computing continuum, and presents its implementation using mainstream Python libraries and dataClay, an active storage platform. The evaluation shows the benefits and trade-offs regarding memory consumption, storage requirements, training times, and execution efficiency across different devices. Experimental results demonstrate that the process of offloading workloads through active storage significantly improves memory efficiency and training speeds while maintaining accuracy. Our findings highlight the potential of active storage to revolutionize AI workload management, making distributed AI deployments more scalable and resource-efficient with a very low entry barrier for domain experts and application developers.

</details>


### [4] [Distributed and Autonomic Minimum Spanning Trees](https://arxiv.org/abs/2512.02683)
*Luiz A. Rodrigues,Elias P. Duarte,Luciana Arantes*

Main category: cs.DC

TL;DR: 提出一种基于VCube虚拟拓扑的自适应生成树算法，用于分布式系统中的广播通信，支持动态故障恢复，每个节点度数不超过log₂n


<details>
  <summary>Details</summary>
Motivation: 传统的一对多广播策略在分布式系统中不可扩展，会给发送者带来沉重负载。需要一种能够自动构建和维护生成树的方法，以支持可扩展的广播通信。

Method: 基于VCube虚拟拓扑构建自适应生成树算法，该拓扑同时作为故障检测器。算法动态创建生成树，支持进程故障和恢复时的透明重建，确保每个节点的入度和树深度不超过log₂n。

Result: 算法能容忍最多n-1个进程故障，正确进程仍通过可扩展的生成树保持连接。当所有进程正常时，每个进程的度数恰好为log₂n。基于该算法提出了两种广播算法：尽力而为广播和可靠广播。

Conclusion: 该自适应生成树算法为分布式系统提供了可扩展的广播解决方案，通过VCube拓扑支持动态故障恢复，相比传统方法具有更好的扩展性和容错性。

Abstract: The most common strategy for enabling a process in a distributed system to broadcast a message is one-to-all communication. However, this approach is not scalable, as it places a heavy load on the sender. This work presents an autonomic algorithm that enables the $n$ processes in a distributed system to build and maintain a spanning tree connecting themselves. In this context, processes are the vertices of the spanning tree. By definition, a spanning tree connects all processes without forming cycles. The proposed algorithm ensures that every vertex in the spanning tree has both an in-degree and the tree depth of at most $log_2 n$. When all processes are correct, the degree of each process is exactly $log_2 n$. A spanning tree is dynamically created from any source process and is transparently reconstructed as processes fail or recover. Up to $n-1$ processes can fail, and the correct processes remain connected through a scalable, functioning spanning tree. To build and maintain the tree, processes use the VCube virtual topology, which also serves as a failure detector. Two broadcast algorithms based on the autonomic spanning tree algorithm are presented: one for best-effort broadcast and one for reliable broadcast. Simulation results are provided, including comparisons with other alternatives.

</details>


### [5] [Designing FAIR Workflows at OLCF: Building Scalable and Reusable Ecosystems for HPC Science](https://arxiv.org/abs/2512.02818)
*Sean R. Wilkinson,Patrick Widener,Sarp Oral,Rafael Ferreira da Silva*

Main category: cs.DC

TL;DR: 本文提出HPC中心应更积极地培育跨学科的FAIR生态系统，通过组件化方法使工作流组件符合FAIR原则，以促进计算组件的发现、共享和重用。


<details>
  <summary>Details</summary>
Motivation: HPC中心的基础设施与用户本地系统差异巨大，导致用户开发与特定HPC中心紧密耦合的数字制品，造成重复劳动。现有FAIR实践多为领域特定，限制了跨学科协作。

Method: 基于欧洲开放科学云EOSC-Life FAIR工作流协作平台的架构，提出针对HPC需求的模型，强调使单个工作流组件符合FAIR原则，而非整个工作流。

Result: 提出了一种组件化的FAIR方法，更好地支持HPC用户多样化和不断变化的需求，同时最大化其工作的长期价值。

Conclusion: HPC中心应设计支持跨学科FAIR生态系统的基础设施，通过组件化FAIR方法促进计算组件的有效发现、共享和重用，减少重复劳动并增强协作。

Abstract: High Performance Computing (HPC) centers provide advanced infrastructure that enables scientific research at extreme scale. These centers operate with hardware configurations, software environments, and security requirements that differ substantially from most users' local systems. As a result, users often develop customized digital artifacts that are tightly coupled to a given HPC center. This practice can lead to significant duplication of effort as multiple users independently create similar solutions to common problems. The FAIR Principles offer a framework to address these challenges. Initially designed to improve data stewardship, the FAIR approach has since been extended to encompass software, workflows, models, and infrastructure. By encouraging the use of rich metadata and community standards, FAIR practices aim to make digital artifacts easier to share and reuse, both within and across scientific domains. Many FAIR initiatives have emerged within individual research communities, often aligned by discipline (e.g. bioinformatics, earth sciences). These communities have made progress in adopting FAIR practices, but their domain-specific nature can lead to silos that limit broader collaboration. Thus, we propose that HPC centers play a more active role in fostering FAIR ecosystems that support research across multiple disciplines. This requires designing infrastructure that enables researchers to discover, share, and reuse computational components more effectively. Here, we build on the architecture of the European Open Science Cloud (EOSC) EOSC-Life FAIR Workflows Collaboratory to propose a model tailored to the needs of HPC. Rather than focusing on entire workflows, we emphasize the importance of making individual workflow components FAIR. This component-based approach better supports the diverse and evolving needs of HPC users while maximizing the long-term value of their work.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [6] [Decentralized Multi-Agent System with Trust-Aware Communication](https://arxiv.org/abs/2512.02410)
*Yepeng Ding,Ahmed Twabi,Junwei Yu,Lingfeng Zhang,Tohru Kondo,Hiroyuki Sato*

Main category: cs.MA

TL;DR: 提出基于区块链的去中心化多智能体系统架构，解决传统集中式系统的单点故障、审查脆弱性、可扩展性限制和信任问题，通过加密原语和链上操作实现可信通信协议。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推动了自主多智能体系统发展，但传统集中式架构存在单点故障、审查脆弱性、可扩展性限制和信任问题，需要新的解决方案。

Method: 提出去中心化多智能体系统架构，基于区块链的去中心化智能体运行时，形式化可信通信协议，利用加密原语和链上操作确保安全性。

Result: 通过全面安全分析验证了协议的安全性属性：可验证交互周期、通信完整性、真实性、不可否认性和条件保密性，性能分析表明系统具有可扩展性和高效性。

Conclusion: 提出的去中心化多智能体系统架构是构建可信多智能体系统的可扩展高效解决方案，解决了传统集中式架构的根本问题。

Abstract: The emergence of Large Language Models (LLMs) is rapidly accelerating the development of autonomous multi-agent systems (MAS), paving the way for the Internet of Agents. However, traditional centralized MAS architectures present significant challenges, including single points of failure, vulnerability to censorship, inherent scalability limitations, and critical trust issues. We propose a novel Decentralized Multi-Agent System (DMAS) architecture designed to overcome these fundamental problems by enabling trust-aware, scalable, and censorship-resistant interactions among autonomous agents. Our DMAS features a decentralized agent runtime underpinned by a blockchain-based architecture. We formalize a trust-aware communication protocol that leverages cryptographic primitives and on-chain operations to provide security properties: verifiable interaction cycles, communication integrity, authenticity, non-repudiation, and conditional confidentiality, which we further substantiate through a comprehensive security analysis. Our performance analysis validates the DMAS as a scalable and efficient solution for building trustworthy multi-agent systems.

</details>


### [7] [EZYer: A simulacrum of high school with generative agent](https://arxiv.org/abs/2512.02561)
*Jinming Yang,Zimu Ji,Weiqi Luo,Gaoxi Wang,Bin Ma,Yueling Deng*

Main category: cs.MA

TL;DR: EZYer是一个面向高中数学教育的生成式智能体，包含教师模块、学生模块和控制器，能够自动生成结构化教学材料、LaTeX课件和学术笔记，并通过多维度评估验证其内容质量优秀。


<details>
  <summary>Details</summary>
Motivation: 现有在线教育工具在课件生成、交互式笔记和内容质量保证方面存在服务不完整、性能不足和交互性弱的问题，需要开发更智能的教育生成系统。

Method: EZYer采用三模块架构：1）教师模块整合文本语料检索和深度生成技术，自动生成结构化教学材料和LaTeX Beamer课件；2）学生模块通过教师、助教、优等生和学困生四角色协作交互，生成学术笔记；3）控制器设置关键词过滤、内容评分、角色协同验证和动态内容校正系统确保学术严谨性。

Result: 通过设计内容准确性、知识覆盖度、可用性、格式正确性和视觉设计吸引力五维评估指标，由五个大语言模型对EZYer生成的100个Beamer课件和笔记进行评分，结果显示EZYer生成的内容质量优秀，具有良好的应用前景。

Conclusion: EZYer作为一个生成式教育智能体，能够有效解决现有教育工具的问题，通过多模块协同和严格的质量控制机制，为高中数学教育提供高质量的自动化内容生成服务。

Abstract: With the rapid development of the online education and large language model, the existing educational tools still suffer from incomplete service, insufficient performance and weak interactivity in terms of courseware generation, interactive notes and quality assurance of content. In particular, the proposed generative agent EZYer : 1) Teacher Module: Integrating the Text Corpus retrieval and in-depth generation technologies, it automatically generates structured teaching materials and LaTeX Beamer courseware in line with the high school mathematics syllabus and supports user-defined image insertion. 2) Student Module: Throughout the collaborative interaction of the four roles of Teacher, Assistant, Top Student and Struggling Student, Note Taker summarizes and generates academic notes to enhance the depth and interest of learning. 3) Controller: set up keyword filtering system, content scoring system, role co-validation system, and dynamic content correction system. This ensure academic strictness and pedagogical propriety of EZYer inputs and outputs. In order to evaluate EZYer, this paper designs five-dimensional evaluation indexes of content accuracy, knowledge coverage, usability, formatting correctness and visual design and appeal, and scores 100 Beamer and Notes generated by EZYer by five large language models, separately, and the results show that the quality of EZYer-generated content is excellent and has a good application prospect.

</details>


### [8] [Beyond Single-Agent Safety: A Taxonomy of Risks in LLM-to-LLM Interactions](https://arxiv.org/abs/2512.02682)
*Piercosma Bisconti,Marcello Galisai,Federico Pierucci,Marcantonio Bracale,Matteo Prandi*

Main category: cs.MA

TL;DR: 论文探讨了为什么针对人机交互设计的安全机制无法扩展到LLM相互交互的环境中，提出了从模型级安全向系统级安全的概念转变，并引入了新兴系统性风险视野框架。


<details>
  <summary>Details</summary>
Motivation: 当前的安全治理实践主要依赖单智能体安全控制，如提示工程、微调和审核层，这些机制假设了单模型对单用户的二元设置。然而，研究和工业发展正快速转向LLM间相互交互的生态系统，在这种系统中，即使每个模型都单独对齐，局部合规也可能聚合成集体失败。

Method: 提出了新兴系统性风险视野框架来形式化系统不稳定性如何从交互结构中产生，而非孤立的不当行为。贡献包括：(i)交互LLM中集体风险的理论解释；(ii)连接微观、中观和宏观层面故障模式的分类法；(iii)InstitutionalAI架构设计提案，用于在多智能体系统中嵌入自适应监督。

Result: 论文识别了当前安全机制的局限性，展示了在LLM间交互生态系统中，即使个体模型都符合安全标准，交互结构本身也可能导致系统性风险。这为理解和治理多模型交互环境中的风险提供了理论基础和框架。

Conclusion: 需要从模型级安全范式转向系统级安全范式，通过InstitutionalAI等架构设计在多智能体系统中嵌入自适应监督机制，以应对LLM间交互生态系统中出现的新兴系统性风险。

Abstract: This paper examines why safety mechanisms designed for human-model interaction do not scale to environments where large language models (LLMs) interact with each other. Most current governance practices still rely on single-agent safety containment, prompts, fine-tuning, and moderation layers that constrain individual model behavior but leave the dynamics of multi-model interaction ungoverned. These mechanisms assume a dyadic setting: one model responding to one user under stable oversight. Yet research and industrial development are rapidly shifting toward LLM-to-LLM ecosystems, where outputs are recursively reused as inputs across chains of agents. In such systems, local compliance can aggregate into collective failure even when every model is individually aligned. We propose a conceptual transition from model-level safety to system-level safety, introducing the framework of the Emergent Systemic Risk Horizon (ESRH) to formalize how instability arises from interaction structure rather than from isolated misbehavior. The paper contributes (i) a theoretical account of collective risk in interacting LLMs, (ii) a taxonomy connecting micro, meso, and macro-level failure modes, and (iii) a design proposal for InstitutionalAI, an architecture for embedding adaptive oversight within multi-agent systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [The 4/$δ$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee](https://arxiv.org/abs/2512.02080)
*PIerre Dantas,Lucas Cordeiro,Youcheng Sun,Waldir Junior*

Main category: cs.AI

TL;DR: 本文提出了首个具有可证明保证的LLM-验证器收敛定理，通过马尔可夫链建模LLM与验证器的交互，证明了对于任何δ>0，程序都能以期望迭代次数≤4/δ的概率收敛到验证状态。


<details>
  <summary>Details</summary>
Motivation: 当前使用形式化验证工具与大型语言模型的方法虽然扩展了软件验证能力，但缺乏理论基础，导致验证过程不可靠、可能陷入循环或不稳定。需要建立具有可证明保证的形式化框架来解决这一关键差距。

Method: 将LLM与验证器的交互建模为离散时间马尔可夫链，状态转移由关键参数δ（错误减少概率）决定。开发了LLM-验证器收敛定理，证明对于任何δ>0，程序都能以期望迭代次数≤4/δ的概率收敛到验证状态。通过超过90,000次试验进行实证验证。

Result: 理论预测与实证结果高度一致：所有运行都达到了验证状态，收敛因子紧密聚集在Cf≈1.0附近。基于此建立了三个操作区域（边缘、实用、高性能）的设计阈值，为LLM辅助验证提供了可预测的资源规划和性能预算框架。

Conclusion: 本文通过理论保证和实验证据为LLM辅助验证建立了清晰的架构基础，消除了启发式调优的需求，为工程师提供了可预测的资源规划和性能预算框架，特别适用于安全关键软件环境的部署。

Abstract: The idea of using Formal Verification tools with large language models (LLMs) has enabled scaling software verification beyond manual workflows. However, current methods remain unreliable. Without a solid theoretical footing, the refinement process can wander; sometimes it settles, sometimes it loops back, and sometimes it breaks away from any stable trajectory. This work bridges this critical gap by developing an LLM-Verifier Convergence Theorem, providing the first formal framework with provable guarantees for termination and convergence. We model the interaction between the LLM and the verifier as a discrete-time Markov Chain, with state transitions determined by a key parameter: the error-reduction probability ($δ$). The procedure reaching the Verified state almost surely demonstrates that the program terminates for any $δ> 0$, with an expected iteration count bounded by $\mathbb{E}[n] \leq 4/δ$. We then stress-tested this prediction in an extensive empirical campaign comprising more than 90,000 trials. The empirical results match the theory with striking consistency. Every single run reached verification, and the convergence factor clustered tightly around $C_f\approx$ 1.0. Consequently, the bound mirrors the system's actual behavior. The evidence is sufficiently robust to support dividing the workflow into three distinct operating zones: marginal, practical, and high-performance. Consequently, we establish the design thresholds with absolute confidence. Together, the theoretical guarantee and the experimental evidence provide a clearer architectural foundation for LLM-assisted verification. Heuristic tuning no longer has to be carried out by the system. Engineers gain a framework that supports predictable resource planning and performance budgeting, precisely what is needed before deploying these pipelines into safety-critical software environments.

</details>


### [10] [Flowchart2Mermaid: A Vision-Language Model Powered System for Converting Flowcharts into Editable Diagram Code](https://arxiv.org/abs/2512.02170)
*Pritam Deka,Barry Devereux*

Main category: cs.AI

TL;DR: Flowchart2Mermaid：一个将流程图图像转换为可编辑Mermaid.js代码的轻量级Web系统，支持混合主动式细化编辑和AI助手


<details>
  <summary>Details</summary>
Motivation: 流程图作为流程沟通的常用工具，通常以静态图像形式分享，难以编辑和重用。现有工具缺乏将流程图图像转换为结构化、版本可控的文本表示的能力。

Method: 开发了一个轻量级Web系统，使用详细的系统提示和视觉语言模型将流程图图像转换为Mermaid.js代码。系统支持内联文本编辑、拖放节点插入和自然语言命令，并集成了AI助手进行混合主动式细化。

Result: 系统能够生成结构化、版本可控的文本表示，并与渲染的图表保持同步。引入了评估指标来评估多个模型的结构准确性、流程正确性、语法有效性和完整性。

Conclusion: Flowchart2Mermaid提供了一种将静态流程图转换为可编辑、可重用Mermaid.js代码的有效方法，克服了传统静态图像的局限性，支持协作编辑和版本控制。

Abstract: Flowcharts are common tools for communicating processes but are often shared as static images that cannot be easily edited or reused. We present \textsc{Flowchart2Mermaid}, a lightweight web system that converts flowchart images into editable Mermaid.js code which is a markup language for visual workflows, using a detailed system prompt and vision-language models. The interface supports mixed-initiative refinement through inline text editing, drag-and-drop node insertion, and natural-language commands interpreted by an integrated AI assistant. Unlike prior image-to-diagram tools, our approach produces a structured, version-controllable textual representation that remains synchronized with the rendered diagram. We further introduce evaluation metrics to assess structural accuracy, flow correctness, syntax validity, and completeness across multiple models.

</details>


### [11] [Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence](https://arxiv.org/abs/2512.02280)
*Noorbakhsh Amiri Golilarz,Sindhuja Penchala,Shahram Rahimi*

Main category: cs.AI

TL;DR: 该论文分析了当前AI系统的七大核心缺陷，指出其缺乏自我监控、元认知、自适应学习等能力，主张向基于认知科学的AI架构转变，以实现真正的自主性和适应性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在感知、语言、推理和多模态领域取得快速进展，但现有系统在自我监控、自我校正和自主行为调节方面存在根本性局限，无法实现稳健的泛化、终身适应性和真实世界自主性。

Method: 通过识别和分析当代AI模型的七大核心缺陷，结合人工系统与生物认知的比较分析，整合AI研究、认知科学和神经科学的见解，论证为什么单纯扩展无法解决这些问题。

Result: 论文确定了七个限制当代AI模型的关键缺陷：缺乏内在自我监控、元认知意识缺失、固定非自适应学习机制、无法重组目标、缺乏表征维护、不足的具身反馈以及内在能动性缺失。

Conclusion: 主张向认知基础AI（认知自主性）的范式转变，这种AI能够实现自我导向的适应、动态表征管理和有意图的目标导向行为，同时配备改革性监督机制，确保自主系统保持可解释性、可治理性并与人类价值观对齐。

Abstract: Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fun- damentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self- monitoring, lack of meta-cognitive awareness, fixed and non- adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust general- ization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.

</details>


### [12] [Model Recovery at the Edge under Resource Constraints for Physical AI](https://arxiv.org/abs/2512.02283)
*Bin Xu,Ayan Banerjee,Sandeep K. S. Gupta*

Main category: cs.AI

TL;DR: MERINDA是一个FPGA加速的模型恢复框架，用于边缘设备上的实时自主系统，通过并行化神经架构替代迭代求解器，显著降低内存和能耗。


<details>
  <summary>Details</summary>
Motivation: 模型恢复（MR）在关键任务自主系统中能实现安全、可解释的决策，但现有基于神经常微分方程（NODEs）的方法在边缘设备上部署困难，因为迭代求解器在FPGA上效率低下，内存和能耗是主要瓶颈。

Method: 提出MERINDA框架，用可并行化的神经架构替代NODEs中的迭代求解器，专门针对FPGA加速优化，减少DRAM使用并提高运行效率。

Result: 相比移动GPU，MERINDA实现了近11倍的DRAM使用量降低和2.2倍的运行速度提升。实验还揭示了在固定精度下内存与能耗的逆相关关系。

Conclusion: MERINDA框架特别适合资源受限、需要实时操作的关键任务自主系统，在边缘设备上实现了高效、低能耗的模型恢复。

Abstract: Model Recovery (MR) enables safe, explainable decision making in mission-critical autonomous systems (MCAS) by learning governing dynamical equations, but its deployment on edge devices is hindered by the iterative nature of neural ordinary differential equations (NODEs), which are inefficient on FPGAs. Memory and energy consumption are the main concerns when applying MR on edge devices for real-time operation. We propose MERINDA, a novel FPGA-accelerated MR framework that replaces iterative solvers with a parallelizable neural architecture equivalent to NODEs. MERINDA achieves nearly 11x lower DRAM usage and 2.2x faster runtime compared to mobile GPUs. Experiments reveal an inverse relationship between memory and energy at fixed accuracy, highlighting MERINDA's suitability for resource-constrained, real-time MCAS.

</details>


### [13] [Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization](https://arxiv.org/abs/2512.02302)
*Varun Kumar Dasoju,Qingsu Cheng,Zeyun Yu*

Main category: cs.AI

TL;DR: 该研究提出了一种用于乳腺上皮细胞分割的框架，仅使用599张训练图像就实现了95.5%的Dice分数，显著减少了医学图像标注所需的时间和专家资源。


<details>
  <summary>Details</summary>
Motivation: 医学图像标注需要大量时间和专业知识，特别是乳腺上皮细胞数据集需要病理学家投入数百小时进行标注。这是一个临床感知AI发展的基本瓶颈。

Method: 1. 使用量子启发的多尺度Gabor滤波器进行边缘增强，创建第四输入通道；2. 提出稳定的多组件损失函数，集成自适应Dice损失和边界感知项；3. 引入基于复杂度的加权采样策略；4. 采用EfficientNet-B7/UNet++架构，支持4到3通道投影；5. 通过指数移动平均和统计异常值检测进行鲁棒验证。

Result: Dice分数达到95.5% ± 0.3%，IoU达到91.2% ± 0.4%。量子增强使边界精度提高2.1%，加权采样使小病灶检测提高3.8%。

Conclusion: 该框架通过有限标注实现了突破性性能，显著减少了医学专家创建数据集所需的时间，解决了临床感知AI发展的基本瓶颈问题。

Abstract: Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.

</details>


### [14] [OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning](https://arxiv.org/abs/2512.02306)
*Boyu Zhu,Xiaofei Wen,Wenjie Jacky Mo,Tinghui Zhu,Yanan Xie,Peng Qi,Muhao Chen*

Main category: cs.AI

TL;DR: OmniGuard是首个全模态安全护栏系统，通过精心推理能力在所有模态（文本、图像、视频、音频）上执行安全防护，使用超过21万样本的全面数据集训练，在15个基准测试中展现出强大的有效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 全模态大语言模型处理多种模态数据带来了新的安全挑战，现有护栏研究主要针对单模态设置，且通常将安全防护视为二元分类，这限制了在不同模态和任务间的鲁棒性。

Method: 提出OmniGuard框架，构建包含超过21万多样化样本的全模态安全数据集，涵盖所有模态的单模态和跨模态样本，每个样本都带有结构化安全标签和通过定向蒸馏从专家模型获得的精心安全评析。

Result: 在15个基准测试上的广泛实验表明，OmniGuard在各种多模态安全场景中实现了强大的有效性和泛化能力，为全模态安全防护提供了统一框架。

Conclusion: OmniGuard通过统一框架在全模态中执行策略和缓解风险，为构建更鲁棒和更强大的全模态安全防护系统铺平了道路。

Abstract: Omni-modal Large Language Models (OLLMs) that process text, images, videos, and audio introduce new challenges for safety and value guardrails in human-AI interaction. Prior guardrail research largely targets unimodal settings and typically frames safeguarding as binary classification, which limits robustness across diverse modalities and tasks. To address this gap, we propose OmniGuard, the first family of omni-modal guardrails that performs safeguarding across all modalities with deliberate reasoning ability. To support the training of OMNIGUARD, we curate a large, comprehensive omni-modal safety dataset comprising over 210K diverse samples, with inputs that cover all modalities through both unimodal and cross-modal samples. Each sample is annotated with structured safety labels and carefully curated safety critiques from expert models through targeted distillation. Extensive experiments on 15 benchmarks show that OmniGuard achieves strong effectiveness and generalization across a wide range of multimodal safety scenarios. Importantly, OmniGuard provides a unified framework that enforces policies and mitigates risks in omni-modalities, paving the way toward building more robust and capable omnimodal safeguarding systems.

</details>


### [15] [Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective](https://arxiv.org/abs/2512.02340)
*Qiyao Xue,Weichen Liu,Shiqi Wang,Haoming Wang,Yuyang Wu,Wei Gao*

Main category: cs.AI

TL;DR: 本文提出了ReMindView-Bench基准测试，用于评估视觉语言模型在多视图空间推理中的表现，发现现有模型在跨视图对齐和视角转换方面存在系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多视图空间推理中难以保持几何一致性和跨视图一致性，缺乏能够隔离多视图推理与单视图感知及时间因素的细粒度基准测试。

Method: 开发了ReMindView-Bench基准测试，系统性地变化视角空间模式和查询类型来探测空间认知关键因素；使用LLM-as-a-judge和自一致性提示进行显式分阶段分析，以及线性探测和熵动态分析进行隐式分析。

Result: 评估了15个当前VLMs，发现它们在跨视图对齐和视角转换方面存在一致性的失败；显式分析显示模型在帧内感知表现良好，但在跨视图信息整合时性能急剧下降；隐式分析显示任务相关信息逐渐丢失，正确与错误轨迹之间的不确定性分离。

Conclusion: ReMindView-Bench为VLM空间推理提供了认知基础的诊断，揭示了多视图空间心理模型在推理过程中的形成、退化和失稳机制，为改进模型的空间推理能力提供了重要见解。

Abstract: Spatial reasoning is a core aspect of human intelligence that allows perception, inference and planning in 3D environments. However, current vision-language models (VLMs) struggle to maintain geometric coherence and cross-view consistency for spatial reasoning in multi-view settings. We attribute this gap to the lack of fine-grained benchmarks that isolate multi-view reasoning from single-view perception and temporal factors. To address this, we present ReMindView-Bench, a cognitively grounded benchmark for evaluating how VLMs construct, align and maintain spatial mental models across complementary viewpoints. ReMindView-Bench systematically varies viewpoint spatial pattern and query type to probe key factors of spatial cognition. Evaluations of 15 current VLMs reveals consistent failures in cross-view alignment and perspective-taking in multi-view spatial reasoning, motivating deeper analysis on the reasoning process. Explicit phase-wise analysis using LLM-as-a-judge and self-consistency prompting shows that VLMs perform well on in-frame perception but degrade sharply when integrating information across views. Implicit analysis, including linear probing and entropy dynamics, further show progressive loss of task-relevant information and uncertainty separation between correct and incorrect trajectories. These results provide a cognitively grounded diagnosis of VLM spatial reasoning and reveal how multi-view spatial mental models are formed, degraded and destabilized across reasoning phases. The ReMindView-Bench benchmark is available at https://huggingface.co/datasets/Xue0823/ReMindView-Bench, and the source codes of benchmark construction and VLM reasoning analysis are available at https://github.com/pittisl/ReMindView-Bench.

</details>


### [16] [Beyond Playtesting: A Generative Multi-Agent Simulation System for Massively Multiplayer Online Games](https://arxiv.org/abs/2512.02358)
*Ran Zhang,Kun Ouyang,Tiancheng Ma,Yida Yang,Dong Fang*

Main category: cs.AI

TL;DR: 使用LLM驱动的生成式智能体构建MMO游戏模拟系统，通过SFT和RL训练智能体模仿真实玩家行为，结合数据驱动的环境模型，为数值设计优化提供可靠、可解释且成本高效的框架。


<details>
  <summary>Details</summary>
Motivation: 传统MMO游戏数值系统和机制设计优化依赖大规模在线实验或基于预定义统计模型的参数调优，这些方法成本高、耗时长且可能干扰玩家体验。虽然简化离线模拟系统可作为替代方案，但其保真度有限，无法准确模拟真实玩家的推理和对干预的反应。

Method: 提出基于大语言模型(LLM)的生成式智能体MMO模拟系统：1) 在大规模真实玩家行为数据上应用监督微调(SFT)和强化学习(RL)，将LLM从通用先验适应到游戏特定领域；2) 基于真实游戏日志训练数据驱动的环境模型，重建动态游戏系统。

Result: 实验表明，该系统与真实世界玩家行为具有很强的一致性，并在干预下产生合理的因果响应，为数据驱动的数值设计优化提供了可靠、可解释且成本高效的框架。

Conclusion: LLM驱动的生成式智能体模拟系统能够准确模拟真实玩家决策，结合数据驱动的环境模型，为MMO游戏数值设计优化提供了一种比传统方法更高效、更可靠的解决方案。

Abstract: Optimizing numerical systems and mechanism design is crucial for enhancing player experience in Massively Multiplayer Online (MMO) games. Traditional optimization approaches rely on large-scale online experiments or parameter tuning over predefined statistical models, which are costly, time-consuming, and may disrupt player experience. Although simplified offline simulation systems are often adopted as alternatives, their limited fidelity prevents agents from accurately mimicking real player reasoning and reactions to interventions. To address these limitations, we propose a generative agent-based MMO simulation system empowered by Large Language Models (LLMs). By applying Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on large-scale real player behavioral data, we adapt LLMs from general priors to game-specific domains, enabling realistic and interpretable player decision-making. In parallel, a data-driven environment model trained on real gameplay logs reconstructs dynamic in-game systems. Experiments demonstrate strong consistency with real-world player behaviors and plausible causal responses under interventions, providing a reliable, interpretable, and cost-efficient framework for data-driven numerical design optimization.

</details>


### [17] [Synthetic Error Injection Fails to Elicit Self-Correction In Language Models](https://arxiv.org/abs/2512.02389)
*David X. Wu,Shreyas Kapur,Anant Sahai,Stuart Russell*

Main category: cs.AI

TL;DR: 该研究探索使用监督学习和人工错误注入来培养语言模型的自我纠正能力，但发现这种方法效果有限，无法显著提升模型性能，即使模型能发现错误也常常重复原错误。


<details>
  <summary>Details</summary>
Motivation: 强化学习已成为激发大语言模型推理和自我纠正能力的主要方法，但其计算成本高昂，促使研究者探索替代方案。受自动驾驶和机器人技术的启发，研究是否可以通过监督学习和合成错误注入来诱导语言模型的自我纠正能力。

Method: 研究采用监督学习方法，在推理链中插入人工错误，然后掩盖这些错误，并监督模型识别和纠正这些错误。通过合成错误注入的方式训练模型进行自我纠正。

Result: 研究发现该方法即使在简单的合成任务上也无法显著提升多个模型的性能。即使模型能够发现自己的错误，也常常会重复原来的错误。合成错误与在线策略错误之间的分布偏移显著降低了微调模型的错误纠正能力，即使合成错误覆盖了在线策略错误。

Conclusion: 研究结果解释了为什么在线策略强化学习方法在激发自我纠正能力方面被证明是独特有效的。监督学习与合成错误注入的方法虽然直观，但在实际应用中效果有限，无法替代强化学习在培养语言模型自我纠正能力方面的作用。

Abstract: Reinforcement learning has become the dominant paradigm for eliciting reasoning and self-correction capabilities in large language models, but its computational expense motivates exploration of alternatives. Inspired by techniques from autonomous driving and robotics, we investigate whether supervised learning with synthetic error injection can induce self-correction abilities in language models. Our approach inserts artificial errors into reasoning chains, masks them, and supervises the model to recognize and correct these mistakes. Despite the intuitive appeal of this method, we find that it fails to significantly improve performance even on simple synthetic tasks across multiple models. Moreover, even when the model catches its own error, it often parrots the original mistake. We find that the distribution shift of synthetic errors to on-policy errors significantly degrades the error-correction capabilities of the fine-tuned model, even with good synthetic coverage of on-policy errors. Our results help explain why on-policy reinforcement learning methods have proven uniquely effective for eliciting self-correction.

</details>


### [18] [Semantic Trading: Agentic AI for Clustering and Relationship Discovery in Prediction Markets](https://arxiv.org/abs/2512.02436)
*Agostino Capponi,Alfio Gliozzo,Brian Zhu*

Main category: cs.AI

TL;DR: 本文提出了一种基于智能AI的管道，能够自动聚类预测市场并识别市场间的依赖关系，通过交易策略验证了这些关系的可操作性。


<details>
  <summary>Details</summary>
Motivation: 预测市场存在碎片化问题，包括重叠问题、隐含等价性和隐藏矛盾，需要一种自动化方法来发现市场间的语义结构关系。

Method: 开发了一个智能AI管道，通过自然语言理解对合同文本和元数据进行聚类分析，识别集群内市场对之间的依赖关系（正相关和反相关）。

Result: 在Polymarket历史数据集上评估，AI识别的关系准确率达到60-70%，基于这些关系的交易策略在一周内获得约20%的平均回报。

Conclusion: 智能AI和大语言模型能够有效发现预测市场中潜在的语义结构，这些发现的关系可以转化为可操作的市场信号。

Abstract: Prediction markets allow users to trade on outcomes of real-world events, but are prone to fragmentation through overlapping questions, implicit equivalences, and hidden contradictions across markets. We present an agentic AI pipeline that autonomously (i) clusters markets into coherent topical groups using natural-language understanding over contract text and metadata, and (ii) identifies within-cluster market pairs whose resolved outcomes exhibit strong dependence, including same-outcome (correlated) and different-outcome (anti-correlated) relationships. Using a historical dataset of resolved markets on Polymarket, we evaluate the accuracy of the agent's relational predictions. We then translate discovered relationships into a simple trading strategy to quantify how these relationships map to actionable signals. Results show that agent-identified relationships achieve roughly 60-70% accuracy, and their induced trading strategies earn about 20% average returns over week-long horizons, highlighting the ability of agentic AI and large language models to uncover latent semantic structure in prediction markets.

</details>


### [19] [Guided Self-Evolving LLMs with Minimal Human Supervision](https://arxiv.org/abs/2512.02472)
*Wenhao Yu,Zhenwen Liang,Chengsong Huang,Kishan Panaganti,Tianqing Fang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: R-Few是一个引导式自进化框架，通过轻量级人类监督实现AI模型的稳定可控自我进化，在数学和通用推理任务上取得持续改进。


<details>
  <summary>Details</summary>
Motivation: AI自进化被认为是通往超智能的路径，但实践中无引导的自进化系统往往很快达到平台期甚至退化，这是由于概念漂移、多样性崩溃和错误进化等问题导致的。需要一种能够稳定可控地自我进化同时最小化人类监督依赖的方法。

Method: 提出R-Few框架，采用引导式自对弈的挑战者-求解器架构。挑战者通过少量人类标注示例指导合成问题生成，求解器在在线难度课程下联合训练人类和合成示例。结合上下文基础训练和混合训练实现轻量级人类监督。

Result: 在数学和通用推理基准测试中，R-Few实现了一致且迭代的改进。例如，Qwen3-8B-Base在数学任务上比R-Zero提高了3.0分，性能与General-Reasoner相当，尽管后者使用了20倍的人类数据。消融研究证实了基础挑战者训练和课程求解器训练的互补贡献。

Conclusion: R-Few通过引导式自对弈框架有效缓解了概念漂移问题，产生了更稳定可控的协同进化动态，为AI自进化提供了一种实用且高效的方法。

Abstract: AI self-evolution has long been envisioned as a path toward superintelligence, where models autonomously acquire, refine, and internalize knowledge from their own learning experiences. Yet in practice, unguided self-evolving systems often plateau quickly or even degrade as training progresses. These failures arise from issues such as concept drift, diversity collapse, and mis-evolution, as models reinforce their own biases and converge toward low-entropy behaviors. To enable models to self-evolve in a stable and controllable manner while minimizing reliance on human supervision, we introduce R-Few, a guided Self-Play Challenger-Solver framework that incorporates lightweight human oversight through in-context grounding and mixed training. At each iteration, the Challenger samples a small set of human-labeled examples to guide synthetic question generation, while the Solver jointly trains on human and synthetic examples under an online, difficulty-based curriculum. Across math and general reasoning benchmarks, R-Few achieves consistent and iterative improvements. For example, Qwen3-8B-Base improves by +3.0 points over R-Zero on math tasks and achieves performance on par with General-Reasoner, despite the latter being trained on 20 times more human data. Ablation studies confirm the complementary contributions of grounded challenger training and curriculum-based solver training, and further analysis shows that R-Few mitigates drift, yielding more stable and controllable co-evolutionary dynamics.

</details>


### [20] [COPE: Chain-Of-Thought Prediction Engine for Open-Source Large Language Model Based Stroke Outcome Prediction from Clinical Notes](https://arxiv.org/abs/2512.02499)
*Yongkai Liu,Helena Feng,Bin Jiang,Yixin Wang,Max Wintermark,David S. Liebeskind,Michael Moseley,Maarten Lansberg,Gregory Albers,Jeremy Heit,Greg Zaharchuk*

Main category: cs.AI

TL;DR: COPE是一个基于思维链推理的大语言模型框架，用于从非结构化临床笔记中预测急性缺血性卒中90天功能结局，性能与GPT-4.1相当，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富的上下文信息，但其非结构化特性限制了在传统预测模型中的使用。需要开发能够利用这些信息进行准确预测的方法。

Method: 开发了COPE框架，使用基于LLaMA-3-8B的两步思维链架构：第一步生成临床推理，第二步输出mRS预测。在464名AIS患者的数据集上进行评估。

Result: COPE的MAE为1.01，±1准确率为74.4%，精确准确率为32.8%，性能与GPT-4.1相当，优于ClinicalBERT、基于结构化变量的机器学习模型和单步LLM。

Conclusion: COPE作为一个轻量级、可解释且保护隐私的开源框架，为从非结构化临床文本进行结局预测提供了准确实用的解决方案。

Abstract: Predicting outcomes in acute ischemic stroke (AIS) guides clinical decision-making, patient counseling, and resource allocation. Clinical notes contain rich contextual information, but their unstructured nature limits their use in traditional predictive models. We developed and evaluated the Chain-of-Thought (CoT) Outcome Prediction Engine (COPE), a reasoning-enhanced large language model framework, for predicting 90-day functional outcomes after AIS from unstructured clinical notes. This study included 464 AIS patients with discharge summaries and 90-day modified Rankin Scale (mRS) scores. COPE uses a two-step CoT framework based on sequential open-source LLaMA-3-8B models: the first generates clinical reasoning, and the second outputs an mRS prediction. We compared COPE with GPT-4.1, ClinicalBERT, a structured variable-based machine learning model (Clinical ML), and a single-step LLM without CoT. Performance was evaluated using mean absolute error (MAE), accuracy within +/-1 mRS point, and exact accuracy. COPE achieved an MAE of 1.01 (95% CI 0.92-1.11), +/-1 accuracy of 74.4% (69.9, 78.8%), and exact accuracy of 32.8% (28.0, 37.6%), comparable to GPT-4.1 and superior to ClinicalBERT [MAE 1.24 (1.13-1.36)], Clinical ML [1.28 (1.18-1.39)], and the single-step LLM [1.20 (1.09-1.33)]. Subgroup analyses showed consistent performance across sex and age, with slightly higher error among older patients, those undergoing thrombectomy, and those with longer summaries. These findings demonstrate that COPE, a lightweight, interpretable, and privacy-preserving open-source framework, provides an accurate and practical solution for outcome prediction from unstructured clinical text.

</details>


### [21] [Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration](https://arxiv.org/abs/2512.02530)
*Yuxiang He,Jian Zhao,Yuchen Yuan,Tianle Zhang,Wei Cai,Haojie Cheng,Ziyan Shi,Ming Zhu,Haichuan Tang,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: Aetheria是一个基于多智能体辩论协作的多模态可解释内容安全框架，通过动态辩论机制和RAG知识检索，显著提升隐式风险识别能力并生成可追溯的审计报告。


<details>
  <summary>Details</summary>
Motivation: 数字内容爆炸式增长给内容安全带来重大挑战。现有审核系统通常基于单一模型或固定流程，在识别隐式风险和提供可解释判断过程方面存在局限。

Method: 提出Aetheria框架，采用五个核心智能体的协作架构，通过基于RAG知识检索的动态相互说服辩论机制，对多模态内容进行深度分析和裁决。

Result: 在提出的AIR-Bench基准测试中，Aetheria不仅生成详细可追溯的审计报告，而且在整体内容安全准确性上显著优于基线方法，特别是在隐式风险识别方面表现突出。

Conclusion: 该框架建立了透明可解释的范式，显著推进了可信AI内容审核领域的发展。

Abstract: The exponential growth of digital content presents significant challenges for content safety. Current moderation systems, often based on single models or fixed pipelines, exhibit limitations in identifying implicit risks and providing interpretable judgment processes. To address these issues, we propose Aetheria, a multimodal interpretable content safety framework based on multi-agent debate and collaboration.Employing a collaborative architecture of five core agents, Aetheria conducts in-depth analysis and adjudication of multimodal content through a dynamic, mutually persuasive debate mechanism, which is grounded by RAG-based knowledge retrieval.Comprehensive experiments on our proposed benchmark (AIR-Bench) validate that Aetheria not only generates detailed and traceable audit reports but also demonstrates significant advantages over baselines in overall content safety accuracy, especially in the identification of implicit risks. This framework establishes a transparent and interpretable paradigm, significantly advancing the field of trustworthy AI content moderation.

</details>


### [22] [Target-specific Adaptation and Consistent Degradation Alignment for Cross-Domain Remaining Useful Life Prediction](https://arxiv.org/abs/2512.02610)
*Yubo Hou,Mohamed Ragab,Min Wu,Chee-Keong Kwoh,Xiaoli Li,Zhenghua Chen*

Main category: cs.AI

TL;DR: TACDA是一种用于跨域剩余使用寿命预测的新型域自适应方法，通过目标域重构策略和聚类配对策略解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 准确预测机械设备的剩余使用寿命可以显著降低维护成本、提高设备运行时间并减少不良后果。现有的数据驱动RUL预测方法通常假设训练和测试数据来自相同分布，但在实际工业环境中这一假设不成立，存在域差异问题。现有的对抗域自适应方法虽然关注获取域不变特征，但忽略了目标特定信息和退化阶段的一致性特征。

Method: 提出TACDA方法：1）在对抗自适应过程中引入目标域重构策略，在学习域不变特征的同时保留目标特定信息；2）开发新颖的聚类和配对策略，实现相似退化阶段之间的一致性对齐。

Result: 通过大量实验证明，TACDA方法在两个不同的评估指标上都表现出卓越性能，超越了最先进的方法。

Conclusion: TACDA方法有效解决了跨域RUL预测中的域差异问题，通过结合目标域重构和退化阶段一致性对齐策略，显著提升了预测性能。

Abstract: Accurate prediction of the Remaining Useful Life (RUL) in machinery can significantly diminish maintenance costs, enhance equipment up-time, and mitigate adverse outcomes. Data-driven RUL prediction techniques have demonstrated commendable performance. However, their efficacy often relies on the assumption that training and testing data are drawn from the same distribution or domain, which does not hold in real industrial settings. To mitigate this domain discrepancy issue, prior adversarial domain adaptation methods focused on deriving domain-invariant features. Nevertheless, they overlook target-specific information and inconsistency characteristics pertinent to the degradation stages, resulting in suboptimal performance. To tackle these issues, we propose a novel domain adaptation approach for cross-domain RUL prediction named TACDA. Specifically, we propose a target domain reconstruction strategy within the adversarial adaptation process, thereby retaining target-specific information while learning domain-invariant features. Furthermore, we develop a novel clustering and pairing strategy for consistent alignment between similar degradation stages. Through extensive experiments, our results demonstrate the remarkable performance of our proposed TACDA method, surpassing state-of-the-art approaches with regard to two different evaluation metrics. Our code is available at https://github.com/keyplay/TACDA.

</details>


### [23] [Exploring Depth Generalization in Large Language Models for Solving Recursive Logic Tasks](https://arxiv.org/abs/2512.02677)
*Zhiyuan He*

Main category: cs.AI

TL;DR: 论文研究大型语言模型在递归推理问题中的深度泛化能力不足，提出了一种循环定位替换管道方法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理递归推理问题时面临深度泛化挑战，即无法处理比训练时更深的嵌套层次结构，即使它们能处理更长的非嵌套序列。

Method: 提出了一种新颖的循环定位替换管道方法，使用两个专门模型：定位器识别可解子表达式，替换器评估这些组件同时保持整体结构。

Result: 在布尔代数、递归算术和命题逻辑三个可控递归深度的领域中，该方法有效缓解了在分布外递归深度测试时的性能衰减。

Conclusion: 标准Transformer架构在深度泛化方面存在局限性，而提出的循环定位替换方法能够有效解决递归推理中的深度泛化问题。

Abstract: Large language models have demonstrated remarkable capabilities across many tasks, yet face significant challenges when dealing with recursive reasoning problems, those requiring the resolution of nested hierarchical structures. While prior research has extensively studied length generalization (a model's ability to handle longer sequences than seen during training), we investigate a distinct and underexplored limitation: depth generalization. Here, depth refers to the number of nested levels in a hierarchical problem, such as the layers of parentheses in a mathematical expression or the nesting of logical clauses in a Boolean formula. Our work reveals that standard transformer architectures struggle with problems involving deeper recursion than encountered during training, even when they perform well on longer but non-nested sequences. This limitation stems from their inability to maintain stack-like behavior, the capacity to track and resolve multiple levels of nested dependencies. Through systematic analysis, we demonstrate how this architectural constraint leads to rapid performance decay as the depth of the recursion increases. To address this challenge, we develop a novel looped locate-and-replace pipeline that decomposes recursive problems into manageable subcomponents. The approach employs two specialized models: a locator that identifies solvable subexpressions and a replacer that evaluates these components while preserving the overall structure. We evaluated this method in three carefully designed domains: Boolean algebra, recursive arithmetic, and propositional logic, each with a controllable depth of recursion. We show that our method effectively alleviates the performance decay when tested on out-of-distribution recursion depth.

</details>


### [24] [Learning What to Attend First: Modality-Importance-Guided Reasoning for Reliable Multimodal Emotion Understanding](https://arxiv.org/abs/2512.02699)
*Hyeongseop Rha,Jeong Hun Yeo,Junil Won,Se Jin Park,Yong Man Ro*

Main category: cs.AI

TL;DR: MIGR框架通过模态重要性引导推理，改善多模态大语言模型的情感理解可靠性，减少推理漂移问题


<details>
  <summary>Details</summary>
Motivation: 现有方法存在推理漂移问题：模型逐渐依赖自身生成的文本而非多模态证据，且解释过度受视觉主导的推理路径影响，导致情感理解不可靠

Method: 提出模态重要性机制识别情感主导模态，基于此重组推理序列，使解释从最关键的情感模态开始；采用两阶段框架：模态对齐监督微调和模态感知奖励优化

Result: 在DFEW基准测试中，MIGR显著提升推理可靠性，将正确预测但情感不一致解释的比例从18.10%降至7.37%

Conclusion: 从情感主导模态开始推理能有效改善多模态情感理解的可靠性，MIGR框架为解决推理漂移问题提供了有效方案

Abstract: In this paper, we present Modality-Importance-Guided Reasoning (MIGR), a framework designed to improve the reliability of reasoning-based multimodal emotion understanding in multimodal large language models. Although existing methods have advanced emotion understanding, they often suffer from reasoning drift: models gradually rely on their own generated text instead of multimodal evidence, and their explanations are overly shaped by visually initiated reasoning paths. To address these issues, we introduce Modality Importance (MI), a simple yet effective mechanism for identifying the emotion-dominant modality. Using MI, MIGR reorganizes reasoning sequences so that explanations begin from the modality most critical to the target emotion, preventing early reasoning from being misled by less informative cues. Our two-stage framework-comprising modality-aligned supervised fine-tuning and modality-aware reward optimization-encourages models to generate emotionally grounded, causally relevant, and coherence-preserving explanations. Experimental results on the DFEW benchmark show that MIGR substantially improves reasoning reliability, decreasing instances of correct predictions accompanied by emotionally inconsistent explanations from 18.10% to 7.37%. These results confirm the benefit of initiating reasoning from the emotion-dominant modality.

</details>


### [25] [Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs](https://arxiv.org/abs/2512.02713)
*Theodoros Aivalis,Iraklis A. Klampanos,Antonis Troumpoukis,Joemon M. Jose*

Main category: cs.AI

TL;DR: 提出基于知识图谱的生成模型溯源框架，通过多模态LLM从图像提取结构化三元组，对比生成图像与训练图像的KG来追踪潜在影响，支持版权分析和AI可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型能力增强，透明度、问责制和版权侵权问题日益突出。需要理解特定训练数据如何影响模型输出，以解决版权分析、数据集透明度和可解释AI的需求。

Method: 利用多模态大语言模型从图像中提取结构化三元组，构建与领域特定本体对齐的知识图谱。通过比较生成图像和训练图像的KG来追踪潜在影响，支持版权分析和透明度评估。

Result: 通过局部训练模型的遗忘实验和大规模模型的风格特定实验验证了方法的有效性。框架支持开发促进人类协作、创造力和激发好奇心的AI系统。

Conclusion: 提出的知识图谱框架为生成模型提供了有效的溯源机制，能够追踪训练数据对输出的影响，支持版权分析、数据集透明度和可解释AI的发展。

Abstract: As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.

</details>


### [26] [Menta: A Small Language Model for On-Device Mental Health Prediction](https://arxiv.org/abs/2512.02716)
*Tianyi Zhang,Xiangyuan Xue,Lingyan Ruan,Shiya Fu,Feng Xia,Simon D'Alfonso,Vassilis Kostakos,Hong Jia*

Main category: cs.AI

TL;DR: Menta是一个专门针对社交媒体数据进行多任务心理健康预测的优化小型语言模型，在多个心理健康分类任务上表现优于现有SLM和部分LLM，并能在移动设备上实时部署。


<details>
  <summary>Details</summary>
Motivation: 心理健康问题影响全球数亿人，但早期检测仍然有限。虽然大型语言模型在心理健康应用中有潜力，但其规模和计算需求阻碍了实际部署。小型语言模型提供了轻量级替代方案，但在基于社交媒体的心理健康预测方面尚未得到充分探索。

Method: Menta是首个专门为社交媒体数据多任务心理健康预测优化的SLM，采用LoRA-based框架、跨数据集策略和平衡准确率导向的损失函数，在六个分类任务上联合训练。

Result: 相比9个最先进的SLM基线，Menta在涵盖抑郁、压力和自杀倾向的任务上平均提升15.2%；在抑郁和压力分类任务上比130亿参数LLM准确率更高，同时模型大小约小3.25倍；可在iPhone 15 Pro Max上实时部署，仅需约3GB内存。

Conclusion: Menta展示了可扩展、保护隐私的心理健康监测潜力，为轻量级心理健康预测模型提供了有效解决方案。

Abstract: Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: https://xxue752-nz.github.io/menta-project/

</details>


### [27] [StockMem: An Event-Reflection Memory Framework for Stock Forecasting](https://arxiv.org/abs/2512.02720)
*He Wang,Wenyilin Xiao,Songqiao Han,Hailiang Huang*

Main category: cs.AI

TL;DR: StockMem：基于事件-反思双层记忆框架的股票价格预测方法，通过结构化新闻事件和挖掘增量信息来提升预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 股票价格预测面临市场波动性和实时事件敏感性的挑战。虽然大语言模型为基于文本的预测提供了新途径，但在金融领域的应用受到噪声新闻数据和文本中缺乏明确答案的限制。通用记忆架构难以识别价格变动的关键驱动因素。

Method: 提出StockMem事件-反思双层记忆框架：1）将新闻结构化为事件，从两个维度挖掘：横向整合整合每日事件，纵向跟踪捕捉事件演化以提取反映市场预期差异的增量信息，构建时序事件知识库；2）通过分析事件-价格动态，形成因果经验的反思知识库；3）预测时检索类似历史场景，结合当前事件、增量数据和过去经验进行推理。

Result: 实验表明StockMem优于现有记忆架构，通过追踪影响价格的信息链提供更优且可解释的推理，增强了金融预测中的决策透明度。

Conclusion: StockMem通过事件-反思双层记忆框架有效解决了股票价格预测中的关键挑战，不仅提高了预测性能，还提供了可解释的推理过程，为金融预测决策提供了更高的透明度。

Abstract: Stock price prediction is challenging due to market volatility and its sensitivity to real-time events. While large language models (LLMs) offer new avenues for text-based forecasting, their application in finance is hindered by noisy news data and the lack of explicit answers in text. General-purpose memory architectures struggle to identify the key drivers of price movements. To address this, we propose StockMem, an event-reflection dual-layer memory framework. It structures news into events and mines them along two dimensions: horizontal consolidation integrates daily events, while longitudinal tracking captures event evolution to extract incremental information reflecting market expectation discrepancies. This builds a temporal event knowledge base. By analyzing event-price dynamics, the framework further forms a reflection knowledge base of causal experiences. For prediction, it retrieves analogous historical scenarios and reasons with current events, incremental data, and past experiences. Experiments show StockMem outperforms existing memory architectures and provides superior, explainable reasoning by tracing the information chain affecting prices, enhancing decision transparency in financial forecasting.

</details>


### [28] [AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping](https://arxiv.org/abs/2512.02726)
*Md Abdul Kadir,Sai Suresh Macharla Vasu,Sidharth S. Nair,Daniel Sonntag*

Main category: cs.AI

TL;DR: LLMs作为异常检测器在复式记账中表现优于传统规则方法和机器学习基准，提供自然语言解释，支持AI增强审计


<details>
  <summary>Details</summary>
Motivation: 传统日记账测试（JETs）产生大量误报且难以检测细微异常，需要更有效的审计异常检测方法

Method: 使用LLaMA和Gemma等最先进大语言模型作为异常检测器，在合成和真实匿名账本上进行基准测试，与传统JETs和机器学习基准比较

Result: LLMs持续优于传统规则型JETs和经典ML基准，同时提供增强可解释性的自然语言解释

Conclusion: 大语言模型在复式记账异常检测中表现出色，支持AI增强审计，人类审计师与基础模型协作可增强财务完整性

Abstract: Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.

</details>


### [29] [Self-Improving AI Agents through Self-Play](https://arxiv.org/abs/2512.02731)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 该论文将心理测量电池的模数理论框架扩展到动力系统领域，将智能体形式化为由计算资源参数化的流，提出了生成器-验证器-更新器(GVU)算子，并推导出保证自改进稳定性的方差不等式条件。


<details>
  <summary>Details</summary>
Motivation: 先前研究建立了AAI能力分数作为智能体表示空间上的静态泛函，但缺乏对智能体作为动力系统的形式化描述。本文旨在将心理测量电池的模数理论框架扩展到动力系统领域，为自改进过程提供严格的数学基础。

Method: 将智能体形式化为由计算资源r参数化的流ν_r，受递归生成器-验证器-更新器(GVU)算子控制。证明该算子在参数流形Θ上生成向量场，并将自改进系数κ识别为能力泛函沿该流的李导数。推导出方差不等式这一谱条件，作为自改进稳定性的充分条件。

Result: 证明了自改进系数κ>0的充分条件是生成和验证的组合噪声足够小（在曲率和步长效应范围内）。应用该形式化框架统一了语言自玩(LSP)、自校正和合成数据引导等最新文献，展示了STaR、SPIN、Reflexion、GANs和AlphaZero等架构都是满足方差不等式的GVU算子的具体拓扑实现。

Conclusion: 该研究为智能体自改进过程提供了统一的动力系统理论框架，通过方差不等式为自改进稳定性提供了数学保证，并将多种现有架构统一为GVU算子的具体实现，为理解和设计自改进系统奠定了理论基础。

Abstract: We extend the moduli-theoretic framework of psychometric batteries to the domain of dynamical systems. While previous work established the AAI capability score as a static functional on the space of agent representations, this paper formalizes the agent as a flow $ν_r$ parameterized by computational resource $r$, governed by a recursive Generator-Verifier-Updater (GVU) operator. We prove that this operator generates a vector field on the parameter manifold $Θ$, and we identify the coefficient of self-improvement $κ$ as the Lie derivative of the capability functional along this flow.
  The central contribution of this work is the derivation of the Variance Inequality, a spectral condition that is sufficient (under mild regularity) for the stability of self-improvement. We show that a sufficient condition for $κ> 0$ is that, up to curvature and step-size effects, the combined noise of generation and verification must be small enough.
  We then apply this formalism to unify the recent literature on Language Self-Play (LSP), Self-Correction, and Synthetic Data bootstrapping. We demonstrate that architectures such as STaR, SPIN, Reflexion, GANs and AlphaZero are specific topological realizations of the GVU operator that satisfy the Variance Inequality through filtration, adversarial discrimination, or grounding in formal systems.

</details>


### [30] [A Framework for Causal Concept-based Model Explanations](https://arxiv.org/abs/2512.02735)
*Anna Rodum Bjøru,Jacob Lysnæs-Larsen,Oskar Jørgensen,Inga Strümke,Helge Langseth*

Main category: cs.AI

TL;DR: 提出基于因果概念的事后可解释AI框架，通过概念干预的充分概率生成局部和全局解释，在CelebA数据集上验证了可理解性和忠实性


<details>
  <summary>Details</summary>
Motivation: 为不可解释模型提供既易于理解又忠实于原模型的解释，解决现有可解释AI方法在可理解性和忠实性方面的不足

Method: 基于因果概念的事后解释框架，通过计算概念干预的充分概率来生成局部和全局解释，使用CelebA数据集上的分类器进行概念验证

Result: 展示了基于清晰概念词汇的解释示例，验证了框架的可理解性；强调了重要假设，确保解释生成与解释解释的上下文一致，从而保证忠实性

Conclusion: 提出了一个结合因果概念的事后可解释AI框架，能够为不可解释模型提供既易于理解又忠实于原模型的解释，为可解释AI研究提供了新方向

Abstract: This work presents a conceptual framework for causal concept-based post-hoc Explainable Artificial Intelligence (XAI), based on the requirements that explanations for non-interpretable models should be understandable as well as faithful to the model being explained. Local and global explanations are generated by calculating the probability of sufficiency of concept interventions. Example explanations are presented, generated with a proof-of-concept model made to explain classifiers trained on the CelebA dataset. Understandability is demonstrated through a clear concept-based vocabulary, subject to an implicit causal interpretation. Fidelity is addressed by highlighting important framework assumptions, stressing that the context of explanation interpretation must align with the context of explanation generation.

</details>


### [31] [Enhancing Automated Paper Reproduction via Prompt-Free Collaborative Agents](https://arxiv.org/abs/2512.02812)
*Zijie Lin,Qilin Cai,Liang Shen,Mingjun Xiao*

Main category: cs.AI

TL;DR: 提出了一种无需人工提示的协作智能体框架，用于自动提升论文到代码生成的准确性和完整性，相比基线方法性能提升约15%和13%。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化论文复现框架缺乏对每个生成步骤输出的验证和精炼机制，或者过度依赖人工设计的提示进行自我精炼，这限制了框架的适应性和可扩展性。

Method: 提出了一种无需提示的协作智能体框架，包含两个协作智能体：验证智能体检查每个步骤的输出是否满足对应系统提示的要求，精炼智能体根据识别出的问题修订输出。该方法仅利用原始系统提示实现自动验证和改进，无需人工为每个步骤设计特定的精炼提示。

Result: 在PaperBench Code-Dev和Paper2CodeBench数据集上的实验表明，该方法显著提高了复现代码的准确性和完整性，相比没有该智能体的基线方法分别获得了约15%和13%的性能提升。与Self-Refine的对比实验验证了该无提示方法在不同数据集上的鲁棒性和一致性。

Conclusion: 提出的无需提示的协作智能体框架能够有效提升自动化论文到代码生成的质量，解决了现有方法在验证和精炼方面的局限性，具有更好的适应性和可扩展性。

Abstract: Automated paper reproduction has emerged as a promising approach to accelerate scientific research, employing multi-step workflow frameworks to systematically convert academic papers into executable code. However, existing frameworks often lack mechanisms to verify and refine the outputs at each generation step, or rely heavily on manually designed prompts for self-refinement, which limits their adaptability and scalability. To address these limitations, we propose a prompt-free collaborative agent framework that automatically enhances the quality of paper-to-code generation. Our approach employs two collaborative agents: a verification agent that examines whether the outputs at each step satisfy the requirements specified in the corresponding system prompt, and a refinement agent that revises the outputs based on the identified issues. Unlike previous methods that require human experts to craft specific refinement prompts for each step, our framework achieves automatic verification and improvement by leveraging only the original system prompts. We integrate our collaborative agents into the Paper2Code framework and conduct comprehensive experiments on PaperBench Code-Dev and Paper2CodeBench datasets. Experimental results demonstrate that our approach significantly improves the accuracy and completeness of reproduced code, achieving performance gains of approximately 15\% and 13\%, respectively, compared to the baseline without our agents. Furthermore, comparative experiments against Self-Refine validate the robustness and consistency of our prompt-free approach across different datasets.

</details>


### [32] [The future of AI in critical mineral exploration](https://arxiv.org/abs/2512.02879)
*Jef Caers*

Main category: cs.AI

TL;DR: 提出基于贝叶斯主义和证伪原则的新科学方法，利用AI减少认知偏差和假阳性，降低矿产勘探成本


<details>
  <summary>Details</summary>
Motivation: 尽管投资增加，但过去20年新矿产发现减少，需要解决能源转型中关键矿产勘探的挑战

Method: 基于贝叶斯主义和证伪原则的哲学方法，将数据采集视为证伪人类假设的手段，使用可验证指标和理性决策确定下一步数据采集

Result: 提供实用的勘探协议模板，需要两种AI形式：1)与领域专家协作的无监督学习方法生成竞争性地质假设；2)人机交互AI算法优化地质、地球物理、地球化学和钻探数据采集规划

Conclusion: AI能够实现严谨的矿产勘探科学方法，减少认知偏差和假阳性，降低勘探成本，推动关键矿产发现

Abstract: The energy transition through increased electrification has put the worlds attention on critical mineral exploration Even with increased investments a decrease in new discoveries has taken place over the last two decades Here I propose a solution to this problem where AI is implemented as the enabler of a rigorous scientific method for mineral exploration that aims to reduce cognitive bias and false positives drive down the cost of exploration I propose a new scientific method that is based on a philosophical approach founded on the principles of Bayesianism and falsification In this approach data acquisition is in the first place seen as a means to falsify human generated hypothesis Decision of what data to acquire next is quantified with verifiable metrics and based on rational decision making A practical protocol is provided that can be used as a template in any exploration campaign However in order to make this protocol practical various form of artificial intelligence are needed I will argue that the most important form are one novel unsupervised learning methods that collaborate with domain experts to better understand data and generate multiple competing geological hypotheses and two humanintheloop AI algorithms that can optimally plan various geological geophysical geochemical and drilling data acquisition where uncertainty reduction of geological hypothesis precedes the uncertainty reduction on grade and tonnage

</details>
